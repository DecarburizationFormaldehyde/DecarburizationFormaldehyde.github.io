<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>机器学习作业 | 脱碳甲醛的博客</title><meta name="keywords" content="机器学习"><meta name="author" content="脱碳甲醛"><meta name="copyright" content="脱碳甲醛"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="作业八 神经网络初步 sklearn中人工神经网络（ANN）主要提供的是多层感知机（MLP），其中有回归和分类两种，回归感知机还有能够自动实现交叉验证的版本。 MLPClassifier二分类 流程如下：  导入iris数据，取后两类 标准化 PCA得到x_pca，y 初始化MLP，训练 绘制分类面  代码如下： 123456789101112131415161718192">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习作业">
<meta property="og:url" content="http://example.com/2023/04/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BD%9C%E4%B8%9A/index.html">
<meta property="og:site_name" content="脱碳甲醛的博客">
<meta property="og:description" content="作业八 神经网络初步 sklearn中人工神经网络（ANN）主要提供的是多层感知机（MLP），其中有回归和分类两种，回归感知机还有能够自动实现交叉验证的版本。 MLPClassifier二分类 流程如下：  导入iris数据，取后两类 标准化 PCA得到x_pca，y 初始化MLP，训练 绘制分类面  代码如下： 123456789101112131415161718192">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/ typora/99586772_p0.png">
<meta property="article:published_time" content="2023-04-21T07:14:07.000Z">
<meta property="article:modified_time" content="2023-04-22T14:14:42.617Z">
<meta property="article:author" content="脱碳甲醛">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/ typora/99586772_p0.png"><link rel="shortcut icon" href="/img/%E5%9B%BE%E6%A0%87.png"><link rel="canonical" href="http://example.com/2023/04/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BD%9C%E4%B8%9A/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '机器学习作业',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-04-22 22:14:42'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/mycss.css"><link rel="stylesheet" href="/css/footer.css"><link rel="stylesheet" href="/css/background.css"><link rel="stylesheet" href="/css/web_bg.css"><meta name="generator" content="Hexo 6.2.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/%E5%A4%B4%E5%83%8F.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">8</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/ typora/99586772_p0.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">脱碳甲醛的博客</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">机器学习作业</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-04-21T07:14:07.000Z" title="发表于 2023-04-21 15:14:07">2023-04-21</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-04-22T14:14:42.617Z" title="更新于 2023-04-22 22:14:42">2023-04-22</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="机器学习作业"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="作业八-神经网络初步">作业八 神经网络初步</h1>
<p>sklearn中人工神经网络（ANN）主要提供的是多层感知机（MLP），其中有回归和分类两种，回归感知机还有能够自动实现交叉验证的版本。</p>
<h2 id="mlpclassifier二分类">MLPClassifier二分类</h2>
<p>流程如下：</p>
<ol type="1">
<li>导入iris数据，取后两类</li>
<li>标准化</li>
<li>PCA得到x_pca，y</li>
<li>初始化MLP，训练</li>
<li>绘制分类面</li>
</ol>
<p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> l1_min_c</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_decision_surface</span>(<span class="params">model, X, y, grid_size=<span class="number">0.02</span></span>):</span><br><span class="line">    <span class="comment"># 获取数据范围</span></span><br><span class="line">    x_min, x_max = X[:, <span class="number">0</span>].<span class="built_in">min</span>() - <span class="number">0.5</span>, X[:, <span class="number">0</span>].<span class="built_in">max</span>() + <span class="number">0.5</span></span><br><span class="line">    y_min, y_max = X[:, <span class="number">1</span>].<span class="built_in">min</span>() - <span class="number">0.5</span>, X[:, <span class="number">1</span>].<span class="built_in">max</span>() + <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 生成网格点</span></span><br><span class="line">    xx, yy = np.meshgrid(np.arange(x_min, x_max, grid_size), np.arange(y_min, y_max, grid_size))</span><br><span class="line">    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])</span><br><span class="line">    Z = Z.reshape(xx.shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 绘制分类面和训练数据</span></span><br><span class="line">    cmap_light = ListedColormap([<span class="string">&#x27;#FFAAAA&#x27;</span>, <span class="string">&#x27;#AAFFAA&#x27;</span>, <span class="string">&#x27;#AAAAFF&#x27;</span>])</span><br><span class="line">    cmap_bold = ListedColormap([<span class="string">&#x27;#FF0000&#x27;</span>, <span class="string">&#x27;#00FF00&#x27;</span>, <span class="string">&#x27;#0000FF&#x27;</span>])</span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)</span><br><span class="line">    plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y, cmap=cmap_bold, edgecolor=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line">    plt.xlim(xx.<span class="built_in">min</span>(), xx.<span class="built_in">max</span>())</span><br><span class="line">    plt.ylim(yy.<span class="built_in">min</span>(), yy.<span class="built_in">max</span>())</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Sepal length&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;Sepal width&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Iris classification using MLP&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">X = iris.data</span><br><span class="line">y = iris.target</span><br><span class="line"></span><br><span class="line">X = X[y != <span class="number">0</span>]</span><br><span class="line">y = y[y != <span class="number">0</span>]</span><br><span class="line"><span class="comment"># 标准化</span></span><br><span class="line">standard=StandardScaler()</span><br><span class="line">X=standard.fit_transform(X)</span><br><span class="line"><span class="comment"># PCA</span></span><br><span class="line">pca=PCA(n_components=<span class="number">2</span>)</span><br><span class="line">x_pca=pca.fit_transform(X)</span><br><span class="line"><span class="comment"># 初始化mlp</span></span><br><span class="line">mlp=MLPClassifier(solver=<span class="string">&#x27;lbfgs&#x27;</span>,hidden_layer_sizes=(<span class="number">5</span>,<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">mlp.fit(x_pca,y)</span><br><span class="line"></span><br><span class="line">plot_decision_surface(mlp, x_pca, y)</span><br></pre></td></tr></table></figure>
<p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230422220300024.png" alt="image-20230422220300024" style="zoom:50%;" /></p>
<h2 id="mlpclassifier多分类">MLPClassifier多分类</h2>
<p>流程如下：</p>
<ol type="1">
<li>导入iris数据</li>
<li>标准化</li>
<li>PCA得到x_pca，y</li>
<li>初始化MLP，训练</li>
<li>绘制分类面</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> plot_confusion_matrix</span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_decision_surface</span>(<span class="params">model, X, y, grid_size=<span class="number">0.02</span></span>):</span><br><span class="line">    <span class="comment"># 获取数据范围</span></span><br><span class="line">    x_min, x_max = X[:, <span class="number">0</span>].<span class="built_in">min</span>() - <span class="number">0.5</span>, X[:, <span class="number">0</span>].<span class="built_in">max</span>() + <span class="number">0.5</span></span><br><span class="line">    y_min, y_max = X[:, <span class="number">1</span>].<span class="built_in">min</span>() - <span class="number">0.5</span>, X[:, <span class="number">1</span>].<span class="built_in">max</span>() + <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 生成网格点</span></span><br><span class="line">    xx, yy = np.meshgrid(np.arange(x_min, x_max, grid_size), np.arange(y_min, y_max, grid_size))</span><br><span class="line">    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])</span><br><span class="line">    Z = Z.reshape(xx.shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 绘制分类面和训练数据</span></span><br><span class="line">    cmap_light = ListedColormap([<span class="string">&#x27;#FFAAAA&#x27;</span>, <span class="string">&#x27;#AAFFAA&#x27;</span>, <span class="string">&#x27;#AAAAFF&#x27;</span>])</span><br><span class="line">    cmap_bold = ListedColormap([<span class="string">&#x27;#FF0000&#x27;</span>, <span class="string">&#x27;#00FF00&#x27;</span>, <span class="string">&#x27;#0000FF&#x27;</span>])</span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)</span><br><span class="line">    plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y, cmap=cmap_bold, edgecolor=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line">    plt.xlim(xx.<span class="built_in">min</span>(), xx.<span class="built_in">max</span>())</span><br><span class="line">    plt.ylim(yy.<span class="built_in">min</span>(), yy.<span class="built_in">max</span>())</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Sepal length&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;Sepal width&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Iris classification using MLP&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line">iris = load_iris()</span><br><span class="line">X = iris.data[:, :<span class="number">2</span>]  <span class="comment"># 只使用前两个特征</span></span><br><span class="line">y = iris.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分数据集</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建多层感知器模型</span></span><br><span class="line">mlp = MLPClassifier(hidden_layer_sizes=(<span class="number">10</span>,), max_iter=<span class="number">1000</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">mlp.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制分类面</span></span><br><span class="line">plot_decision_surface(mlp, X_train, y_train)</span><br></pre></td></tr></table></figure>
<p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230422220443459.png" alt="image-20230422220443459" style="zoom:50%;" /></p>
<h2 id="mlpregressor">MLPRegressor</h2>
<p>程序流程如下：</p>
<ol type="1">
<li>创建数据X，y</li>
<li>为y添加随机噪声</li>
<li>初始化MLP</li>
<li>训练MLP</li>
<li>绘制预测效果图</li>
</ol>
<p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPRegressor</span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line"><span class="comment"># 创建数据</span></span><br><span class="line">x = np.linspace(-<span class="number">5</span>, <span class="number">5</span>, <span class="number">100</span>)</span><br><span class="line">y = np.sin(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加随机噪声</span></span><br><span class="line">np.random.seed(<span class="number">42</span>)</span><br><span class="line">y_noisy = y + <span class="number">0.2</span> * np.random.normal(size=x.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建多层感知器模型</span></span><br><span class="line">mlp = MLPRegressor(hidden_layer_sizes=(<span class="number">50</span>,), max_iter=<span class="number">1000</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">mlp.fit(x.reshape(-<span class="number">1</span>, <span class="number">1</span>), y_noisy)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测并绘制结果</span></span><br><span class="line">x_test = np.linspace(-<span class="number">5.5</span>, <span class="number">5.5</span>, <span class="number">100</span>)</span><br><span class="line">y_pred = mlp.predict(x_test.reshape(-<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">plt.plot(x_test, y_pred, label=<span class="string">&#x27;MLP Regressor&#x27;</span>,color=<span class="string">&#x27;#FFA628&#x27;</span>)</span><br><span class="line">plt.plot(x, y, label=<span class="string">&#x27;True function&#x27;</span>,color=<span class="string">&#x27;g&#x27;</span>)</span><br><span class="line">plt.scatter(x, y_noisy, edgecolor=<span class="string">&#x27;b&#x27;</span>, s=<span class="number">20</span>, label=<span class="string">&#x27;Noisy samples&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.title(<span class="string">&#x27;MLP Regressor&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230422220624823.png" alt="image-20230422220624823" style="zoom:50%;" /></p>
<h1 id="作业七-逻辑回归分类">作业七 逻辑回归分类</h1>
<p>由于都是从sklearn中调用，并不涉及什么复杂算法，因此下面采用列表的方式描述程序作用</p>
<h2 id="二分类逻辑回归">二分类逻辑回归</h2>
<p>首先说明下面程序的目的：</p>
<table>
<thead>
<tr class="header">
<th>1.观察不同惩罚项系数对应参数变化</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>2.观察不同惩罚项系数对应错误率</strong></td>
</tr>
<tr class="even">
<td><strong>3.可视化二分类结果</strong></td>
</tr>
</tbody>
</table>
<p>流程如下：</p>
<ol type="1">
<li>导入iris数据，取后两类</li>
<li>标准化</li>
<li>PCA得到x_pca，y</li>
<li>初始化逻辑回归</li>
<li>调整参数c，分别训练逻辑回归得到权重参数和错误率</li>
<li>绘制错误率和权重参数曲线</li>
<li>绘制分类面</li>
</ol>
<p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> l1_min_c</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">X = iris.data</span><br><span class="line">y = iris.target</span><br><span class="line"><span class="comment"># 选出前两类</span></span><br><span class="line">X = X[y != <span class="number">0</span>]</span><br><span class="line">y = y[y != <span class="number">0</span>]</span><br><span class="line"><span class="comment"># 画出图像</span></span><br><span class="line">plt.figure()</span><br><span class="line">plt.scatter(X[y == <span class="number">2</span>, <span class="number">0</span>], X[y == <span class="number">2</span>, <span class="number">1</span>], color=<span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;0&#x27;</span>)</span><br><span class="line">plt.scatter(X[y == <span class="number">1</span>, <span class="number">0</span>], X[y == <span class="number">1</span>, <span class="number">1</span>], color=<span class="string">&#x27;g&#x27;</span>, label=<span class="string">&#x27;1&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># 训练</span></span><br><span class="line">cs = l1_min_c(X, y, loss=<span class="string">&#x27;log&#x27;</span>) * np.logspace(<span class="number">0</span>, <span class="number">7</span>, <span class="number">16</span>)</span><br><span class="line"><span class="comment"># 初始化逻辑回归</span></span><br><span class="line">clf = LogisticRegression(</span><br><span class="line">    penalty=<span class="string">&#x27;l1&#x27;</span>,</span><br><span class="line">    solver=<span class="string">&#x27;liblinear&#x27;</span>,</span><br><span class="line">    tol=<span class="number">1e-6</span>,</span><br><span class="line">    max_iter=<span class="built_in">int</span>(<span class="number">1e6</span>),</span><br><span class="line">    warm_start=<span class="literal">True</span>,</span><br><span class="line">    intercept_scaling=<span class="number">1000.0</span>,</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 错误率</span></span><br><span class="line">errors = []</span><br><span class="line"><span class="comment"># 各个特征对参数</span></span><br><span class="line">coefs_ = []</span><br><span class="line"><span class="comment"># 拟合观察参数</span></span><br><span class="line"><span class="keyword">for</span> c <span class="keyword">in</span> cs:</span><br><span class="line">    clf.set_params(C=c)</span><br><span class="line">    clf.fit(X, y)</span><br><span class="line">    y_pre = clf.predict(X)</span><br><span class="line">    error = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(y)):</span><br><span class="line">        <span class="keyword">if</span> y_pre[i] != y[i]:</span><br><span class="line">            error = error + <span class="number">1</span></span><br><span class="line">    errors.append(error)</span><br><span class="line">    coefs_.append(clf.coef_.ravel().copy())</span><br><span class="line">errors = np.array(errors) / <span class="built_in">len</span>(y)</span><br><span class="line">coefs_ = np.array(coefs_)</span><br><span class="line"><span class="comment"># 绘制参数变化</span></span><br><span class="line">plt.plot(np.log10(cs), coefs_, marker=<span class="string">&quot;o&quot;</span>)</span><br><span class="line">ymin, ymax = plt.ylim()</span><br><span class="line">plt.xlabel(<span class="string">&quot;log(C)&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Coefficients&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Logistic Regression Path&quot;</span>)</span><br><span class="line">plt.axis(<span class="string">&quot;tight&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># 绘制错误率</span></span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(np.log10(cs), errors, marker=<span class="string">&#x27;^&#x27;</span>, color=<span class="string">&#x27;orange&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;error rate&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;log(C)&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># 最优拟合</span></span><br><span class="line">clf.set_params(C=<span class="number">1</span>)</span><br><span class="line">clf.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># PCA可视化</span></span><br><span class="line">pca = PCA(n_components=<span class="number">2</span>)</span><br><span class="line">X1 = pca.fit_transform(X)</span><br><span class="line">clf.set_params(C=<span class="number">1</span>)</span><br><span class="line">clf.fit(X1, y)</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.scatter(X1[y == <span class="number">2</span>, <span class="number">0</span>], X1[y == <span class="number">2</span>, <span class="number">1</span>], color=<span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;2&#x27;</span>)</span><br><span class="line">plt.scatter(X1[y == <span class="number">1</span>, <span class="number">0</span>], X1[y == <span class="number">1</span>, <span class="number">1</span>], color=<span class="string">&#x27;g&#x27;</span>, label=<span class="string">&#x27;1&#x27;</span>)</span><br><span class="line">plt.plot([<span class="built_in">min</span>(X1[:, <span class="number">0</span>]), <span class="built_in">max</span>(X1[:, <span class="number">0</span>])], [-(<span class="built_in">min</span>(X1[:, <span class="number">0</span>]) * clf.coef_[<span class="number">0</span>, <span class="number">0</span>] + clf.intercept_[<span class="number">0</span>]) / clf.coef_[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">                                          -(<span class="built_in">max</span>(X1[:, <span class="number">0</span>]) * clf.coef_[<span class="number">0</span>, <span class="number">0</span>] + clf.intercept_[<span class="number">0</span>]) / clf.coef_[<span class="number">0</span>, <span class="number">1</span>]],</span><br><span class="line">         label=<span class="string">&#x27;classier&#x27;</span>, linewidth=<span class="number">3.0</span>, color=<span class="string">&#x27;black&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.xlabel(<span class="string">&#x27;component 1&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;component 2&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>结果如下：</p>
<p>不同惩罚项对应的参数变化，可以看出当惩罚项小于1时，对于模型的稀疏化效果较好。</p>
<p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230422214826267.png" alt="image-20230422214826267" style="zoom:50%;" /></p>
<p>不同惩罚项系数对应的分类错误率，选择为10时效果较好；</p>
<p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230422214946938.png" alt="image-20230422214946938" style="zoom:50%;" /></p>
<p>分类结果效果如图：</p>
<p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230422215101050.png" alt="image-20230422215101050" style="zoom:50%;" /></p>
<h2 id="多分类逻辑回归">多分类逻辑回归</h2>
<p>首先说明下面程序的目的：</p>
<table>
<thead>
<tr class="header">
<th>1.绘制多分类的分类面</th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<p>流程如下：</p>
<ol type="1">
<li>导入iris数据</li>
<li>标准化</li>
<li>PCA得到x_pca，y</li>
<li>初始化逻辑回归，训练逻辑回归</li>
<li>绘制分类面</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> l1_min_c</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">X = iris.data</span><br><span class="line">y = iris.target</span><br><span class="line"><span class="comment"># 标准化</span></span><br><span class="line">standard=StandardScaler()</span><br><span class="line">X=standard.fit_transform(X)</span><br><span class="line"><span class="comment"># PCA</span></span><br><span class="line">pca=PCA(n_components=<span class="number">2</span>)</span><br><span class="line">x_pca=pca.fit_transform(X)</span><br><span class="line"><span class="comment"># 初始化逻辑回归</span></span><br><span class="line">clf = LogisticRegression(</span><br><span class="line">    solver=<span class="string">&#x27;liblinear&#x27;</span>,</span><br><span class="line">    max_iter=<span class="built_in">int</span>(<span class="number">1e6</span>),</span><br><span class="line">    warm_start=<span class="literal">True</span>,</span><br><span class="line">    intercept_scaling=<span class="number">1000.0</span></span><br><span class="line">)</span><br><span class="line">clf.fit(x_pca,y)</span><br><span class="line">coef,intercept=np.array(clf.coef_),np.array(clf.intercept_)</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.scatter(x_pca[y == <span class="number">2</span>, <span class="number">0</span>], x_pca[y == <span class="number">2</span>, <span class="number">1</span>], color=<span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;2&#x27;</span>)</span><br><span class="line">plt.scatter(x_pca[y == <span class="number">1</span>, <span class="number">0</span>], x_pca[y == <span class="number">1</span>, <span class="number">1</span>], color=<span class="string">&#x27;g&#x27;</span>, label=<span class="string">&#x27;1&#x27;</span>)</span><br><span class="line">plt.scatter(x_pca[y == <span class="number">0</span>, <span class="number">0</span>], x_pca[y == <span class="number">0</span>, <span class="number">1</span>], color=<span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;0&#x27;</span>)</span><br><span class="line">plt.plot([<span class="built_in">min</span>(x_pca[:, <span class="number">0</span>]), <span class="built_in">max</span>(x_pca[:, <span class="number">0</span>])], [-(<span class="built_in">min</span>(x_pca[:, <span class="number">0</span>]) * coef[<span class="number">0</span>, <span class="number">0</span>] + intercept[<span class="number">0</span>]) / coef[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">                                          -(<span class="built_in">max</span>(x_pca[:, <span class="number">0</span>]) * coef[<span class="number">0</span>, <span class="number">0</span>] + intercept[<span class="number">0</span>]) / coef[<span class="number">0</span>, <span class="number">1</span>]],</span><br><span class="line">         label=<span class="string">&#x27;classier&#x27;</span>, linewidth=<span class="number">3.0</span>, color=<span class="string">&#x27;black&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.plot([<span class="built_in">min</span>(x_pca[:, <span class="number">0</span>]), <span class="built_in">max</span>(x_pca[:, <span class="number">0</span>])], [-(<span class="built_in">min</span>(x_pca[:, <span class="number">0</span>]) * coef[<span class="number">1</span>, <span class="number">0</span>] + intercept[<span class="number">1</span>]) / coef[<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                                          -(<span class="built_in">max</span>(x_pca[:, <span class="number">0</span>]) * coef[<span class="number">1</span>, <span class="number">0</span>] + intercept[<span class="number">1</span>]) / coef[<span class="number">1</span>, <span class="number">1</span>]],</span><br><span class="line">         label=<span class="string">&#x27;classier&#x27;</span>, linewidth=<span class="number">3.0</span>, color=<span class="string">&#x27;black&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">plt.plot([<span class="built_in">min</span>(x_pca[:, <span class="number">0</span>]), <span class="built_in">max</span>(x_pca[:, <span class="number">0</span>])], [-(<span class="built_in">min</span>(x_pca[:, <span class="number">0</span>]) * coef[<span class="number">2</span>, <span class="number">0</span>] + intercept[<span class="number">2</span>]) / coef[<span class="number">2</span>, <span class="number">1</span>],</span><br><span class="line">                                          -(<span class="built_in">max</span>(x_pca[:, <span class="number">0</span>]) * coef[<span class="number">2</span>, <span class="number">0</span>] + intercept[<span class="number">2</span>]) / coef[<span class="number">2</span>, <span class="number">1</span>]],</span><br><span class="line">         label=<span class="string">&#x27;classier&#x27;</span>, linewidth=<span class="number">3.0</span>, color=<span class="string">&#x27;black&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">plt.ylim(-<span class="number">5</span>,<span class="number">5</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.xlabel(<span class="string">&#x27;component 1&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;component 2&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230422215323041.png" alt="image-20230422215323041" style="zoom:50%;" /></p>
<h1 id="作业六">作业六</h1>
<h2 id="bayesian-linear-regression">Bayesian Linear Regression</h2>
<p>所有算法都放在同一个Python文件下，函数算法伪代码如下：</p>
<table>
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="header">
<th>Algorithm1: fit</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>input: X,t,degree, <span
class="math inline">\(\alpha,\beta,\phi\)</span></td>
</tr>
<tr class="even">
<td>output: <span class="math inline">\(m_n,S_n\)</span></td>
</tr>
<tr class="odd">
<td>1. <strong><span class="math inline">\(if\)</span></strong>
len(X.shape) == 1: # 预先判断形状<br /> 2. X=X.reshape(-1,1)<br />3.
<strong><span class="math inline">\(if\)</span></strong> len(t.shape)
==1:<br />4. t=t.reshape(-1,1)<br />5. <span
class="math inline">\(S_n^{-1}=\alpha I+\beta\phi(X)^T\phi(X)\)</span> #
计算协方差的逆<br />6. <span
class="math inline">\(S_n=\)</span>np.linalg.inv(<span
class="math inline">\(S_n^{-1}\)</span>)<br />7. <span
class="math inline">\(m_n=\beta S_n \phi(X)^Tt\)</span> # 计算均值
<br />8.<br />9. return <span
class="math inline">\(m_n,S_n\)</span></td>
</tr>
</tbody>
</table>
<table>
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="header">
<th>Algorithm2: predict</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>input: X, <span class="math inline">\(\phi,m_n,S_n\)</span></td>
</tr>
<tr class="even">
<td>output: <span class="math inline">\(mean,\sigma^2\)</span></td>
</tr>
<tr class="odd">
<td>1. <span class="math inline">\(\sigma^2\)</span> = <span
class="math inline">\(\frac{1}{\beta}+\phi(X)S_n\phi(X)^T\)</span><br />2.
mean=<span class="math inline">\(\phi(x)m_n\)</span><br />3.<br/>4.
return mean, <span class="math inline">\(\sigma ^2\)</span></td>
</tr>
</tbody>
</table>
<p>代码实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> multivariate_normal</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> Polyfeature <span class="keyword">import</span> Polyfeature</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BLR</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,n_features,alpha=<span class="number">0</span>,beta=<span class="number">1</span>,phi=<span class="string">&#x27;linear&#x27;</span></span>):</span><br><span class="line">        self.n_features=n_features</span><br><span class="line">        self.alpha=alpha</span><br><span class="line">        self.beta=beta</span><br><span class="line">        self.phi=phi</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    alpha 表示w的先验的精度</span></span><br><span class="line"><span class="string">    beta  表示数据的精度</span></span><br><span class="line"><span class="string">    phi   表示基函数，可选参数为：linear、gaussain、polynomial、sigmoid</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">gaussian</span>(<span class="params">self,x, mu, sigma</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span> / (sigma * np.sqrt(<span class="number">2</span> * np.pi)) * np.exp(-(x - mu) ** <span class="number">2</span> / (<span class="number">2</span> * sigma ** <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self,X,t</span>):</span><br><span class="line">        <span class="comment"># 检查向量是否是二维数组并转化</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(X.shape) == <span class="number">1</span>:</span><br><span class="line">            X=X.reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(t.shape) == <span class="number">1</span>:</span><br><span class="line">            t=t.reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 是否要0均值？</span></span><br><span class="line">        <span class="keyword">global</span> phi_x</span><br><span class="line">        <span class="keyword">global</span> x</span><br><span class="line">        <span class="keyword">if</span> self.phi==<span class="string">&#x27;linear&#x27;</span>:</span><br><span class="line">            phi_x=X</span><br><span class="line">            x=np.dot(phi_x,phi_x.T)</span><br><span class="line">        <span class="keyword">if</span> self.phi==<span class="string">&#x27;polynomial&#x27;</span>:</span><br><span class="line">            polyf=Polyfeature(self.n_features)</span><br><span class="line">            phi_x=polyf.fit_transform(X)</span><br><span class="line">            x=np.dot(phi_x.T,phi_x)</span><br><span class="line">        <span class="comment"># Sn的逆</span></span><br><span class="line">        Sn_inverse=self.alpha*np.eye(x.shape[<span class="number">0</span>])+self.beta*x</span><br><span class="line">        <span class="comment"># 计算期望</span></span><br><span class="line">        mn=self.beta*np.dot(np.dot(np.linalg.inv(Sn_inverse),phi_x.T),t)</span><br><span class="line"></span><br><span class="line">        self.phi_x=phi_x</span><br><span class="line">        self.Sn_inverse=Sn_inverse</span><br><span class="line">        self.mn=mn</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self,X</span>):</span><br><span class="line">        <span class="keyword">if</span> self.phi==<span class="string">&#x27;linear&#x27;</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(X.shape)==<span class="number">1</span>:</span><br><span class="line">                X = X.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">                sigma2=<span class="number">1</span>/self.beta+np.dot(np.dot(self.phi_x.T,np.linalg.inv(self.Sn_inverse)),self.phi_x)</span><br><span class="line">                t_pre=self.gaussian(X,self.mn,np.sqrt(sigma2))</span><br><span class="line">                <span class="keyword">return</span> t_pre</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.phi==<span class="string">&#x27;polynomial&#x27;</span>:</span><br><span class="line">            polyf=Polyfeature(self.n_features)</span><br><span class="line">            X=polyf.fit_transform(X)</span><br><span class="line"></span><br><span class="line">        sigma2 = np.diag(<span class="number">1</span> / self.beta + X @ np.linalg.inv(self.Sn_inverse) @ X.T).reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">        mean=np.dot(X,self.mn)</span><br><span class="line"></span><br><span class="line">        upper = mean + np.sqrt(sigma2)</span><br><span class="line">        lower = mean - np.sqrt(sigma2)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> mean,sigma2,upper,lower</span><br></pre></td></tr></table></figure>
<p>回归效果：</p>
<p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/90e39f72c8da404c0738ddf8072aae4.png" alt="90e39f72c8da404c0738ddf8072aae4" style="zoom: 67%;" /></p>
<h2 id="不同样本数量影响拟合效果">不同样本数量影响拟合效果</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">   x_1=np.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">100</span>)</span><br><span class="line">    X_data=[np.array([<span class="number">0.5</span>]),</span><br><span class="line">                     np.array([<span class="number">0.3</span>,<span class="number">0.6</span>]),</span><br><span class="line">                     np.array([<span class="number">0.25</span>,<span class="number">0.5</span>,<span class="number">0.75</span>,<span class="number">0.8</span>]),</span><br><span class="line">                     np.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">60</span>)]</span><br><span class="line">j=<span class="number">1</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">6</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> X_data:</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">2</span>,j)</span><br><span class="line">    t=np.sin(<span class="number">2</span>*np.pi*i)+np.random.normal(loc=<span class="number">0</span>,scale=<span class="number">0.2</span>,size=i.shape)</span><br><span class="line">    <span class="keyword">if</span> j&lt;<span class="number">2</span>:</span><br><span class="line">        blr = BLR(<span class="number">5</span>, phi=<span class="string">&#x27;polynomial&#x27;</span>,alpha=<span class="number">0.2</span>)</span><br><span class="line">        plt.title(<span class="string">&#x27;alpha=0.2&#x27;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        blr = BLR(<span class="number">4</span>, phi=<span class="string">&#x27;polynomial&#x27;</span>)</span><br><span class="line">        plt.title(<span class="string">&#x27;without alpha&#x27;</span>)</span><br><span class="line">    j=j+<span class="number">1</span></span><br><span class="line">    <span class="comment"># 绘制sin原图像</span></span><br><span class="line">    plt.plot(x_1,np.sin(<span class="number">2</span>*np.pi*x_1),label=<span class="string">&#x27;sin(x)&#x27;</span>)</span><br><span class="line">    <span class="comment"># 绘制数据散点</span></span><br><span class="line">    plt.scatter(i, t, color=<span class="string">&#x27;g&#x27;</span>,label=<span class="string">&#x27;samples&#x27;</span>)</span><br><span class="line">    blr.fit(i, t)</span><br><span class="line">    plt.plot(x_1, blr.predict(x_1)[<span class="number">0</span>], color=<span class="string">&#x27;black&#x27;</span>,label=<span class="string">&#x27;prediction&#x27;</span>)</span><br><span class="line">    <span class="comment"># 绘制阴影部分</span></span><br><span class="line">    plt.fill_between(x_1.squeeze(), blr.predict(x_1)[<span class="number">3</span>].squeeze(), blr.predict(x_1)[<span class="number">2</span>].squeeze(), alpha=<span class="number">0.4</span>,label=<span class="string">&#x27;varience&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.xlabel(<span class="string">&#x27;X&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;t&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img
src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230408203151173.png"
alt="image-20230408203151173" />
<figcaption aria-hidden="true">image-20230408203151173</figcaption>
</figure>
<p>同时，我调整了样本数量较小时的<span
class="math inline">\(\alpha\)</span>值，下图是无正则化的情况（样本数量为1时，必须有正则化否则出现奇异矩阵）：</p>
<figure>
<img
src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230408203316307.png"
alt="image-20230408203316307" />
<figcaption aria-hidden="true">image-20230408203316307</figcaption>
</figure>
<h2 id="交叉验证调优">交叉验证调优</h2>
<p>因为要做调优，所以固定生成数据，设定种子为0。</p>
<p>在固定<span
class="math inline">\(\alpha=0,beta=10\)</span>时，首先确定degree：</p>
<p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230408213637573.png" alt="image-20230408213637573" style="zoom:50%;" /></p>
<p>best degree is 9 min RMSE in test sets: 0.2014522467351943</p>
<p>接下来在<span
class="math inline">\(degrer=9\)</span>的情况下，寻找<span
class="math inline">\(\alpha\)</span>的参数最优情况：</p>
<p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230408221238294.png" alt="image-20230408221238294" style="zoom:50%;" /></p>
<p>parameter_best is 2.848035868435799e-05</p>
<p>最后，按以上两种情况搜寻参数<span
class="math inline">\(\beta\)</span>：</p>
<p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230408221701245.png" alt="image-20230408221701245" style="zoom: 50%;" /></p>
<p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230408221719701.png" alt="image-20230408221719701" style="zoom:50%;" /></p>
<p>beta_best is 14.84968262254465</p>
<p>最终参数选择结果为：</p>
<table>
<thead>
<tr class="header">
<th><span class="math inline">\(\alpha\)</span></th>
<th>2.848035868435799e-05</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(degree\)</span></td>
<td><strong>9</strong></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\beta\)</span></td>
<td><strong>14.84968262254465</strong></td>
</tr>
</tbody>
</table>
<p>最终拟合结果：</p>
<p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230408222416810.png" alt="image-20230408222416810" style="zoom: 50%;" /></p>
<p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230408222947483.png" alt="image-20230408222947483" style="zoom: 50%;" /></p>
<h2 id="模拟拟合过程似然先验">模拟拟合过程（似然、先验）</h2>
<p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230408233948782.png" alt="image-20230408233948782" style="zoom:67%;" /></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> multivariate_normal, norm</span><br><span class="line"><span class="keyword">from</span> numpy.random <span class="keyword">import</span> seed, uniform, randn</span><br><span class="line"><span class="keyword">from</span> numpy.linalg <span class="keyword">import</span> inv</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">x, a</span>):</span><br><span class="line">    <span class="keyword">return</span> a[<span class="number">0</span>] + a[<span class="number">1</span>] * x</span><br><span class="line"></span><br><span class="line">a = np.array([-<span class="number">0.3</span>, <span class="number">0.5</span>])</span><br><span class="line">N = <span class="number">30</span></span><br><span class="line">sigma = <span class="number">0.2</span></span><br><span class="line">X = uniform(-<span class="number">1</span>, <span class="number">1</span>, (N, <span class="number">1</span>))</span><br><span class="line">T = f(X, a) + randn(N, <span class="number">1</span>) * sigma</span><br><span class="line"></span><br><span class="line">beta = (<span class="number">1</span> / sigma) ** <span class="number">2</span> <span class="comment"># precision</span></span><br><span class="line">alpha = <span class="number">2.0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">posterior_w</span>(<span class="params">phi, t, S0, m0</span>):</span><br><span class="line">    SN = inv(inv(S0) + beta * Phi.T @ Phi)</span><br><span class="line">    mN = SN @ (inv(S0) @ m0 + beta * Phi.T @ t)</span><br><span class="line">    <span class="keyword">return</span> SN, mN</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sample_vals</span>(<span class="params">X, T, ix</span>):</span><br><span class="line">    x_in = X[ix]</span><br><span class="line">    Phi = np.c_[np.ones_like(x_in), x_in]</span><br><span class="line">    t = T[[ix]]</span><br><span class="line">    <span class="keyword">return</span> Phi, t</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_prior</span>(<span class="params">m, S, liminf=-<span class="number">1</span>, limsup=<span class="number">1</span>, step=<span class="number">0.05</span>, ax=plt, **kwargs</span>):</span><br><span class="line">    grid = np.mgrid[liminf:limsup + step:step, liminf:limsup + step:step]</span><br><span class="line">    nx = grid.shape[-<span class="number">1</span>]</span><br><span class="line">    z = multivariate_normal.pdf(grid.T.reshape(-<span class="number">1</span>, <span class="number">2</span>), mean=m.ravel(), cov=S).reshape(nx, nx).T</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ax.contourf(*grid, z, cmap=<span class="string">&#x27;jet&#x27;</span>,interpolation=<span class="string">&#x27;nearest&#x27;</span>,**kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_sample_w</span>(<span class="params">mean, cov, size=<span class="number">10</span>, ax=plt</span>):</span><br><span class="line">    w = np.random.multivariate_normal(mean=mean.ravel(), cov=cov, size=size)</span><br><span class="line">    x = np.linspace(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> wi <span class="keyword">in</span> w:</span><br><span class="line">        ax.plot(x, f(x, wi), c=<span class="string">&quot;tab:blue&quot;</span>, alpha=<span class="number">0.4</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_likelihood_obs</span>(<span class="params">X, T, ix, ax=plt</span>):</span><br><span class="line">    W = np.mgrid[-<span class="number">1</span>:<span class="number">1</span>:<span class="number">0.1</span>, -<span class="number">1</span>:<span class="number">1</span>:<span class="number">0.1</span>]</span><br><span class="line">    x, t = sample_vals(X, T, ix)</span><br><span class="line">    mean = W.T.reshape(-<span class="number">1</span>, <span class="number">2</span>) @ x.T</span><br><span class="line"></span><br><span class="line">    likelihood = norm.pdf(t, loc=mean, scale=np.sqrt(<span class="number">1</span> / beta)).reshape(<span class="number">20</span>, <span class="number">20</span>).T</span><br><span class="line">    ax.contourf(*W, likelihood,cmap=<span class="string">&#x27;jet&#x27;</span>,interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">    ax.scatter(-<span class="number">0.3</span>, <span class="number">0.5</span>, c=<span class="string">&quot;white&quot;</span>, marker=<span class="string">&quot;+&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">SN = np.eye(<span class="number">2</span>) / alpha</span><br><span class="line">mN = np.zeros((<span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">seed(<span class="number">1643</span>)</span><br><span class="line">N = <span class="number">20</span></span><br><span class="line">nobs = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">20</span>]</span><br><span class="line">ix_fig = <span class="number">1</span></span><br><span class="line">fig, ax = plt.subplots(<span class="built_in">len</span>(nobs) + <span class="number">1</span>, <span class="number">3</span>, figsize=(<span class="number">10</span>, <span class="number">12</span>))</span><br><span class="line">plot_prior(mN, SN, ax=ax[<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">1</span>].scatter(-<span class="number">0.3</span>, <span class="number">0.5</span>, c=<span class="string">&quot;white&quot;</span>, marker=<span class="string">&quot;+&quot;</span>)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">0</span>].axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">plot_sample_w(mN, SN, ax=ax[<span class="number">0</span>, <span class="number">2</span>])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, N + <span class="number">1</span>):</span><br><span class="line">    Phi, t = sample_vals(X, T, i)</span><br><span class="line">    SN, mN = posterior_w(Phi, t, SN, mN)</span><br><span class="line">    <span class="keyword">if</span> i + <span class="number">1</span> <span class="keyword">in</span> nobs:</span><br><span class="line">        plot_likelihood_obs(X, T, i, ax=ax[ix_fig, <span class="number">0</span>])</span><br><span class="line">        plot_prior(mN, SN, ax=ax[ix_fig, <span class="number">1</span>])</span><br><span class="line">        ax[ix_fig, <span class="number">1</span>].scatter(-<span class="number">0.3</span>, <span class="number">0.5</span>, c=<span class="string">&quot;white&quot;</span>, marker=<span class="string">&quot;+&quot;</span>)</span><br><span class="line">        ax[ix_fig, <span class="number">2</span>].scatter(X[:i + <span class="number">1</span>], T[:i + <span class="number">1</span>], c=<span class="string">&quot;crimson&quot;</span>)</span><br><span class="line">        ax[ix_fig, <span class="number">2</span>].set_xlim(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        ax[ix_fig, <span class="number">2</span>].set_ylim(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">for</span> l <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">            ax[ix_fig, l].set_xlabel(<span class="string">&quot;$w_0$&quot;</span>)</span><br><span class="line">            ax[ix_fig, l].set_ylabel(<span class="string">&quot;$w_1$&quot;</span>)</span><br><span class="line">        plot_sample_w(mN, SN, ax=ax[ix_fig, <span class="number">2</span>])</span><br><span class="line">        ix_fig += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">titles = [<span class="string">&quot;likelihood&quot;</span>, <span class="string">&quot;prior/posterior&quot;</span>, <span class="string">&quot;data space&quot;</span>]</span><br><span class="line"><span class="keyword">for</span> axi, title <span class="keyword">in</span> <span class="built_in">zip</span>(ax[<span class="number">0</span>], titles):</span><br><span class="line">    axi.set_title(title, size=<span class="number">15</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h1 id="作业五">作业五</h1>
<h2 id="等价核绘制">等价核绘制</h2>
<p>首先是高斯核的绘制，下图是一个取值为线性的高斯核函数的图像<img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402182640901.png" alt="image-20230402182640901" style="zoom: 80%;" /></p>
<p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402182755965.png" alt="image-20230402182755965" style="zoom:67%;" /></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gaussianLike</span>(<span class="params">mu,sigma,x</span>):</span><br><span class="line">    <span class="keyword">return</span> np.exp((-<span class="number">1</span>/<span class="number">2</span>)*np.matmul(np.matmul((x-mu),np.linalg.inv(sigma)),(x-mu).reshape(<span class="built_in">len</span>(x),<span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gaussianKernel</span>(<span class="params">gaussianLike,x</span>):</span><br><span class="line">    <span class="keyword">return</span> np.dot(gaussianLike(np.zeros(<span class="number">2</span>,),np.eye(<span class="number">2</span>,<span class="number">2</span>),x),gaussianLike(np.zeros(<span class="number">2</span>,),np.eye(<span class="number">2</span>,<span class="number">2</span>),x))</span><br><span class="line"></span><br><span class="line">x=np.linspace(-<span class="number">2</span>,<span class="number">2</span>,<span class="number">100</span>)</span><br><span class="line">y=np.linspace(-<span class="number">2</span>,<span class="number">2</span>,<span class="number">100</span>)</span><br><span class="line">X, Y = np.meshgrid(x, y)</span><br><span class="line">Z=[]</span><br><span class="line">z1=np.ones((<span class="number">100</span>,<span class="number">100</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> x:</span><br><span class="line">    n=<span class="number">0</span></span><br><span class="line">    z=[]</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> y:</span><br><span class="line">        m=<span class="number">0</span></span><br><span class="line">        z.append(gaussianKernel(gaussianLike,[i,j]))</span><br><span class="line">        z1[n,m]=gaussianKernel(gaussianLike,[i,j])</span><br><span class="line">        m+=<span class="number">1</span></span><br><span class="line">    n+=<span class="number">1</span></span><br><span class="line">    Z.append(z)</span><br><span class="line">Z=np.array(Z)</span><br><span class="line"></span><br><span class="line">plt.imshow(Z,cmap=<span class="string">&#x27;hot&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">ax = plt.axes(projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line">ax.plot_surface(X,Y,Z,cmap=<span class="string">&#x27;rainbow&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>下面复现课本的等价核：</p>
<p><strong>高斯核</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gaussian_kernel</span>(<span class="params">x, y, sigma</span>):</span><br><span class="line">    <span class="keyword">return</span> np.exp(-np.linalg.norm(x - y)**<span class="number">2</span> / (<span class="number">2</span> * (sigma ** <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_kernel_matrix</span>(<span class="params">X, sigma</span>):</span><br><span class="line">    n = X.shape[<span class="number">0</span>]</span><br><span class="line">    K = np.zeros((n, n))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i, n):</span><br><span class="line">            K[i, j] = gaussian_kernel(X[i], X[j], sigma)</span><br><span class="line">            K[j, i] = K[i, j]</span><br><span class="line">    <span class="keyword">return</span> K</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成示例数据集</span></span><br><span class="line">X = np.linspace(-<span class="number">5</span>, <span class="number">5</span>, <span class="number">100</span>).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">y = np.sin(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算不同带宽参数下的高斯等价核矩阵</span></span><br><span class="line">sigmas = [<span class="number">0.1</span>, <span class="number">1</span>, <span class="number">10</span>]</span><br><span class="line"><span class="keyword">for</span> sigma <span class="keyword">in</span> sigmas:</span><br><span class="line">    K = compute_kernel_matrix(X, sigma)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 绘制高斯核形状图像</span></span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.imshow(K, cmap=<span class="string">&#x27;jet&#x27;</span>, interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">r&#x27;Gaussian Kernel with $\sigma=$&#x27;</span> + <span class="built_in">str</span>(sigma))</span><br><span class="line">    plt.colorbar()</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img
src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402183003203.png"
alt="image-20230402183003203" />
<figcaption aria-hidden="true">image-20230402183003203</figcaption>
</figure>
<figure>
<img
src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402183010833.png"
alt="image-20230402183010833" />
<figcaption aria-hidden="true">image-20230402183010833</figcaption>
</figure>
<figure>
<img
src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402183017836.png"
alt="image-20230402183017836" />
<figcaption aria-hidden="true">image-20230402183017836</figcaption>
</figure>
<p><strong>多项式核</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">polynomial_kernel</span>(<span class="params">x, y, degree, coef0=<span class="number">0</span></span>):</span><br><span class="line">    <span class="keyword">return</span> (np.dot(x, y) + coef0) ** degree</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_kernel_matrix</span>(<span class="params">X, degree, coef0=<span class="number">0</span></span>):</span><br><span class="line">    n = X.shape[<span class="number">0</span>]</span><br><span class="line">    K = np.zeros((n, n))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i, n):</span><br><span class="line">            K[i, j] = polynomial_kernel(X[i], X[j], degree, coef0)</span><br><span class="line">            K[j, i] = K[i, j]</span><br><span class="line">    <span class="keyword">return</span> K</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成示例数据集</span></span><br><span class="line">X = np.linspace(-<span class="number">5</span>, <span class="number">5</span>, <span class="number">100</span>).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">y = np.sin(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算不同阶数和常数项参数下的多项式核矩阵</span></span><br><span class="line">degrees = [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">coef0s = [-<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line"><span class="keyword">for</span> degree <span class="keyword">in</span> degrees:</span><br><span class="line">    <span class="keyword">for</span> coef0 <span class="keyword">in</span> coef0s:</span><br><span class="line">        K = compute_kernel_matrix(X, degree, coef0)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 绘制多项式核形状图像</span></span><br><span class="line">        plt.figure()</span><br><span class="line">        plt.imshow(K, cmap=<span class="string">&#x27;jet&#x27;</span>, interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">        plt.title(<span class="string">&#x27;Polynomial Kernel with degree=&#x27;</span> + <span class="built_in">str</span>(degree) + <span class="string">&#x27; and coef0=&#x27;</span> + <span class="built_in">str</span>(coef0))</span><br><span class="line">        plt.colorbar()</span><br><span class="line">        plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img
src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402183116818.png"
alt="image-20230402183116818" />
<figcaption aria-hidden="true">image-20230402183116818</figcaption>
</figure>
<figure>
<img
src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402183128404.png"
alt="image-20230402183128404" />
<figcaption aria-hidden="true">image-20230402183128404</figcaption>
</figure>
<figure>
<img
src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402183137656.png"
alt="image-20230402183137656" />
<figcaption aria-hidden="true">image-20230402183137656</figcaption>
</figure>
<p><strong>Sigmoid核</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid_kernel</span>(<span class="params">x, y, alpha, c</span>):</span><br><span class="line">    <span class="keyword">return</span> np.tanh(alpha * np.dot(x, y) + c)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_kernel_matrix</span>(<span class="params">X, alpha, c</span>):</span><br><span class="line">    n = X.shape[<span class="number">0</span>]</span><br><span class="line">    K = np.zeros((n, n))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i, n):</span><br><span class="line">            K[i, j] = sigmoid_kernel(X[i], X[j], alpha, c)</span><br><span class="line">            K[j, i] = K[i, j]</span><br><span class="line">    <span class="keyword">return</span> K</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成示例数据集</span></span><br><span class="line">X = np.linspace(-<span class="number">5</span>, <span class="number">5</span>, <span class="number">100</span>).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">y = np.sin(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算不同超参数下的 Sigmoid 核矩阵</span></span><br><span class="line">alphas = [<span class="number">0.1</span>, <span class="number">0.5</span>, <span class="number">1</span>]</span><br><span class="line">cs = [-<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line"><span class="keyword">for</span> alpha <span class="keyword">in</span> alphas:</span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> cs:</span><br><span class="line">        K = compute_kernel_matrix(X, alpha, c)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 绘制 Sigmoid 核形状图像</span></span><br><span class="line">        plt.figure()</span><br><span class="line">        plt.imshow(K, cmap=<span class="string">&#x27;jet&#x27;</span>, interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">        plt.title(<span class="string">&#x27;Sigmoid Kernel with alpha=&#x27;</span> + <span class="built_in">str</span>(alpha) + <span class="string">&#x27; and c=&#x27;</span> + <span class="built_in">str</span>(c))</span><br><span class="line">        plt.colorbar()</span><br><span class="line">        plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img
src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402183249517.png"
alt="image-20230402183249517" />
<figcaption aria-hidden="true">image-20230402183249517</figcaption>
</figure>
<figure>
<img
src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402183257364.png"
alt="image-20230402183257364" />
<figcaption aria-hidden="true">image-20230402183257364</figcaption>
</figure>
<figure>
<img
src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402183304889.png"
alt="image-20230402183304889" />
<figcaption aria-hidden="true">image-20230402183304889</figcaption>
</figure>
<h2 id="似然">似然</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">random.seed(<span class="number">615</span>)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_synth_data</span>(<span class="params">N, beta</span>):</span><br><span class="line">    X_N =np.random.uniform(-<span class="number">1</span>,<span class="number">1</span>, N)</span><br><span class="line">    X_N = np.column_stack((np.ones(N), X_N))</span><br><span class="line">    <span class="comment"># for this example the true function is f(x,a) = a_0 + a_1*x</span></span><br><span class="line">    <span class="comment"># where a_0 = -.3 and a_1 = .5 are the parameters that we</span></span><br><span class="line">    <span class="comment"># are going to estimate</span></span><br><span class="line">    a = np.array([-<span class="number">.3</span>, <span class="number">.5</span>])</span><br><span class="line">    t = np.dot(X_N, a)</span><br><span class="line">    <span class="keyword">return</span> X_N, t + np.random.normal(loc=<span class="number">0.0</span>, scale=np.sqrt(<span class="number">1.</span>/beta), size=N)</span><br><span class="line"></span><br><span class="line">beta_ = <span class="number">25.0</span></span><br><span class="line">alpha = <span class="number">2.0</span></span><br><span class="line">N = <span class="number">20</span></span><br><span class="line">X_N, t_N = get_synth_data(N, beta_)</span><br><span class="line">x = np.linspace(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">70</span>)</span><br><span class="line">y = np.linspace(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">70</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">w0, w1 = np.meshgrid(x, y)</span><br><span class="line">m_0 = [<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">S_0 = <span class="number">1</span>/alpha * np.eye(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">n = <span class="number">1</span></span><br><span class="line">X_n = X_N[<span class="built_in">range</span>(n), :]</span><br><span class="line">t_n = t_N[<span class="built_in">range</span>(n)]</span><br><span class="line">plt.xlim(-<span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line">plt.ylim(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">plt.scatter(X_n[:, <span class="number">1</span>], t_n)</span><br><span class="line">plt.title(<span class="string">&quot;First point in the data set&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>);</span><br><span class="line">plt.ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">likelihood</span>(<span class="params">t_, x, w, beta</span>):</span><br><span class="line">    <span class="keyword">from</span> math <span class="keyword">import</span> sqrt</span><br><span class="line">    <span class="keyword">return</span> stats.norm.pdf(t_,loc=np.dot(w,x), scale=sqrt(<span class="number">1.</span>/beta))</span><br><span class="line"></span><br><span class="line">Z = np.zeros((<span class="built_in">len</span>(y), <span class="built_in">len</span>(x)))</span><br><span class="line"><span class="keyword">for</span> i, w1 <span class="keyword">in</span> <span class="built_in">enumerate</span>(y):</span><br><span class="line">    <span class="keyword">for</span> j, w0 <span class="keyword">in</span> <span class="built_in">enumerate</span>(x):</span><br><span class="line">        Z[i, j] = likelihood(t_n[-<span class="number">1</span>], X_n[-<span class="number">1</span>,:], np.array([w0, w1]), beta_)</span><br><span class="line">extent = (-<span class="number">1</span>,<span class="number">1</span>,-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">plt.imshow(Z, extent=extent, origin=<span class="string">&#x27;lower&#x27;</span>)</span><br><span class="line">plt.plot(-<span class="number">0.3</span>, <span class="number">0.5</span>, <span class="string">&#x27;w+&#x27;</span>, markeredgewidth=<span class="number">2</span>, markersize=<span class="number">12</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Likelihood of the first point in the data set, white cross = true value&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;w0&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;w1&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img
src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402184647229.png"
alt="image-20230402184647229" />
<figcaption aria-hidden="true">image-20230402184647229</figcaption>
</figure>
<figure>
<img
src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402184827621.png"
alt="image-20230402184827621" />
<figcaption aria-hidden="true">image-20230402184827621</figcaption>
</figure>
<figure>
<img
src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402184922104.png"
alt="image-20230402184922104" />
<figcaption aria-hidden="true">image-20230402184922104</figcaption>
</figure>
<h1 id="作业一-多项式拟合">作业一 多项式拟合</h1>
<h2 id="理论推导">理论推导</h2>
<p><span class="math display">\[
\min ||f(\omega;x)-t||^2\\
\sum_{i=0}^{n}{\omega_i*x_i^j}=t
\]</span></p>
<p>写成矩阵形式： <span class="math display">\[
XW=T
\]</span> 使用平方和最小来衡量，设损失函数： <span
class="math display">\[
L(x)=\frac{1}{2}\sum^{N}_{i=1}{(\sum_{j=0}^{M}{\omega_jx_i^j-y_i)^2}}
\]</span> 对损失函数求导，令导数等于0： <span class="math display">\[
\begin{array}{l}
\frac{\partial L(x;\omega)}{\partial \omega_i}=0 \\
\\
\frac{1}{2}\sum_{i=1}^{N}{2(\sum^{j=0}_{M}{\omega_jx_i^j-y_i)}\times
x_i^k}=0 \\
\\
\sum_{i=1}^{N}{\sum^{M}_{j=1}{\omega_ix_i^{j+k}}}=\sum_{j=1}^{M}{x_i^ky_i}(k=0,1,2,3,\cdots,M)
\end{array}
\]</span> 那么就有： <span class="math display">\[
\begin{array}{l}
X=\sum^M_{j=1}{x_i^{j+k}} \\
W=\omega_i \\
Y=\sum_{i=1}^{M}{x_i^ky_i}\\
XW=Y
\end{array}
\]</span> 将以<span
class="math inline">\(x\)</span>为参数的非线性模型转化为以<span
class="math inline">\(w\)</span>的线性模型，从而转化为矩阵方程求解问题,需要将方程特征进行组合，实现上使用sklearn，进行多项式特征组合，然后使用线性回归进行预测：</p>
<p>算法语言描述：</p>
<ol type="1">
<li><p>生成一个（特征数目+1，特征数目+1）的矩阵</p></li>
<li><p>分别计算0-特征阶数的幂</p></li>
<li><p>返回特征混合矩阵</p></li>
<li><p>线性回归</p></li>
</ol>
<h2 id="代码实现">代码实现</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Polyfeature</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,n_features</span>):</span><br><span class="line">        self.n_features=n_features</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 一元特征混合</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, x</span>):</span><br><span class="line">        xf = np.zeros((<span class="built_in">len</span>(x), self.n_features + <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.n_features + <span class="number">1</span>):</span><br><span class="line">            xf[:,i] = np.power(x, i).reshape(np.shape(xf[:,i]))</span><br><span class="line">        self.xf=xf</span><br><span class="line">        <span class="keyword">return</span> xf</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">transform</span>(<span class="params">self,x</span>):</span><br><span class="line">        xf = np.zeros((<span class="built_in">len</span>(x), self.n_features + <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.n_features + <span class="number">1</span>):</span><br><span class="line">            xf[:, i] = np.power(x, i).reshape(np.shape(xf[:, i]))</span><br><span class="line">        self.xf = xf</span><br><span class="line">        <span class="keyword">return</span> xf</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit_transform</span>(<span class="params">self, x</span>):</span><br><span class="line">        xf = np.zeros((<span class="built_in">len</span>(x), self.n_features + <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.n_features + <span class="number">1</span>):</span><br><span class="line">            xf[:, i] = np.power(x, i).reshape(np.shape(xf[:, i]))</span><br><span class="line">            self.xf = xf</span><br><span class="line">        <span class="keyword">return</span> xf</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">linearregression</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self,x,y,Lambda=<span class="number">0</span></span>):</span><br><span class="line">        c = np.dot(x.T, x)</span><br><span class="line">        I = np.eye(np.shape(c)[<span class="number">0</span>])</span><br><span class="line">        d = np.dot(Lambda, I)</span><br><span class="line">        e = (c + d)</span><br><span class="line">        e = np.linalg.inv(e)</span><br><span class="line">        w = np.dot(x.T, y)</span><br><span class="line">        w = np.dot(e, w)</span><br><span class="line">        self.w = w</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self,x</span>):</span><br><span class="line">        y=np.dot(x,self.w)</span><br><span class="line">        <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">polyregression</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,features</span>):</span><br><span class="line">        self.n_features=features</span><br><span class="line">    <span class="comment"># 生成数据</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">create_data</span>(<span class="params">self,n</span>):</span><br><span class="line">        self.n=n</span><br><span class="line">        X=np.random.rand(n,<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 考虑到需要保证高斯白噪声的0均值</span></span><br><span class="line">        noise=<span class="number">0.3</span>*np.random.uniform(low=-<span class="number">1</span>, high=<span class="number">1</span>, size=(n,<span class="number">1</span>))</span><br><span class="line">        t=np.sin(X*<span class="number">2</span>*math.pi)+noise</span><br><span class="line">        self.X=X</span><br><span class="line">        self.t=t</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 划分数据集</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">splitData</span>(<span class="params">self</span>):</span><br><span class="line">        X_train, X_test, T_train, T_test = train_test_split(self.X, self.t, test_size=<span class="number">0.3</span>, random_state=<span class="number">0</span>)</span><br><span class="line">        self.X_train=X_train</span><br><span class="line">        self.X_test=X_test</span><br><span class="line">        self.T_train=T_train</span><br><span class="line">        self.T_test=T_test</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 多项式拟合</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self</span>):</span><br><span class="line">        poly = PolynomialFeatures(self.n_features)</span><br><span class="line">        x_train_poly = poly.fit_transform(self.X_train)</span><br><span class="line"></span><br><span class="line">        lin=LinearRegression()</span><br><span class="line">        lin.fit(x_train_poly,self.T_train)</span><br><span class="line"></span><br><span class="line">        self.lin=lin</span><br><span class="line">        self.poly=poly</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">draw</span>(<span class="params">self</span>):</span><br><span class="line">        plt.style.use(<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line">        plt.figure()</span><br><span class="line">        plt.plot(np.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">50</span>),np.sin(np.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">50</span>)*<span class="number">2</span>*math.pi),color=<span class="string">&#x27;green&#x27;</span>)</span><br><span class="line">        plt.scatter(self.X,self.t,marker=<span class="string">&#x27;o&#x27;</span>,edgecolor=<span class="string">&#x27;blue&#x27;</span>,color=<span class="string">&#x27;white&#x27;</span>,linewidths=<span class="string">&#x27;1.1&#x27;</span>)</span><br><span class="line">        plt.plot(np.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">50</span>),self.lin.predict(self.poly.transform(np.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">50</span>).reshape(-<span class="number">1</span>,<span class="number">1</span>))),color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">        s=<span class="string">&#x27;n_features=&#x27;</span>+<span class="built_in">str</span>(self.n_features)</span><br><span class="line">        plt.text(<span class="number">0.7</span>,<span class="number">1</span>,s)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;X&#x27;</span>)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;Y&#x27;</span>)</span><br><span class="line">        plt.savefig(<span class="string">&#x27;features=&#x27;</span>+<span class="built_in">str</span>(self.n_features)+<span class="string">&#x27; samples=&#x27;</span>+<span class="built_in">str</span>(self.n)+<span class="string">&#x27;.png&#x27;</span>)</span><br><span class="line">        plt.show()</span><br><span class="line">    <span class="comment"># 衡量拟合的标准</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">RSME</span>(<span class="params">self</span>):</span><br><span class="line">        T_test_predict=self.lin.predict(self.poly.transform(self.X_test))</span><br><span class="line">        SSE=np.<span class="built_in">sum</span>(np.square(self.T_test-T_test_predict))</span><br><span class="line">        MSE=SSE/<span class="built_in">len</span>(T_test_predict)</span><br><span class="line">        rsme=np.sqrt(MSE)</span><br><span class="line">        <span class="keyword">return</span> rsme</span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 对不同特征选择的比较</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">features_test</span>():</span><br><span class="line">        RSME=[]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">            poly=polyregression(i)</span><br><span class="line">            poly.create_data(<span class="number">20</span>)</span><br><span class="line">            poly.splitData()</span><br><span class="line">            poly.fit()</span><br><span class="line">            poly.draw()</span><br><span class="line">            RSME.append(poly.RSME())</span><br><span class="line"></span><br><span class="line">        plt.figure()</span><br><span class="line">        plt.plot(np.linspace(<span class="number">0</span>,<span class="number">10</span>,<span class="number">10</span>),RSME,marker=<span class="string">&#x27;^&#x27;</span>,label=<span class="string">&quot;points&quot;</span>)</span><br><span class="line">        plt.show()</span><br><span class="line">    <span class="comment"># 对不同样本数量的比较</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">samples_test</span>():</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> [<span class="number">20</span>,<span class="number">200</span>,<span class="number">500</span>]:</span><br><span class="line">            RSME=[]</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">50</span>):</span><br><span class="line">                poly=polyregression(i)</span><br><span class="line">                poly.create_data(j)</span><br><span class="line">                poly.splitData()</span><br><span class="line">                poly.fit()</span><br><span class="line">                poly.draw()</span><br><span class="line">                RSME.append(poly.RSME())</span><br><span class="line">            plt.figure()</span><br><span class="line">            plt.plot(np.linspace(<span class="number">0</span>,<span class="number">50</span>,<span class="number">50</span>),RSME,marker=<span class="string">&#x27;^&#x27;</span>,label=<span class="string">&quot;points&quot;</span>)</span><br><span class="line">            plt.savefig(<span class="string">&#x27;sample=&#x27;</span>+<span class="built_in">str</span>(j)+<span class="string">&#x27;.png&#x27;</span>)</span><br><span class="line">            plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># features_test()</span></span><br><span class="line">    samples_test()</span><br></pre></td></tr></table></figure>
<h2 id="结果对比">结果对比</h2>
<p>不同的特征数量，首先全部针对样本数量为10的情况： <img
src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/features=0%20samples=10.png"
alt="features=0 samples=10" /></p>
<figure>
<img
src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/features=1%20samples=10.png"
alt="features=1 samples=10" />
<figcaption aria-hidden="true">features=1 samples=10</figcaption>
</figure>
<figure>
<img
src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/features=2%20samples=10.png"
alt="features=2 samples=10" />
<figcaption aria-hidden="true">features=2 samples=10</figcaption>
</figure>
<figure>
<img
src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/features=3%20samples=10.png"
alt="features=3 samples=10" />
<figcaption aria-hidden="true">features=3 samples=10</figcaption>
</figure>
<figure>
<img
src="G:\专业学习\第六学期\机器学习\实验一\selectF\features=4%20samples=10.png"
alt="features=4 samples=10" />
<figcaption aria-hidden="true">features=4 samples=10</figcaption>
</figure>
<figure>
<img
src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/features=5%20samples=10.png"
alt="features=5 samples=10" />
<figcaption aria-hidden="true">features=5 samples=10</figcaption>
</figure>
<p>从中可以大致看出，在选择特征过少时，会出现欠拟合现象，选择过多后则会过拟合，针对样本量为20的情况下，RSME曲线如图：
<img
src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/sample=20.png"
alt="sample=20.png" />
图上显示的情况，并不是与我们预期中的情况完全吻合，其原因可能是因为测试集样本数量过少，导致无法很好的捕捉曲线拟合的问题，于是我们对其他样本数量进行对比
、 <img
src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/sample=200.png"
alt="sample=200.png" /> <img
src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/sample=500.png"
alt="sample=500.png" /><br />
可以看出样本数量增多后，特征的选择有明显的趋势。尝试复现使用样本为10的情况：
<img
src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/sample=10.png"
alt="sample=10" /> 且样本数量会明显的影响拟合的效果。</p>
<figure>
<img
src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/features=5%20samples=10.png"
alt="features=5 samples=10" />
<figcaption aria-hidden="true">features=5 samples=10</figcaption>
</figure>
<figure>
<img
src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/features=5%20samples=20.png"
alt="features=5 samples=20" />
<figcaption aria-hidden="true">features=5 samples=20</figcaption>
</figure>
<figure>
<img
src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/features=5%20samples=200.png"
alt="features=5 samples=200" />
<figcaption aria-hidden="true">features=5 samples=200</figcaption>
</figure>
<figure>
<img
src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/features=5%20samples=500.png"
alt="features=5 samples=500" />
<figcaption aria-hidden="true">features=5 samples=500</figcaption>
</figure>
<p>针对样本为10，特征为5的情况下进行正则化：</p>
<p><span class="math inline">\(\lambda\)</span>=0.7740859059011267</p>
<figure>
<img
src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230311220541756.png"
alt="image-20230311220541756" />
<figcaption aria-hidden="true">image-20230311220541756</figcaption>
</figure>
<h1 id="作业二">作业二</h1>
<h2 id="频率学派与贝叶斯学派">频率学派与贝叶斯学派</h2>
<ul>
<li>频率观点认为频率能够趋近概率，模型的参数是一定的，只要采样数目足够多就能逼近参数值，我的理解是其符合大数定律的思想（此为辛钦大数定律）：
<span class="math display">\[
\lim_{n\to
\infty}P\left(\left|\frac{1}{n}\sum_{i=1}^{n}{a_i-\mu}  \right|&lt;
\varepsilon\right)=1
\]</span></li>
<li>贝叶斯观点认为模型的参数是在变化的，样本是一定的。 <span
class="math display">\[
p(w|D)=\frac{p(D|w)p(w)}{p(D)}
\]</span> 以一元高斯分布为例，解释样本分布问题：</li>
<li>频率：
频率的思想是以样本代替总体，从而得到模型参数，假设有数据集<span
class="math inline">\(D=\{x_1,x_2,\cdot\cdot\cdot,x_n\}\)</span>，则估计得到的一元高斯分布的参数为
<span class="math display">\[
\hat\mu=\frac{1}{n}\sum_{i=1}^{n}{x_i}
\]</span> <span class="math display">\[
\hat{\sigma^2}=\frac{1}{n}\sum_{i=1}^{n}{(x_i-\hat\mu)}^2
\]</span>
样本分布显然是和总体有差异的，对其求期望可以得到，均值为无偏估计，而方差存在偏差，而偏差随着样本数目n的增大而减小（<span
class="math inline">\(E(\hat\sigma^2)=\frac{n-1}{n}\sigma^2\)</span>）。</li>
<li>贝叶斯：
贝叶斯的思想认为所有参数都是一个分布，而样本是固定不变的量。所以通过先验尽可能使逼近高斯分布。
<span class="math display">\[
p(D|w)=\frac{p(w|D)p(D)}{p(w)}
\]</span> 有似然函数，其中<span
class="math inline">\(p(D)\)</span>为一个常数，可被忽略（归一化），根据课本给出的高斯分布求解结果，发现他的方差和均值均为无偏估计。
## 公式推导 <img
src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230421154051248.png"
alt="image-20230421154051248" /></li>
</ul>
<p>引入先验</p>
<figure>
<img
src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230421154116419.png"
alt="image-20230421154116419" />
<figcaption aria-hidden="true">image-20230421154116419</figcaption>
</figure>
<p>在这里将数据的概率分布进行了归一，认为样本概率为一常数</p>
<figure>
<img
src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230421154257436.png"
alt="image-20230421154257436" />
<figcaption aria-hidden="true">image-20230421154257436</figcaption>
</figure>
<p>然后对<span class="math inline">\(\ln
p(\mathbf{w}|\alpha)\)</span>求解：</p>
<figure>
<img
src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230421154321678.png"
alt="image-20230421154321678" />
<figcaption aria-hidden="true">image-20230421154321678</figcaption>
</figure>
<p>取负数：<br />
<span class="math display">\[
-\ln p(\mathbf{t|x},w,\beta)p(\mathbf{w}|\alpha)=
\frac{\beta}{2}\sum_{n=1}^{N}
{(x-y_n(x_n,\mathbf{w}))^2 }
+\frac{\alpha}{2}\mathbf{w^T}\mathbf{w}
-\frac{n}{2}\ln \frac{\beta}{2\pi}-\frac{M+1}{2}\ln \alpha+\frac{M+1}{2}
\ln 2\pi
\]</span> 后三项均为常数，对最大化没有任何影响，因此损失函数为：</p>
<figure>
<img
src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230421154342936.png"
alt="image-20230421154342936" />
<figcaption aria-hidden="true">image-20230421154342936</figcaption>
</figure>
<h1 id="作业三">作业三</h1>
<h2 id="基函数图像复现">基函数图像复现</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib.ticker <span class="keyword">import</span> MultipleLocator</span><br><span class="line"></span><br><span class="line">x_major_locator=MultipleLocator(<span class="number">1</span>)</span><br><span class="line">y_major_locator=MultipleLocator(<span class="number">0.25</span>)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>,<span class="number">5</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigma</span>(<span class="params">x,b</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>/(np.exp((-x+b)*<span class="number">10</span>)+<span class="number">1</span>)</span><br><span class="line">x=np.linspace(-<span class="number">1</span>,<span class="number">1</span>,<span class="number">100</span>)</span><br><span class="line">b=np.linspace(-<span class="number">1</span>,<span class="number">1</span>,<span class="number">11</span>).tolist()</span><br><span class="line"><span class="keyword">for</span> bi <span class="keyword">in</span> b:</span><br><span class="line">    plt.plot(x,sigma(x,bi))</span><br><span class="line">plt.xlim(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">plt.ylim(<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line">ax=plt.gca()</span><br><span class="line">ax.xaxis.set_major_locator(x_major_locator)</span><br><span class="line">ax.yaxis.set_major_locator(y_major_locator)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">def gaussian(mu,sigma,x,b):</span></span><br><span class="line"><span class="string">    return 1/(np.sqrt(2*np.pi)*sigma)*np.exp(-np.square((x+b)*5-mu)/2*np.square(sigma))</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">plt.subplot(1,3,2)</span></span><br><span class="line"><span class="string">for bi in b:</span></span><br><span class="line"><span class="string">    plt.plot(x,gaussian(0,1,x,bi))</span></span><br><span class="line"><span class="string">plt.xlim(-1,1)</span></span><br><span class="line"><span class="string">plt.ylim(0,0.4)</span></span><br><span class="line"><span class="string">plt.show()</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">poly</span>(<span class="params">x,n</span>):</span><br><span class="line">    <span class="keyword">return</span> np.power(x,n)</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>)</span><br><span class="line">n=np.linspace(<span class="number">1</span>,<span class="number">10</span>,<span class="number">10</span>).tolist()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> n:</span><br><span class="line">    plt.plot(x,poly(x,i))</span><br><span class="line">plt.xlim(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">plt.ylim(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">ax=plt.gca()</span><br><span class="line">y_major_locator1=MultipleLocator(<span class="number">0.5</span>)</span><br><span class="line">ax.xaxis.set_major_locator(x_major_locator)</span><br><span class="line">ax.yaxis.set_major_locator(y_major_locator1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gaussian1</span>(<span class="params">mu,sigma,x,b</span>):</span><br><span class="line">    <span class="keyword">return</span> np.exp(-np.square((x+b)*<span class="number">5</span>-mu)/<span class="number">2</span>*np.square(sigma))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"><span class="keyword">for</span> bi <span class="keyword">in</span> b:</span><br><span class="line">    plt.plot(x,gaussian1(<span class="number">0</span>,<span class="number">1</span>,x,bi))</span><br><span class="line"></span><br><span class="line">ax=plt.gca()</span><br><span class="line">ax.xaxis.set_major_locator(x_major_locator)</span><br><span class="line">ax.yaxis.set_major_locator(y_major_locator)</span><br><span class="line"></span><br><span class="line">plt.xlim(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">plt.ylim(<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img
src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230317214519144.png"
alt="image-20230317214519144" />
<figcaption aria-hidden="true">image-20230317214519144</figcaption>
</figure>
<h1 id="作业四-多项式拟合加强版">作业四 多项式拟合（加强版）</h1>
<h2 id="实验项目结构">实验项目结构</h2>
<p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230326184103754.png" alt="image-20230326184103754" style=" float:left" />
/&gt;其中，data储存固化的数据</p>
<p>将数据生成函数与多项式拟合功能分离，建立createData.py</p>
<p>交叉验证函数</p>
<p>线性回归</p>
<p>多项式特征生成和多项式回归</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">createData.py</span><br><span class="line">__________________</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成数据集</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_data</span>(<span class="params">n,beta</span>):</span><br><span class="line">    n = n</span><br><span class="line">    X = np.linspace(<span class="number">0</span>, <span class="number">1</span>, n).reshape(n, <span class="number">1</span>)</span><br><span class="line">    noise = beta * np.random.uniform(low=-<span class="number">1</span>, high=<span class="number">1</span>, size=(n, <span class="number">1</span>))</span><br><span class="line">    t = np.sin(X * <span class="number">2</span> * np.pi) + noise</span><br><span class="line">    X = X</span><br><span class="line">    t = t</span><br><span class="line">    data=np.hstack((X,t))</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">splitData</span>(<span class="params">X,t</span>):</span><br><span class="line">    X_train, X_test, T_train, T_test = train_test_split(X, t, test_size=<span class="number">0.2</span>, random_state=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> X_train,X_test,T_train,T_test</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据固化</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">tocsv</span>(<span class="params">data</span>):</span><br><span class="line">    df=pd.DataFrame(data)</span><br><span class="line">    df.to_csv(<span class="string">&#x27;.\data\sample=&#x27;</span>+<span class="built_in">str</span>(data.shape[<span class="number">0</span>])+<span class="string">&#x27;.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    data=create_data(<span class="number">10</span>,<span class="number">0.1</span>)</span><br><span class="line">    tocsv(data)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">Cross_Validation.py</span><br><span class="line">_________________________________________</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Cross_Validation</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_folds</span>):</span><br><span class="line">        self.n_folds = n_folds</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">CV</span>(<span class="params">self,x,y</span>):</span><br><span class="line">        kf = KFold(n_splits=self.n_folds)</span><br><span class="line">        x_train=[]</span><br><span class="line">        x_test=[]</span><br><span class="line">        y_train=[]</span><br><span class="line">        y_test=[]</span><br><span class="line">        <span class="keyword">for</span> train_index,test_index <span class="keyword">in</span> kf.split(x):</span><br><span class="line">            xtr, xte = x[train_index], x[test_index]</span><br><span class="line">            ytr, yte = y[train_index], y[test_index]</span><br><span class="line">            x_train.append(xtr)</span><br><span class="line">            x_test.append(xte)</span><br><span class="line">            y_train.append(ytr)</span><br><span class="line">            y_test.append(yte)</span><br><span class="line">        <span class="keyword">return</span> x_train, x_test, y_train, y_test</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">linearregression.py</span><br><span class="line">_______________________</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">linearregression</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self,x,y,Lambda=<span class="number">0</span></span>):</span><br><span class="line">        c = np.dot(x.T, x)</span><br><span class="line">        I = np.eye(np.shape(c)[<span class="number">0</span>])</span><br><span class="line">        d = np.dot(Lambda, I)</span><br><span class="line">        e = (c + d)</span><br><span class="line">        e = np.linalg.inv(e)</span><br><span class="line">        w = np.dot(x.T, y)</span><br><span class="line">        w = np.dot(e, w)</span><br><span class="line">        self.w = w</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self,x</span>):</span><br><span class="line">        y=np.dot(x,self.w)</span><br><span class="line">        <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">Polyfeature.py</span><br><span class="line">____________________</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Polyfeature</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,n_features</span>):</span><br><span class="line">        self.n_features=n_features</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 一元特征混合</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># 单个数字</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(x,<span class="built_in">int</span>):</span><br><span class="line">            x=np.array([x])</span><br><span class="line">        <span class="comment"># 数组计算</span></span><br><span class="line">        xf = np.zeros((<span class="built_in">len</span>(x), self.n_features + <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.n_features + <span class="number">1</span>):</span><br><span class="line">            xf[:,i] = np.power(x, i).reshape(np.shape(xf[:,i]))</span><br><span class="line">        self.xf=xf</span><br><span class="line">        <span class="keyword">return</span> xf</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit_transform</span>(<span class="params">self,x</span>):</span><br><span class="line">        <span class="comment"># 单个数字</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(x, <span class="built_in">int</span>):</span><br><span class="line">            x = np.array([x])</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(x,<span class="built_in">float</span>):</span><br><span class="line">            x = np.array([x])</span><br><span class="line">        <span class="comment"># 数组计算</span></span><br><span class="line">        xf = np.zeros((<span class="built_in">len</span>(x), self.n_features + <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.n_features + <span class="number">1</span>):</span><br><span class="line">            xf[:, i] = np.power(x, i).reshape(np.shape(xf[:, i]))</span><br><span class="line">        <span class="keyword">return</span> xf</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br></pre></td><td class="code"><pre><span class="line">PolyRegress.py</span><br><span class="line">______________________________________</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.ticker <span class="keyword">as</span> mticker</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> Polyfeature <span class="keyword">import</span> Polyfeature</span><br><span class="line"><span class="keyword">from</span> linearregression <span class="keyword">import</span> linearregression</span><br><span class="line"><span class="keyword">from</span> Cross_Validation <span class="keyword">import</span> Cross_Validation</span><br><span class="line"><span class="keyword">from</span> createData <span class="keyword">import</span> create_data</span><br><span class="line"><span class="keyword">from</span> createData <span class="keyword">import</span> splitData</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">polyRegression</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, features, n_lambda</span>):</span><br><span class="line">        self.n_features = features</span><br><span class="line">        self.n_lambda = n_lambda</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 拟合</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self,x,y,l</span>):</span><br><span class="line">        <span class="comment"># 混合特征</span></span><br><span class="line">        pf=Polyfeature(self.n_features)</span><br><span class="line">        pf.fit(x)</span><br><span class="line">        <span class="comment"># 线性回归</span></span><br><span class="line">        lin = linearregression()</span><br><span class="line">        lin.fit(pf.xf,y,Lambda=l)</span><br><span class="line"></span><br><span class="line">        self.lin = lin</span><br><span class="line">        self.poly = pf</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self,x</span>):</span><br><span class="line">        x=self.poly.fit_transform(x)</span><br><span class="line">        prediction=self.lin.predict(x)</span><br><span class="line">        <span class="keyword">return</span> prediction</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">draw</span>(<span class="params">self,X,t</span>):</span><br><span class="line">        plt.style.use(<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line">        plt.figure()</span><br><span class="line">        plt.plot(np.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">50</span>),np.sin(np.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">50</span>)*<span class="number">2</span>*math.pi),c=<span class="string">&#x27;green&#x27;</span>)</span><br><span class="line">        plt.scatter(X,t,marker=<span class="string">&#x27;o&#x27;</span>,edgecolor=<span class="string">&#x27;blue&#x27;</span>,c=<span class="string">&#x27;white&#x27;</span>,linewidths=<span class="number">1.1</span>)</span><br><span class="line">        plt.plot(np.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">50</span>),</span><br><span class="line">                 self.lin.predict(self.poly.fit_transform(np.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">50</span>).reshape(-<span class="number">1</span>,<span class="number">1</span>))),</span><br><span class="line">                 c=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">        s=<span class="string">&#x27;n_features=&#x27;</span>+<span class="built_in">str</span>(self.n_features)</span><br><span class="line">        plt.text(<span class="number">0.7</span>,<span class="number">1</span>,s)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;X&#x27;</span>)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;Y&#x27;</span>)</span><br><span class="line">        s=<span class="string">&#x27;cv\\features=&#x27;</span>+<span class="built_in">str</span>(self.n_features)+<span class="string">&#x27; samples=&#x27;</span>+<span class="built_in">str</span>(<span class="number">1</span>)+<span class="string">&#x27;.png&#x27;</span></span><br><span class="line">        plt.savefig(<span class="string">&#x27;11.png&#x27;</span>)</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">cv_pridict</span>(<span class="params">self, X, y, n_fold</span>):</span><br><span class="line">        cv = Cross_Validation(n_fold)</span><br><span class="line">        X_train, X_test, y_train, y_test = cv.CV(X,y)</span><br><span class="line">        y_allPredict = np.ones((<span class="number">1</span>, self.n_lambda))</span><br><span class="line">        Lambda = np.logspace(-<span class="number">10</span>, -<span class="number">7</span>, self.n_lambda)</span><br><span class="line">        w=[]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_fold):</span><br><span class="line">            y_predict = np.zeros((y_test[i].shape[<span class="number">0</span>], self.n_lambda))</span><br><span class="line">            k=<span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> np.nditer(Lambda) :</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;第&#x27;</span>,k+<span class="number">1</span>+self.n_lambda*i,<span class="string">&#x27;次:&#x27;</span>,j)</span><br><span class="line">                poly = self.fit(X_train[i], y_train[i], j)</span><br><span class="line">                y_pre = self.predict(X_test[i])</span><br><span class="line">                w.append(self.lin.w)</span><br><span class="line">                y_predict[:, k] = y_pre.ravel()</span><br><span class="line">                k=k+<span class="number">1</span></span><br><span class="line">            y_allPredict = np.vstack((y_allPredict, y_predict))</span><br><span class="line">        y_allPredict = y_allPredict[<span class="number">1</span>:]</span><br><span class="line">        <span class="keyword">return</span> y_allPredict, cv, y_test, y_train, X_test, X_train,w</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">RMSE_CV</span>(<span class="params">self, y_allPredict, y_measure, n</span>):</span><br><span class="line">        press = np.square(np.subtract(y_allPredict, y_measure.reshape(-<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">        press_all = np.<span class="built_in">sum</span>(press, axis=<span class="number">0</span>)</span><br><span class="line">        RMSECV = np.sqrt(press_all / n)</span><br><span class="line">        lambda_best_index= np.argmin(RMSECV)</span><br><span class="line">        lambda_best=np.logspace(-<span class="number">10</span>,-<span class="number">7</span>, self.n_lambda)[lambda_best_index]</span><br><span class="line">        <span class="keyword">return</span> RMSECV, lambda_best</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">bias_cv</span>(<span class="params">self, y_allPredict, y_expect, n</span>):</span><br><span class="line">        press = np.square(np.subtract(y_allPredict, y_expect.reshape(-<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">        press_all = np.<span class="built_in">sum</span>(press, axis=<span class="number">0</span>)</span><br><span class="line">        bias_cv = press_all / n</span><br><span class="line">        <span class="keyword">return</span> bias_cv</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">variance_cv</span>(<span class="params">self,y_allPredict, y_expect</span>):</span><br><span class="line">        press = np.square(np.subtract(y_allPredict, y_expect.reshape(-<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">        variance=np.average(press,axis=<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> variance</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_error_cv</span>(<span class="params">self,y_allPredict,y,Lambda,w</span>):</span><br><span class="line">        press = np.square(np.subtract(y_allPredict, y.reshape(-<span class="number">1</span>, <span class="number">1</span>)))</span><br><span class="line">        error1 = np.<span class="built_in">sum</span>(press, axis=<span class="number">0</span>)/<span class="number">2</span></span><br><span class="line">        error2 = np.linalg.norm(w,axis=<span class="number">1</span>)</span><br><span class="line">        error_temp=[]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">            e=np.average(error2[i*<span class="number">5</span>:(i+<span class="number">1</span>)*<span class="number">5</span>])</span><br><span class="line">            error_temp.append(e)</span><br><span class="line">        error2=np.array(error_temp)*Lambda/<span class="number">2</span></span><br><span class="line">        error=error1+error2</span><br><span class="line">        <span class="keyword">return</span> error</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">show_Select_lambda</span>(<span class="params">self,RMSECV</span>):</span><br><span class="line">        x=np.logspace(-<span class="number">10</span>,-<span class="number">7</span>,self.n_lambda)</span><br><span class="line">        plt.plot(x,</span><br><span class="line">                 RMSECV,marker=<span class="string">&#x27;^&#x27;</span>,</span><br><span class="line">                 markersize=<span class="number">10</span>,</span><br><span class="line">                 markerfacecolor=<span class="string">&#x27;orange&#x27;</span>,</span><br><span class="line">                 color=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;lambda&#x27;</span>)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;RMSECV&#x27;</span>)</span><br><span class="line">        ax = plt.gca()</span><br><span class="line">        ax.set_xscale(<span class="string">&quot;log&quot;</span>)</span><br><span class="line">        ax.set_xlim(ax.get_xlim()[::-<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">RSME</span>(<span class="params">self,X,t</span>):</span><br><span class="line">        T_predict = self.lin.predict(self.poly.fit_transform(X))</span><br><span class="line">        SSE = np.<span class="built_in">sum</span>(np.square(t - T_predict))</span><br><span class="line">        MSE = SSE / <span class="built_in">len</span>(T_predict)</span><br><span class="line">        rsme = np.sqrt(MSE)</span><br><span class="line">        <span class="keyword">return</span> rsme</span><br></pre></td></tr></table></figure>
<h2 id="调整beta和lambda观察rmse变化">调整<span
class="math inline">\(\beta\)</span>和<span
class="math inline">\(\lambda\)</span>观察RMSE变化</h2>
<p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__name__&#x27;</span>:</span><br><span class="line">   beta=np.linspace(<span class="number">0</span>,<span class="number">0.5</span>,<span class="number">1000</span>)</span><br><span class="line">   Lambda=np.logspace(-<span class="number">10</span>,<span class="number">0</span>,<span class="number">1000</span>)</span><br><span class="line">   RMSE_SUM=[]</span><br><span class="line">   <span class="comment"># beta和lambda对拟合效果影响</span></span><br><span class="line">   <span class="keyword">for</span> j <span class="keyword">in</span> beta:</span><br><span class="line">        poly = polyRegression(<span class="number">8</span>, <span class="number">1000</span>)</span><br><span class="line">        data=create_data(<span class="number">10</span>,j)</span><br><span class="line">        X=data[:,<span class="number">0</span>]</span><br><span class="line">        t=data[:,<span class="number">1</span>]</span><br><span class="line">        y_allPredict, cv, y_test, y_train, X_test, X_train = poly.cv_pridict(X, t, <span class="number">5</span>)</span><br><span class="line">        RMSECV, best_lambda = poly.RMSE_CV(y_allPredict, t, X.shape[<span class="number">0</span>])</span><br><span class="line">        RMSE_SUM.append(RMSECV)</span><br><span class="line">    RMSE=np.array(RMSE_SUM)</span><br><span class="line">    X, Y = np.meshgrid(Lambda, beta)</span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">15</span>,<span class="number">15</span>))</span><br><span class="line">    ax = plt.axes(projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line">    ax.set_xlabel(<span class="string">&#x27;beta&#x27;</span>)</span><br><span class="line">    ax.set_ylabel(<span class="string">&#x27;lambda&#x27;</span>)</span><br><span class="line">    ax.set_zlabel(<span class="string">&#x27;RSME&#x27;</span>)</span><br><span class="line">    ax.plot_surface(np.log(Y), np.log(X), RMSE, rstride=<span class="number">1</span>, cstride=<span class="number">1</span>, cmap=plt.get_cmap(<span class="string">&#x27;rainbow&#x27;</span>))</span><br><span class="line">    ax.set_title(<span class="string">&#x27;Surface plot&#x27;</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<center left>
<img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230323215538367.png" alt="image-20230323215538367" style="zoom:50%;"  width="800"/>
<img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230323220045143.png" alt="image-20230323220045143" style="zoom: 33%;" width="1250" />
</center>
<p>右图<span class="math inline">\(-\ln \beta\)</span>值作为x轴，<span
class="math inline">\(\ln \lambda\)</span>作为y轴，左图反之。</p>
<p>为了方便观察，对局部作图：</p>
<p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/img.png" alt="img" style="zoom: 67%;" /></p>
<p>首先，从<span class="math inline">\(\ln
\lambda\)</span>方向观察，可以看出<span
class="math inline">\(\lambda\)</span>对RMSE的影响呈波浪状，存在多个极小值，当<span
class="math inline">\(\lambda\)</span>取很小的值时，在<span
class="math inline">\(-ln\beta\)</span>较大的时候出现了比较严重的过拟合。</p>
<p>然后从<span class="math inline">\(-\ln
\beta\)</span>方向观察，可以看出<span
class="math inline">\(\beta\)</span>对RMSE的影响实际上并不大，呈小而密的波浪趋势。</p>
<h2 id="正则化前后回归系数">正则化前后回归系数</h2>
<p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 选择参数lambda，给出拟合表达</span></span><br><span class="line">    df=pd.read_csv(<span class="string">&#x27;./data/sample=10.csv&#x27;</span>)</span><br><span class="line">    X=df.values[:,<span class="number">1</span>]</span><br><span class="line">    t=df.values[:,<span class="number">2</span>]</span><br><span class="line">    x_train, x_test, T_train, T_test=splitData(X,t)</span><br><span class="line">    <span class="comment"># 正则化</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        poly = polyRegression(i, <span class="number">50</span>)</span><br><span class="line">        y_allPredict, cv, y_test, y_train, X_test, X_train = poly.cv_pridict(X, t, <span class="number">5</span>)</span><br><span class="line">        RMSECV, best_lambda = poly.RMSE_CV(y_allPredict, t, X.shape[<span class="number">0</span>])</span><br><span class="line">        poly_best=polyRegression(i,<span class="number">5</span>)</span><br><span class="line">        poly_best.fit(x_train,T_train,best_lambda)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;次数为&#x27;</span>,i,<span class="string">&#x27;时的权重集合：&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(poly_best.lin.w)</span><br><span class="line">    <span class="comment"># 无正则化</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;无正则化\n&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        poly = polyRegression(i, <span class="number">50</span>)</span><br><span class="line">        poly.fit(x_train, T_train, <span class="number">0</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;次数为&#x27;</span>, i, <span class="string">&#x27;时的权重集合：&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(poly.lin.w)</span><br><span class="line">    rmse_train=[]</span><br><span class="line">    rmse_test=[]</span><br></pre></td></tr></table></figure>
<p>无正则化：</p>
<table>
<colgroup>
<col style="width: 6%" />
<col style="width: 17%" />
<col style="width: 17%" />
<col style="width: 17%" />
<col style="width: 18%" />
<col style="width: 6%" />
<col style="width: 17%" />
</colgroup>
<thead>
<tr class="header">
<th><span class="math inline">\(w\)</span></th>
<th>0</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>……</th>
<th>9</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td>-0.08673405</td>
<td>0.43162238</td>
<td>0.5695881</td>
<td>-0.05816218</td>
<td></td>
<td>-0.07491257</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td>-1.05343403</td>
<td>-2.17473669</td>
<td>11.14510403</td>
<td></td>
<td>10.41748047</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td>1.16724815</td>
<td>-33.31060868</td>
<td></td>
<td>-34.4765625</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td>22.29544252</td>
<td></td>
<td>56.09375</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>-60.</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>-14.375</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>34.796875</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>44.5625</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>-2.0625</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>-35.390625</td>
</tr>
</tbody>
</table>
<p>正则化后：</p>
<table>
<colgroup>
<col style="width: 6%" />
<col style="width: 17%" />
<col style="width: 17%" />
<col style="width: 17%" />
<col style="width: 17%" />
<col style="width: 6%" />
<col style="width: 17%" />
</colgroup>
<thead>
<tr class="header">
<th><span class="math inline">\(w\)</span></th>
<th>0</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>……</th>
<th>9</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td>-0.07776724</td>
<td>0.15514244</td>
<td>0.17544013</td>
<td>0.33805469</td>
<td></td>
<td>0.21515437</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td>-0.52292037</td>
<td>-0.38363097</td>
<td>-0.80726911</td>
<td></td>
<td>-0.44372143</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td>-0.25709792</td>
<td>-0.42717323</td>
<td></td>
<td>-0.42050595</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td>0.41092392</td>
<td></td>
<td>-0.25649878</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>-0.10138744</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>0.02127489</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>0.1134249</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>0.1815334</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>0.23170656</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>0.26874031</td>
</tr>
</tbody>
</table>
<h2 id="bias-variance结构">bias-variance结构</h2>
<p>程序如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 期望计算</span></span><br><span class="line">    predictAll=[]</span><br><span class="line">    T11=[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">        data1 = create_data(<span class="number">25</span>, np.random.uniform(<span class="number">0</span>,<span class="number">0.5</span>))</span><br><span class="line">        X1 = data1[:,<span class="number">0</span>]</span><br><span class="line">        t1 = data1[:,<span class="number">1</span>]</span><br><span class="line">        x1_train, x1_test, T1_train, T1_test = splitData(X1, t1)</span><br><span class="line">        poly_evey=polyRegression(<span class="number">25</span>,<span class="number">100</span>)</span><br><span class="line">        y_allPredict, cv, y_test, y_train, X_test, X_train,w = poly_evey.cv_pridict(X1, t1, <span class="number">5</span>)</span><br><span class="line">        predictAll.append(y_allPredict)</span><br><span class="line">        RMSECV, best_lambda = poly_evey.RMSE_CV(y_allPredict, t1, X1.shape[<span class="number">0</span>])</span><br><span class="line">        poly_evey.fit(x1_train,T1_train,best_lambda)</span><br><span class="line">        t_predict=poly_evey.predict(X1)</span><br><span class="line">        T11.append(t_predict)</span><br><span class="line"></span><br><span class="line">    T1=np.array(T11)</span><br><span class="line">    f_hat=np.average(T1,axis=<span class="number">0</span>)</span><br><span class="line">    poly11=polyRegression(<span class="number">25</span>,<span class="number">100</span>)</span><br><span class="line">    variances=[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> predictAll:</span><br><span class="line">        variance=poly11.variance_cv(i,f_hat)</span><br><span class="line">        variances.append(variance)</span><br><span class="line">    variance=np.average(variances,axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 生成一个新数据集</span></span><br><span class="line">    data2 = create_data(<span class="number">25</span>, np.random.uniform(<span class="number">0</span>, <span class="number">0.5</span>))</span><br><span class="line">    X2 = data2[:, <span class="number">0</span>]</span><br><span class="line">    t2 = data2[:, <span class="number">1</span>]</span><br><span class="line">    x2_train, x2_test, T2_train, T2_test = splitData(X2, t2)</span><br><span class="line">    poly2=polyRegression(<span class="number">25</span>,<span class="number">100</span>)</span><br><span class="line">    y_allPredict, cv, y_test, y_train, X_test, X_train, w = poly2.cv_pridict(X2, t2, <span class="number">5</span>)</span><br><span class="line">    RMSECV, best_lambda = poly2.RMSE_CV(y_allPredict, t2, X2.shape[<span class="number">0</span>])</span><br><span class="line">    poly2.show_Select_lambda(RMSECV)</span><br><span class="line">    bias_2=poly2.bias_cv(y_allPredict,f_hat,X2.shape[<span class="number">0</span>])</span><br><span class="line">    w=np.array(w)</span><br><span class="line">    error=poly2.test_error_cv(y_allPredict,t2,np.logspace(-<span class="number">10</span>,-<span class="number">7</span>,<span class="number">100</span>),w)</span><br><span class="line">    <span class="built_in">print</span>(bias_2)</span><br><span class="line"></span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.plot(np.logspace(-<span class="number">10</span>,-<span class="number">7</span>, <span class="number">100</span>),bias_2,label=<span class="string">&#x27;bias^2&#x27;</span>,color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">    plt.plot(np.logspace(-<span class="number">10</span>,-<span class="number">7</span>, <span class="number">100</span>),variance, label=<span class="string">&#x27;variance&#x27;</span>, color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">    plt.plot(np.logspace(-<span class="number">10</span>,-<span class="number">7</span>, <span class="number">100</span>),bias_2+variance, label=<span class="string">&#x27;bias^2+variance&#x27;</span>, color=<span class="string">&#x27;pink&#x27;</span>)</span><br><span class="line">    plt.plot(np.logspace(-<span class="number">10</span>,-<span class="number">7</span>, <span class="number">100</span>),error,label=<span class="string">&#x27;test error&#x27;</span>, color=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">    ax = plt.gca()</span><br><span class="line">    ax.set_xscale(<span class="string">&quot;log&quot;</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230326185731318.png" alt="image-20230326185731318" style="zoom:80%;" /></p>
<h2 id="degreelambda寻优过程"><span
class="math inline">\(degree\)</span>、<span
class="math inline">\(lambda\)</span>寻优过程</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">rmse_train=[]</span><br><span class="line">rmse_test=[]</span><br><span class="line"><span class="comment"># 寻找最优次数</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    poly = polyRegression(i, <span class="number">50</span>)</span><br><span class="line">    poly.fit(x_train,T_train,<span class="number">0</span>)</span><br><span class="line">    rmse_train.append(poly.RSME(x_train,T_train))</span><br><span class="line">    rmse_test.append(poly.RSME(x_test,T_test))</span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(np.linspace(<span class="number">0</span>,<span class="number">10</span>,<span class="number">10</span>),</span><br><span class="line">         rmse_test,</span><br><span class="line">         label=<span class="string">&#x27;test&#x27;</span>,</span><br><span class="line">         marker=<span class="string">&#x27;o&#x27;</span>,</span><br><span class="line">         markerfacecolor=<span class="string">&#x27;white&#x27;</span></span><br><span class="line">         , markeredgecolor=<span class="string">&#x27;b&#x27;</span>,</span><br><span class="line">         color=<span class="string">&#x27;b&#x27;</span>,</span><br><span class="line">         markeredgewidth=<span class="number">1.5</span>)</span><br><span class="line">plt.plot(np.linspace(<span class="number">0</span>,<span class="number">10</span>,<span class="number">10</span>),rmse_train,</span><br><span class="line">         label=<span class="string">&#x27;train&#x27;</span>,</span><br><span class="line">         marker=<span class="string">&#x27;o&#x27;</span>,</span><br><span class="line">         markerfacecolor=<span class="string">&#x27;white&#x27;</span>,</span><br><span class="line">         markeredgecolor=<span class="string">&#x27;r&#x27;</span>,</span><br><span class="line">         color=<span class="string">&#x27;r&#x27;</span>,</span><br><span class="line">         markeredgewidth=<span class="number">1.5</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;RMSE&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;degree&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line">best_degree=np.argmin(np.array(rmse_test))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;best degree is&#x27;</span>,best_degree)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;min RMSE in test sets:&#x27;</span>,np.<span class="built_in">min</span>(rmse_test))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对最优次数寻找合适的lambda</span></span><br><span class="line">poly = polyRegression(best_degree, <span class="number">50</span>)</span><br><span class="line">poly.fit(x_train, T_train, <span class="number">0</span>)</span><br><span class="line">poly.draw(X,t)</span><br><span class="line">y_allPredict, cv, y_test, y_train, X_test, X_train,w = poly.cv_pridict(X, t, <span class="number">5</span>)</span><br><span class="line">RMSECV, best_lambda = poly.RMSE_CV(y_allPredict, t, X.shape[<span class="number">0</span>])</span><br><span class="line">poly.show_Select_lambda(RMSECV)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;best lambda is&#x27;</span>,best_lambda)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;min RMSE with regularization:&#x27;</span>,np.<span class="built_in">min</span>(RMSECV))</span><br><span class="line">poly_best = polyRegression(best_degree, <span class="number">50</span>)</span><br><span class="line">poly_best.fit(x_train, T_train, best_lambda)</span><br><span class="line">poly_best.draw(X, t)</span><br></pre></td></tr></table></figure>
<p>degree寻优：</p>
<p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230326191813731.png" alt="image-20230326191813731" style="zoom:50%;" /></p>
<p><span class="math inline">\(lambda\)</span>寻优：</p>
<p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230326191840244.png" alt="image-20230326191840244" style="zoom: 67%;" /></p>
正则化前后图像对比：
<center>
<img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230326191928367.png" alt="image-20230326191928367" style="zoom:50%;" />
<img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230326191912106.png" alt="image-20230326191912106" style="zoom:50%;" />
</center>
<p>左图为未正则化，右图为正则化后。输出结果为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">best degree is 5</span><br><span class="line">min RMSE in test sets: 0.11753272730633338</span><br><span class="line">best lambda is 1.8420699693267162e-08</span><br><span class="line">min RMSE with regularization: 0.0998645060490816</span><br></pre></td></tr></table></figure>
<h2 id="样本数目影响">样本数目影响</h2>
<p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">RMSEs=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>,<span class="number">50</span>):</span><br><span class="line">    data=create_data(i,<span class="number">0.25</span>)</span><br><span class="line">    X=data[:,<span class="number">0</span>]</span><br><span class="line">    t=data[:,<span class="number">1</span>]</span><br><span class="line">    X_train, X_test, T_train, T_test=splitData(X,t)</span><br><span class="line">    poly=polyRegression(<span class="number">8</span>,<span class="number">50</span>)</span><br><span class="line">    poly.fit(X_train,T_train,<span class="number">0</span>)</span><br><span class="line">    rmse=poly.RSME(X,t)</span><br><span class="line">    RMSEs.append(rmse)</span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(np.linspace(<span class="number">10</span>,<span class="number">50</span>,<span class="number">40</span>),RMSEs)</span><br><span class="line">plt.ylabel(<span class="string">&quot;RMSE&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;samples&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230326193335597.png" alt="image-20230326193335597" style="zoom:50%;" /></p>
<p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230326193511771.png" alt="image-20230326193511771" style="zoom:50%;" /></p>
<p>上图是样本数量在（10,200）的RMSE图，下图是样本数量在（10,20）的RMSE图，可以明显看出随着样布数目增长RMSE逐渐趋于稳定，仅有很小的波动。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://example.com">脱碳甲醛</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2023/04/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BD%9C%E4%B8%9A/">http://example.com/2023/04/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BD%9C%E4%B8%9A/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">脱碳甲醛的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></div><div class="post_share"><div class="social-share" data-image="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/ typora/99586772_p0.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/04/23/pythonHighDeminsion/"><img class="prev-cover" src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/ typora/99586772_p0.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Python高维数据分析实验报告</div></div></a></div><div class="next-post pull-right"><a href="/2022/09/14/pythonSummry/"><img class="next-cover" src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/ typora/99177471_p0_master1200.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Python基础语法总结</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/%E5%A4%B4%E5%83%8F.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">脱碳甲醛</div><div class="author-info__description">菜狗，心血来潮</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">8</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/DecarburizationFormaldehyde" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:690615906@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎来到海鲜批发市场！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BD%9C%E4%B8%9A%E5%85%AB-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%88%9D%E6%AD%A5"><span class="toc-number">1.</span> <span class="toc-text">作业八 神经网络初步</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#mlpclassifier%E4%BA%8C%E5%88%86%E7%B1%BB"><span class="toc-number">1.1.</span> <span class="toc-text">MLPClassifier二分类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#mlpclassifier%E5%A4%9A%E5%88%86%E7%B1%BB"><span class="toc-number">1.2.</span> <span class="toc-text">MLPClassifier多分类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#mlpregressor"><span class="toc-number">1.3.</span> <span class="toc-text">MLPRegressor</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BD%9C%E4%B8%9A%E4%B8%83-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%88%86%E7%B1%BB"><span class="toc-number">2.</span> <span class="toc-text">作业七 逻辑回归分类</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E5%88%86%E7%B1%BB%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92"><span class="toc-number">2.1.</span> <span class="toc-text">二分类逻辑回归</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E5%88%86%E7%B1%BB%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92"><span class="toc-number">2.2.</span> <span class="toc-text">多分类逻辑回归</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BD%9C%E4%B8%9A%E5%85%AD"><span class="toc-number">3.</span> <span class="toc-text">作业六</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#bayesian-linear-regression"><span class="toc-number">3.1.</span> <span class="toc-text">Bayesian Linear Regression</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%8D%E5%90%8C%E6%A0%B7%E6%9C%AC%E6%95%B0%E9%87%8F%E5%BD%B1%E5%93%8D%E6%8B%9F%E5%90%88%E6%95%88%E6%9E%9C"><span class="toc-number">3.2.</span> <span class="toc-text">不同样本数量影响拟合效果</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E8%B0%83%E4%BC%98"><span class="toc-number">3.3.</span> <span class="toc-text">交叉验证调优</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E6%8B%9F%E6%8B%9F%E5%90%88%E8%BF%87%E7%A8%8B%E4%BC%BC%E7%84%B6%E5%85%88%E9%AA%8C"><span class="toc-number">3.4.</span> <span class="toc-text">模拟拟合过程（似然、先验）</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BD%9C%E4%B8%9A%E4%BA%94"><span class="toc-number">4.</span> <span class="toc-text">作业五</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AD%89%E4%BB%B7%E6%A0%B8%E7%BB%98%E5%88%B6"><span class="toc-number">4.1.</span> <span class="toc-text">等价核绘制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%BC%E7%84%B6"><span class="toc-number">4.2.</span> <span class="toc-text">似然</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BD%9C%E4%B8%9A%E4%B8%80-%E5%A4%9A%E9%A1%B9%E5%BC%8F%E6%8B%9F%E5%90%88"><span class="toc-number">5.</span> <span class="toc-text">作业一 多项式拟合</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%90%86%E8%AE%BA%E6%8E%A8%E5%AF%BC"><span class="toc-number">5.1.</span> <span class="toc-text">理论推导</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">5.2.</span> <span class="toc-text">代码实现</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E6%9E%9C%E5%AF%B9%E6%AF%94"><span class="toc-number">5.3.</span> <span class="toc-text">结果对比</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BD%9C%E4%B8%9A%E4%BA%8C"><span class="toc-number">6.</span> <span class="toc-text">作业二</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A2%91%E7%8E%87%E5%AD%A6%E6%B4%BE%E4%B8%8E%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AD%A6%E6%B4%BE"><span class="toc-number">6.1.</span> <span class="toc-text">频率学派与贝叶斯学派</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BD%9C%E4%B8%9A%E4%B8%89"><span class="toc-number">7.</span> <span class="toc-text">作业三</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E5%87%BD%E6%95%B0%E5%9B%BE%E5%83%8F%E5%A4%8D%E7%8E%B0"><span class="toc-number">7.1.</span> <span class="toc-text">基函数图像复现</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BD%9C%E4%B8%9A%E5%9B%9B-%E5%A4%9A%E9%A1%B9%E5%BC%8F%E6%8B%9F%E5%90%88%E5%8A%A0%E5%BC%BA%E7%89%88"><span class="toc-number">8.</span> <span class="toc-text">作业四 多项式拟合（加强版）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E9%A1%B9%E7%9B%AE%E7%BB%93%E6%9E%84"><span class="toc-number">8.1.</span> <span class="toc-text">实验项目结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B0%83%E6%95%B4beta%E5%92%8Clambda%E8%A7%82%E5%AF%9Frmse%E5%8F%98%E5%8C%96"><span class="toc-number">8.2.</span> <span class="toc-text">调整\(\beta\)和\(\lambda\)观察RMSE变化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AD%A3%E5%88%99%E5%8C%96%E5%89%8D%E5%90%8E%E5%9B%9E%E5%BD%92%E7%B3%BB%E6%95%B0"><span class="toc-number">8.3.</span> <span class="toc-text">正则化前后回归系数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#bias-variance%E7%BB%93%E6%9E%84"><span class="toc-number">8.4.</span> <span class="toc-text">bias-variance结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#degreelambda%E5%AF%BB%E4%BC%98%E8%BF%87%E7%A8%8B"><span class="toc-number">8.5.</span> <span class="toc-text">\(degree\)、\(lambda\)寻优过程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A0%B7%E6%9C%AC%E6%95%B0%E7%9B%AE%E5%BD%B1%E5%93%8D"><span class="toc-number">8.6.</span> <span class="toc-text">样本数目影响</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/04/23/pythonHighDeminsion/" title="Python高维数据分析实验报告"><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/ typora/99586772_p0.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Python高维数据分析实验报告"/></a><div class="content"><a class="title" href="/2023/04/23/pythonHighDeminsion/" title="Python高维数据分析实验报告">Python高维数据分析实验报告</a><time datetime="2023-04-23T11:14:46.000Z" title="发表于 2023-04-23 19:14:46">2023-04-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/04/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BD%9C%E4%B8%9A/" title="机器学习作业"><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/ typora/99586772_p0.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="机器学习作业"/></a><div class="content"><a class="title" href="/2023/04/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BD%9C%E4%B8%9A/" title="机器学习作业">机器学习作业</a><time datetime="2023-04-21T07:14:07.000Z" title="发表于 2023-04-21 15:14:07">2023-04-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/09/14/pythonSummry/" title="Python基础语法总结"><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/ typora/99177471_p0_master1200.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Python基础语法总结"/></a><div class="content"><a class="title" href="/2022/09/14/pythonSummry/" title="Python基础语法总结">Python基础语法总结</a><time datetime="2022-09-14T15:00:09.000Z" title="发表于 2022-09-14 23:00:09">2022-09-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/07/18/day-4/" title="暑期Python学习（四）"><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/ typora/99207958_p0_master1200.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="暑期Python学习（四）"/></a><div class="content"><a class="title" href="/2022/07/18/day-4/" title="暑期Python学习（四）">暑期Python学习（四）</a><time datetime="2022-07-18T15:45:31.600Z" title="发表于 2022-07-18 23:45:31">2022-07-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/07/16/day3/" title="暑期Python学习（三）"><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/ typora/99710643_p0_master1200.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="暑期Python学习（三）"/></a><div class="content"><a class="title" href="/2022/07/16/day3/" title="暑期Python学习（三）">暑期Python学习（三）</a><time datetime="2022-07-16T12:31:02.423Z" title="发表于 2022-07-16 20:31:02">2022-07-16</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By 脱碳甲醛</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>