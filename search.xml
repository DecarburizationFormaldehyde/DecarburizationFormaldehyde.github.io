<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>定式（？）——小目高挂脱先</title>
      <link href="/2024/10/20/%E5%AE%9A%E5%BC%8F%EF%BC%88%EF%BC%9F%EF%BC%89%E2%80%94%E2%80%94%E5%B0%8F%E7%9B%AE%E4%BD%8E%E6%8C%82%E8%84%B1%E5%85%88/"/>
      <url>/2024/10/20/%E5%AE%9A%E5%BC%8F%EF%BC%88%EF%BC%9F%EF%BC%89%E2%80%94%E2%80%94%E5%B0%8F%E7%9B%AE%E4%BD%8E%E6%8C%82%E8%84%B1%E5%85%88/</url>
      
        <content type="html"><![CDATA[<h2 id="定式小目高挂脱先">定式（？）——小目高挂脱先</h2><p>断更久，记录一个之前下出来的棋型，算是一个小飞刀，是相对场合下法。</p><p>首先我们看这个我当时下出来的情况，白12没有继续走断外边的下法，选择了脱先高挂，这时我们复习一个棋型：</p><figure><img src="E:\图片\小目高挂脱先-1.png" alt="小目高挂脱先-1" /><figcaption aria-hidden="true">小目高挂脱先-1</figcaption></figure><h3 id="点三三跳出">点三三跳出</h3><p>在这个经典的三三棋型中一般认为白棋不好脱先，因为白棋脱先，黑棋小尖棋型饱满，补了冲了打，还有先手压缩的味道，是极大的一手。</p><figure><img src="E:\图片\小目高挂脱先-2.png" alt="小目高挂脱先-2" /><figcaption aria-hidden="true">小目高挂脱先-2</figcaption></figure><p>因此在刚才的图中黑棋是有理由不应对白棋的高挂的，局部手割分析的话实际上是白棋损了一个冲的味道和黑棋挡的交换，实际上加厚了黑棋，将来飞出更加硬气了。</p><figure><img src="E:\图片\小目高挂脱先-3.png" alt="小目高挂脱先-3" /><figcaption aria-hidden="true">小目高挂脱先-3</figcaption></figure><p>那么白棋肯定也不乐意了，我挂你小目，这么大你竟敢不理？托上来给你空掏了</p><figure><img src="E:\图片\小目高挂脱先-4.png" alt="小目高挂脱先-4" /><figcaption aria-hidden="true">小目高挂脱先-4</figcaption></figure><p>下面就是定式应法了，白棋要求黑棋给空，黑棋表示能给，但不能给太多：</p><figure><img src="E:\图片\小目高挂脱先-5.png" alt="小目高挂脱先-5" /><figcaption aria-hidden="true">小目高挂脱先-5</figcaption></figure><p>黑棋扳虎坚实，白棋退了一拆快速展开，江维杰（吐槽一下输入法，打出来都是姜维）老师的书中描述此时白稍好（虽然对棋型的评价也是从江老师的书里抄的），但是行棋至此要考虑一点搭配的问题，下面研究有些脱离定式书了就，不一定对，大家辩证学习：</p><h3 id="序盘惨案开端">序盘？惨案开端！</h3><p>此时我的kataGO认为白棋亏了，白棋应该跳出罩住黑棋，或者去右上挂角，我们先看挂角的情况：</p><figure><img src="E:\图片\小目高挂脱先-6.png" alt="小目高挂脱先-6" /><figcaption aria-hidden="true">小目高挂脱先-6</figcaption></figure><p>挂角很容易理解，超大飞是白棋的权利，白棋右下厚势，如果能够先手在右上便宜拿到外势，那么再超大飞搭配良好，白棋有良好的发展。</p><p>当我们看到这张图后，自然不能让白棋便宜那么经营这个右侧模样的要点无非两个一个右上的尖（疑似俗手）或者跳，另一个就是O5的形势消涨的要点，那么现在我们也不难理解为何AI强调要大跳出来罩住白棋，其实与右上一致同样为一个配合问题，我们来摆一个白好的图：</p><figure><img src="E:\图片\小目高挂脱先-7.png" alt="小目高挂脱先-7" /><figcaption aria-hidden="true">小目高挂脱先-7</figcaption></figure><p>白棋先手压缩黑棋阵势，并且经营出来一块摸样左侧也隐隐有成阵势的趋势，显然白棋好下。</p><p>现在我们已经分析好了目前的局面，那么场上几个比较大的点就是：</p><figure><img src="E:\图片\小目高挂脱先-8.png" alt="小目高挂脱先-8" /><figcaption aria-hidden="true">小目高挂脱先-8</figcaption></figure><p>这个点的意思都很明确，都是形势消涨的点，那么我们肯定是希望尽可能走先手把能抢的都抢到，那么排除AB位置，那么我们来看C、D、E、F：</p><figure><img src="E:\图片\小目高挂脱先-9.png" alt="小目高挂脱先-9" /><figcaption aria-hidden="true">小目高挂脱先-9</figcaption></figure><p>E点贴出白棋若脱先，黑棋三间高挂要点，逼迫白棋做活，白棋扳虎局部活棋，轮黑先手，貌似无不可</p><p>同理在F点也是，白棋大可以脱先，但同比贴出，出头速度更快，也更灵巧，E、F点的规划均为将来挂在左上与白棋展开漫长的乱战，但局面上黑棋应稍优</p><p>D点显然对白棋没有威胁，因此不做考虑，C点白棋扳，黑棋长为后手也不太好，当然以上点均可下</p><figure><img src="E:\图片\小目高挂脱先-10.png" alt="小目高挂脱先-10" /><figcaption aria-hidden="true">小目高挂脱先-10</figcaption></figure><p>实战选择飞在F点上，白棋很给面子的应了一手，很快的啊，抢了碰：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/u=1528357968,478459734&fm=253&fmt=auto" alt="img" style="zoom:33%;" /></p><figure><img src="E:\图片\小目高挂脱先-11.png" alt="小目高挂脱先-11" /><figcaption aria-hidden="true">小目高挂脱先-11</figcaption></figure><p>这时AI不再推荐扳了，扳帮黑棋为空，有按摩的嫌疑，实战白棋长一个，这一串瞄着我气紧的问题，但是白7立不好，因为断点依旧存在</p><figure><img src="E:\图片\小目高挂脱先-12.png" alt="小目高挂脱先-12" /><figcaption aria-hidden="true">小目高挂脱先-12</figcaption></figure><p>陆续行棋至此：</p><figure><img src="E:\图片\小目高挂脱先-13.png" alt="小目高挂脱先-13" /><figcaption aria-hidden="true">小目高挂脱先-13</figcaption></figure><p>这里黑白双方暂时都不太肯花一手棋来吃住左下的角，黑10、12目前来看完全是空手套白狼，是没有什么损失的，但是如果爆了白棋两子，基本标志白棋局部布局失败</p><h3 id="人心不足蛇吞象">人心不足蛇吞象</h3><figure><img src="E:\图片\小目高挂脱先-14.png" alt="小目高挂脱先-14" /><figcaption aria-hidden="true">小目高挂脱先-14</figcaption></figure><p>我们继续关注右下的变化，这时黑棋被打吃一子，事实上此子关系甚大，因为黑棋二子头气紧，如脱先，被白棋打了打被爆掉三个子，疑似被吃了棋筋，那么事实真的如此吗？</p><figure><img src="E:\图片\小目高挂脱先-15.png" alt="小目高挂脱先-15" /><figcaption aria-hidden="true">小目高挂脱先-15</figcaption></figure><p>事实上，这时候AI已经给白棋胜率为0了，为什么呢？太小了，白棋出现了判断的问题，不排除也有计算问题，在右上还有挂角的配合大场，选了一个两手棋才能吃掉的子上边，与黑棋补角相比小太多了，然而气紧的黑棋依然诱惑者白棋去花手数去吃：</p><figure><img src="E:\图片\小目高挂脱先-16.png" alt="小目高挂脱先-16" /><figcaption aria-hidden="true">小目高挂脱先-16</figcaption></figure><p>直至黑棋9引征，白棋才逐渐意识到并没有破掉多少黑棋的空，而自己的搭配十分差劲，且被黑棋四处打入，准备在角部乱战，但也为时已晚，后面白棋虽然表现出来了极其强大的力量，但由于序盘阶段对于搭配的理解不够好，最后还是惨败。</p><h3 id="总结">总结</h3><p>疑似挂着羊头卖狗肉了，标题写的定式，实际上全是序盘思想，就这样吧，一时兴起更新一下。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 围棋定式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tranformer全流程零基础解析</title>
      <link href="/2024/07/21/tranformer%E7%BB%86%E8%8A%82%E8%A7%A3%E6%9E%90/"/>
      <url>/2024/07/21/tranformer%E7%BB%86%E8%8A%82%E8%A7%A3%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h2 id="transformer全流程零基础解析">Transformer全流程零基础解析</h2><blockquote><p>[!NOTE]</p><p>诈骗预警：虽然说是零基础，但是还是要有一般的深度学习基础，例如:基本的深度网络概念、pytorch 基本使用、对权重的基本认识等。</p></blockquote><p>本文将详细拆解Transformer的各个基本组件，并且配合基本的代码讲解，另外，本文的零基础为NLP领域零基础用户，需要有一定的深度学习认知，因此本文更偏向专业性，不会偏向通俗科普，但是读完本文可以秒杀市面上所有的Transformer介绍，下面开始正文。</p><p>原文链接：[<a href="https://arxiv.org/abs/1706.03762">1706.03762]Attention Is All You Need (arxiv.org)</a></p><h3 id="前言">前言</h3><p>本文的介绍思路将与市面上的大部分顺序不同，虽然Transformer提出的原文叫做<strong>AttentionIs All You Need</strong>，但是本文并不会优先介绍attention机制（毕竟还有一篇论文叫做<strong>Attention Is Not All You NeedAnymore</strong>），<em>所以在详细介绍attention之前就请把他当作一个线性层罢</em>。</p><h3 id="transformer总览">Transformer总览</h3><p>接下来这张图我们将会反复出现，这张图就是Transformer的总体架构，其主要构成为Encoder-Decoder框架以及外围的结果输出部分和输入嵌入部分，见下图：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240725223605806.png" alt="image-20240725223605806" style="zoom: 67%;" /></p><p>嗯，看到这儿肯定是觉得一脸懵逼的，然后内心一阵暗骂：这都啥玩意？别急，下面我们将按照程序运行的基本顺序来逐个模块进行讲解，基本顺序为输入与嵌入、E-D架构（后面均简称为E-D架构）、输出，按照该顺序我们简单获得一个整体运行的认识。</p><h3 id="输入与嵌入">输入与嵌入</h3><p>相比写的已经烂大街的各种注意力机制的文章，大家最迷糊的一般都是从输入开始的，我们会疑惑的点大概有以下：</p><ul><li>字符串怎么输入？输入后怎么计算？</li><li>嵌入有什么用？又该怎么嵌入？</li><li>位置编码如何发挥作用？又有什么用？</li></ul><p>下面就一个一个的进行解决：</p><h4 id="token">Token</h4><p>我们首先来解决第一个问题，这要牵扯到最最最古老的NLP思想——Token。</p><blockquote><p>Token是指文本中的一个基本单元，通常是词或短语。这个切分token的过程，成为分词（Tokenization）。</p></blockquote><p>我们先简单举个例子：</p><p><code>"Never give up”</code>，考虑对这个句子进行切分，我们很容易想到可以将其切分为<code>-Never-give-up</code>，这是一种基于空格的切分方式，其中Never、give、up都是一个token。</p><p>有些叛逆的同学肯定觉得，我偏不，不就是切分句子吗，我要切分成</p><p><code>-Nevergive-up</code>。甚至还有一些更叛逆的同学想：你说通常token是词或短语是不是也有不太通常的情况，我就要这样切<code>-N-e-v-e-r-g-i-v-e-u-p</code>。</p><p>虽然上面两个同学他都有一定的歪理，但是别忘了我们要解决的问题是什么。我们希望计算机能够理解自然语言，然而计算机并不能对字符串进行什么运算处理，因此我们应该力求通过分割句子的方式来让计算机理解句子的意义。</p><p>于是，词表（Vocabulary）出现了，词表是一个由token与数字组成的一个dict（hashmap）。计算机固然没办法理解一个字符形式的token，但理解一个与token对应的数字还是可以做到的。这让我想起一句话：语言不是什么玄而又玄的，而是十分符合统计学的。</p><p>然后我们来仔细聊聊分词罢。</p><h4 id="tokenization">Tokenization</h4><p>我们刚才说两个同学都有一定歪理，是的，他俩甚至犟嘴的都有道理，甚至都有一定程度的应用。Tokenization在 Transformer 中所处的位置如下：</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240728093346164.png"alt="image-20240728093346164" /><figcaption aria-hidden="true">image-20240728093346164</figcaption></figure><p>目前，分词任务有三个粒度的分词，分别是：</p><ul><li>词粒度</li><li>字粒度</li><li>Subword 粒度</li></ul><p>再介绍这些分词的情况与手段前，我们先回顾并提出一点问题：</p><ul><li>我们要解决的问题是有意义的分出token</li><li>需要兼顾词表的大小与推理速度</li><li>能不能保证模型能够认识从来没见过的词，即，OOV（Out ofVocabulary）问题</li></ul><h5 id="词粒度">词粒度</h5><p>词粒度基本是最直观的分词手段了，也是最符合我们平时认知的方式。英语的话，由于词与词之间存在空格，就非常方便的可以完成分词，中文的话相对比较麻烦。</p><p>优点：</p><ul><li>非常的人类、能很好的保持语义信息</li></ul><p>缺点</p><ul><li>会有一张超级大的词表</li><li>难以避免OOV问题<ul><li>或许存在一些解决方法：使用未知标记（UNK）</li></ul></li><li>一些同前缀、同后缀的单词难以获得相关性</li></ul><h5 id="字粒度">字粒度</h5><p>字粒度比较狠，就直接分成一个个的字母，这种对于中文而言就比较亲民了，英文划分后几乎是没什么含义的</p><p>优点：</p><ul><li>词表规模大大减小</li><li>很少出现未知词汇，基本都可以组合</li></ul><p>缺点：</p><ul><li>没有太多语义信息</li><li>句子切分得到的token 数量大大增加，提高运算量。</li></ul><h5 id="subword子词粒度">Subword（子词）粒度</h5><p>当我们看到上面两种方式各有优劣，那我们能不能折中一下（折中！）拥有两个优点？</p><p>举个例子就可以简单理解了：</p><blockquote><p>例句：he is likely to be unfriendly to me</p><p>分词：‘he' 'is' 'like' 'ly' 'to' 'be' 'un' 'friend' 'ly' 'to''me'</p></blockquote><p>现在优点就很明显了：</p><ul><li>词表尽可能小，因为可以用尽量少的子词来组成词汇</li><li>有更好的泛化能力，可以学习到词汇之间的变化与关系</li></ul><p>划分子词的方法有常见的几种：</p><ul><li>Byte Pair Encoding（BPE）</li><li>WordPiece</li><li>SentencePiece</li></ul><p>我们简单聊聊BPE方法罢。</p><h6 id="bpe">BPE</h6><p>BPE的构造流程和哈夫曼树非常像，其算法流程如下：</p><ol type="1"><li>规定subword词表的大小</li><li>在每个单词后加上&lt;/w&gt;，此举的目的在于区分一些前缀和后缀</li><li>将语料库中的所有单词划分为单个字符，用所有的单个字符建立最初的词典，并统计每个字符的概率</li><li>挑出频次最高的字符对，然后重复2，3直到到达规定的词表的大小</li></ol><p>然后简单举个例子：</p><blockquote><p>a tidy tiger tied a tie tighter to tidy her tiny tail</p></blockquote><p>1.给单词后边加上&lt;/w&gt;，并统计每个词出现的频率</p><blockquote><p>​ 'a </w>': 2, ​ 't i d y </w>': 2, ​ 't i g e r </w>': 1, ​ 't i e d</w>': 1, ​ 't i e </w>': 1, ​ 't i g h t e r </w>': 1, ​ 't o </w>': 1, ​'h e r </w>': 1, ​ 't i n y </w>': 1, ​ 't a i l </w>': 1,</p></blockquote><ol start="2" type="1"><li>拆成单个字符，并统计频率，构成初始的子词词典</li></ol><blockquote><p>'</w>': 12, 'a': 3, 't': 10, 'i': 8, 'd': 3, 'y': 3, 'g': 2, 'e': 5,'r': 3, 'h': 2, 'o': 1, 'n': 1, 'l': 1,</p></blockquote><ol start="3" type="1"><li>统计语料中相邻子词对的出现频率，选取频率最高的子词对合并成新的子词加入词表，并更新词典</li></ol><blockquote><p>'</w>': 12, 'a': 3, 't': 3, # [修改] 'i': 1, # [修改] 'd': 3, 'y': 3,'g': 2, 'e': 5, 'r': 3, 'h': 2, 'o': 1, 'n': 1, 'l': 1, 'ti': 7, #[增加]</p></blockquote><p>以此类推，BPE 实现代码在[4]中有，感兴趣可以看一下</p><h5 id="tokenization-总结">Tokenization 总结</h5><p>盗张图先（），这是 RNN 接受token并处理的过程。</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/rnn.gif" alt="rnn" style="zoom: 67%;" /></p><p>从上图我们可以看出来，Tokenization的本质其实就是一个字符到数字的映射，<strong>其维护的是一个字典，而不是权重</strong>，也就是说每一个字符or词or短语都有一个唯一确定的数字与其对应，是不是有点熟悉，没错，one-hot就是这样的，但是明显one-hot太笨了，有没有更强一点的算法呢？</p><h4 id="embedding">Embedding</h4><p>首先，我们来看Input Embedding 和 OutputEmbedding，在这之前我们有必要了解一下什么是embedding以及为什么要embedding。</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240728093023512.png" alt="image-20240728093023512" /></p><h5 id="为什么不直接用token">为什么不直接用token？</h5><p>当我们有一些实践经验后，我们可以清晰地看到Tokenization后的结果：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240728110916819.png" alt="image-20240728110916819" /></p><p>而其真正的输入方式正是用one-hot编码的形式，通过矩阵输入，也就是说token对应的正是one-hot编码中的<code>1</code>的index</p><p>所以现在就很清晰了，one-hot编码最大的问题就是：他是一个正交矩阵，这就意味着词与词之间不存在任何的相关性，因此有必要开发一种新方法。</p><h5 id="word2vec">word2vec</h5><p>又是一个名词，word2vec，全称应该叫：word to vector，这就很好理解了，是把词翻译为向量的模型。word2vec包含两个模型：skip-gram 和 CBOW 。</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/1_bBETsVNLyjnaFJgM9avkeQ.webp" /></p><h6 id="skip-gram">skip-gram</h6><p>skip-gram（跳元模型），其核心要义就是在给定中心词的情况下，来生成上下文词的条件概率。例如，给定一句话</p><blockquote><p>The man loves his son.</p></blockquote><p>设定中心词为<code>loves</code>，skip-gram模型考虑上下文生成词的条件概率：<span class="math display">\[P(&#39;the&#39;,&#39;man&#39;,&#39;his&#39;,&#39;son&#39;|&#39;loves&#39;)=P(&#39;the&#39;|&#39;loves&#39;)P(&#39;man&#39;|&#39;loves&#39;)P(&#39;&#39;his&#39;|&#39;loves&#39;)P(&#39;son&#39;|&#39;loves&#39;)\]</span>了解这么多也差不多了（由于公式很怪），我们来简单粗暴的总结一下skip-gram的任务，skip-gram要在给定一个词的情况下，找出上下文概率最大的词，也就是一个多分类任务，那么下面该怎么做，我想大家应该心里都有数吧（）</p><p>决定还是继续写一下，简单写一下公式，小结的时候再理解一次本质。那么，当给定一个中心词<spanclass="math inline">\(\omega_c\)</span>去预测上下文中的一个词<spanclass="math inline">\(\omega_o\)</span>的概率那么就可以表示为 <spanclass="math display">\[P(\omega_o|\omega_c)=\frac{exp(u_o^Tv_c)}{\sum_{i\in V}exp(u_i^Tv_c)}\]</span> 其中，<span class="math inline">\(u\)</span> 和 <spanclass="math inline">\(v\)</span>均为一个向量，分别表示上下文和中心词。</p><h6 id="cbow">CBOW</h6><p>CBOW（连续词袋模型），其实就是正好和skip-gram是反的，skip-gram给定中心词预测多个上下文，而CBOW是给定上下文进行选词填空，实际上，连续词袋模型依旧是一个分类任务，其模型大体上也和skip-gram相似。</p><p>在这里不再赘述公式（因为我觉得看了也看不太懂）</p><h6 id="word2vec-小结">word2vec 小结</h6><p>基本了解原理后，我们来从头来理解一下，word2vec的输入实际上是one-hot编码，而其架构实际上就是一个很简单的MLP，那么这个过程我们就可以很简单的表示为：<span class="math display">\[u^{&#39;}=Wu\]</span> <imgsrc="http://mccormickml.com/assets/word2vec/matrix_mult_w_one_hot.png"alt="使用独热向量进行矩阵乘法的影响" /></p><p>所以，实际上我们可以将one-hot编码理解为一种在MLP权重中查询知识的过程，而输出结果就是一个嵌入表示向量，而这个输出结果实际上是<strong>可逆的</strong>（就是一个矩阵方程而已）。</p><p>然而在实现的时候，比如skip-gram因为要查询整个词表，会有极大的运算负担，因此提出了负采样的优化方案，这里就要不继续介绍了。</p><h4 id="位置编码">位置编码</h4><p>位置编码是Transformer中很重要的一部分，再介绍位置编码之前，我们要先区分一下encoding和embedding。</p><p>embedding我们刚在前面介绍过，embedding是将token转换为一种稠密向量（与one-hot的稀疏向量对应）的手段，encoding（编码）同样也是一种生成词向量的方式，二者不同点主要有二：</p><ul><li>embedding主要指通过神经网络生成词向量的黑盒模式，而encoding是通过公式可以直观理解的白盒生成（如one-hot）</li><li>embedding更侧重于嵌入的词向量结果，而encoding更侧重于编码的过程而不是词向量结果</li></ul><p>接下来，我们要回答几个问题：</p><ul><li>为什么要有位置编码？</li><li>位置编码原理如何？有何缺点？该作何改进？</li><li>位置编码是怎么作用于任务的？</li></ul><h6 id="为什么要有位置编码">为什么要有位置编码</h6><p>位置编码，顾名思义，就是通过一套规则对序列中元素的位置进行唯一的编码。那么为什么要有位置编码呢？</p><p>在旧时代的NLP中，我们一般使用CNN/RNN来建模文本，其中CNN可以编码一定的绝对位置信息（很大程度上来自zero-padding），而RNN的序列依赖特性更是天生适合序列问题或者位置信息的建模。因此，在旧时代的NLP，基本无须单独做位置编码。</p><p>Transformer和以前的应用于序列学习的框架并不同，其在计算时并不会参考位置，即使位置调换也完全没有关系（留个伏笔，等写到attention再回收）,因此需要添加位置编码作为位置信息。</p><h6 id="位置编码分类与介绍">位置编码分类与介绍</h6><p>位置编码一般被分为两种：<strong>绝对位置编码</strong>和<strong>相对位置编码</strong>。</p><p><em>绝对位置编码</em>，也就是每个元素大家一人一个数字分别对应自己的index，还有一些模型采用了可学习的位置编码，例如bert</p><p>最常见的绝对位置编码也就是我们常用的数组index了，这具有一个很显著的缺点，按照这种编码方式，那么越是后面的元素其位置编码权重越大，因为越是后面的元素其位置编码值越大。（就是这么简单粗暴）</p><p><em>相对位置编码</em>，即考虑词与词之间的相对位置，<strong>而不是单纯的考虑其所在的位置。</strong></p><h6 id="正余弦位置编码">正余弦位置编码</h6><p>Transformer 中使用的经典正余弦位置编码属于绝对位置编码，其公式如下：<span class="math display">\[PE(pos,2i)=sin(\frac{pos}{10000^{\frac{2i}{d_{model}}}}) \\PE(pos,2i+1)=cos(\frac{pos}{10000^{\frac{2i}{d_{model}}}})\]</span> 其中<spanclass="math inline">\(pos\)</span>表示其所在的位置，<spanclass="math inline">\(2i\)</span> 和 <spanclass="math inline">\(2i+1\)</span> 表示位置编码内的维度索引，而<spanclass="math inline">\(d_{model}\)</span>表示词向量的维度。这看起来有点抽象，那让我们变形一下，让他变得直观一点：<span class="math display">\[PE_{pos}=\begin{bmatrix}sin(\omega_1\cdot pos)\\cos(\omega_1\cdotpos)\\sin(\omega_2\cdot pos)\\cos(\omega_2\cdotpos)\\\vdots\\sin(\omega_{d/2}\cdot pos)\\cos(\omega_{d/2}\cdotpos)\end{bmatrix}\]</span> 其中，<spanclass="math inline">\(\omega_i=\frac{1}{10000^{\frac{2i}{d_{model}}}}\)</span>，现在看着是不是舒服多了，那么这个编码到底是怎么来表示出位置关系的呢？</p><p>首先我们先回忆一下二进制表示十进制：</p><table><thead><tr class="header"><th>十进制</th><th>二进制</th></tr></thead><tbody><tr class="odd"><td>0</td><td>0000</td></tr><tr class="even"><td>1</td><td>0001</td></tr><tr class="odd"><td>2</td><td>0010</td></tr><tr class="even"><td>3</td><td>0011</td></tr><tr class="odd"><td>4</td><td>0100</td></tr><tr class="even"><td>5</td><td>0101</td></tr><tr class="odd"><td>6</td><td>0110</td></tr><tr class="even"><td>7</td><td>0111</td></tr><tr class="odd"><td>8</td><td>1000</td></tr></tbody></table><p>——待续——</p><h4 id="总结">总结</h4><blockquote><p><strong>交趾之南有越裳国。周公居摄六年，制礼作乐，天下和平。越裳以三象重译而献白雉。</strong></p></blockquote><div style="text-align: center;"><p><iframe    id="ppt"    width="100%"    src="https://onedrive.live.com/embed?resid=F0D7612D44C925FB%21550&authkey=!AJ96EnctAg9b05Q&em=2"    frameborder="0"    style="display: block; max-width: 960px; margin: auto;"></iframe></p></div><h3 id="参考内容">参考内容</h3><p>[1] <ahref="https://www.analyticsvidhya.com/blog/2020/05/what-is-tokenization-nlp/">Whatis Tokenization in NLP? Here’s All You Need To Know</a></p><p>[2] <ahref="https://mp.weixin.qq.com/s/0ewnWvf8sQflmamcXpcUfQ">小米面试官：“Tokenization是什么”。封面看着眼熟 (qq.com)</a></p><p>[3] <ahref="https://blog.csdn.net/wsmrzx/article/details/129296403">NLP学习笔记(十)分词(下)-CSDN博客</a></p><p>[4] <a href="https://zhuanlan.zhihu.com/p/695414398">BPE（Byte PairEncoding）算法python实现 - 知乎 (zhihu.com)</a></p><p>[5] <ahref="https://zh.d2l.ai/chapter_natural-language-processing-pretraining/word2vec.html">14.1.词嵌入（word2vec） — 动手学深度学习 2.0.0 documentation (d2l.ai)</a></p><p>[6] <ahref="https://www.analyticsvidhya.com/blog/2021/07/word2vec-for-word-embeddings-a-beginners-guide/">Word2VecFor Word Embeddings -A Beginner's Guide (analyticsvidhya.com)</a></p><p>[7] <a href="https://jalammar.github.io/illustrated-word2vec/">TheIllustrated Word2vec – Jay Alammar – Visualizing machine learning oneconcept at a time. (jalammar.github.io)</a></p><p>[8] <a href="https://www.cnblogs.com/peghoty/p/3857839.html">word2vec中的数学原理详解 - peghoty - 博客园 (cnblogs.com)</a></p><p>[9] <ahref="http://www.bimant.com/blog/transformer-positional-encoding-illustration/">Transformer位置编码图解- BimAnt</a></p><p>[10] <ahref="https://blog.csdn.net/v_JULY_v/article/details/134085503">一文通透位置编码：从标准位置编码、旋转位置编码RoPE到ALiBi、LLaMA2 Long(含NTK-aware简介)-CSDN博客</a></p><p>[11] <a href="https://zhuanlan.zhihu.com/p/626828066">【OpenLLM009】大模型基础组件之位置编码-万字长文全面解读LLM中的位置编码与长度外推性（上）- 知乎 (zhihu.com)</a></p><p>[12] <ahref="https://kazemnejad.com/blog/transformer_architecture_positional_encoding/">Transformer架构：位置编码 - Amirhossein Kazemnejad 的博客</a></p><p>[13] <ahref="https://blog.csdn.net/xian0710830114/article/details/133377460">一文搞懂Transformer的位置编码_transformer位置编码-CSDN博客</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>多元统计学（一）</title>
      <link href="/2024/06/11/%E5%A4%9A%E5%85%83%E7%BB%9F%E8%AE%A1%E5%AD%A6%EF%BC%88%E4%B8%80%EF%BC%89/"/>
      <url>/2024/06/11/%E5%A4%9A%E5%85%83%E7%BB%9F%E8%AE%A1%E5%AD%A6%EF%BC%88%E4%B8%80%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h2 id="多元统计学一">多元统计学（一）</h2><p>ok，又是新坑，我们来搞一下多元统计学，狠狠的补充一下基础。数学和那啥人工智能基础还不太一样，这玩意就抽象太多了，嗯，因此咱就只能尽可能融入一些自己的理解，但是就会让这个数学描述不甚严谨。（音乐预警）</p><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="100%" height="86" src="//music.163.com/outchain/player?type=2&amp;id=2103661510&amp;auto=0&amp;height=66"></iframe><h3 id="多元">多元</h3><p>首先，笔者默认大家是掌握了基本的概率论与数理统计的，这样我们就可以减少很多东西的介绍，而进行直接推广理解。</p><p>在各位的大二的概率论与数理统计和高等数学中已经很好的接触了二元函数乃至多元函数，但是如果我说线性代数先天和多元函数很般配呢（）</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240612230038124.png" alt="image-20240612230038124" /></p><p>咳咳，虽然画风有点子诡异。既然我们要聊多元统计，总要先聊聊多元的理解。通俗一点的讲，我们首先来回顾二维平面下对于一个点的表示：</p><p>存在一个直角坐标系<spanclass="math inline">\(XoY\)</span>，则在该平面的点均可以表示为一个二元数对（或许称之为一个二元关系也不是不行），记作<spanclass="math inline">\((x,y)\)</span>。我们理解一下，如果在直线上表示一个点可以表示为<spanclass="math inline">\(x=x_1\)</span>，二维平面上表达为<spanclass="math inline">\((x,y)=(x_1,y_1)\)</span>​，实际上对于空间上的一个点的表示可以简单理解为几个坐标的简单罗列，这时向量刚好起到了这个作用！</p><p><strong>理解1：在高维空间中，向量就可以表示一个点</strong></p><p>现在，我们重新建立一下观念，那么不管多少维的数据（其实就是要给点），那么我们都可以转换为一个向量<spanclass="math inline">\(\mathbf{x}\)</span>（特别强调：加粗小写x才是向量）</p><p>现在我们就可以获得一个统一的函数描述，数学表达为： <spanclass="math display">\[z=f(\mathbf{x})\]</span> 好的，现在我们进入多元的世界罢。</p><h3 id="多元随机变量">多元随机变量</h3><p>其实理解随机变量就理解为是一个向量<spanclass="math inline">\(\mathbf{x}\)</span>（如果需要了解随机变量与随机样本的话咱可以单独写一下），但是在统计学中是要把随机变量记作大写字母的（怪麻烦的，很可能与后边的描述有冲突），这块需要大家自己去看一下阅读材料</p><p>分布函数：这里服从二元定义的推广（能够直接导出概率）</p><p>密度函数：这里服从二元定义的推广（对其各个维度积分得到分布函数）</p><p>独立性：服从二元定义，注意这里的定义很严格，切忌凭自己感觉来判断</p><p>期望：服从基本定义，记作<spanclass="math inline">\(\mu=E(X)\)</span></p><p>协方差矩阵：由于在多元统计中，变量为一个向量<spanclass="math inline">\(\mathbf{x}\)</span>，因此对一个随机变量求方差实际上是得到一个矩阵，也就是协方差矩阵<spanclass="math inline">\(\Sigma\)</span>，同样对两个随机变量<spanclass="math inline">\(x,y\)</span>​，也可以采用相同方法求二者的协方差矩阵</p><h3 id="统计距离">统计距离</h3><p>这里我们来描述一下两个比较著名的距离，欧式距离和马氏距离</p><p>欧式距离和马氏距离最大的区别就是在度量尺度上的一个改进</p><h4 id="欧式距离"><strong>欧式距离</strong></h4><p><span class="math display">\[d(P,Q)=\sqrt{(x_1-y_1)^2+(x_2-y_2)^2+\cdot\cdot\cdot+(x_n-y_n)^2}\]</span></p><p>欧式距离中，每个分量（或称维度/坐标轴，全看你理解的舒适程度）对距离的贡献一致，而且两个分量之间距离不一定具有意义，原因是两个分量不一定都拥有相同的尺度，分量1单位为cm，分量2单位为km，即使二者值完全相同，例如，<spanclass="math inline">\(x_1=50cm,x_2=0.5m,y_1=30cm,y_2=0.3m\)</span>,但是对距离的贡献却是不同的。</p><h4 id="马氏距离">马氏距离</h4><p>其实我们早就接触过了这种思想，即标准化，既然单位（衡量尺度）有问题，那么我们就通过一些手段来统一单位</p><p>马哈拉诺比斯距离，是用来衡量分布间距离的一种手段，即在总体<spanclass="math inline">\(G:N(\mu,\Sigma)\)</span>种抽取的随机样本<spanclass="math inline">\(X,Y\)</span>下，两点之间的距离为： <spanclass="math display">\[d_m^2(X,Y)=(\mathbf{X}-\mathbf{Y})^T\mathbf{\Sigma^{-1}}(\mathbf{X}-\mathbf{Y})\]</span> 如何理解呢，我们首先来看<spanclass="math inline">\((\mathbf{X}-\mathbf{Y})^T(\mathbf{X}-\mathbf{Y})\)</span>，在很久很久以前我们学习二次型的时候是不是记得二次型的表示为<span class="math display">\[\mathbf{X}\Lambda\mathbf{X}^T\]</span>所以这个定义是什么意思，就很明白了，即普普通通的各个轴上的距离的平方再乘以协方差逆，达到无量纲化的目的</p><h3 id="多元高斯分布">多元高斯分布</h3><p>在认识一个分布的时候我们需要认识几点：概率密度，分布函数，期望，方差，基本性质。下面就围绕这几点进行简单介绍：</p><p>首先我们回顾一元高斯的密度函数： <span class="math display">\[f(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}\]</span> 可将其改写为： <span class="math display">\[f(x)=(2\pi)^{-\frac{1}{2}}\sigma^{-1}exp[-\frac{1}{2}(x-\mu)^T(\sigma^2)^{-1}(x-\mu)]\]</span> 可以推广为多元高斯分布： <span class="math display">\[f(\mathbf{x})=(2\pi)^{-\frac{p}{2}}|\Sigma|^{-\frac{1}{2}}exp[-\frac{1}{2}(\mathbf{x}-\mu)^T\Sigma^{-1}(\mathbf{x}-\mu)]\]</span> 其中，<spanclass="math inline">\(p\)</span>为p元正态分布，其中<spanclass="math inline">\(x\in R^{p\times 1}\)</span>，<spanclass="math inline">\(E(\mathbf{X})=\mu,D(\mathbf{X})=\Sigma\)</span></p><h3 id="总结">总结</h3><p>这玩意我确实不擅长写，但是这章基本为基础知识，等着快进到算法就舒服了。</p><h3 id="自主阅读">自主阅读</h3><p>教材：</p><iframe src="多元统计分析 第5版_何晓群_第一章.pdf" width="800px" height="800px" frameborder="0" scrolling="no"></iframe>]]></content>
      
      
      
        <tags>
            
            <tag> 多元统计分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>定式——无忧角托</title>
      <link href="/2024/05/31/%E5%AE%9A%E5%BC%8F%E2%80%94%E2%80%94%E6%97%A0%E5%BF%A7%E8%A7%92%E6%89%98/"/>
      <url>/2024/05/31/%E5%AE%9A%E5%BC%8F%E2%80%94%E2%80%94%E6%97%A0%E5%BF%A7%E8%A7%92%E6%89%98/</url>
      
        <content type="html"><![CDATA[<h2 id="定式无忧角托">定式——无忧角托</h2><p>嗯，开新坑，主要是对于一些角部定式手段的记录，变化图不一定能写全，第一次尝试写这种文章，写的不好请指正。</p><p>首先摆一个常见的开局：</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/%E6%97%A0%E5%BF%A7%E8%A7%92%E6%89%98.png"alt="无忧角托" /><figcaption aria-hidden="true">无忧角托</figcaption></figure><p>虽然在AI视角来看，托并不是最优的一手，但是托能够衍生出很复杂的考验，对于新手而言会产生比较复杂的判断问题。</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/%E6%97%A0%E5%BF%A7%E8%A7%92%E6%89%98-1.png"alt="无忧角托-1" /><figcaption aria-hidden="true">无忧角托-1</figcaption></figure><p>这里大概有三个点可以考虑</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/%E6%97%A0%E5%BF%A7%E8%A7%92%E6%89%98-2.png"alt="无忧角托-2" /><figcaption aria-hidden="true">无忧角托-2</figcaption></figure><h3 id="挡的下法">挡的下法</h3><p>走在A位，黑棋表示忍让，未来依旧是一个平稳的布局，二者大体两分，但白棋略亏，因为白棋爬在二路，而黑棋已经在上方形成了牢固的实地。</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/%E6%97%A0%E5%BF%A7%E8%A7%92%E6%89%98-3.png"alt="无忧角托-3" /><figcaption aria-hidden="true">无忧角托-3</figcaption></figure><h3 id="外扳的下法">外扳的下法</h3><p>走在B位，是黑棋强硬的一手，要求把白棋杀死在角部，这时白棋大体只能扭断战斗，在角部腾挪是很困难的，而黑棋也基本职能无奈单长一个，行棋至此，白棋可以脱先了。</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/%E6%97%A0%E5%BF%A7%E8%A7%92%E6%89%98-4.png"alt="无忧角托-4" /><figcaption aria-hidden="true">无忧角托-4</figcaption></figure><p>那，为什么只能无奈单长呢？</p><h4 id="含蓄要求保留实地">含蓄要求保留实地</h4><p>黑棋打在外面，白棋爬在三路取得外势，完全回到两分，白棋取得一个硬头和外势，黑棋取得实地，但效率极低，故不肯，比如左上棋型立二拆一，且角部仍有先手骚扰。</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/%E6%97%A0%E5%BF%A7%E8%A7%92%E6%89%98-5.png"alt="无忧角托-5" /><figcaption aria-hidden="true">无忧角托-5</figcaption></figure><h4 id="直接要求保留实地">直接要求保留实地</h4><p>变化图1，可以看到白棋想要直接保留角部时，由于棋型缺陷被白棋分断，右侧黑一子被撞伤；可能感觉黑棋拔花可以接受，但黑花被白棋限制，发展空间有限。</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/%E6%97%A0%E5%BF%A7%E8%A7%92%E6%89%98-6.png"alt="变化图1" /><figcaption aria-hidden="true">变化图1</figcaption></figure><p>变化图2，可以看到当黑棋直接粘时，白棋不是直接串烂黑棋，而是先手打一下，现在是白棋优的局面，因为白棋在外面白白（指的是几乎完全没有损失）取得了三个子，而且这里会让黑棋有一种陷入泥潭的感觉</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/%E6%97%A0%E5%BF%A7%E8%A7%92%E6%89%98-7.png"alt="变化图2" /><figcaption aria-hidden="true">变化图2</figcaption></figure><p>如果后续走成下图，白棋在外面每一手棋都有25目的价值，而黑棋基本上都是几目棋的价值，而且是厚上加厚棋型，显然是不好的。</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/%E6%97%A0%E5%BF%A7%E8%A7%92%E6%89%98-8.png"alt="无忧角托-8" /><figcaption aria-hidden="true">无忧角托-8</figcaption></figure><h3 id="内扳的下法">内扳的下法</h3><p>内扳如果手割分析，黑棋尖了一飞，白棋走在二路，明显亏损，因此白字明显为一个弃子，要看轻，通过黑棋飞的弱点来取得外势，略有亏损，仍可以接受。</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/%E6%97%A0%E5%BF%A7%E8%A7%92%E6%89%98-9.png"alt="无忧角托-9" /><figcaption aria-hidden="true">无忧角托-9</figcaption></figure><h3 id="总结">总结</h3><p>无忧角托的定式，大部分是白有小亏损的，是不如直接碰无忧角的，但是外扳下法可能可以考验一下对手的判断，一旦黑棋下错，则黑棋大损。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 围棋定式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>超图简单入门</title>
      <link href="/2024/05/02/%E8%B6%85%E5%9B%BE%E7%AE%80%E5%8D%95%E5%85%A5%E9%97%A8/"/>
      <url>/2024/05/02/%E8%B6%85%E5%9B%BE%E7%AE%80%E5%8D%95%E5%85%A5%E9%97%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="超图简单入门">超图简单入门</h2><p>经过小两个月的调（bai）整（lan），堂堂复更（但精神状态不佳）！</p><p>最近在研究一些图模型的工作，因此决定写一写记录一下，记录一下最近的工作。</p><h3 id="图模型">图模型</h3><p>首先，简单讲一下图模型（graph），图模型可以定义为<spanclass="math inline">\(G=&lt;N,E&gt;\)</span>，即通过一个边集合<spanclass="math inline">\(E\)</span>，和一个点集合<spanclass="math inline">\(N\)</span>组成。其中边集通过二元关系来描述，即<spanclass="math inline">\(E=\{\}\)</span></p><p>——————————未完待续——————————</p>]]></content>
      
      
      
        <tags>
            
            <tag> 图模型与复杂网络建模 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习中的优化</title>
      <link href="/2024/02/23/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%BC%98%E5%8C%96/"/>
      <url>/2024/02/23/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%BC%98%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<h2 id="深度学习中的优化">深度学习中的优化</h2><p>听着挺高端的是不，还听着挺难的，确实，单单来讲里边的数学确实有点子麻烦，但是我们有了一些计算机工具，我们就不需要从数学推导角度去深度的理解了。</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/v2-b7cc78b42bd5c9c03686e5e3765d6751_r.jpg" alt="img" style="zoom:33%;" /></p><h3 id="优化与凸优化">优化与凸优化</h3><p>无论如何我们都是无法避开讲一些数学的，（虽然俺的数学是个二把刀）我们尽力少用一些抽象的数学表达来描述清楚，但也会有一些朴素且不严谨（对于理解是无伤大雅的）</p><h4 id="优化">优化</h4><p>首先优化是什么呢？为了变得更好而采取的动作。优化实际上和规划是很像的（其实优化是规划的子集），（<del>有一说一现在高考连线性规划都不学了</del>）都有某个目标函数和某些约束模型，最终得到最佳的参数组合。举个例子，我们知道找一个函数的最值我们需要用导数来寻找，但是可不可以通过某种搜索的方法穷举出最值呢？就拿一个二次函数来讲：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240224102140786.png" style="zoom:50%;" /></p><p>右上角的点为随机选择的初始点，我们希望找一个下坡路从而找到一个低点（是不是有点贪心的感觉，所以他也会有贪心出现的错误），然后逐渐逼近最低点，用数学的方式表达：<span class="math display">\[argmin \ x^2\]</span> 没有约束条件，用到的求解方法表现为： <spanclass="math display">\[x_{t}=x_{t-1}-\eta \ \omega\]</span>其中各种符号具体是什么意思，稍后我们在解释，我们先来看另一种情况：</p><p><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240224111422091.png" /></p><p>我们依旧采用原来的算法，但是会发现：诶好像这个不是最小值，这也就是我们刚才提到的贪心的弊端，他没有全局视野，就很容易搜索到局部（极值）而不是最值，这也是我们接下来要面对的挑战之一。</p><p>回到深度学习上来，深度学习中的优化主要体现在使模型的loss函数的值尽可能小，从而训练得到尽可能完美的参数。同时我们会认识到不是所有的机器学习都涉及优化，比如一些有解析解的机器学习方法我们就不需要进行优化。</p><h4 id="凸优化">凸优化</h4><p>至于凸优化我们就迅速略过，凸优化涉及的数学知识就有点难理解了，挑两个重点公式和概念提一嘴：</p><p><strong>凸集：</strong>对于一个集合<spanclass="math inline">\(X\)</span>，任意一个<spanclass="math inline">\(a,b\in X\)</span>，都有<spanclass="math inline">\(\lambda a+(1-\lambda)b \in X\)</span>，其中<spanclass="math inline">\(\lambda \in [0,1]\)</span>，那么称集合<spanclass="math inline">\(X\)</span>为凸的。</p><p>用人话来说的话就是一个集合中两点的连线扔在集合中，为什么是这样表示呢，我们设想一个点集，那么<spanclass="math inline">\(a,b\)</span>最佳的表达方式其实一个向量对吧，是的，当我们进入深度学习后要习惯以向量视角看问题，那么我们对上面的公式进行整型：<span class="math display">\[\lambda a+(1-\lambda)b=\lambda(a-b)+b\]</span> 这样我们发现这刚好是一条线段上的所有点</p><p><strong>凸函数：</strong>这里我们就按照高数中的凸函数进行理解即可<span class="math display">\[f(\lambda x+(1-\lambda)x^{&#39;}) \leq \lambdaf(x)+(1-\lambda)f(x^{&#39;})\]</span><em>p.s.</em>这里还有个小故事，大家感兴趣可以去查一下，国内和国外的数学教材凸凹定义其实是反的</p><p><strong>性质</strong></p><p>性质大多是比较重要的，我们就记一下就好了（就别证明了罢）</p><ul><li>凸优化中局部极小值即为全局极小值</li><li>凸优化下的约束可以转化为拉格拉日乘子法</li><li>也可以采用罚函数法或者投影法</li></ul><h3 id="梯度下降">梯度下降</h3><h4 id="数学概念">数学概念</h4><p>先回忆一些数学概念，梯度，一种向量，是各个轴上的偏导数，函数沿着梯度方向变化率最大。</p><p>然后我们来回到一元函数，这很有有益于理解：</p><p><span class="math display">\[x_{t}=x_{t-1}-\eta \ f^{&#39;}(x)\]</span> 现在我们可以解释之前的公式了，其中<spanclass="math inline">\(\eta\)</span>被称为学习率，表现为梯度下降的步长，而这个一阶导数提供了梯度方向，这里可以自己分类讨论一下（当其大于0？当其小于0？）就能体会到这个数学机器是如何工作的了。</p><h4 id="代码示例">代码示例</h4><p>虽然之前是通过<code>numpy</code>手搓过梯度下降的方法的，但是现在<code>pytorch</code>提供了更多的方便。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义二次函数 f(x) = x^2</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">quadratic_function</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> x**<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始值</span></span><br><span class="line">x = torch.tensor(<span class="number">10.0</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义学习率和迭代次数</span></span><br><span class="line">learning_rate = <span class="number">0.1</span></span><br><span class="line">iterations = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 梯度下降优化过程</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(iterations):</span><br><span class="line">    <span class="comment"># 计算二次函数的值</span></span><br><span class="line">    y = quadratic_function(x)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 使用自动微分计算梯度</span></span><br><span class="line">    y.backward()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 更新参数</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        x -= learning_rate * x.grad</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 重置梯度</span></span><br><span class="line">    x.grad.zero_()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出最小值</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最小值 x =&quot;</span>, x.item())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最小值 f(x) =&quot;</span>, quadratic_function(x).item())</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240225101148445.png" alt="image-20240225101148445" style="zoom: 50%;" /></p><p>ok，问题我们之前大部分已经提过了，比如什么局部最优啊，现在我们要抛出一个新问题，学习率能瞎写吗？答案是也许能，但不好，所以我们要研究怎么搞好学习率。下面是一个瞎写学习率的情况（初始点为10）：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240225104832923.png" style="zoom:50%;" /></p><h4 id="学习率">学习率</h4><p>再研究学习率之前，我们要先提一嘴多维的梯度下降，其实公式也没啥：<span class="math display">\[x_{t}=x_{t-1}-\eta \nabla f(x)\]</span> 梯度一般由一个雅克比矩阵给出，其为一个向量。</p><p>Hessian矩阵<spanclass="math inline">\(H\)</span>，我想应该不需要介绍了，这里我们不去管什么泰勒展开的推导，我们仅仅记住结论：</p><p><strong>牛顿法：</strong>最优的梯度下降（吗？），<spanclass="math inline">\(x_{t}=x_{t-1}-H^{-1} \nablaf(x)\)</span>，显然是有问题的，存储Hessian矩阵可能要花费大量内存，在凸优化上牛顿法非常好用</p><p><strong>预处理：</strong><spanclass="math inline">\(x_{t}=x_{t-1}-\eta \  diag(H)^{-1} \nablaf(x)\)</span>，相当于在每个方向（变量）上选择了不同的学习率</p><h3 id="随机梯度下降">随机梯度下降</h3><h4 id="数学理论">数学理论</h4><p>这个就是我们常用的SGD了，其核心也就是一个用抽样来估计总体，从而降低运算所需的时间，假设使用梯度下降法，样本记做<spanclass="math inline">\(x_i\)</span>，那么计算总的loss为： <spanclass="math display">\[Loss(X)=\frac{1}{n}\sum_{i=1}^{n}{Loss(x_i)}\]</span> 其中我们需要计算梯度： <span class="math display">\[\nabla Loss(X)=\frac{1}{n}\sum_{i=1}^{n}{\nabla Loss(x_i)}\]</span>于是我们有了一个朴实无华的想法，那我直接少算几个不就行了（）你别说，你还真别说，还真是这么搞得。</p><p>随机梯度下降就是均匀随机采样一个<spanclass="math inline">\(x_i\)</span>，然后直接算一个$Loss(x_i) <spanclass="math inline">\(，然后扔进梯度下降公式。\)</span>$x_{t+1}=x_t- Loss(x_i) <span class="math display">\[那这么搞是否有点问题呢？只算一个有没有可能算的不准呢？当然有可能，但是在统计学上其实问题不大：\]</span> <em>iLoss(x_i)= </em>{i=1}^{n}{Loss(x_i)}=Loss(X) $$</p><h4 id="代码示例-1">代码示例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义函数 f(x1, x2) = x1^2 + 2 * x2^2</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">quadratic_function</span>(<span class="params">x1, x2</span>):</span><br><span class="line">    <span class="keyword">return</span> x1 ** <span class="number">2</span> + <span class="number">2</span> * x2 ** <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化参数</span></span><br><span class="line">x1 = torch.tensor(-<span class="number">3.0</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">x2 = torch.tensor(-<span class="number">6.0</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义学习率和迭代次数</span></span><br><span class="line">learning_rate = <span class="number">0.1</span></span><br><span class="line">iterations = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 记录优化过程中的点</span></span><br><span class="line">x1_history = [x1.item()]</span><br><span class="line">x2_history = [x2.item()]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机梯度下降优化过程</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(iterations):</span><br><span class="line">    <span class="comment"># 计算函数的值</span></span><br><span class="line">    y = quadratic_function(x1, x2)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 使用自动微分计算梯度</span></span><br><span class="line">    y.backward()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 更新参数，在梯度上加上随机波动</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        x1 -= learning_rate * (x1.grad+torch.normal(<span class="number">0.0</span>, <span class="number">1</span>, (<span class="number">1</span>,)).item())</span><br><span class="line">        x2 -= learning_rate * (x2.grad+torch.normal(<span class="number">0.0</span>, <span class="number">1</span>, (<span class="number">1</span>,)).item())</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 重置梯度</span></span><br><span class="line">    x1.grad.zero_()</span><br><span class="line">    x2.grad.zero_()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 记录参数</span></span><br><span class="line">    x1_history.append(x1.item())</span><br><span class="line">    x2_history.append(x2.item())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成网格点</span></span><br><span class="line">x1_grid, x2_grid = np.meshgrid(np.linspace(-<span class="number">5</span>, <span class="number">1</span>, <span class="number">100</span>), np.linspace(-<span class="number">6</span>, <span class="number">1</span>, <span class="number">100</span>))</span><br><span class="line">z = quadratic_function(torch.tensor(x1_grid), torch.tensor(x2_grid))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制等高线图</span></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line">plt.contourf(x1_grid, x2_grid, z, levels=<span class="number">20</span>, cmap=<span class="string">&#x27;viridis&#x27;</span>)</span><br><span class="line">plt.colorbar(label=<span class="string">&#x27;Function Value&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x1&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;x2&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Contour Plot of Quadratic Function&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制优化过程中的点</span></span><br><span class="line">plt.plot(x1_history, x2_history, marker=<span class="string">&#x27;o&#x27;</span>, color=<span class="string">&#x27;red&#x27;</span>, label=<span class="string">&#x27;Optimization Path&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240225160700344.png" /></p><h4 id="动态学习率">动态学习率</h4><p>这块直接摆一下公式，俺表示这就是炼丹的玄学部分了：</p><ul><li>$(t)=<em>i    if  t_i &lt;t &lt;t</em>{t+1} $分段常数</li><li><span class="math inline">\(\eta (t)=\eta_0 \cdot e^{-\lambdat}\)</span>指数衰减</li><li><span class="math inline">\(\eta (t)=\eta_0 \cdot (\betat+1)^{-\alpha}\)</span>多项式衰减</li></ul><h3 id="总结">总结</h3><p>喵的写太多了，到这里基本上就可以入门了，也有一定的数学基础了，但是我不认为去仔细研究数学的一些严谨的收敛证明是有用的。后边就要靠自己去看一看啦，比如什么Ada，Adam，小批量随机梯度下降之类的。</p><h3 id="参考链接">参考链接</h3><p><a href="https://zh.d2l.ai/chapter_optimization/index.html">11.优化算法 — 动手学深度学习 2.0.0 documentation (d2l.ai)</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据挖掘实验</title>
      <link href="/2024/02/23/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AE%9E%E9%AA%8C/"/>
      <url>/2024/02/23/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AE%9E%E9%AA%8C/</url>
      
        <content type="html"><![CDATA[<h1 id="python基础语法学习总结">Python基础语法学习总结</h1><h2 id="实验目的">实验目的</h2><p>学习Python基本语法</p><h2 id="实验场地与设备">实验场地与设备</h2><p>线上</p><h2 id="实验方式">实验方式</h2><p>阅读教程与程序设计</p><h2 id="实验设计">实验设计</h2><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/Python%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80.png"alt="Python语言基础" /><figcaption aria-hidden="true">Python语言基础</figcaption></figure><p><span class="math display">\[图1.1 Python基础语法学习实验设计\]</span></p><h2 id="实验内容">实验内容</h2><h3 id="python语法总结">1. Python语法总结</h3><h4 id="python基本语法">1.1 Python基本语法</h4><h4 id="基本语句">（1） 基本语句</h4><p>①首先是输入输出语句，输入语句比较简单为<code>name=input()</code>，基本输出语句为<code>print()</code>,拼接输出使用逗号。</p><p>② 注释采用<code>#</code> 进行书写</p><p>③代码风格：Python采用的是缩进式代码风格，所以对于复制粘贴比较不友好</p><p>④条件判断语句：<code>if 条件1 :...elif 条件2 : ... else : ...</code></p><p>⑤ 循环语句：</p><p>第一种是<code>for</code>循环：<code>for x in []:</code><code>for x in ...:</code>循环就是把每个元素代入变量x，然后执行缩进块的语句</p><p>第二种是<code>while</code>循环：<code>while 条件判断语句 :</code><code>break</code>、<code>continue</code>和java中用法相同</p><h4 id="数据类型">（2） 数据类型</h4><p><strong>①整数：</strong>对于很大的数，很难数清楚0的个数。Python允许在数字中间以_分隔。</p><p><strong>② 浮点数：</strong>允许使用科学计数法定义</p><p><strong>③字符串：</strong>在Python没有严格要求<code>''</code>和<code>""</code>的区别在，也就是说没有区分字符和字符串使用二者没有任何区别。</p><ul><li>转义符和Java中保持一致</li><li>Python允许用<code>r''</code>表示<code>''</code>内部的字符串默认不转义</li></ul><p><strong>④ 布尔值：</strong></p><p>在Python中要注意：<code>True</code>、<code>False</code>要注意开头首字母大写。可以进行与、或、非的运算，运算符分别为：<code>and</code>，<code>or</code>，<code>not</code></p><p><strong>⑤空值：</strong>空值用<code>None</code>表示，意义与Java中的<code>null</code>相同。</p><p><strong>⑥ list：</strong></p><p>list是Python内置的一种数据类型，list是一种有序的集合，可以随时添加和删除其中的元素。此数据类型在Java的实用类中有封装。list和数组很像，声明方式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">classname = [<span class="string">&#x27;老六&#x27;</span>,<span class="string">&#x27;老八&#x27;</span>,<span class="string">&#x27;老九&#x27;</span>]</span><br></pre></td></tr></table></figure><p>想要调取其中的某个元素也和数组一致，赋值修改等也相同<br />下面列举一下list的ADT</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">list:</span><br><span class="line">append(&#x27;Elem&#x27;)  # 在末尾添加新的元素</span><br><span class="line">insert(i,&#x27;Elem&#x27;) # 将元素插入指定位置</span><br><span class="line">pop() # 删除末尾元素</span><br><span class="line">pop(i) # 删除i处的元素</span><br><span class="line">len(list) # list列表的长度</span><br></pre></td></tr></table></figure><p>list允许混合类型，也允许list嵌套，从而出现多维数组。</p><p><strong>⑦ tuple</strong></p><p>tuple被称为元组，其最大的特点就是不可修改，声明方式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">classname = (<span class="string">&#x27;老六&#x27;</span>,<span class="string">&#x27;老八&#x27;</span>,<span class="string">&#x27;老九&#x27;</span>)</span><br></pre></td></tr></table></figure><p>tuple在定义时要确定元素个数，这里有一个问题，在定义只有一个元素的tuple时，Python语法会认为这是一个小括号，因此在定义一个元组的tuple时，要加一个<code>,</code>避免歧义。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t=(<span class="number">1</span>,)</span><br></pre></td></tr></table></figure><p><strong>⑧ 字典（dict）</strong></p><p>字典全称为dictionary，在Java实用类中叫hashmap。其由键值对（key-value）组成，查找速度快。下面是一种初始化方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d = &#123;<span class="string">&#x27;Michael&#x27;</span>: <span class="number">95</span>, <span class="string">&#x27;Bob&#x27;</span>: <span class="number">75</span>, <span class="string">&#x27;Tracy&#x27;</span>: <span class="number">85</span>&#125;</span><br></pre></td></tr></table></figure><p>也可以放入指定的key中：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d[<span class="string">&#x27;Adam&#x27;</span>] = <span class="number">67</span></span><br></pre></td></tr></table></figure><p>查找value:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d[<span class="string">&#x27;Adam&#x27;</span>]</span><br></pre></td></tr></table></figure><p>key与value是多对一的关系，key需要是一个不可变对象保证key做hash运算后的唯一性。如果多次对某个key赋值，后边的value会覆盖前面的value提供了几个函数：</p><ol type="1"><li>通过<code>in</code>来判断key是否在dict中，返回值为布尔值，格式为：<code>key in dict</code></li><li>get()方法，<code>dict.get('key',空返回值)</code>key不存在时返回空返回值，空返回值可自定义，如果没有定义的话返回None</li><li>pop()方法，删除key，如果有value也一并删除，格式为<code>pop('key')</code></li></ol><p><strong>⑨ 集合（set）</strong></p><p>set是一组key的集合,集合特点；无序性、确定性、互异性要创建一个set，需要提供一个list作为输入集合：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="built_in">set</span>([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure><ul><li>方法： <code>add(key)</code>添加一个新的元素<code>remove(key)</code>删除一个元素</li><li>两个set可以做交运算和并运算： 交运算：<code>s1&amp;s2</code>并运算：<code>s1|s2</code></li></ul><h4 id="理解变量">（3） 理解变量</h4><p>在Python中变量仅仅是一个一个字母，变量与所对应的值之间的关系靠指针联系起来的。所以很重要的一点就是：<strong>当我们使用变量时，更多的要关注变量指向的东西，他可能是值，也可能是一个函数，也可能是一个变量</strong></p><h4 id="模块">1.2 模块</h4><h4 id="模块导入">（1） 模块导入</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><h4 id="模块下载">（2） 模块下载</h4><p>模块下载有比较复杂的方法，也有比较傻瓜式的。先说复杂的，使用Python中自带的pip包管理工具，用命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install numpy</span><br></pre></td></tr></table></figure><p>但是使用pip需要事先了解要导的包的名字，而且不能批量导入，而且在Python编程里也有编程一分钟，导包一小时的说法。pip下载第三方库的源可能会很慢或者失效，需要会自己添加国内的高速镜像。</p><p>傻瓜式的导包，例如在pycharm中可以直接在代码中写出自己需要的包，然后交给pycharm自己去下载，或者用Anaconda提前构建好的Python的库环境。</p><h4 id="函数式编程">1.3 函数式编程</h4><h4 id="函数">（1） 函数</h4><p><strong>① 函数定义</strong></p><p>在Python中定义函数为，<code>def 函数名(参数):</code>然后，在缩进块中编写函数体，函数的返回值用<code>return</code>语句返回。<br />如果没有return语句，函数执行完毕后也会返回结果，只是结果为None。returnNone可以简写为return。</p><p>1）空函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">nop</span>():</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>在这里<code>pass</code>作为占位符，表示跳过，也可以用在<code>if</code>的缩进块。</p><p>2）参数限制：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(x, (<span class="built_in">int</span>, <span class="built_in">float</span>)):</span><br><span class="line">      <span class="keyword">raise</span> TypeError(<span class="string">&#x27;bad operand type&#x27;</span>)</span><br></pre></td></tr></table></figure><p>实际上参数限制就是定义一个报错，<code>isinstance()</code>判断数据类型，如果不是就提出一个错误。<strong>作为一个弱类型语言，定义这一步是很有必要的，有助于读懂代码。</strong></p><p>3）返回值：</p><p>Python允许返回多个值，其返回的实际上是一个tuple元组，但是也可以用两个变量接收。</p><p><strong>② 参数定义</strong></p><p>在Python中函数参数的定义也比较灵活，提供位置参数、默认参数、可变参数、关键字（key）参数等</p><p>1）位置参数：位置参数指的是参数在传入时，实参和形参有着严格的位置对应关系，为常用参数形式。</p><p>2）默认参数：默认参数是指在位置参数的基础上为其添加默认值，有默认值的参数为默认参数，没有默认值的参数为必选参数基本定义形式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">my_def</span>(<span class="params">a,b=<span class="number">1</span></span>):</span><br><span class="line">    a=b+<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> </span><br></pre></td></tr></table></figure><p>需要注意的是：</p><ul><li>默认参数必须在必选参数后边，否则会无法辨认是否输入必选参数，从而报错。</li><li>默认参数的默认值一定是<strong>不变对象</strong>，由于Python中的变量定义为指针指向，会导致可变对象值发生变化</li></ul><p>3）不可变对象有：数值类型、字符串、tuple元组、None等</p><p>4）可变参数：可变参数指的是参数的数目不固定，定义形式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">my_function</span>(<span class="params">*v</span>):</span><br><span class="line">    <span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> vi <span class="keyword">in</span> v:</span><br><span class="line">        <span class="built_in">sum</span>+=vi</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span></span><br></pre></td></tr></table></figure><p>在可变参数中传入的所有参数将作为一个tuple被接收，该tuple的变量名为函数在定义时的形参名，定义时的需要在参数名前加一个<code>*</code>。</p><p>5）关键字（key）参数</p><p>此处的关键字和c语言中的关键字并不是一个意义，而是在dict中的key的意义。即在传递参数时，同时传递键（key）和值(value),Python会自动封装为一个dict。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">my_function</span>(<span class="params">**v</span>):</span><br><span class="line">    <span class="built_in">print</span>(v)</span><br><span class="line">    <span class="keyword">return</span> </span><br></pre></td></tr></table></figure><p>6）命名关键字参数</p><p>在关键字参数上，进一步限制传入的key的命名，就有了命名关键词参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">person</span>(<span class="params">name, age, *, city, job</span>):</span><br><span class="line">    <span class="built_in">print</span>(name, age, city, job)</span><br></pre></td></tr></table></figure><p>这里需要一个<code>*</code>区分位置参数与命名关键字参数，如果在这之前有可变参数，那么就不需要加<code>*</code>。<br />命名关键字参数必须传入参数名，这和位置参数不同。如果没有传入参数名，调用将报错：</p><p>7）参数组合</p><p>在一个函数中使用多个参数要保证其中的顺序，依次为：必选参数、默认参数、可变参数、命名关键字参数和关键字参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">onefunction</span>(<span class="params">a,b,c=<span class="number">0</span>,*args,job,city,**kw</span>):</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>tips：</p><ul><li>使用<code>*args</code>和<code>**kw</code>是Python的习惯写法。</li><li>可变参数和关键字参数有一点层级的感觉，中间包裹的是命名关键字参数这个比较尴尬的参数。</li></ul><p><strong>③ 递归函数</strong></p><p>写法与Java相同。</p><h4 id="实用方法">（2） 实用方法</h4><p><strong>① 切片</strong></p><p>切片是一个针对tuple和list方便地取元素的方法，语法规则：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">L[起始坐标:终止坐标:步长]</span><br></pre></td></tr></table></figure><p>当起始坐标为0时可以省略；步长为1时可以省略。</p><p><strong>② 迭代</strong></p><p>迭代是循环的增强，但是想要弄清迭代，需要知道两件事：一个是能不能迭代，一个是迭代出的数据是什么</p><p>想要知道一个数据能否迭代可以通过一个函数来完成：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections.abc <span class="keyword">import</span> Iterable</span><br><span class="line">L=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line"><span class="built_in">isinstance</span>(L,Iterable)</span><br></pre></td></tr></table></figure><p>迭代出的是什么，和要迭代的对象的储存方式，要特殊记忆一下dic。</p><p><strong>③ 列表生成器</strong></p><p>一种快捷生成list的方式，一个例子如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[x * x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>)]</span><br></pre></td></tr></table></figure><p>如果想要筛选生成的值，可以在<code>for</code>后加上<code>if</code>作为<strong>筛选条件</strong>，注意这里是筛选条件，因此这里和平时的<code>if else</code>并不是一个东西。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[x * x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>) <span class="keyword">if</span> x % <span class="number">2</span> == <span class="number">0</span>]</span><br></pre></td></tr></table></figure><p><strong>④ 生成器</strong></p><p>生成器是一种惰性的计算方式。包含<code>yield</code>关键字，当一个函数包含<code>yield</code>关键字时，他就成了一个generator函数。<code>yield</code>在generator函数中起到了一个return的作用，即到<code>yield</code>便返回。在调用时，使用一个变量接受一个generator对象。使用<code>next()</code>函数依次获得下一个返回值。</p><p><strong>⑤ 迭代器</strong></p><p>区分<code>Iterable</code>和<code>Iterator</code></p><p><code>Iterable</code>是可迭代的，是直接可用于<code>for</code>循环的。包括dict、list、tuple、set、str、grenerator。<code>Iterator</code>是迭代器，是直接可用于<code>next()</code>函数的，生成器都是<code>Iterator</code>对象，集合数据类型可以通过<code>iter()</code>获取<code>Interator</code>对象。</p><h4 id="函数式编程-1">（3） 函数式编程</h4><p>函数式编程是一种面向过程的编程思想，实际上是将复杂问题转化为一个个函数。</p><p>在Java的函数定义中，除去<code>void</code>类型不返回值，其余的都需要返回值。因此也就经常存在，使用一个变量接受函数值：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">function</span><span class="params">(x,y)</span>&#123;</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> a=function(x,y);</span><br></pre></td></tr></table></figure><p>那么是不是存在一种可能，我们可以将函数嵌套，让函数调用函数，让函数返回函数，彻底抛弃变量？</p><p>抛弃变量、只有函数就是彻底的函数式编程</p><p><strong>① 理解高阶函数</strong></p><p>之前有过变量名和值的理解，在Python中变量名和值是一个指针指向的关系。同理，函数名和函数也是这样的，函数名也是一个变量。也就是说，我们可以通过函数名，拿到函数体。也就是说函数名是什么并不重要，我们看中的是函数体。</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/%E7%BB%98%E5%9B%BE1.png"alt="绘图1" /><figcaption aria-hidden="true">绘图1</figcaption></figure><p>那么设想一种情况，现在我们定义了函数f2，那么我可以随便写一个函数，然后返回一个变量f2，那么实际上我就拿到了函数体。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">f2</span>(<span class="params">a,b</span>):</span><br><span class="line">    <span class="keyword">return</span> a+b</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">f3</span>():</span><br><span class="line">    <span class="keyword">return</span> f2</span><br><span class="line"><span class="built_in">print</span>(f3()(<span class="number">1</span>,<span class="number">2</span>))</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20220909173741530.png"alt="image-20220909173741530" /><figcaption aria-hidden="true">image-20220909173741530</figcaption></figure><p>然后我们在设想另一种情况，现在我们定义了另一种情况，我们在一个函数中写了一个f1作为局部变量，那么我就可以传入变量f2，然后就相当于传入了函数体。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">f2</span>(<span class="params">a,b</span>):</span><br><span class="line">    <span class="keyword">return</span> a+b</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">f1</span>(<span class="params">a,b,f</span>):</span><br><span class="line">    <span class="keyword">return</span> f(a,b)</span><br><span class="line"><span class="built_in">print</span>(f1(<span class="number">1</span>,<span class="number">2</span>,f2))</span><br></pre></td></tr></table></figure><p>现在就可以进行一个区分：</p><ul><li><code>f</code>代表函数名，是变量</li><li><code>f()</code>代表数值，是函数的返回值，返回值是一个量</li></ul><p>高阶函数，就是让函数的参数能够接收别的函数。</p><p>实用的几个函数，有必要查表即可</p><p><strong>② 返回函数</strong></p><p>同上文理解，只不过是将一个函数嵌套入了另一个函数</p><p><strong>③ lambda表达式</strong></p><p>与Java中语法相同，目的是为了简化返回函数嵌套</p><h4 id="面向对象编程">1.4 面向对象编程</h4><h4 id="类和对象">（1）类和对象</h4><p>创建类：语法如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">类名</span>(<span class="title class_ inherited__">继承的类</span>):</span><br></pre></td></tr></table></figure><p>python的类非常随意，几乎可以不定义就能用。在类中自带有一个构造函数<code>__init__()</code>,此函数可以重新定义</p><p>生成对象：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a=A()</span><br></pre></td></tr></table></figure><h4 id="访问权限">（2）访问权限</h4><p>如果要让内部属性不被外部访问，可以把属性的名称前加上两个下划线<code>__</code>，在Python中，实例的变量名如果以<code>__</code>开头，就变成了一个私有变量（private），只有内部可以访问，外部不能访问。</p><p>此外，<code>__ __</code>这种变量都是特殊变量，在不清楚的时候不要随便乱改</p><h4 id="继承和多态">（3）继承和多态</h4><p>和Java中的思想完全相同</p><h4 id="常用变量和方法">（4）常用变量和方法</h4><p>① <code>__slots__</code></p><p>用这个变量可以起到参数列表的功能，可以在一定程度上限制参数的变量名，用turple进行限定</p><p>② <code>@property</code></p><p>注解编程，可以起到一个简化定义setter和getter函数的作用。<spanclass="citation"data-cites="property注解在getter方法上">@property注解在getter方法上</span>，然后会自动生成<span class="citation" data-cites="函数名.setter">@函数名.setter</span>的注解，但是要注意的一点是，在getter中就不能使用函数名作为自身的调用值，否则会出现无限的调用，产生爆栈。</p><p>③ 多继承</p><p>与Java相同</p><p>⑤ <code>__str__</code>:和Java中的toString方法相同</p><h4 id="错误调试">1.5 错误调试</h4><h4 id="错误处理">（1）错误处理</h4><p>参照Java中，对比来学习即可：</p><p>两种方法，一是尝试，二是抛出，尝试采用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line"><span class="keyword">pass</span></span><br><span class="line"><span class="keyword">except</span> baseexception  :</span><br><span class="line"><span class="keyword">pass</span></span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line"><span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>抛出采用<code>raise</code>关键字</p><h4 id="测试">（2）测试</h4><p>①断言：<code>assert</code>的意思是，表达式<code>n != 0</code>应该是<code>True</code>，否则，根据程序运行的逻辑，后面的代码肯定会出错。</p><p>如果断言失败，<code>assert</code>语句本身就会抛出<code>AssertionError</code></p><p>② 断点：在强大IDE的辅助下，使用断点调试应该是最简单的。</p><h3 id="实践">2.实践</h3><h4 id="石头剪子布">2.1 石头剪子布</h4><p>使用random包中的random函数和条件控制语句，模拟两个电脑互相猜拳：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">win</span>(<span class="params">pc,cc</span>):</span><br><span class="line">    <span class="keyword">if</span> (cc==<span class="number">1</span> <span class="keyword">and</span> pc==<span class="number">2</span>) <span class="keyword">or</span> (cc==<span class="number">2</span> <span class="keyword">and</span> pc==<span class="number">3</span>)<span class="keyword">or</span>(cc==<span class="number">3</span> <span class="keyword">and</span> pc==<span class="number">1</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;电脑一输&quot;</span>)</span><br><span class="line">    <span class="keyword">elif</span> pc==cc:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;平&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;电脑二输&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">computer_choice</span>():</span><br><span class="line">    cc=random.randint(<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">return</span> cc</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show</span>(<span class="params">pc,cc</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;电脑一的出招为&quot;</span>,pc)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;电脑二的出招为&quot;</span>,cc)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">        pc=computer_choice()</span><br><span class="line">        cc=computer_choice()</span><br><span class="line">        show(pc,cc)</span><br><span class="line">        win(pc,cc)</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20220914212607801.png"alt="image-20220914212607801" /><figcaption aria-hidden="true">image-20220914212607801</figcaption></figure><p>改进提升一下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">win</span>(<span class="params">pc,cc</span>):</span><br><span class="line">    <span class="keyword">if</span> (cc==<span class="number">1</span> <span class="keyword">and</span> pc==<span class="number">2</span>) <span class="keyword">or</span> (cc==<span class="number">2</span> <span class="keyword">and</span> pc==<span class="number">3</span>)<span class="keyword">or</span>(cc==<span class="number">3</span> <span class="keyword">and</span> pc==<span class="number">1</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;玩家输&quot;</span>)</span><br><span class="line">    <span class="keyword">elif</span> pc==cc:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;平&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;玩家赢&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">computer_choice</span>():</span><br><span class="line">    cc=random.randint(<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">return</span> cc</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">str</span>(<span class="params">cc</span>):</span><br><span class="line">    <span class="keyword">if</span> cc==<span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;石头&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> cc==<span class="number">2</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;剪刀&#x27;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;布&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show</span>(<span class="params">f,pc,cc</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;电脑一的出招为&quot;</span>,f(pc))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;电脑二的出招为&quot;</span>,f(cc))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">        cc=computer_choice()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;请输入：1.石头 2.剪刀 3.布&quot;</span>)</span><br><span class="line">        pc=<span class="built_in">input</span>()</span><br><span class="line">        show(<span class="built_in">str</span>,pc,cc)</span><br><span class="line">        win(pc,cc)</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20220914213324805.png"alt="image-20220914213324805" /><figcaption aria-hidden="true">image-20220914213324805</figcaption></figure><h4 id="atm模拟">2.2 ATM模拟</h4><p>通过类和对象简单的设计了一个ATM取钱模拟器</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> Account</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ATM</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,money,accounts</span>):</span><br><span class="line">        self.money=money</span><br><span class="line">        self.accounts=accounts</span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">money</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self._money;</span><br><span class="line"><span class="meta">    @money.setter</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">money</span>(<span class="params">self,value</span>):</span><br><span class="line">        self._money=value</span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">accounts</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self._accounts</span><br><span class="line"><span class="meta">    @accounts.setter</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">accounts</span>(<span class="params">self,value</span>):</span><br><span class="line">        self._accounts=value</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">searchId</span>(<span class="params">self,<span class="built_in">id</span></span>):</span><br><span class="line">        <span class="keyword">for</span> account <span class="keyword">in</span> self.accounts:</span><br><span class="line">            <span class="keyword">if</span> account.<span class="built_in">id</span>==<span class="built_in">id</span>:</span><br><span class="line">                <span class="keyword">return</span> account</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">lode</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;请输入账号id&#x27;</span>)</span><br><span class="line">        <span class="built_in">id</span> = <span class="built_in">input</span>()</span><br><span class="line">        account1 = self.searchId(<span class="built_in">id</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;请输入密码&#x27;</span>)</span><br><span class="line">        password = <span class="built_in">input</span>()</span><br><span class="line">        <span class="keyword">if</span> password == account1.password:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;欢迎&quot;</span>, account1.name)</span><br><span class="line">        <span class="keyword">return</span> account1</span><br><span class="line">    <span class="comment"># 存钱</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">save_money</span>(<span class="params">self</span>):</span><br><span class="line">        account=self.lode();</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;请输入要存入的数目&quot;</span>)</span><br><span class="line">        saveMneyValue=<span class="built_in">input</span>()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;存款成功&#x27;</span>)</span><br><span class="line">        account.remain=<span class="built_in">int</span>(account.remain)+<span class="built_in">int</span>(saveMneyValue)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;您的账户余额为&#x27;</span>,account.remain)</span><br><span class="line">        self.money=self.money+<span class="built_in">int</span>(saveMneyValue)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 取钱</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">withdraw_money</span>(<span class="params">self</span>):</span><br><span class="line">        account=self.lode()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;请输入要取出的数目&#x27;</span>)</span><br><span class="line">        withdrawMoneyValue=<span class="built_in">input</span>()</span><br><span class="line">        <span class="keyword">if</span> account.remain &gt; withdrawMoneyValue:</span><br><span class="line">            account.remain=<span class="built_in">int</span>(account.remain)-<span class="built_in">int</span>(withdrawMoneyValue)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;取款成功，您的账户余额为&#x27;</span>,account.remain)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;您的账户余额不足&#x27;</span>)</span><br><span class="line">        self.money=<span class="built_in">int</span>(self.money)-<span class="built_in">int</span>(withdrawMoneyValue)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__str__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;当前ATM中有金额&quot;</span>,self.money,<span class="string">&quot;元&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># atm1=ATM(1000)</span></span><br><span class="line">    <span class="comment"># atm1.__str__()</span></span><br><span class="line">    <span class="comment"># atm1.ave_money(200)</span></span><br><span class="line">    <span class="comment"># atm1.__str__()</span></span><br><span class="line">    <span class="comment"># atm1.withdraw_money(200)</span></span><br><span class="line">    <span class="comment"># atm1.__str__()</span></span><br><span class="line">    accounts=[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        name=<span class="built_in">input</span>()</span><br><span class="line">        <span class="built_in">id</span> = <span class="built_in">input</span>()</span><br><span class="line">        password=<span class="built_in">input</span>()</span><br><span class="line">        remain=<span class="built_in">input</span>()</span><br><span class="line">        accounts.append(Account.account(name, <span class="built_in">id</span>, password, remain))</span><br><span class="line">    atm2=ATM(<span class="number">10000</span>,accounts)</span><br><span class="line">    atm2.save_money()</span><br><span class="line">    atm2.withdraw_money()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">account</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,name,<span class="built_in">id</span>,password,remain</span>):</span><br><span class="line">        self.name=name</span><br><span class="line">        self.remain=remain</span><br><span class="line">        self.password=password</span><br><span class="line">        self.<span class="built_in">id</span>=<span class="built_in">id</span></span><br><span class="line"></span><br><span class="line">    __slots__ = (<span class="string">&#x27;name&#x27;</span>,<span class="string">&#x27;remain&#x27;</span>,<span class="string">&#x27;password&#x27;</span>,<span class="string">&#x27;id&#x27;</span>)</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20220914214759256.png"alt="image-20220914214759256" /><figcaption aria-hidden="true">image-20220914214759256</figcaption></figure><h4 id="圣诞树画图">2.3 圣诞树画图</h4><p>使用Python自带的turtle包，进行圣诞树绘制：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> turtle</span><br><span class="line"></span><br><span class="line">screen = turtle.Screen()</span><br><span class="line">screen.setup(<span class="number">375</span>, <span class="number">700</span>)</span><br><span class="line"></span><br><span class="line">circle = turtle.Turtle()</span><br><span class="line">circle.shape(<span class="string">&#x27;circle&#x27;</span>)</span><br><span class="line">circle.color(<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">circle.speed(<span class="string">&#x27;fastest&#x27;</span>)</span><br><span class="line">circle.up()</span><br><span class="line"></span><br><span class="line">square = turtle.Turtle()</span><br><span class="line">square.shape(<span class="string">&#x27;square&#x27;</span>)</span><br><span class="line">square.color(<span class="string">&#x27;green&#x27;</span>)</span><br><span class="line">square.speed(<span class="string">&#x27;fastest&#x27;</span>)</span><br><span class="line">square.up()</span><br><span class="line"></span><br><span class="line">circle.goto(<span class="number">0</span>, <span class="number">280</span>)</span><br><span class="line">circle.stamp()</span><br><span class="line"></span><br><span class="line">k = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">13</span>):</span><br><span class="line">    y = <span class="number">30</span> * i</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i - k):</span><br><span class="line">        x = <span class="number">30</span> * j</span><br><span class="line">        square.goto(x, -y + <span class="number">280</span>)</span><br><span class="line">        square.stamp()</span><br><span class="line">        square.goto(-x, -y + <span class="number">280</span>)</span><br><span class="line">        square.stamp()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">4</span> == <span class="number">0</span>:</span><br><span class="line">        x = <span class="number">30</span> * (j + <span class="number">1</span>)</span><br><span class="line">        circle.color(<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">        circle.goto(-x, -y + <span class="number">280</span>)</span><br><span class="line">        circle.stamp()</span><br><span class="line">        circle.goto(x, -y + <span class="number">280</span>)</span><br><span class="line">        circle.stamp()</span><br><span class="line">        k += <span class="number">3</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">4</span> == <span class="number">3</span>:</span><br><span class="line">        x = <span class="number">30</span> * (j + <span class="number">1</span>)</span><br><span class="line">        circle.color(<span class="string">&#x27;yellow&#x27;</span>)</span><br><span class="line">        circle.goto(-x, -y + <span class="number">280</span>)</span><br><span class="line">        circle.stamp()</span><br><span class="line">        circle.goto(x, -y + <span class="number">280</span>)</span><br><span class="line">        circle.stamp()</span><br><span class="line"></span><br><span class="line">square.color(<span class="string">&#x27;brown&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">13</span>, <span class="number">17</span>):</span><br><span class="line">    y = <span class="number">30</span> * i</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">        x = <span class="number">30</span> * j</span><br><span class="line">        square.goto(x, -y + <span class="number">280</span>)</span><br><span class="line">        square.stamp()</span><br><span class="line">        square.goto(-x, -y + <span class="number">280</span>)</span><br><span class="line">        square.stamp()</span><br><span class="line">turtle.mainloop()</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20220914215352995.png"alt="image-20220914215352995" /><figcaption aria-hidden="true">image-20220914215352995</figcaption></figure><h2 id="总结">3.总结</h2><p>Python作为一个弱类型语言，是有他的弊端的，在一些需要数据类型转换和严格控制数据类型的情况下，会非常难受。而Python最大的优势在于有大量的库，这些库在特定的编程领域会非常便利。Python本身的语言具有极强的灵活性，而灵活性的言外之意就是规范性很难确定。因此，Python的重点是将第三方包为我所用，在数值计算中发挥他最大的作用。</p><h1 id="实验二-numpy和matplotlib包学习">实验二numpy和matplotlib包学习</h1><h2 id="实验目的-1">实验目的</h2><ol type="1"><li>掌握基本的numpy对象及其对应方法</li><li>掌握常用的numpy数学函数，学习查找numpy帮助文档</li><li>重点学习numpy线性代数方法</li><li>掌握matplotlib的绘图对象关系</li><li>掌握基本的绘制图形的方法，包括绘制、属性设置、子图</li><li>能够通过查阅文档、示例，画出复杂图像</li></ol><h2 id="实验场地与设备-1">实验场地与设备</h2><p>实验室4074</p><h2 id="实验方式-1">实验方式</h2><p>阅读教程与程序设计</p><h2 id="实验设计-1">实验设计</h2><figure><img src="C:\Users\HP\Desktop\常用计算库.png" alt="常用计算库" /><figcaption aria-hidden="true">常用计算库</figcaption></figure><h2 id="实验内容-1">实验内容</h2><h3 id="概述">概述</h3><h4 id="numpy概述">1.numpy概述</h4><p>NumPy是使用Python进行科学计算的基础包。它包含如下的内容：</p><ul><li>一个强大的N维数组对象。</li><li>复杂的（广播）功能。</li><li>用于集成C / C ++和Fortran代码的工具。</li><li>有用的线性代数，傅里叶变换和随机数功能。</li></ul><p>除了明显的科学用途外，NumPy还可以用作通用数据的高效多维容器。可以定义任意数据类型。这使NumPy能够无缝快速地与各种数据库集成。</p><p>API文档：<ahref="https://numpy.org/doc/stable/reference/arrays.html#">Array objects— NumPy v1.23 Manual</a></p><h4 id="matplotlib概述">2.matplotlib概述</h4><p>Matplotlib是一个Python2D绘图库，它以多种硬拷贝格式和跨平台的交互式环境生成出版物质量的图形。</p><p>API文档：<a href="https://matplotlib.org/stable/api/index.html">APIReference — Matplotlib 3.6.0 documentation</a></p><h3 id="具体实验">具体实验</h3><h4id="数组存取以及关于内存位置相同的思考">1.数组存取以及关于内存位置相同的思考</h4><p>通过切片、整数列表、列表生成式等方法尝试数组取出，并对切片内存相同提出解决方案。联想到线性代数，取出子数组对于判断海森矩阵是否正定有很大意义。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实现对数组元素的存取</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment">#导入numpy包</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;-----------数组存取----------&#x27;</span>)</span><br><span class="line">a=np.arange(<span class="number">9</span>).reshape(<span class="number">3</span>,<span class="number">3</span>) <span class="comment">#建立0-8的一个3*3的二位数组</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;输出数组a：&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;-----------取出第一行----------&#x27;</span>)</span><br><span class="line"><span class="comment"># 取出第一行所有元素</span></span><br><span class="line">b=a[<span class="number">0</span>,:]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;输出数组b：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line"><span class="comment"># 取子数组</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;-----------取出子数组----------&#x27;</span>)</span><br><span class="line">x=a[:<span class="number">2</span>,:<span class="number">2</span>]</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;-----------验证内存相同----------&#x27;</span>)</span><br><span class="line"><span class="comment"># 修改数组b内一元素，并输出a,b</span></span><br><span class="line">b[<span class="number">0</span>]=<span class="number">11</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;修改后的数组a，b：&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;-----------如何处理内存相同----------&#x27;</span>)</span><br><span class="line"><span class="comment"># 可见通过切片存取数组，只是一个可修改的视图，二者共用同一内存空间。我考虑到两种方法：一是使用列表生成器，二是进行深拷贝</span></span><br><span class="line"><span class="comment"># 列表生成器取出a第一列</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;-----------列表存取法----------&#x27;</span>)</span><br><span class="line">l=[i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(a.shape[<span class="number">1</span>])]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;生成的list：&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(l)</span><br><span class="line">b=a[<span class="number">0</span>,l]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;输出数组b：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line"><span class="comment"># 修改数组b内一元素，并输出a,b</span></span><br><span class="line">b[<span class="number">0</span>]=<span class="number">3</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;修改后的数组a，b：&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 深拷贝方法（我个人认为这个更简单）</span></span><br><span class="line"><span class="comment"># 先用切片取出第一行所有元素</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;-----------深拷贝方法----------&#x27;</span>)</span><br><span class="line">b=a[<span class="number">0</span>,:]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;输出数组b：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line"><span class="comment"># 进行拷贝</span></span><br><span class="line">c=b.copy()</span><br><span class="line"><span class="comment"># 修改数组b内一元素，并输出b,c</span></span><br><span class="line">c[<span class="number">0</span>]=<span class="number">5</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;修改后的数组b,c：&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line"><span class="built_in">print</span>(c)</span><br></pre></td></tr></table></figure><p>输出结果：</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20220925191202086.png"alt="image-20220925191202086" /><figcaption aria-hidden="true">image-20220925191202086</figcaption></figure><p>而在内存存储中，ndarray是以头地址加地址步长构成的，所以可以在处理连续的存取时，就可以通过指针直接映射到一个视图上。而整数序列不能保证连续分布，就只能拷贝一份。</p><h4 id="结构数组练习">2.结构数组练习</h4><p>新建一个<code>dtype</code>:<code>student</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 结构数组类似c中的strut，和面向对象中的对象数组也比较相似</span></span><br><span class="line"><span class="comment"># 定义结构数组</span></span><br><span class="line">studentType=np.dtype(&#123;</span><br><span class="line">    <span class="string">&#x27;names&#x27;</span>:[<span class="string">&#x27;name&#x27;</span>,<span class="string">&#x27;age&#x27;</span>,<span class="string">&#x27;id&#x27;</span>,<span class="string">&#x27;grades&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;formats&#x27;</span>:[<span class="string">&#x27;S20&#x27;</span>,<span class="string">&#x27;i8&#x27;</span>,<span class="string">&#x27;S20&#x27;</span>,<span class="string">&#x27;f8&#x27;</span>]</span><br><span class="line">&#125;)</span><br><span class="line"><span class="comment"># 创建studentType类型的对象</span></span><br><span class="line">a=np.array([(<span class="string">&#x27;lisi&#x27;</span>,<span class="number">11</span>,<span class="string">&#x27;202011000&#x27;</span>,<span class="number">90.2</span>)],</span><br><span class="line">            dtype=studentType)</span><br><span class="line"><span class="comment"># 输出a</span></span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"><span class="comment"># 这时出现了一个问题：每个字符串类型的数据都自动补齐了一个b，观察一下属性列表</span></span><br><span class="line"><span class="built_in">print</span>(a.dtype)</span><br><span class="line"><span class="comment"># 发现没有什么问题</span></span><br><span class="line"><span class="comment"># 查阅资料得知，b表示字符串为bytes类型，是字节字符串，在字符的前面会加一个b。numpy中没办法将bytes直接转化为str类型，会出现如下报错：</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">print(a[&#x27;name&#x27;],decode())</span></span><br><span class="line"><span class="string">AttributeError: &#x27;numpy.ndarray&#x27; object has no attribute &#x27;decode&#x27;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 结构数组的优点在于赋予了数组中各个数值意义，那么也就有相应的存取方案</span></span><br><span class="line"><span class="comment"># 例如，取出姓名</span></span><br><span class="line"><span class="built_in">print</span>(a[<span class="string">&#x27;name&#x27;</span>])</span><br><span class="line"><span class="comment"># 判断name对应的numpy属性</span></span><br><span class="line"><span class="built_in">print</span>(a[<span class="string">&#x27;name&#x27;</span>].dtype)</span><br></pre></td></tr></table></figure><p>输出结果： <imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221002130955868.png"alt="image-20221002130955868" /></p><h4 id="自定义ufunc函数">3.自定义ufunc函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">triangle_wave</span>(<span class="params">x,c,c0,hc</span>):</span><br><span class="line">    x=x-<span class="built_in">int</span>(x)</span><br><span class="line">    <span class="keyword">if</span> x&gt;=c:r=<span class="number">0.0</span></span><br><span class="line">    <span class="keyword">elif</span> x &lt;c0: r=x/c0*hc</span><br><span class="line">    <span class="keyword">else</span>:r=(c-x)/(c-c0)*hc</span><br><span class="line">    <span class="keyword">return</span> r</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用一个高阶函数frompyfunc</span></span><br><span class="line">triangle_ufunc=np.frompyfunc(triangle_wave,<span class="number">4</span>,<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 在这里第二个参数指的是输入到高阶函数的返回值中的函数的参数个数，第三个参数是返回函数的返回参数个数</span></span><br><span class="line"><span class="comment"># 新建一个数组</span></span><br><span class="line">a=np.random.rand(<span class="number">9</span>).reshape(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"><span class="comment"># 尝试调用</span></span><br><span class="line">y=triangle_ufunc(a,<span class="number">0.6</span>,<span class="number">0.4</span>,<span class="number">1.0</span>)</span><br><span class="line"><span class="comment"># 输出y</span></span><br><span class="line"><span class="built_in">print</span>(y)</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221002192935954.png"alt="image-20221002192935954" /><figcaption aria-hidden="true">image-20221002192935954</figcaption></figure><h4 id="numpy实现梯度下降法求最小值">4.numpy实现梯度下降法求最小值</h4><p>使用numpy实现梯度下降，具体见下注释：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 函数对多项式函数求导函数</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">分析：多项式函数求导数公式：</span></span><br><span class="line"><span class="string">y=a*x^n</span></span><br><span class="line"><span class="string">y‘=n*a*x^(n-1)</span></span><br><span class="line"><span class="string">思路：在numpy中的有多项式函数构造器，本质上其利用的就是一个list列表，那么操作list列表就达到了求导的目的；</span></span><br><span class="line"><span class="string">算法流程：</span></span><br><span class="line"><span class="string">1.获取np.array对象的shape，并将shape元组中的的长度取出，设为count</span></span><br><span class="line"><span class="string">2.声明一个临时变量list</span></span><br><span class="line"><span class="string">3.对np.array的内容进行迭代，按照顺序，ndarray第1个元素乘count-1（count-1减去的是常数项那一位，刚好得到是首个元素的次数），将结果添加到list中，count每次循环-1</span></span><br><span class="line"><span class="string">4.返回ndarray，其中要将list进行切片（目的是将常数项去除，保证使用构造器时次数正确）</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dxfun1</span>(<span class="params">x</span>):</span><br><span class="line">    m=x.shape</span><br><span class="line">    count=<span class="built_in">int</span>(m[<span class="number">0</span>])</span><br><span class="line">    <span class="built_in">list</span>=[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> np.nditer(x):</span><br><span class="line">        <span class="built_in">list</span>.append(i*(count-<span class="number">1</span>))</span><br><span class="line">        count=count-<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> np.array(<span class="built_in">list</span>[<span class="number">0</span>:<span class="built_in">len</span>(<span class="built_in">list</span>) - <span class="number">1</span>])</span><br><span class="line"><span class="comment"># 构造多项式函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dxfun</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> np.poly1d(dxfun1(x))</span><br><span class="line"><span class="comment"># 理想最速梯度下降算法：</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">理想最速梯度下降：</span></span><br><span class="line"><span class="string">梯度下降需要解决的两个任务：寻找搜索方向和搜索步长，理想状态下搜索方向就是最快的沿着函数曲线下降，一阶导数表明了运动的趋势，二阶导数表明了运动的速度</span></span><br><span class="line"><span class="string">所以当搜寻最小值时，那么一阶导数就要为负，而二阶导数要为负梯度，才能保证其下降速度是最快的</span></span><br><span class="line"><span class="string">搜索步长：最佳步长可对lambda求导数，得到一个表达式</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">算法步骤：</span></span><br><span class="line"><span class="string">1.给定一个varepsilon作为可容忍的误差，选定初始点x</span></span><br><span class="line"><span class="string">2.根据梯度下降和最优步长移动点x，更新x位置</span></span><br><span class="line"><span class="string">3.判断x位置是否满足可容忍的误差，如满足则输出最小值，如不满足则继续进行迭代</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">GD</span>(<span class="params">x,varepsilon,a</span>):</span><br><span class="line">    min1=<span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">        <span class="keyword">if</span> np.poly1d(dxfun1(a))(x)&lt;=varepsilon:</span><br><span class="line">            min1 = np.poly1d(a)(x)</span><br><span class="line">            <span class="keyword">return</span> min1</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            ddx=dxfun1(dxfun1(a))</span><br><span class="line">            lambda_1=<span class="number">1</span>/np.poly1d(ddx)(x)**<span class="number">2</span></span><br><span class="line">            x=x-lambda_1*np.poly1d(ddx)(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># a=np.linspace(1,5,5)</span></span><br><span class="line">    a=np.array([<span class="number">1</span>,<span class="number">0</span>,<span class="number">4</span>])</span><br><span class="line">    <span class="comment"># 输出原函数：</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;原函数：&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(np.poly1d(a))</span><br><span class="line">    <span class="comment"># 输出导函数</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;导函数&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(dxfun(a))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;最小值为：&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(GD(<span class="number">1</span>,<span class="number">0.001</span>,a))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 拟合多项式</span></span><br><span class="line">    a_1 = np.array([<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>])</span><br><span class="line">    f = np.poly1d(a)</span><br><span class="line">    x=np.linspace(<span class="number">0</span>,<span class="number">4</span>*np.pi,<span class="number">40</span>)</span><br><span class="line">    y=f(x)*np.sin(x)+<span class="number">5</span>*np.cos(x)</span><br><span class="line">    z = np.polyfit(x, y, <span class="number">6</span>)</span><br><span class="line">    f1=np.poly1d(z)</span><br><span class="line">    z1 = f1(x)</span><br><span class="line">    <span class="built_in">print</span>(GD(<span class="number">20</span>, <span class="number">0.001</span>, z))</span><br></pre></td></tr></table></figure><p>输出结果： <imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221002130924057.png"alt="image-20221002130924057" /></p><h4 id="梯度下降法可视化">5.梯度下降法可视化</h4><p>使用散点图记录中间过程，用折线图画出函数轮廓得到如图：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 函数对多项式函数求导函数</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">分析：多项式函数求导数公式：</span></span><br><span class="line"><span class="string">y=a*x^n</span></span><br><span class="line"><span class="string">y‘=n*a*x^(n-1)</span></span><br><span class="line"><span class="string">思路：在numpy中的有多项式函数构造器，本质上其利用的就是一个list列表，那么操作list列表就达到了求导的目的；</span></span><br><span class="line"><span class="string">算法流程：</span></span><br><span class="line"><span class="string">1.获取np.array对象的shape，并将shape元组中的的长度取出，设为count</span></span><br><span class="line"><span class="string">2.声明一个临时变量list</span></span><br><span class="line"><span class="string">3.对np.array的内容进行迭代，按照顺序，ndarray第1个元素乘count-1（count-1减去的是常数项那一位，刚好得到是首个元素的次数），将结果添加到list中，count每次循环-1</span></span><br><span class="line"><span class="string">4.返回ndarray，其中要将list进行切片（目的是将常数项去除，保证使用构造器时次数正确）</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dxfun1</span>(<span class="params">x</span>):</span><br><span class="line">    m=x.shape</span><br><span class="line">    count=<span class="built_in">int</span>(m[<span class="number">0</span>])</span><br><span class="line">    <span class="built_in">list</span>=[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> np.nditer(x):</span><br><span class="line">        <span class="built_in">list</span>.append(i*(count-<span class="number">1</span>))</span><br><span class="line">        count=count-<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> np.array(<span class="built_in">list</span>[<span class="number">0</span>:<span class="built_in">len</span>(<span class="built_in">list</span>) - <span class="number">1</span>])</span><br><span class="line"><span class="comment"># 构造多项式函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dxfun</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> np.poly1d(dxfun1(x))</span><br><span class="line"><span class="comment"># 理想最速梯度下降算法：</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">理想最速梯度下降：</span></span><br><span class="line"><span class="string">梯度下降需要解决的两个任务：寻找搜索方向和搜索步长，理想状态下搜索方向就是最快的沿着函数曲线下降，一阶导数表明了运动的趋势，二阶导数表明了运动的速度</span></span><br><span class="line"><span class="string">所以当搜寻最小值时，那么一阶导数就要为负，而二阶导数要为负梯度，才能保证其下降速度是最快的</span></span><br><span class="line"><span class="string">搜索步长：最佳步长可对lambda求导数，得到一个表达式</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">算法步骤：</span></span><br><span class="line"><span class="string">1.给定一个varepsilon作为可容忍的误差，选定初始点x</span></span><br><span class="line"><span class="string">2.根据梯度下降和最优步长移动点x，更新x位置</span></span><br><span class="line"><span class="string">3.判断x位置是否满足可容忍的误差，如满足则输出最小值，如不满足则继续进行迭代</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">GD</span>(<span class="params">x,varepsilon,a</span>):</span><br><span class="line">    min1=<span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">        <span class="keyword">if</span> np.poly1d(dxfun1(a))(x)&lt;=varepsilon:</span><br><span class="line">            min1 = np.poly1d(a)(x)</span><br><span class="line">            plt.scatter(x, min1)</span><br><span class="line">            <span class="keyword">return</span> min1</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            ddx=dxfun1(dxfun1(a))</span><br><span class="line">            lambda_1=<span class="number">1</span>/np.poly1d(ddx)(x)**<span class="number">2</span></span><br><span class="line">            x=x-lambda_1*np.poly1d(ddx)(x)</span><br><span class="line">            y=np.poly1d(a)(x)</span><br><span class="line">            plt.scatter(x,y)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># a=np.linspace(1,5,5)</span></span><br><span class="line">    a=np.array([<span class="number">1</span>,<span class="number">0</span>,<span class="number">4</span>])</span><br><span class="line">    <span class="comment"># 输出原函数：</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;原函数：&#x27;</span>)</span><br><span class="line">    y1=np.poly1d(a)</span><br><span class="line">    <span class="built_in">print</span>(y1)</span><br><span class="line">    <span class="comment"># 输出导函数</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;导函数&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(dxfun(a))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;最小值为：&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(GD(<span class="number">10</span>,<span class="number">0.001</span>,a))</span><br><span class="line">    <span class="comment"># 绘制二次函数y1图像</span></span><br><span class="line">    x1=np.linspace(-<span class="number">10</span>,<span class="number">10</span>,<span class="number">20</span>)</span><br><span class="line">    plt.plot(x1,y1(x1))</span><br><span class="line">    <span class="comment"># 拟合多项式</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    a_1 = np.array([1, 0, 0])</span></span><br><span class="line"><span class="string">    f = np.poly1d(a)</span></span><br><span class="line"><span class="string">    x=np.linspace(0,4*np.pi,40)</span></span><br><span class="line"><span class="string">    y=f(x)*np.sin(x)+5*np.cos(x)</span></span><br><span class="line"><span class="string">    z = np.polyfit(x, y, 6)</span></span><br><span class="line"><span class="string">    f1=np.poly1d(z)</span></span><br><span class="line"><span class="string">    z1 = f1(x)</span></span><br><span class="line"><span class="string">    print(&#x27;拟合计算最小值&#x27;)</span></span><br><span class="line"><span class="string">    print(GD(13, 0.001, z))</span></span><br><span class="line"><span class="string">    plt.figure(x,z1)&#x27;&#x27;&#x27;</span></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p>二次函数梯度下降可视化，如图所示：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221002152415012.png" alt="image-20221002152415012" style="zoom:50%;" /></p><p>自定义函数f1：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221002154352417.png" alt="image-20221002154352417" style="zoom: 50%;" /></p><p>但是，如果出的试点选择为0和5，那么得到的结果为：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221002160351783.png" alt="image-20221002160351783" style="zoom: 67%;" /><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221002160300703.png" alt="image-20221002160300703" style="zoom: 67%;" /></p><p>经过测试可知，选取初始点极其重要，不好的选点在非凸优化中很容易引起陷入局部最优，从而找不到全局最优。</p><h4 id="折线图">6.折线图</h4><p>采用鸢尾花数据集，但是仅观察数据集中各个数据的特征，不做聚类分析，首先是三种鸢尾花的不同特征的比较：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line">iris =datasets.load_iris()</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">通过查看load_iris源代码，可以看出，一共是三种花：&#x27;setosa&#x27;, &#x27;versicolor&#x27;, &#x27;virginica&#x27;，各有四种属性：&#x27;sepal length (cm)&#x27;, &#x27;sepal width (cm)&#x27;,&#x27;petal length (cm)&#x27;, &#x27;petal width (cm)&#x27;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;查看品类名称：&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(iris.target_names)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;查看特征名称：&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(iris.feature_names)</span><br><span class="line"><span class="comment"># 整理各种数据，分为三类画图</span></span><br><span class="line">y1=[]</span><br><span class="line">y2=[]</span><br><span class="line">y3=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(iris.data.shape[<span class="number">0</span>]):</span><br><span class="line">    <span class="keyword">if</span> iris.target[i]==<span class="number">0</span>:</span><br><span class="line">        y1.append(iris.data[i,:])</span><br><span class="line">    <span class="keyword">elif</span> iris.target[i]==<span class="number">1</span>:</span><br><span class="line">        y2.append(iris.data[i, :])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        y3.append(iris.data[i, :])</span><br><span class="line"><span class="comment"># 建立一个和list长度相同的数组x，便于画图</span></span><br><span class="line">x1=np.linspace(<span class="number">1</span>, <span class="built_in">len</span>(y1), <span class="built_in">len</span>(y1))</span><br><span class="line">x2=np.linspace(<span class="number">1</span>, <span class="built_in">len</span>(y2), <span class="built_in">len</span>(y2))</span><br><span class="line">x3=np.linspace(<span class="number">1</span>, <span class="built_in">len</span>(y3), <span class="built_in">len</span>(y3))</span><br><span class="line"><span class="comment"># 将list y转化为ndarray</span></span><br><span class="line">y1=np.array(y1)</span><br><span class="line">y2=np.array(y2)</span><br><span class="line">y3=np.array(y3)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 针对不同类型分别绘制折线图</span></span><br><span class="line"><span class="comment"># sepal length (cm)</span></span><br><span class="line">plt.figure(<span class="number">1</span>)</span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.plot(x1,y1[:,<span class="number">0</span>],label=<span class="string">&quot;setosa&quot;</span>)</span><br><span class="line">plt.plot(x2,y2[:,<span class="number">0</span>],label=<span class="string">&quot;versicolor&quot;</span>)</span><br><span class="line">plt.plot(x3,y3[:,<span class="number">0</span>],label=<span class="string">&quot;virginica&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;sepal length (cm)&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;x&quot;</span>)</span><br><span class="line">plt.legend() <span class="comment">#用于生成图例</span></span><br><span class="line">plt.title(<span class="string">&quot;sepal length (cm)&quot;</span>)</span><br><span class="line"><span class="comment"># sepal width (cm)</span></span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.plot(x1,y1[:,<span class="number">1</span>],label=<span class="string">&quot;setosa&quot;</span>)</span><br><span class="line">plt.plot(x2,y2[:,<span class="number">1</span>],label=<span class="string">&quot;versicolor&quot;</span>)</span><br><span class="line">plt.plot(x3,y3[:,<span class="number">1</span>],label=<span class="string">&quot;virginica&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;sepal width (cm)&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;x&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.title(<span class="string">&quot;sepal width (cm)&quot;</span>)</span><br><span class="line"><span class="comment"># petal length (cm)</span></span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">plt.plot(x1,y1[:,<span class="number">2</span>],label=<span class="string">&quot;setosa&quot;</span>)</span><br><span class="line">plt.plot(x2,y2[:,<span class="number">2</span>],label=<span class="string">&quot;versicolor&quot;</span>)</span><br><span class="line">plt.plot(x3,y3[:,<span class="number">2</span>],label=<span class="string">&quot;virginica&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;petal length (cm)&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;x&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.title(<span class="string">&quot;petal length (cm)&quot;</span>)</span><br><span class="line"><span class="comment"># petal width (cm)</span></span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line">plt.plot(x1,y1[:,<span class="number">2</span>],label=<span class="string">&quot;setosa&quot;</span>)</span><br><span class="line">plt.plot(x2,y2[:,<span class="number">2</span>],label=<span class="string">&quot;versicolor&quot;</span>)</span><br><span class="line">plt.plot(x3,y3[:,<span class="number">2</span>],label=<span class="string">&quot;virginica&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;petal width (cm)&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;x&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.title(<span class="string">&quot;petal width (cm)&quot;</span>)</span><br><span class="line">plt.tight_layout() <span class="comment">#自适应分布</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>在做到后边时，突然想到其实在做完筛选后，其实可以添加一个排序，那么就会使图像非常清晰可见，见右图</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221002175529645.png" alt="image-20221002175529645" style="zoom:67%;" /><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221002184429334.png" alt="image-20221002184429334" style="zoom: 67%;" /></p><h4 id="柱状图">7.柱状图</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 提取setosa中的sepal length的范围,绘制柱形图</span></span><br><span class="line">y1_sl,s=np.histogram(y1[:,<span class="number">0</span>],bins=[<span class="number">4</span>,<span class="number">4.5</span>,<span class="number">5</span>,<span class="number">5.5</span>,<span class="number">6</span>])</span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line"></span><br><span class="line">l = [<span class="string">&#x27;4-4.5&#x27;</span>,<span class="string">&#x27;4.5-5&#x27;</span>,<span class="string">&#x27;5-5.5&#x27;</span>,<span class="string">&#x27;5.5-6&#x27;</span>]</span><br><span class="line">l=np.array(l)</span><br><span class="line">ax.bar(<span class="built_in">range</span>(<span class="built_in">len</span>(l)), y1_sl,tick_label=l)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221002183734784.png" alt="image-20221002183734784" style="zoom:50%;" /></p><p>操作时发现，matplotlib2.x版本中的bar是不支持使用字符串列表作为x，y两轴的，但是3.x版本就允许了，所以在使用包时要注意观察官方文档中给出包版本。</p><h4 id="散点图">8.散点图</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 绘制散点图</span></span><br><span class="line">plt.clf()</span><br><span class="line">plt.scatter(y1[:,<span class="number">0</span>],y1[:,<span class="number">1</span>],label=<span class="string">&quot;setosa&quot;</span>)</span><br><span class="line">plt.scatter(y2[:,<span class="number">0</span>],y2[:,<span class="number">1</span>],label=<span class="string">&quot;versicolor&quot;</span>)</span><br><span class="line">plt.scatter(y3[:,<span class="number">0</span>],y3[:,<span class="number">1</span>],label=<span class="string">&quot;virginica&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.xlabel(iris.feature_names[<span class="number">0</span>])   <span class="comment">#x轴名称</span></span><br><span class="line">plt.ylabel(iris.feature_names[<span class="number">1</span>])   <span class="comment">#y轴名称</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221002190949615.png" alt="image-20221002190949615" style="zoom:67%;" /></p><p>从图中可以看出不是很好区分，那么可以换一下其他属性继续作图：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221002191244939.png" alt="image-20221002191244939" style="zoom: 67%;" /></p><h4 id="饼图">9.饼图</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 绘制饼图</span></span><br><span class="line">plt.figure(figsize=(<span class="number">4</span>,<span class="number">4</span>))</span><br><span class="line">plt.pie(y1_sl,labels=[<span class="string">&#x27;4-4.5&#x27;</span>,<span class="string">&#x27;4.5-5&#x27;</span>,<span class="string">&#x27;5-5.5&#x27;</span>,<span class="string">&#x27;5.5-6&#x27;</span>],autopct=<span class="string">&#x27;%.2f%%&#x27;</span>,explode=(<span class="number">0.2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>),)</span><br><span class="line">zhfont1 = matplotlib.font_manager.FontProperties(fname=<span class="string">&quot;SourceHanSerifSC-Light.otf&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;setosa中的sepal length各个区间占比&#x27;</span>,fontproperties=zhfont1)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221002192645105.png" alt="image-20221002192645105" style="zoom:67%;" /></p><h4 id="d绘图">10.3D绘图</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成数据x</span></span><br><span class="line">x=np.arange(-<span class="number">4</span>,<span class="number">4</span>,<span class="number">0.125</span>)</span><br><span class="line"><span class="comment"># 生成数据y</span></span><br><span class="line">y=np.arange(-<span class="number">4</span>,<span class="number">4</span>,<span class="number">0.125</span>)</span><br><span class="line"><span class="comment"># 对x、y数据执行网格化</span></span><br><span class="line">x,y= np.meshgrid(x,y)</span><br><span class="line"><span class="comment"># 定义z</span></span><br><span class="line">z1 = np.exp(-x**<span class="number">2</span> - y**<span class="number">2</span>)</span><br><span class="line">z2 = np.exp(-(x - <span class="number">1</span>)**<span class="number">2</span> - (y - <span class="number">1</span>)**<span class="number">2</span>)</span><br><span class="line">z=(z1+z2)/<span class="number">2</span></span><br><span class="line"><span class="comment"># 绘制3d图像</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = Axes3D(fig)</span><br><span class="line">ax.plot_surface(x,y,z,cmap=plt.get_cmap(<span class="string">&#x27;rainbow&#x27;</span>))</span><br><span class="line">plt.xlabel(<span class="string">&quot;x&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;y&quot;</span>)</span><br><span class="line">ax.set_zlabel(<span class="string">&quot;z&quot;</span>)</span><br><span class="line"></span><br><span class="line">fig.show()</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221002194419179.png" alt="image-20221002194419179" style="zoom:67%;" /></p><h3 id="总结-1">总结</h3><p>经过对这两个库的学习发现，这两个库的功能都相当强大。对于numpy来说要理解numpy中ndarray的使用方法，切片、迭代使用频率都比较高。matplotlib主要是理解他的artist对象，理解后其实可以通过官网的example直接套用模板就可以做出很好的效果。理解artist对象后在对官网示例进行编辑、美化，为自己所用。</p><h1 id="实验三-数据探索分析">实验三 数据探索分析</h1><h2 id="实验目的-2">实验目的</h2><ol type="1"><li>使用矩阵计算和统计量进行EDA</li><li>使用可视化技术进行EDA</li><li>掌握数据相似性和相异性计算</li></ol><h2 id="实验场地与设备-2">实验场地与设备</h2><p>实验室4074</p><h2 id="实验方式-2">实验方式</h2><p>阅读教程与程序设计</p><h2 id="实验设计-2">实验设计</h2><p>要尽可能多的使用可视化方法<img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/EDA.png" alt="EDA" style="zoom:50%;" /></p><h2 id="实验内容-2">实验内容</h2><p>导入企鹅数据集</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=UTF-8</span></span><br><span class="line"><span class="comment"># This Python file uses the following encoding: utf-8</span></span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;../penguins_size.csv&#x27;</span>)</span><br></pre></td></tr></table></figure><p>企鹅数据集的特征及解释：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">变量                 类型       含义</span></span><br><span class="line"><span class="string">----------------    ------- ---------------------</span></span><br><span class="line"><span class="string">species             integer企鹅种类 (Adelie, Gentoo, Chinstrap)</span></span><br><span class="line"><span class="string">island            integer所在岛屿 (Biscoe, Dream, Torgersen)</span></span><br><span class="line"><span class="string">bill_length_mm    double嘴峰长度 (单位毫米)</span></span><br><span class="line"><span class="string">bill_depth_mm    double嘴峰深度 (单位毫米)</span></span><br><span class="line"><span class="string">flipper_length_mminteger鰭肢长度 (单位毫米)</span></span><br><span class="line"><span class="string">body_mass_g        integer体重 (单位克)</span></span><br><span class="line"><span class="string">sex                integer性别</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>首先验证是否有缺失值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 观察缺失值</span></span><br><span class="line"><span class="built_in">print</span>(df.isnull().<span class="built_in">sum</span>())</span><br></pre></td></tr></table></figure><p>结果如下，发现有缺失值，然后直接删除缺失值行，再次观察缺失值。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">species               0</span><br><span class="line">island                0</span><br><span class="line">culmen_length_mm      2</span><br><span class="line">culmen_depth_mm       2</span><br><span class="line">flipper_length_mm     2</span><br><span class="line">body_mass_g           2</span><br><span class="line">sex                  10</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 直接删除缺失值行</span></span><br><span class="line">df = df.dropna()</span><br><span class="line"><span class="comment"># 再次观察缺失值</span></span><br><span class="line"><span class="built_in">print</span>(df.isnull().<span class="built_in">sum</span>())</span><br></pre></td></tr></table></figure><p><strong>现在我想要了解各种企鹅的数量，并通过饼状图可视化：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 各种企鹅的数量</span></span><br><span class="line">species_count=df[<span class="string">&#x27;species&#x27;</span>].value_counts()</span><br><span class="line"><span class="built_in">print</span>(species_count)</span><br><span class="line"><span class="comment"># 绘制饼状图</span></span><br><span class="line">plt.figure(figsize=(<span class="number">4</span>,<span class="number">4</span>))</span><br><span class="line">labels=species_count.index</span><br><span class="line">plt.pie(species_count,labels=labels,autopct=<span class="string">&#x27;%.2f%%&#x27;</span>,explode=(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.1</span>))</span><br><span class="line">zhfont1 = matplotlib.font_manager.FontProperties(fname=<span class="string">&quot;../SourceHanSerifSC-Light.otf&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;企鹅各个种类占比&#x27;</span>,fontproperties=zhfont1)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>结果：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204164120934.png" alt="image-20230204164120934" style="zoom: 67%;" /></p><h3 id="每个岛屿有多少企鹅"><strong>每个岛屿有多少企鹅？</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 每个岛屿有多少企鹅</span></span><br><span class="line">island_count=df[<span class="string">&#x27;island&#x27;</span>].value_counts()</span><br><span class="line"><span class="built_in">print</span>(island_count)</span><br><span class="line"><span class="comment"># 绘制饼图</span></span><br><span class="line">plt.figure(figsize=(<span class="number">4</span>,<span class="number">4</span>))</span><br><span class="line">labels=island_count.index</span><br><span class="line">plt.pie(island_count,labels=labels,autopct=<span class="string">&#x27;%.2f%%&#x27;</span>,explode=(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.1</span>))</span><br><span class="line">plt.title(<span class="string">&#x27;各个岛屿企鹅数占比&#x27;</span>,fontproperties=zhfont1)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>结果：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204164243087.png" alt="image-20230204164243087" style="zoom:67%;" /></p><h3id="每种类型企鹅各种体征属性的均值和分布"><strong>每种类型企鹅各种体征属性的均值和分布</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#按种类找出数据</span></span><br><span class="line">Adelie=df[df[<span class="string">&#x27;species&#x27;</span>].isin([<span class="string">&#x27;Adelie&#x27;</span>])]</span><br><span class="line">Gentoo=df[df[<span class="string">&#x27;species&#x27;</span>].isin([<span class="string">&#x27;Gentoo&#x27;</span>])]</span><br><span class="line">Chinstrap=df[df[<span class="string">&#x27;species&#x27;</span>].isin([<span class="string">&#x27;Chinstrap&#x27;</span>])]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 每种类型企鹅各种体征属性的均值和分布</span></span><br><span class="line">Adelie_means=Adelie.mean()</span><br><span class="line">Gentoo_means=Gentoo.mean()</span><br><span class="line">Chinstrap_means=Chinstrap.mean()</span><br><span class="line"></span><br><span class="line"><span class="comment">#均值可视化</span></span><br><span class="line">plt.figure(<span class="number">1</span>)</span><br><span class="line"><span class="comment"># culmen_length_mm</span></span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.bar([<span class="string">&#x27;Adelie&#x27;</span>,<span class="string">&#x27;Gentoo&#x27;</span>,<span class="string">&#x27;Chinstrap&#x27;</span>],</span><br><span class="line">        [Adelie_means[<span class="string">&#x27;culmen_length_mm&#x27;</span>],</span><br><span class="line">         Gentoo_means[<span class="string">&#x27;culmen_length_mm&#x27;</span>],</span><br><span class="line">         Chinstrap_means[<span class="string">&#x27;culmen_length_mm&#x27;</span>]]</span><br><span class="line">        )</span><br><span class="line">plt.xlabel(<span class="string">&#x27;species&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;culmen_length_mm&#x27;</span>)</span><br><span class="line"><span class="comment"># culmen_depth_mm</span></span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.bar([<span class="string">&#x27;Adelie&#x27;</span>,<span class="string">&#x27;Gentoo&#x27;</span>,<span class="string">&#x27;Chinstrap&#x27;</span>],</span><br><span class="line">        [Adelie_means[<span class="string">&#x27;culmen_depth_mm&#x27;</span>],</span><br><span class="line">         Gentoo_means[<span class="string">&#x27;culmen_depth_mm&#x27;</span>],</span><br><span class="line">         Chinstrap_means[<span class="string">&#x27;culmen_depth_mm&#x27;</span>]]</span><br><span class="line">        )</span><br><span class="line">plt.xlabel(<span class="string">&#x27;species&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;culmen_depth_mm&#x27;</span>)</span><br><span class="line"><span class="comment"># flipper_length_mm</span></span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">plt.bar([<span class="string">&#x27;Adelie&#x27;</span>,<span class="string">&#x27;Gentoo&#x27;</span>,<span class="string">&#x27;Chinstrap&#x27;</span>],</span><br><span class="line">        [Adelie_means[<span class="string">&#x27;flipper_length_mm&#x27;</span>],</span><br><span class="line">         Gentoo_means[<span class="string">&#x27;flipper_length_mm&#x27;</span>],</span><br><span class="line">         Chinstrap_means[<span class="string">&#x27;flipper_length_mm&#x27;</span>]]</span><br><span class="line">        )</span><br><span class="line">plt.xlabel(<span class="string">&#x27;species&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;flipper_length_mm&#x27;</span>)</span><br><span class="line"><span class="comment"># body_mass_g</span></span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line">plt.bar([<span class="string">&#x27;Adelie&#x27;</span>,<span class="string">&#x27;Gentoo&#x27;</span>,<span class="string">&#x27;Chinstrap&#x27;</span>],</span><br><span class="line">        [Adelie_means[<span class="string">&#x27;body_mass_g&#x27;</span>],</span><br><span class="line">         Gentoo_means[<span class="string">&#x27;body_mass_g&#x27;</span>],</span><br><span class="line">         Chinstrap_means[<span class="string">&#x27;body_mass_g&#x27;</span>]]</span><br><span class="line">        )</span><br><span class="line">plt.xlabel(<span class="string">&#x27;species&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;body_mass_g &#x27;</span>)</span><br><span class="line">plt.tight_layout() <span class="comment">#自适应分布</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>结果</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204164449475.png" alt="image-20230204164449475" style="zoom:67%;" /></p><h3 id="不同种企鹅的分布"><strong>不同种企鹅的分布</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># culmen_length_mm分布</span></span><br><span class="line">plt.figure()</span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">species=[Adelie,Gentoo,Chinstrap]</span><br><span class="line">labels=[<span class="string">&#x27;Adelie&#x27;</span>,<span class="string">&#x27;Gentoo&#x27;</span>,<span class="string">&#x27;Chinstrap&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    sns.kdeplot(species[i][<span class="string">&#x27;culmen_length_mm&#x27;</span>],shade=<span class="literal">True</span>,label=labels[i])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;culmen_length_mm&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;display&#x27;</span>)</span><br><span class="line"><span class="comment"># culmen_depth_mm</span></span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    sns.kdeplot(species[i][<span class="string">&#x27;culmen_depth_mm&#x27;</span>],shade=<span class="literal">True</span>,label=labels[i])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;culmen_depth_mm&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;display&#x27;</span>)</span><br><span class="line"><span class="comment"># flipper_length_mm</span></span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    sns.kdeplot(species[i][<span class="string">&#x27;flipper_length_mm&#x27;</span>],shade=<span class="literal">True</span>,label=labels[i])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;flipper_length_mm&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;display&#x27;</span>)</span><br><span class="line"><span class="comment"># body_mass_g</span></span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    sns.kdeplot(species[i][<span class="string">&#x27;body_mass_g&#x27;</span>],shade=<span class="literal">True</span>,label=labels[i])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;body_mass_g&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;display&#x27;</span>)</span><br><span class="line">plt.tight_layout() <span class="comment">#自适应分布</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>结果：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204164609212.png" alt="image-20230204164609212" style="zoom:67%;" /></p><h3 id="嘴峰长度和深度的关联"><strong>嘴峰长度和深度的关联</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 嘴峰长度和深度的关联</span></span><br><span class="line">markers=[<span class="string">&#x27;o&#x27;</span>,<span class="string">&#x27;^&#x27;</span>,<span class="string">&#x27;&gt;&#x27;</span>]</span><br><span class="line">plt.figure()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    plt.scatter(species[i][<span class="string">&#x27;culmen_length_mm&#x27;</span>],species[i][<span class="string">&#x27;culmen_depth_mm&#x27;</span>],label=labels[i],marker=markers[i])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;culmen_length_mm&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;culmen_depth_mm&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204164705383.png" alt="image-20230204164705383" style="zoom:67%;" /></p><h3 id="相似相异指标"><strong>相似相异指标</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 采用数字特征，计算皮尔逊系数</span></span><br><span class="line">Adelie_corr = Adelie.corr()</span><br><span class="line">Gentoo_corr=Gentoo.corr()</span><br><span class="line">Chinstrap_corr=Chinstrap.corr()</span><br><span class="line"></span><br><span class="line">corrs=[Adelie_corr,Gentoo_corr,Chinstrap_corr]</span><br><span class="line"><span class="comment"># 并绘制热图</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    plt.figure()</span><br><span class="line">    sns.heatmap(corrs[i], vmax=<span class="number">1</span>, vmin=-<span class="number">1</span>, center=<span class="number">0</span>)</span><br><span class="line">    plt.xticks(rotation=-<span class="number">15</span>)</span><br><span class="line">    plt.yticks(rotation=<span class="number">75</span>)</span><br><span class="line">    plt.title(labels[i]+<span class="string">&#x27;各特征相关性&#x27;</span>,fontproperties=zhfont1)</span><br><span class="line">    plt.tight_layout() <span class="comment">#自适应分布</span></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204164830893.png" alt="image-20230204164830893" style="zoom: 50%;" /><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204164842868.png" alt="image-20230204164842868" style="zoom: 50%;" /><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204164853560.png" alt="image-20230204164853560" style="zoom: 50%;" /></p><h3 id="数据散布矩阵"><strong>数据散布矩阵</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据散布图矩阵</span></span><br><span class="line">features=[<span class="string">&#x27;culmen_length_mm&#x27;</span>,<span class="string">&#x27;culmen_depth_mm&#x27;</span>,<span class="string">&#x27;flipper_length_mm&#x27;</span>,<span class="string">&#x27;body_mass_g&#x27;</span>]</span><br><span class="line">plt.figure(figsize=(<span class="number">25</span>,<span class="number">25</span>))</span><br><span class="line">n=<span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">        aix=plt.subplot(<span class="number">4</span>,<span class="number">4</span>,n)</span><br><span class="line">        <span class="keyword">if</span> i!=j:</span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">                plt.scatter(species[k][features[j]],species[k][features[i]],label=labels[k],marker=markers[k])</span><br><span class="line">            plt.xlabel(<span class="string">&#x27;culmen_length_mm&#x27;</span>)</span><br><span class="line">            plt.ylabel(<span class="string">&#x27;culmen_depth_mm&#x27;</span>)</span><br><span class="line">            n=n+<span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            plt.scatter(<span class="number">0</span>,<span class="number">0</span>,color=<span class="string">&#x27;white&#x27;</span>)</span><br><span class="line">            n=n+<span class="number">1</span></span><br><span class="line">plt.tight_layout() <span class="comment">#自适应分布</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204165102779.png"alt="image-20230204165102779" /><figcaption aria-hidden="true">image-20230204165102779</figcaption></figure><h3id="不同种类企鹅的体重是否有显著性差异"><strong>不同种类企鹅的体重是否有显著性差异</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 不同种类企鹅的体重是否有显著性差异</span></span><br><span class="line">body_mass_gs=[Adelie[<span class="string">&#x27;body_mass_g&#x27;</span>],Gentoo[<span class="string">&#x27;body_mass_g&#x27;</span>],Chinstrap[<span class="string">&#x27;body_mass_g&#x27;</span>]]</span><br><span class="line"><span class="comment"># 绘制箱图</span></span><br><span class="line">plt.figure()</span><br><span class="line">plt.boxplot(body_mass_gs,labels=labels,showmeans=<span class="literal">True</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># 绘制小提琴图</span></span><br><span class="line">plt.figure()</span><br><span class="line">plt.violinplot(body_mass_gs,showmeans=<span class="literal">True</span>)</span><br><span class="line">plt.xticks(ticks = [<span class="number">1</span>, <span class="number">2</span>,<span class="number">3</span>], labels = labels, fontsize = <span class="number">11</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204165141807.png" alt="image-20230204165141807" style="zoom:50%;" /><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204165150819.png" alt="image-20230204165150819" style="zoom:50%;" /></p><h2 id="总结-2">总结</h2><p>EDA是为了发现各种问题，全面的了解数据，以直观的方式表达。可以从以下的角度入手：</p><ol type="1"><li>特征均值、方差、分布</li><li>样本数据与特征的关系</li><li>特征与特征间的关系</li></ol><h1 id="实验四-分类方法-svm算法">实验四 分类方法-SVM算法</h1><h2 id="实验目的-3">实验目的</h2><ol type="1"><li>掌握sklearn调用SVM</li><li>了解sklearn中SVM的参数和使用效果</li><li>了解sklearn的正则化方法，以及确认正则化系数的方法</li><li>实现线性SVM算法</li></ol><h2 id="实验场地与设备-3">实验场地与设备</h2><p>实验室4074</p><h2 id="实验方式-3">实验方式</h2><p>阅读教程与程序设计</p><h2 id="实验设计-3">实验设计</h2><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204180455883.png" alt="image-20230204180455883" style="zoom:50%;" /></p><h2 id="实验内容-3">实验内容</h2><h3 id="基本知识点总结">1.基本知识点总结</h3><p>（1) 基本概念</p><p>支持向量机（support vector machines,SVM）是一种二分类模型，它的基本模型是定义在特征空间上的间隔最大的线性分类器；SVM还包括核技巧(kerneltrick)，这使它成为实质上的非线性分类器。</p><p>对于支持向量机来说，数据点被视为p 维向量，而我们想知道是否可以用(p-1)维超平面来分开这些点。这就是所谓的线性分类器。可能有许多超平面可以把数据分类。最佳超平面的一个合理选择是以最大间隔把两个类分开的超平面。因此，我们要选择能够让到每边最近的数据点的距离最大化的超平面。如果存在这样的超平面，则称为<strong>最大间隔超平面</strong>，而其定义的线性分类器被称为<strong>最大间隔分类器</strong></p><p>（2) 分类</p><p>按照决策面类型分为：</p><ul><li>核函数为线性的SVM</li><li>线性SVM分类器</li><li>核函数为径向基核函数的SVM分类器</li><li>核函数为多项式的SVM分类器</li></ul><p>（3）算法</p><p>SVM的学习策略就是间隔最大化，可形式化为一个求解凸二次规划的问题，也等价于正则化的合页损失函数的最小化问题。SVM的的学习算法就是求解凸二次规划的最优化算法。</p><p><strong>举出线性支持向量机算法如下：</strong></p><p><strong>输入</strong>：训练数据集<spanclass="math inline">\(T={(x_1,y_1),(x_2,y_2),…,(x_N,y_N)}\)</span></p><p>其中<spanclass="math inline">\(x_i∈R^n,y_i∈{+1,-1},i=1,2,...,N\)</span></p><p><strong>输出</strong>：分离超平面和分类决策函数</p><p>（1）选择惩罚参数 <spanclass="math inline">\(C&gt;0\)</span>，构造并求解凸二次规划问题 <spanclass="math display">\[min 1/2 \sum_{i=1}^N\sum_{j=1}^N{α_i α_j y_i y_j(x_i·x_j)}-\sum_{i=1}^N{α_i}\]</span></p><p><span class="math display">\[s.t.∑_{i=1}^N{α_i y_i}=0,0≤α_i≤C,i=1,2,...,N\]</span></p><p>得到最优解 <spanclass="math inline">\(α^*=(α_1^*,α_2^*,...,α_N^*)\)</span></p><p>（2）计算<span class="math inline">\(w^*=∑_{i=1}^N{α_i^* y_i x_i}\)</span></p><p>选择 <span class="math inline">\(\alpha^*\)</span> 的一个分量 <spanclass="math inline">\(\alpha^*_j\)</span>满足条件 <spanclass="math inline">\(0&lt;\alpha^*_j&lt;C\)</span> ，计算<spanclass="math inline">\(b^*=y_i-∑_{i=1}^N{α_i^* y_i }\)</span></p><p>（3）求分离超平面<span class="math inline">\(w^*·x+b^*=0\)</span></p><p>分类决策函数：<spanclass="math inline">\(f(x)=sign(w^*·x+b^*)\)</span></p><p>（4） 模型特点</p><p>SVM的潜在缺点包括以下方面：</p><ul><li><p>需要对输入数据进行完全标记</p></li><li><p>未校准类成员概率</p></li><li><p>SVM仅直接适用于两类任务。因此，必须应用将多类任务减少到几个二元问题的算法</p></li></ul><h3 id="线性svm实现">2.线性SVM实现</h3><h4 id="smo算法">SMO算法</h4><p>SMO表示<strong>序列最小优化 ( Sequential Minimal Optimization)</strong>。Platt的SMO算法是将大优化问题分解为多个小优化问题来求解的。这些小优化问题往往很容易求解,并且对它们进行顺序求解的结果与将它们作为整体来求解的结果是完全一致的。在结果完全相同的同时,SMO算法的求解时间短很多。</p><p><strong>简化版SMO</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">smoSimple.py</span><br><span class="line">input：maxIter,X,y,toler,C</span><br><span class="line">output：b，alphas</span><br><span class="line"></span><br><span class="line"> alphas = np.mat(np.zeros((m,1)))#初始化alpha参数，设置为0</span><br><span class="line"> for iterSmo in range(maxIter):</span><br><span class="line"> for i in range(np.shape(X)[0]):</span><br><span class="line"> 计算Ei</span><br><span class="line"> if ((y[i]*Ei &lt; -toler) and (alphas[i] &lt; C)) or ((y[i]*Ei &gt; -toler) and (alphas[i] &gt; 0)):</span><br><span class="line">            随机选择一个向量</span><br><span class="line">            j = selectJrand(i,m)</span><br><span class="line">            进行优化</span><br><span class="line">            alphaPairsChanged += 1</span><br><span class="line">            #打印统计信息</span><br><span class="line">            print(&quot;第%d次迭代 样本:%d, alpha优化次数:%d&quot; % (iterSmo,i,alphaPairsChanged))</span><br><span class="line"> if (alphaPairsChanged == 0): iterSmo += 1</span><br><span class="line">        else:</span><br><span class="line">            iterSmo = 0</span><br><span class="line">        print(&quot;迭代次数：%d&quot; % iterSmo)</span><br><span class="line">    return b,alphas</span><br></pre></td></tr></table></figure><p>Python实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">selectJrand</span>(<span class="params">i,m</span>):</span><br><span class="line">    j=i</span><br><span class="line">    <span class="keyword">while</span>(j==i): <span class="comment">#选择一个不等于i的j</span></span><br><span class="line">        j = <span class="built_in">int</span>(random.uniform(<span class="number">0</span>,m))</span><br><span class="line">    <span class="keyword">return</span> j</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">clipAlpha</span>(<span class="params">aj,H,L</span>):</span><br><span class="line">    <span class="keyword">if</span> aj &gt; H:</span><br><span class="line">        aj = H</span><br><span class="line">    <span class="keyword">if</span> L &gt; aj:</span><br><span class="line">        aj = L</span><br><span class="line">    <span class="keyword">return</span> aj</span><br><span class="line"></span><br><span class="line"><span class="comment">#简化版SMO算法</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">smoSimple</span>(<span class="params">dataMatIn,classLabels,C,toler,maxIter</span>):</span><br><span class="line">    dataMatrix = np.mat(dataMatIn); labelMat = np.mat(classLabels).transpose()</span><br><span class="line">    b = <span class="number">0</span>; m,n = np.shape(dataMatrix)</span><br><span class="line">    alphas = np.mat(np.zeros((m,<span class="number">1</span>)))<span class="comment">#初始化alpha参数，设置为0</span></span><br><span class="line">    iterSmo = <span class="number">0</span> <span class="comment">#初始化迭代次数</span></span><br><span class="line">    <span class="keyword">while</span>(iterSmo &lt; maxIter):</span><br><span class="line">        alphaPairsChanged = <span class="number">0</span><span class="comment">#用于记录alpha是否已经进行优化</span></span><br><span class="line">        <span class="comment">#步骤1. 计算误差Ei</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">            fXi = <span class="built_in">float</span>(np.multiply(alphas,labelMat).T*(dataMatrix*dataMatrix[i,:].T)) + b</span><br><span class="line">            Ei = fXi - <span class="built_in">float</span>(labelMat[i])</span><br><span class="line">            <span class="keyword">if</span> ((labelMat[i]*Ei &lt; -toler) <span class="keyword">and</span> (alphas[i] &lt; C)) <span class="keyword">or</span> ((labelMat[i]*Ei &gt; -toler) <span class="keyword">and</span> (alphas[i] &gt; <span class="number">0</span>)):</span><br><span class="line">                j = selectJrand(i,m)</span><br><span class="line">                <span class="comment">#步骤1. 计算误差Ej</span></span><br><span class="line">                fXj = <span class="built_in">float</span>(np.multiply(alphas,labelMat).T*(dataMatrix*dataMatrix[j,:].T)) + b</span><br><span class="line">                Ej = fXj - <span class="built_in">float</span>(labelMat[j])</span><br><span class="line">                <span class="comment">#保存更新前的alpha值，使用浅拷贝</span></span><br><span class="line">                alphaIold = alphas[i].copy()</span><br><span class="line">                alphaJold = alphas[j].copy()</span><br><span class="line">                <span class="comment">#步骤2：计算上界H和下界L</span></span><br><span class="line">                <span class="keyword">if</span> (labelMat[i] != labelMat[j]):</span><br><span class="line">                    L = <span class="built_in">max</span>(<span class="number">0</span>,alphas[j] - alphas[i])</span><br><span class="line">                    H = <span class="built_in">min</span>(C,C + alphas[j] - alphas[i])</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    L = <span class="built_in">max</span>(<span class="number">0</span>,alphas[j] + alphas[i] - C)</span><br><span class="line">                    H = <span class="built_in">min</span>(C,alphas[j] + alphas[i])</span><br><span class="line">                <span class="keyword">if</span> L==H: <span class="built_in">print</span>(<span class="string">&quot;L==H&quot;</span>); <span class="keyword">continue</span></span><br><span class="line">                <span class="comment">#步骤3：计算eta</span></span><br><span class="line">                eta = <span class="number">2.0</span> * dataMatrix[i,:]*dataMatrix[j,:].T - dataMatrix[i,:]*dataMatrix[i,:].T - dataMatrix[j,:]*dataMatrix[j,:].T</span><br><span class="line">                <span class="keyword">if</span> eta &gt;=<span class="number">0</span> : <span class="built_in">print</span>(<span class="string">&quot;eta&gt;=0&quot;</span>);<span class="keyword">continue</span></span><br><span class="line">                <span class="comment">#步骤4：更新alpha_j</span></span><br><span class="line">                alphas[j] -= labelMat[j]*(Ei-Ej)/eta</span><br><span class="line">                <span class="comment">#步骤5：修剪alpha_j</span></span><br><span class="line">                alphas[j] = clipAlpha(alphas[j],H,L)</span><br><span class="line">                <span class="keyword">if</span> (<span class="built_in">abs</span>(alphas[j] - alphaJold) &lt; <span class="number">0.00001</span>) : <span class="built_in">print</span>(<span class="string">&quot;j not moving enough&quot;</span>) ; <span class="keyword">continue</span></span><br><span class="line">                <span class="comment">#步骤6：更新alpha_i</span></span><br><span class="line">                alphas[i] += labelMat[j]*labelMat[i]*(alphaJold - alphas[j])</span><br><span class="line">                <span class="comment">#步骤7：更新b_1和b_2</span></span><br><span class="line">                b1 = b - Ei - labelMat[i]*(alphas[i] - alphaIold)*dataMatrix[i,:]*dataMatrix[i,:].T \</span><br><span class="line">                - labelMat[j]*(alphas[j] - alphaJold)*dataMatrix[i,:]*dataMatrix[j,:].T</span><br><span class="line">                b2 = b - Ej - labelMat[i]*(alphas[i] - alphaIold)*dataMatrix[i,:]*dataMatrix[j,:].T \</span><br><span class="line">                - labelMat[j]*(alphas[j] - alphaJold)*dataMatrix[j,:]*dataMatrix[j,:].T</span><br><span class="line">                <span class="comment">#步骤8：根据b_1和b_2更新b</span></span><br><span class="line">                <span class="keyword">if</span> (<span class="number">0</span> &lt; alphas[i]) <span class="keyword">and</span> (C &gt; alphas[i]) :</span><br><span class="line">                    b = b1</span><br><span class="line">                <span class="keyword">elif</span> (<span class="number">0</span> &lt; alphas[j]) <span class="keyword">and</span> (C &gt; alphas[j]):</span><br><span class="line">                    b = b2</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    b = (b1 + b2)/<span class="number">2.0</span></span><br><span class="line">                <span class="comment">#统计优化次数</span></span><br><span class="line">                <span class="comment">#如果程序执行到for循环的最后一行都不执行continue语句，那么就已经成功地改变了一对alpha，同时可以增加alphaPairsChanged的值</span></span><br><span class="line">                alphaPairsChanged += <span class="number">1</span></span><br><span class="line">                <span class="comment">#打印统计信息</span></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;第%d次迭代 样本:%d, alpha优化次数:%d&quot;</span> % (iterSmo,i,alphaPairsChanged))</span><br><span class="line">        <span class="comment">#更新迭代次数</span></span><br><span class="line">        <span class="comment">#在for循环之外，需要检查alpha值是否做了更新，如果有更新则将iterSmo设为0后继续运行程序。只有在所有数据集上遍历maxIter次，且不再发生任何alpha修改之后，程序才会停止并退出while循环</span></span><br><span class="line">        <span class="keyword">if</span> (alphaPairsChanged == <span class="number">0</span>): iterSmo += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            iterSmo = <span class="number">0</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;迭代次数：%d&quot;</span> % iterSmo)</span><br><span class="line">    <span class="keyword">return</span> b,alphas</span><br></pre></td></tr></table></figure><h3 id="支持向量机核方法对比">3.支持向量机核方法对比</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm, datasets</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_meshgrid</span>(<span class="params">x, y, h=<span class="number">.02</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;创建要绘制的点网格</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    参数</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    x: 创建网格x轴所需要的数据</span></span><br><span class="line"><span class="string">    y: 创建网格y轴所需要的数据</span></span><br><span class="line"><span class="string">    h: 网格大小的可选大小，可选填</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    返回</span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string">    xx, yy : n维数组</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    x_min, x_max = x.<span class="built_in">min</span>() - <span class="number">1</span>, x.<span class="built_in">max</span>() + <span class="number">1</span></span><br><span class="line">    y_min, y_max = y.<span class="built_in">min</span>() - <span class="number">1</span>, y.<span class="built_in">max</span>() + <span class="number">1</span></span><br><span class="line">    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),</span><br><span class="line">                         np.arange(y_min, y_max, h))</span><br><span class="line">    <span class="keyword">return</span> xx, yy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_contours</span>(<span class="params">ax, clf, xx, yy, **params</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;绘制分类器的决策边界。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    参数</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    ax: matplotlib子图对象</span></span><br><span class="line"><span class="string">    clf: 一个分类器</span></span><br><span class="line"><span class="string">    xx: 网状网格meshgrid的n维数组</span></span><br><span class="line"><span class="string">    yy: 网状网格meshgrid的n维数组</span></span><br><span class="line"><span class="string">    params: 传递给contourf的参数字典，可选填</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])</span><br><span class="line">    Z = Z.reshape(xx.shape)</span><br><span class="line">    out = ax.contourf(xx, yy, Z, **params)</span><br><span class="line">    <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入数据以便后续使用</span></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line"><span class="comment"># 采用前两个特征</span></span><br><span class="line">X = iris.data[:, :<span class="number">2</span>]</span><br><span class="line">y = iris.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个SVM实例并拟合数据。由于要绘制支持向量，因此我们不缩放数据</span></span><br><span class="line">C = <span class="number">1.0</span>  <span class="comment"># SVM正则化参数</span></span><br><span class="line">models = (svm.SVC(kernel=<span class="string">&#x27;linear&#x27;</span>, C=C),</span><br><span class="line">          svm.LinearSVC(C=C, max_iter=<span class="number">10000</span>),</span><br><span class="line">          svm.SVC(kernel=<span class="string">&#x27;rbf&#x27;</span>, gamma=<span class="number">0.7</span>, C=C),</span><br><span class="line">          svm.SVC(kernel=<span class="string">&#x27;poly&#x27;</span>, degree=<span class="number">3</span>, gamma=<span class="string">&#x27;auto&#x27;</span>, C=C))</span><br><span class="line">models = (clf.fit(X, y) <span class="keyword">for</span> clf <span class="keyword">in</span> models)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 为图像设置标题</span></span><br><span class="line">titles = (<span class="string">&#x27;SVC with linear kernel&#x27;</span>,</span><br><span class="line">          <span class="string">&#x27;LinearSVC (linear kernel)&#x27;</span>,</span><br><span class="line">          <span class="string">&#x27;SVC with RBF kernel&#x27;</span>,</span><br><span class="line">          <span class="string">&#x27;SVC with polynomial (degree 3) kernel&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置一个2x2结构的画布</span></span><br><span class="line">fig, sub = plt.subplots(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.subplots_adjust(wspace=<span class="number">0.4</span>, hspace=<span class="number">0.4</span>)</span><br><span class="line"></span><br><span class="line">X0, X1 = X[:, <span class="number">0</span>], X[:, <span class="number">1</span>]</span><br><span class="line">xx, yy = make_meshgrid(X0, X1)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> clf, title, ax <span class="keyword">in</span> <span class="built_in">zip</span>(models, titles, sub.flatten()):</span><br><span class="line">    plot_contours(ax, clf, xx, yy,</span><br><span class="line">                  cmap=plt.cm.coolwarm, alpha=<span class="number">0.8</span>)</span><br><span class="line">    ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=<span class="number">20</span>, edgecolors=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line">    ax.set_xlim(xx.<span class="built_in">min</span>(), xx.<span class="built_in">max</span>())</span><br><span class="line">    ax.set_ylim(yy.<span class="built_in">min</span>(), yy.<span class="built_in">max</span>())</span><br><span class="line">    ax.set_xlabel(<span class="string">&#x27;Sepal length&#x27;</span>)</span><br><span class="line">    ax.set_ylabel(<span class="string">&#x27;Sepal width&#x27;</span>)</span><br><span class="line">    ax.set_xticks(())</span><br><span class="line">    ax.set_yticks(())</span><br><span class="line">    ax.set_title(title)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204171813486.png"alt="image-20230204171813486" /><figcaption aria-hidden="true">image-20230204171813486</figcaption></figure><h3id="通过svm对鸢尾花数据集做预处理训练预测并进行准确率估计">4.通过SVM对鸢尾花数据集做预处理、训练、预测并进行准确率估计。</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> colors</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line"><span class="comment">#读入数据</span></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line"><span class="comment">#定义训练集和测试集</span></span><br><span class="line">X= iris.data</span><br><span class="line">y=iris.target</span><br><span class="line">x=X[:,<span class="number">0</span>:<span class="number">2</span>]</span><br><span class="line"><span class="comment">#在 X中取前两列作为特征（为了后期的可视化画图）</span></span><br><span class="line">x_train,x_test,y_train,y_test=model_selection.train_test_split(x,y,random_state=<span class="number">0</span>,test_size=<span class="number">0.3</span>)</span><br><span class="line"><span class="comment"># 用train_test_split将数据随机分为训练集和测试集，测试集占总数据的30%（test_size=0.3),random_state是随机数种子</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#搭建模型，训练SVM分类器</span></span><br><span class="line">classifier=svm.SVC(kernel=<span class="string">&#x27;rbf&#x27;</span>,gamma=<span class="number">0.1</span>,decision_function_shape=<span class="string">&#x27;ovo&#x27;</span>,C=<span class="number">0.8</span>)</span><br><span class="line"><span class="comment">#开始训练</span></span><br><span class="line">classifier.fit(x_train,y_train.ravel())</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show_accuracy</span>(<span class="params">y_hat,y_train,<span class="built_in">str</span></span>):</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#（4）计算svm分类器的准确率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;SVM-输出训练集的准确率为：&quot;</span>,classifier.score(x_train,y_train))</span><br><span class="line">y_hat=classifier.predict(x_train)</span><br><span class="line">show_accuracy(y_hat,y_train,<span class="string">&#x27;训练集&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;SVM-输出测试集的准确率为：&quot;</span>,classifier.score(x_test,y_test))</span><br><span class="line">y_hat=classifier.predict(x_test)</span><br><span class="line">show_accuracy(y_hat,y_test,<span class="string">&#x27;测试集&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看决策函数，通过decision_function()实现。decision_function中每一列的值代表距离各类别的距离。</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\npredict:\n&#x27;</span>, classifier.predict(x_train))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#绘制图像</span></span><br><span class="line">x1_min, x1_max = x[:, <span class="number">0</span>].<span class="built_in">min</span>(), x[:, <span class="number">0</span>].<span class="built_in">max</span>()</span><br><span class="line">x2_min, x2_max = x[:, <span class="number">1</span>].<span class="built_in">min</span>(), x[:, <span class="number">1</span>].<span class="built_in">max</span>()</span><br><span class="line">x1, x2 = np.mgrid[x1_min:x1_max:<span class="number">200j</span>, x2_min:x2_max:<span class="number">200j</span>]</span><br><span class="line"></span><br><span class="line">grid_test = np.stack((x1.flat, x2.flat), axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 测试点，再通过stack()函数，axis=1，生成测试点</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;grid_test = \n&quot;</span>, grid_test)</span><br><span class="line"><span class="comment"># 预测分类值</span></span><br><span class="line">grid_hat = classifier.predict(grid_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;grid_hat = \n&quot;</span>, grid_hat)</span><br><span class="line"></span><br><span class="line">grid_hat = grid_hat.reshape(x1.shape)</span><br><span class="line"><span class="comment">#绘制</span></span><br><span class="line">cm_light = mpl.colors.ListedColormap([<span class="string">&#x27;#A0FFA0&#x27;</span>, <span class="string">&#x27;#FFA0A0&#x27;</span>, <span class="string">&#x27;#A0A0FF&#x27;</span>])</span><br><span class="line">cm_dark = mpl.colors.ListedColormap([<span class="string">&#x27;g&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;b&#x27;</span>])</span><br><span class="line"></span><br><span class="line">alpha=<span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">plt.pcolormesh(x1, x2, grid_hat, cmap=cm_light) <span class="comment"># 预测值的显示</span></span><br><span class="line"><span class="comment"># plt.scatter(x[:, 0], x[:, 1], c=y, edgecolors=&#x27;k&#x27;, s=50, cmap=cm_dark)  # 样本</span></span><br><span class="line">plt.plot(x[:, <span class="number">0</span>], x[:, <span class="number">1</span>], <span class="string">&#x27;o&#x27;</span>, alpha=alpha, color=<span class="string">&#x27;blue&#x27;</span>, markeredgecolor=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line">plt.scatter(x_test[:, <span class="number">0</span>], x_test[:, <span class="number">1</span>], s=<span class="number">120</span>, facecolors=<span class="string">&#x27;none&#x27;</span>, zorder=<span class="number">10</span>)  <span class="comment"># 圈中测试集样本</span></span><br><span class="line">plt.xlabel(<span class="string">u&#x27;花萼长度&#x27;</span>, fontsize=<span class="number">13</span>)</span><br><span class="line">plt.ylabel(<span class="string">u&#x27;花萼宽度&#x27;</span>, fontsize=<span class="number">13</span>)</span><br><span class="line">plt.xlim(x1_min, x1_max)</span><br><span class="line">plt.ylim(x2_min, x2_max)</span><br><span class="line">plt.title(<span class="string">u&#x27;鸢尾花SVM二特征分类&#x27;</span>, fontsize=<span class="number">15</span>)</span><br><span class="line"><span class="comment"># plt.grid()</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204172358319.png"alt="image-20230204172358319" /><figcaption aria-hidden="true">image-20230204172358319</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204172435520.png"alt="image-20230204172435520" /><figcaption aria-hidden="true">image-20230204172435520</figcaption></figure><h3 id="正则化项选择">5.正则化项选择</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> permutation_test_score</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"></span><br><span class="line">iris = load_iris()</span><br><span class="line">X = iris.data</span><br><span class="line">y = iris.target</span><br><span class="line"></span><br><span class="line">clf = SVC(kernel=<span class="string">&quot;linear&quot;</span>, random_state=<span class="number">7</span>)</span><br><span class="line">cv = StratifiedKFold(<span class="number">2</span>, shuffle=<span class="literal">True</span>, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">score_iris, perm_scores_iris, pvalue_iris = permutation_test_score(</span><br><span class="line">    clf, X, y, scoring=<span class="string">&quot;accuracy&quot;</span>, cv=cv, n_permutations=<span class="number">1000</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(score_iris)</span><br></pre></td></tr></table></figure><h3 id="svr">6.SVR</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVR</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">data=sio.loadmat(<span class="string">&quot;NIRcorn.mat&quot;</span>)</span><br><span class="line">cornwavelength=data[<span class="string">&quot;cornwavelength&quot;</span>]</span><br><span class="line">x=[]</span><br><span class="line"><span class="comment"># 输出观察发现，是一个ndarray组成的list所以只取第一个元素</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(cornwavelength)):</span><br><span class="line">    x.append(cornwavelength[i][<span class="number">0</span>])</span><br><span class="line">x=np.array(x).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"><span class="comment"># 获取吸光率</span></span><br><span class="line">cornspect = data[<span class="string">&#x27;cornspect&#x27;</span>]</span><br><span class="line"><span class="comment"># 随机取出1组透光率</span></span><br><span class="line">rd=np.random.randint(<span class="number">0</span>,<span class="number">80</span>,<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 存储透光率数据</span></span><br><span class="line">y = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">700</span>):</span><br><span class="line">    y.append(cornspect[rd[<span class="number">0</span>], i])</span><br><span class="line">y=np.array(y).ravel()</span><br><span class="line"><span class="comment">#径向基函数拟合模型</span></span><br><span class="line">svr_rbf = SVR(kernel=<span class="string">&quot;rbf&quot;</span>, C=<span class="number">100</span>, gamma=<span class="number">0.1</span>, epsilon=<span class="number">0.1</span>)</span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line">fig=plt.figure(<span class="number">1</span>)</span><br><span class="line">plt.plot(x, svr_rbf.fit(x, y).predict(x))</span><br><span class="line">plt.scatter(x,y,s=<span class="number">2</span>,c=<span class="string">&#x27;green&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment">#多项式核拟合模型</span></span><br><span class="line">svr_poly = SVR(kernel=<span class="string">&quot;rbf&quot;</span>, C=<span class="number">50</span>, gamma=<span class="string">&#x27;auto&#x27;</span>, epsilon=<span class="number">0.1</span>)</span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line">fig=plt.figure(<span class="number">2</span>)</span><br><span class="line">plt.plot(x, svr_poly.fit(x, y).predict(x))</span><br><span class="line">plt.scatter(x,y,s=<span class="number">2</span>,c=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204181207801.png" alt="image-20230204181207801" style="zoom:33%;" /></p><h2 id="总结-3">总结</h2><p>SVM作为一个经典的模型，他综合了代数、几何、优化、泛函等一系列数学知识，是一个简洁而又漂亮的模型。这种模型对于我继续学习具有很大帮助。</p><h1 id="实验五-关联分析算法应用">实验五 关联分析算法应用</h1><h2 id="实验目的-4">实验目的</h2><ol type="1"><li>对给定数据集进行整理，利用apriori，FP-Growth算法对给定数据集进行分类；</li><li>理解不同分类的算法的原理，掌握apriori， FP-Growth 算法的应用；</li><li>掌握apriori算法原理；</li><li>掌握FP-Growth算法原理；</li><li>调用sklearn中的数据集进行相关算法的实验</li></ol><h2 id="实验场地与设备-4">实验场地与设备</h2><p>实验室4074</p><h2 id="实验方式-4">实验方式</h2><p>阅读教程与程序设计</p><h2 id="实验设计-4">实验设计</h2><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204175935517.png" alt="image-20230204175935517" style="zoom:50%;" /></p><h2 id="实验内容-4">实验内容</h2><h3 id="知识总结">1.知识总结</h3><p>（1）基本概念</p><p>支持度：关联规则A-&gt;B的支持度support=P(AB)，指的是事件A和事件B同时发生的概率</p><p>置信度：置信度confidence=P(B|A)=P(AB)/P(A),指的是发生事件A的基础上发生事件B的概率。</p><p>k项集：如果事件A中包含k个元素，那么称这个事件A为k项集，并且事件A满足最小支持度阈值的事件称为频繁k项集</p><p>（2）Apriori算法</p><p>Apriori算法过程分为两个步骤：</p><p>第一步通过迭代，检索出事务数据库中的所有频繁项集，即支持度不低于用户设定的阈值的项集；</p><p>第二步利用频繁项集构造出满足用户最小信任度的规则。</p><p>（3） FP-Growth算法</p><p>FP Tree算法包括三步：</p><ul><li><p>扫描数据，得到所有频繁一项集的的计数。然后删除支持度低于阈值的项，将1项频繁集放入项头表，并按照支持度降序排列。扫描数据，将读到的原始数据剔除非频繁1项集，并按照支持度降序排列。读入排序后的数据集，插入FP树，插入时按照排序后的顺序，插入FP树中，排序靠前的节点是祖先节点，而靠后的是子孙节点。如果有共用的祖先，则对应的公用祖先节点计数加1。插入后，如果有新节点出现，则项头表对应的节点会通过节点链表链接上新节点。直到所有的数据都插入到FP树后，FP树的建立完成。</p></li><li><p>从项头表的底部项依次向上找到项头表项对应的条件模式基。从条件模式基递归挖掘得到项头表项项的频繁项集。</p></li><li><p>如果不限制频繁项集的项数，则返回步骤4所有的频繁项集，否则只返回满足项数要求的频繁项集。</p></li></ul><ol start="4" type="1"><li>两大算法比较</li></ol><p>经典的关联规则挖掘算法包括Apriori算法和FP-growth算法。apriori算法多次扫描交易数据库，每次利用候选频繁集产生频繁集；而FP-growth则利用树形结构，无需产生候选频繁集而是直接得到频繁集，大大减少扫描交易数据库的次数，从而提高了算法的效率，FPTree算法改进了Apriori算法的I/O瓶颈，巧妙的利用了树结构，这让我们想起了BIRCH聚类，BIRCH聚类也是巧妙的利用了树结构来提高算法运行速度。利用内存数据结构以空间换时间是常用的提高算法运行时间瓶颈的办法。但是apriori的算法扩展性较好，可以用于并行计算等领域。</p><h3 id="apriori算法进行关联分析">2.Apriori算法进行关联分析</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_data_set</span>():</span><br><span class="line">    data_set = [</span><br><span class="line">        [<span class="string">&#x27;beer&#x27;</span>, <span class="string">&#x27;baby diapers&#x27;</span>, <span class="string">&#x27;shorts&#x27;</span>]</span><br><span class="line">        , [<span class="string">&#x27;baby diapers&#x27;</span>, <span class="string">&#x27;shorts&#x27;</span>]</span><br><span class="line">        , [<span class="string">&#x27;baby diapers&#x27;</span>, <span class="string">&#x27;milk&#x27;</span>]</span><br><span class="line">        , [<span class="string">&#x27;beer&#x27;</span>, <span class="string">&#x27;baby diapers&#x27;</span>, <span class="string">&#x27;shorts&#x27;</span>]</span><br><span class="line">        , [<span class="string">&#x27;beer&#x27;</span>, <span class="string">&#x27;milk&#x27;</span>]</span><br><span class="line">        , [<span class="string">&#x27;baby diapers&#x27;</span>, <span class="string">&#x27;milk&#x27;</span>]</span><br><span class="line">        , [<span class="string">&#x27;beer&#x27;</span>, <span class="string">&#x27;milk&#x27;</span>]</span><br><span class="line">        , [<span class="string">&#x27;beer&#x27;</span>, <span class="string">&#x27;baby diapers&#x27;</span>, <span class="string">&#x27;milk&#x27;</span>, <span class="string">&#x27;shorts&#x27;</span>]</span><br><span class="line">        , [<span class="string">&#x27;beer&#x27;</span>, <span class="string">&#x27;baby diapers&#x27;</span>, <span class="string">&#x27;milk&#x27;</span>]</span><br><span class="line">    ]</span><br><span class="line">    <span class="keyword">return</span> data_set</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_C1</span>(<span class="params">data_set</span>):</span><br><span class="line">    C1 = <span class="built_in">set</span>()</span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> data_set:</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> t:</span><br><span class="line">            item_set = <span class="built_in">frozenset</span>([item])</span><br><span class="line">            C1.add(item_set)</span><br><span class="line">    <span class="keyword">return</span> C1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">is_apriori</span>(<span class="params">Ck_item, Lksub1</span>):</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> Ck_item:</span><br><span class="line">        sub_Ck = Ck_item - <span class="built_in">frozenset</span>([item])</span><br><span class="line">        <span class="keyword">if</span> sub_Ck <span class="keyword">not</span> <span class="keyword">in</span> Lksub1:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_Ck</span>(<span class="params">Lksub1, k</span>):</span><br><span class="line">    Ck = <span class="built_in">set</span>()</span><br><span class="line">    len_Lksub1 = <span class="built_in">len</span>(Lksub1)</span><br><span class="line">    list_Lksub1 = <span class="built_in">list</span>(Lksub1)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(len_Lksub1):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, len_Lksub1):</span><br><span class="line">            l1 = <span class="built_in">list</span>(list_Lksub1[i])</span><br><span class="line">            l2 = <span class="built_in">list</span>(list_Lksub1[j])</span><br><span class="line">            l1.sort()</span><br><span class="line">            l2.sort()</span><br><span class="line">            <span class="keyword">if</span> l1[<span class="number">0</span>:k-<span class="number">2</span>] == l2[<span class="number">0</span>:k-<span class="number">2</span>]:</span><br><span class="line">                Ck_item = list_Lksub1[i] | list_Lksub1[j]</span><br><span class="line">                <span class="keyword">if</span> is_apriori(Ck_item, Lksub1):</span><br><span class="line">                    Ck.add(Ck_item)</span><br><span class="line">    <span class="keyword">return</span> Ck</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_Lk_by_Ck</span>(<span class="params">data_set, Ck, min_support, support_data</span>):</span><br><span class="line">    Lk = <span class="built_in">set</span>()</span><br><span class="line">    item_count = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> data_set:</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> Ck:</span><br><span class="line">            <span class="keyword">if</span> item.issubset(t):</span><br><span class="line">                <span class="keyword">if</span> item <span class="keyword">not</span> <span class="keyword">in</span> item_count:</span><br><span class="line">                    item_count[item] = <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    item_count[item] += <span class="number">1</span></span><br><span class="line">    t_num = <span class="built_in">float</span>(<span class="built_in">len</span>(data_set))</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> item_count:</span><br><span class="line">        <span class="keyword">if</span> (item_count[item] / t_num) &gt;= min_support:</span><br><span class="line">            Lk.add(item)</span><br><span class="line">            support_data[item] = item_count[item] / t_num</span><br><span class="line">    <span class="keyword">return</span> Lk</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_L</span>(<span class="params">data_set, k, min_support</span>):</span><br><span class="line">    support_data = &#123;&#125;</span><br><span class="line">    C1 = create_C1(data_set)</span><br><span class="line">    L1 = generate_Lk_by_Ck(data_set, C1, min_support, support_data)</span><br><span class="line">    Lksub1 = L1.copy()</span><br><span class="line">    L = []</span><br><span class="line">    L.append(Lksub1)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, k+<span class="number">1</span>):</span><br><span class="line">        Ci = create_Ck(Lksub1, i)</span><br><span class="line">        Li = generate_Lk_by_Ck(data_set, Ci, min_support, support_data)</span><br><span class="line">        Lksub1 = Li.copy()</span><br><span class="line">        L.append(Lksub1)</span><br><span class="line">    <span class="keyword">return</span> L, support_data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_big_rules</span>(<span class="params">L, support_data, min_conf</span>):</span><br><span class="line">    big_rule_list = []</span><br><span class="line">    sub_set_list = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(L)):</span><br><span class="line">        <span class="keyword">for</span> freq_set <span class="keyword">in</span> L[i]:</span><br><span class="line">            <span class="keyword">for</span> sub_set <span class="keyword">in</span> sub_set_list:</span><br><span class="line">                <span class="keyword">if</span> sub_set.issubset(freq_set):</span><br><span class="line">                    conf = support_data[freq_set] / support_data[freq_set - sub_set]</span><br><span class="line">                    big_rule = (freq_set - sub_set, sub_set, conf)</span><br><span class="line">                    <span class="keyword">if</span> conf &gt;= min_conf <span class="keyword">and</span> big_rule <span class="keyword">not</span> <span class="keyword">in</span> big_rule_list:</span><br><span class="line">                        big_rule_list.append(big_rule)</span><br><span class="line">            sub_set_list.append(freq_set)</span><br><span class="line">    <span class="keyword">return</span> big_rule_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Test</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    data_set = load_data_set()</span><br><span class="line">    L, support_data = generate_L(data_set, k=<span class="number">3</span>, min_support=<span class="number">0.2</span>)</span><br><span class="line">    big_rules_list = generate_big_rules(L, support_data, min_conf=<span class="number">0.7</span>)</span><br><span class="line">    <span class="keyword">for</span> Lk <span class="keyword">in</span> L:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;=&quot;</span>*<span class="number">50</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;frequent &quot;</span> + <span class="built_in">str</span>(<span class="built_in">len</span>(<span class="built_in">list</span>(Lk)[<span class="number">0</span>])) + <span class="string">&quot;-itemsets\t\tsupport&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;=&quot;</span>*<span class="number">50</span>)</span><br><span class="line">        <span class="keyword">for</span> freq_set <span class="keyword">in</span> Lk:</span><br><span class="line">            <span class="built_in">print</span>(freq_set, support_data[freq_set])</span><br><span class="line">    <span class="built_in">print</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Big Rules&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> big_rules_list:</span><br><span class="line">        <span class="built_in">print</span>(item[<span class="number">0</span>], <span class="string">&quot;=&gt;&quot;</span>, item[<span class="number">1</span>], <span class="string">&quot;conf: &quot;</span>, item[<span class="number">2</span>])</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204173031686.png" alt="image-20230204173031686" style="zoom:50%;" /></p><h3 id="fp-growth算法进行关联分析">3.FP-Growth算法进行关联分析</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">treeNode</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, nameValue, numOccur, parentNode</span>):</span><br><span class="line">        self.name = nameValue</span><br><span class="line">        self.count = numOccur</span><br><span class="line">        self.nodeLink = <span class="literal">None</span> <span class="comment">#nodeLink 变量用于链接相似的元素项</span></span><br><span class="line">        self.parent = parentNode <span class="comment">#指向当前节点的父节点</span></span><br><span class="line">        self.children = &#123;&#125; <span class="comment">#空字典，存放节点的子节点</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">inc</span>(<span class="params">self, numOccur</span>):<span class="comment">#计数加1</span></span><br><span class="line">        self.count += numOccur</span><br><span class="line"></span><br><span class="line"><span class="comment">#将树以文本形式显示</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">disp</span>(<span class="params">self, ind=<span class="number">1</span></span>):</span><br><span class="line">        <span class="built_in">print</span> (<span class="string">&#x27;  &#x27;</span> * ind, self.name, <span class="string">&#x27; &#x27;</span>, self.count)</span><br><span class="line">        <span class="keyword">for</span> child <span class="keyword">in</span> self.children.values():</span><br><span class="line">            child.disp(ind + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#构建FP-tree</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">createTree</span>(<span class="params">dataSet, minSup=<span class="number">1</span></span>):</span><br><span class="line">    headerTable = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> trans <span class="keyword">in</span> dataSet:  <span class="comment">#第一次遍历：统计各个数据的频繁度</span></span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> trans:</span><br><span class="line">            headerTable[item] = headerTable.get(item, <span class="number">0</span>) + dataSet[trans]</span><br><span class="line">            <span class="comment">#用头指针表统计各个类别的出现的次数，计算频繁量：头指针表[类别]=出现次数</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">list</span>(headerTable):  <span class="comment">#删除未达到最小频繁度的数据</span></span><br><span class="line">        <span class="keyword">if</span> headerTable[k] &lt; minSup:</span><br><span class="line">            <span class="keyword">del</span> (headerTable[k])</span><br><span class="line">    freqItemSet = <span class="built_in">set</span>(headerTable.keys())<span class="comment">#保存达到要求的数据</span></span><br><span class="line">    <span class="comment"># print (&#x27;freqItemSet: &#x27;,freqItemSet)</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(freqItemSet) == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span>, <span class="literal">None</span>  <span class="comment">#若达到要求的数目为0</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> headerTable: <span class="comment">#遍历头指针表</span></span><br><span class="line">        headerTable[k] = [headerTable[k], <span class="literal">None</span>]  <span class="comment">#保存计数值及指向每种类型第一个元素项的指针</span></span><br><span class="line">    <span class="comment"># print (&#x27;headerTable: &#x27;,headerTable)</span></span><br><span class="line">    retTree = treeNode(<span class="string">&#x27;Null Set&#x27;</span>, <span class="number">1</span>, <span class="literal">None</span>)  <span class="comment">#初始化tree</span></span><br><span class="line">    <span class="keyword">for</span> tranSet, count <span class="keyword">in</span> dataSet.items():  <span class="comment"># 第二次遍历：</span></span><br><span class="line">        localD = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> tranSet:  <span class="comment"># put transaction items in order</span></span><br><span class="line">            <span class="keyword">if</span> item <span class="keyword">in</span> freqItemSet:<span class="comment">#只对频繁项集进行排序</span></span><br><span class="line">                localD[item] = headerTable[item][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment">#使用排序后的频率项集对树进行填充</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(localD) &gt; <span class="number">0</span>:</span><br><span class="line">            orderedItems = [v[<span class="number">0</span>] <span class="keyword">for</span> v <span class="keyword">in</span> <span class="built_in">sorted</span>(localD.items(), key=<span class="keyword">lambda</span> p: p[<span class="number">1</span>], reverse=<span class="literal">True</span>)]</span><br><span class="line">            updateTree(orderedItems, retTree, headerTable, count)  <span class="comment"># populate tree with ordered freq itemset</span></span><br><span class="line">    <span class="keyword">return</span> retTree, headerTable  <span class="comment">#返回树和头指针表</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">updateTree</span>(<span class="params">items, inTree, headerTable, count</span>):</span><br><span class="line">    <span class="keyword">if</span> items[<span class="number">0</span>] <span class="keyword">in</span> inTree.children:  <span class="comment"># 首先检查是否存在该节点</span></span><br><span class="line">        inTree.children[items[<span class="number">0</span>]].inc(count)  <span class="comment"># 存在则计数增加</span></span><br><span class="line">    <span class="keyword">else</span>:  <span class="comment"># 不存在则将新建该节点</span></span><br><span class="line">        inTree.children[items[<span class="number">0</span>]] = treeNode(items[<span class="number">0</span>], count, inTree)<span class="comment">#创建一个新节点</span></span><br><span class="line">        <span class="keyword">if</span> headerTable[items[<span class="number">0</span>]][<span class="number">1</span>] == <span class="literal">None</span>:  <span class="comment"># 若原来不存在该类别，更新头指针列表</span></span><br><span class="line">            headerTable[items[<span class="number">0</span>]][<span class="number">1</span>] = inTree.children[items[<span class="number">0</span>]]<span class="comment">#更新指向</span></span><br><span class="line">        <span class="keyword">else</span>:<span class="comment">#更新指向</span></span><br><span class="line">            updateHeader(headerTable[items[<span class="number">0</span>]][<span class="number">1</span>], inTree.children[items[<span class="number">0</span>]])</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(items) &gt; <span class="number">1</span>:  <span class="comment">#仍有未分配完的树，迭代</span></span><br><span class="line">        updateTree(items[<span class="number">1</span>::], inTree.children[items[<span class="number">0</span>]], headerTable, count)</span><br><span class="line"></span><br><span class="line"><span class="comment">#节点链接指向树中该元素项的每一个实例。</span></span><br><span class="line"><span class="comment"># 从头指针表的 nodeLink 开始,一直沿着nodeLink直到到达链表末尾</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">updateHeader</span>(<span class="params">nodeToTest, targetNode</span>):</span><br><span class="line">    <span class="keyword">while</span> (nodeToTest.nodeLink != <span class="literal">None</span>):</span><br><span class="line">        nodeToTest = nodeToTest.nodeLink</span><br><span class="line">    nodeToTest.nodeLink = targetNode</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将读取的文件的一行数据转换成数组</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cast_line_to_array</span>(<span class="params">line</span>):</span><br><span class="line">    lines = line.split()</span><br><span class="line">    line_data = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> lines:</span><br><span class="line">        line_data.append(<span class="built_in">int</span>(i))</span><br><span class="line">    <span class="keyword">return</span> line_data</span><br><span class="line"><span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 从文件中读取数据</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_data</span>():</span><br><span class="line">    data = [</span><br><span class="line">    [<span class="string">&#x27;beer&#x27;</span>, <span class="string">&#x27;baby diapers&#x27;</span>, <span class="string">&#x27;shorts&#x27;</span>]</span><br><span class="line">    , [<span class="string">&#x27;baby diapers&#x27;</span>, <span class="string">&#x27;shorts&#x27;</span>]</span><br><span class="line">    , [<span class="string">&#x27;baby diapers&#x27;</span>, <span class="string">&#x27;milk&#x27;</span>]</span><br><span class="line">    , [<span class="string">&#x27;beer&#x27;</span>, <span class="string">&#x27;baby diapers&#x27;</span>, <span class="string">&#x27;shorts&#x27;</span>]</span><br><span class="line">    , [<span class="string">&#x27;beer&#x27;</span>, <span class="string">&#x27;milk&#x27;</span>]</span><br><span class="line">    , [<span class="string">&#x27;baby diapers&#x27;</span>, <span class="string">&#x27;milk&#x27;</span>]</span><br><span class="line">    , [<span class="string">&#x27;beer&#x27;</span>, <span class="string">&#x27;milk&#x27;</span>]</span><br><span class="line">    , [<span class="string">&#x27;beer&#x27;</span>, <span class="string">&#x27;baby diapers&#x27;</span>, <span class="string">&#x27;milk&#x27;</span>, <span class="string">&#x27;shorts&#x27;</span>]</span><br><span class="line">    , [<span class="string">&#x27;beer&#x27;</span>, <span class="string">&#x27;baby diapers&#x27;</span>, <span class="string">&#x27;milk&#x27;</span>]</span><br><span class="line">    ]</span><br><span class="line"><span class="comment">#     file = open(filepath)</span></span><br><span class="line"><span class="comment">#     line = file.readline()</span></span><br><span class="line"><span class="comment">#     data.append(cast_line_to_array(line))</span></span><br><span class="line"><span class="comment">#     while line:</span></span><br><span class="line"><span class="comment">#         line = file.readline()</span></span><br><span class="line"><span class="comment">#         data.append(cast_line_to_array(line))</span></span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"><span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loadSimpDat</span>():</span><br><span class="line">    simpDat = [[<span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;z&#x27;</span>, <span class="string">&#x27;h&#x27;</span>, <span class="string">&#x27;j&#x27;</span>, <span class="string">&#x27;p&#x27;</span>],</span><br><span class="line">               [<span class="string">&#x27;z&#x27;</span>, <span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, <span class="string">&#x27;v&#x27;</span>, <span class="string">&#x27;u&#x27;</span>, <span class="string">&#x27;t&#x27;</span>, <span class="string">&#x27;s&#x27;</span>],</span><br><span class="line">               [<span class="string">&#x27;z&#x27;</span>],</span><br><span class="line">               [<span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;n&#x27;</span>, <span class="string">&#x27;o&#x27;</span>, <span class="string">&#x27;s&#x27;</span>],</span><br><span class="line">               [<span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;z&#x27;</span>, <span class="string">&#x27;q&#x27;</span>, <span class="string">&#x27;t&#x27;</span>, <span class="string">&#x27;p&#x27;</span>],</span><br><span class="line">               [<span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;z&#x27;</span>, <span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;q&#x27;</span>, <span class="string">&#x27;s&#x27;</span>, <span class="string">&#x27;t&#x27;</span>, <span class="string">&#x27;m&#x27;</span>]]</span><br><span class="line">    <span class="keyword">return</span> simpDat</span><br><span class="line"><span class="comment">#createInitSet() 用于实现上述从列表到字典的类型转换过程</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">createInitSet</span>(<span class="params">dataSet</span>):</span><br><span class="line">    retDict = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> trans <span class="keyword">in</span> dataSet:</span><br><span class="line">        retDict[<span class="built_in">frozenset</span>(trans)] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> retDict</span><br><span class="line"></span><br><span class="line"><span class="comment">#从FP树中发现频繁项集</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ascendTree</span>(<span class="params">leafNode, prefixPath</span>):  <span class="comment">#递归上溯整棵树</span></span><br><span class="line">    <span class="keyword">if</span> leafNode.parent != <span class="literal">None</span>:</span><br><span class="line">        prefixPath.append(leafNode.name)</span><br><span class="line">        ascendTree(leafNode.parent, prefixPath)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">findPrefixPath</span>(<span class="params">basePat, treeNode</span>):  <span class="comment">#参数：指针，节点；</span></span><br><span class="line">    condPats = &#123;&#125;</span><br><span class="line">    <span class="keyword">while</span> treeNode != <span class="literal">None</span>:</span><br><span class="line">        prefixPath = []</span><br><span class="line">        ascendTree(treeNode, prefixPath)<span class="comment">#寻找当前非空节点的前缀</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(prefixPath) &gt; <span class="number">1</span>:</span><br><span class="line">            condPats[<span class="built_in">frozenset</span>(prefixPath[<span class="number">1</span>:])] = treeNode.count <span class="comment">#将条件模式基添加到字典中</span></span><br><span class="line">        treeNode = treeNode.nodeLink</span><br><span class="line">    <span class="keyword">return</span> condPats</span><br><span class="line"></span><br><span class="line"><span class="comment">#递归查找频繁项集</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mineTree</span>(<span class="params">inTree, headerTable, minSup, preFix, freqItemList</span>):</span><br><span class="line">    <span class="comment"># 头指针表中的元素项按照频繁度排序,从小到大</span></span><br><span class="line">    bigL = [v[<span class="number">0</span>] <span class="keyword">for</span> v <span class="keyword">in</span> <span class="built_in">sorted</span>(headerTable.items(), key=<span class="keyword">lambda</span> p: <span class="built_in">str</span>(p[<span class="number">1</span>]))]<span class="comment">#python3修改</span></span><br><span class="line">    <span class="keyword">for</span> basePat <span class="keyword">in</span> bigL:  <span class="comment">#从底层开始</span></span><br><span class="line">        <span class="comment">#加入频繁项列表</span></span><br><span class="line">        newFreqSet = preFix.copy()</span><br><span class="line">        newFreqSet.add(basePat)</span><br><span class="line">        <span class="comment">#print (&#x27;finalFrequent Item: &#x27;,newFreqSet)</span></span><br><span class="line">        freqItemList.append(newFreqSet)</span><br><span class="line">        <span class="comment">#递归调用函数来创建基</span></span><br><span class="line">        condPattBases = findPrefixPath(basePat, headerTable[basePat][<span class="number">1</span>])</span><br><span class="line">        <span class="comment">#print (&#x27;condPattBases :&#x27;,basePat, condPattBases)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#2. 构建条件模式Tree</span></span><br><span class="line">        myCondTree, myHead = createTree(condPattBases, minSup)</span><br><span class="line">        <span class="comment">#将创建的条件基作为新的数据集添加到fp-tree</span></span><br><span class="line">        <span class="comment">#print (&#x27;head from conditional tree: &#x27;, myHead)</span></span><br><span class="line">        <span class="keyword">if</span> myHead != <span class="literal">None</span>: <span class="comment">#3. 递归</span></span><br><span class="line">            <span class="comment">#print(&#x27;conditional tree for: &#x27;,newFreqSet)</span></span><br><span class="line">            <span class="comment">#myCondTree.disp(1)</span></span><br><span class="line">            mineTree(myCondTree, myHead, minSup, newFreqSet, freqItemList)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment">#simpDat = loadSimpDat()</span></span><br><span class="line">    simpDat = load_data()</span><br><span class="line">    <span class="comment">#print(simpDat)</span></span><br><span class="line">    initSet = createInitSet(simpDat)</span><br><span class="line">    <span class="comment">#print(initSet)</span></span><br><span class="line">    myFPtree, myHeaderTab = createTree(initSet, <span class="number">3</span>)</span><br><span class="line">    <span class="comment">#myFPtree.disp()</span></span><br><span class="line">    <span class="comment">#print(findPrefixPath(&#x27;t&#x27;, myHeaderTab[&#x27;t&#x27;][1]))</span></span><br><span class="line">    freqItems = []</span><br><span class="line">    mineTree(myFPtree, myHeaderTab, <span class="number">3</span>, <span class="built_in">set</span>([]), freqItems)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;将树以文本形式展示:&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(myFPtree.disp())</span><br><span class="line">    <span class="built_in">print</span>(freqItems)</span><br><span class="line">    <span class="built_in">print</span>()</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204173146239.png" alt="image-20230204173146239" style="zoom:50%;" /></p><h2 id="总结-4">总结</h2><p>这两个算法Aprior比较容易理解，fp-grow的方式虽然有数据结构的基础，在python上实现依旧比较有难度。</p><h1 id="实验六-聚类分析">实验六 聚类分析</h1><h2 id="实验目的-5">实验目的</h2><ol type="1"><li>实现k-means算法</li><li>通过sklearn库调用kmeans算法以及改进算法；</li></ol><h2 id="实验场地与设备-5">实验场地与设备</h2><p>实验室4074</p><h2 id="实验方式-5">实验方式</h2><p>阅读教程与程序设计</p><h2 id="实验设计-5">实验设计</h2><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204175718032.png"alt="image-20230204175718032" /><figcaption aria-hidden="true">image-20230204175718032</figcaption></figure><h2 id="实验内容-5">实验内容</h2><h3 id="kmeans实现">1.Kmeans实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_wine</span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line"><span class="keyword">import</span> Select_K</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Kmeans</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, k=<span class="number">2</span>, tolerance=<span class="number">0.01</span></span>):</span><br><span class="line">        self.k = k</span><br><span class="line">        self.tol = tolerance</span><br><span class="line">        self.features_count = -<span class="number">1</span></span><br><span class="line">        self.classifications = <span class="literal">None</span></span><br><span class="line">        self.centroids = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, data</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param data: numpy数组，约定shape为：(数据数量，数据维度)</span></span><br><span class="line"><span class="string">        :type data: numpy.ndarray</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.features_count = data.shape[<span class="number">1</span>]</span><br><span class="line">        <span class="comment"># 初始化聚类中心（维度：k个 * features种数）</span></span><br><span class="line">        self.centroids = np.zeros([self.k, data.shape[<span class="number">1</span>]])</span><br><span class="line">        <span class="comment"># self.centroids = np.array(gene).reshape(3, 13)</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.k):</span><br><span class="line">            self.centroids[i] = data[i]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            <span class="comment"># 清空聚类列表</span></span><br><span class="line">            self.classifications = [[] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.k)]</span><br><span class="line">            <span class="comment"># 对每个点与聚类中心进行距离计算</span></span><br><span class="line">            <span class="keyword">for</span> feature_set <span class="keyword">in</span> data:</span><br><span class="line">                <span class="comment"># 预测分类</span></span><br><span class="line">                classification = self.predict(feature_set)</span><br><span class="line">                <span class="comment"># 加入类别</span></span><br><span class="line">                self.classifications[classification].append(feature_set)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 记录前一次的结果</span></span><br><span class="line">            prev_centroids = np.ndarray.copy(self.centroids)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 更新中心</span></span><br><span class="line">            <span class="keyword">for</span> classification <span class="keyword">in</span> <span class="built_in">range</span>(self.k):</span><br><span class="line">                self.centroids[classification] = np.average(self.classifications[classification], axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 检测相邻两次中心的变化情况</span></span><br><span class="line">            <span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">range</span>(self.k):</span><br><span class="line">                <span class="keyword">if</span> np.linalg.norm(prev_centroids[c] - self.centroids[c]) &gt; self.tol:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 如果都满足条件（上面循环没break），则返回</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, data</span>):</span><br><span class="line">        <span class="comment"># 距离</span></span><br><span class="line">        distances = np.linalg.norm(data - self.centroids, axis=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 最小距离索引</span></span><br><span class="line">        <span class="keyword">return</span> distances.argmin()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">showkmeans</span>(<span class="params">self,labels</span>):</span><br><span class="line">        fig = plt.figure()</span><br><span class="line">        plt.style.use(<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line">        colors = [<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;g&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;m&#x27;</span>, <span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;k&#x27;</span>, <span class="string">&#x27;w&#x27;</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.k):</span><br><span class="line">            color = colors[i % <span class="built_in">len</span>(colors)]</span><br><span class="line">            <span class="keyword">for</span> feature_set <span class="keyword">in</span> self.classifications[i]:</span><br><span class="line">                plt.scatter(feature_set[<span class="number">0</span>], feature_set[<span class="number">1</span>],color=color)</span><br><span class="line">        <span class="keyword">for</span> centroid <span class="keyword">in</span> self.centroids:</span><br><span class="line">            plt.scatter(</span><br><span class="line">                        centroid[<span class="number">0</span>],</span><br><span class="line">                        centroid[<span class="number">1</span>],</span><br><span class="line">                        marker=<span class="string">&quot;^&quot;</span>,</span><br><span class="line">                        color=<span class="string">&quot;orange&quot;</span>,</span><br><span class="line">                        s=<span class="number">70</span>,</span><br><span class="line">                        edgecolors=<span class="string">&#x27;k&#x27;</span>,</span><br><span class="line">                        linewidths=<span class="number">1.5</span></span><br><span class="line">                        )</span><br><span class="line">        plt.xlabel(labels[<span class="number">0</span>])</span><br><span class="line">        plt.ylabel(labels[<span class="number">1</span>])</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">showkmeansByPCA</span>(<span class="params">self,pca</span>):</span><br><span class="line">        fig = plt.figure()</span><br><span class="line">        colors = [<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;g&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;m&#x27;</span>, <span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;k&#x27;</span>, <span class="string">&#x27;w&#x27;</span>]</span><br><span class="line">        plt.style.use(<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.k):</span><br><span class="line">            color = colors[i % <span class="built_in">len</span>(colors)]</span><br><span class="line">            <span class="keyword">for</span> feature_set <span class="keyword">in</span> pca.transform(self.classifications[i]):</span><br><span class="line">                plt.scatter(feature_set[<span class="number">0</span>], feature_set[<span class="number">1</span>],color=color)</span><br><span class="line">        <span class="keyword">for</span> centroid <span class="keyword">in</span> pca.transform(self.centroids):</span><br><span class="line">            plt.scatter(</span><br><span class="line">                        centroid[<span class="number">0</span>],</span><br><span class="line">                        centroid[<span class="number">1</span>],</span><br><span class="line">                        marker=<span class="string">&quot;^&quot;</span>,</span><br><span class="line">                        color=<span class="string">&quot;orange&quot;</span>,</span><br><span class="line">                        s=<span class="number">70</span>,</span><br><span class="line">                        edgecolors=<span class="string">&#x27;k&#x27;</span>,</span><br><span class="line">                        linewidths=<span class="number">1.5</span></span><br><span class="line">                        )</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;Principle Componet1&#x27;</span>)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;Principle Componet2&#x27;</span>)</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">showkmeansByPCA3D</span>(<span class="params">self,pca</span>):</span><br><span class="line">        fig = plt.figure()</span><br><span class="line">        ax = plt.axes(projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line">        colors = [<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;g&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;m&#x27;</span>, <span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;k&#x27;</span>, <span class="string">&#x27;w&#x27;</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.k):</span><br><span class="line">            color = colors[i % <span class="built_in">len</span>(colors)]</span><br><span class="line">            <span class="keyword">for</span> feature_set <span class="keyword">in</span> pca.transform(self.classifications[i]):</span><br><span class="line">                ax.scatter3D(feature_set[<span class="number">0</span>], feature_set[<span class="number">1</span>]</span><br><span class="line">                            ,feature_set[<span class="number">2</span>],color=color)</span><br><span class="line">        <span class="keyword">for</span> centroid <span class="keyword">in</span> pca.transform(self.centroids):</span><br><span class="line">            ax.scatter3D(</span><br><span class="line">                        centroid[<span class="number">0</span>],</span><br><span class="line">                        centroid[<span class="number">1</span>],</span><br><span class="line">                        centroid[<span class="number">2</span>],</span><br><span class="line">                        marker=<span class="string">&quot;^&quot;</span>,</span><br><span class="line">                        color=<span class="string">&quot;orange&quot;</span>,</span><br><span class="line">                        s=<span class="number">70</span>,</span><br><span class="line">                        edgecolors=<span class="string">&#x27;k&#x27;</span>,</span><br><span class="line">                        linewidths=<span class="number">1.5</span></span><br><span class="line">                        )</span><br><span class="line">        ax.set_xlabel(<span class="string">&#x27;Principle Componet1&#x27;</span>)</span><br><span class="line">        ax.set_ylabel(<span class="string">&#x27;Principle Componet2&#x27;</span>)</span><br><span class="line">        ax.set_zlabel(<span class="string">&#x27;Principle Componet3&#x27;</span>)</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        plt.show()</span><br></pre></td></tr></table></figure><h3 id="kmeans-的不适用情况">2.Kmeans 的不适用情况</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">12</span>))</span><br><span class="line"></span><br><span class="line">n_samples = <span class="number">1500</span></span><br><span class="line">random_state = <span class="number">170</span></span><br><span class="line">X, y = make_blobs(n_samples=n_samples, random_state=random_state)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Incorrect number of clusters</span></span><br><span class="line">y_pred = KMeans(n_clusters=<span class="number">2</span>, random_state=random_state).fit_predict(X)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">221</span>)</span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y_pred)</span><br><span class="line">plt.title(<span class="string">&quot;Incorrect Number of Blobs&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Anisotropicly distributed data</span></span><br><span class="line"><span class="comment"># 这块本质上就是对坐标进行变换，我们画出的坐标轴是垂直的，</span></span><br><span class="line"><span class="comment"># 但是实际上坐标轴应该是一个平行四边形</span></span><br><span class="line"><span class="comment"># transformation实际上就是对坐标轴进行旋转，通过反三角函数就可以控制</span></span><br><span class="line">transformation = [[<span class="number">0.2</span>, <span class="number">0</span>],</span><br><span class="line">                  [<span class="number">0.4</span>, <span class="number">0.4</span>]]</span><br><span class="line">X_aniso = np.dot(X, transformation)</span><br><span class="line">y_pred = KMeans(n_clusters=<span class="number">3</span>, random_state=random_state).fit_predict(X_aniso)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">222</span>)</span><br><span class="line">plt.scatter(X_aniso[:, <span class="number">0</span>], X_aniso[:, <span class="number">1</span>], c=y_pred)</span><br><span class="line">plt.title(<span class="string">&quot;Anisotropicly Distributed Blobs&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Different variance</span></span><br><span class="line">X_varied, y_varied = make_blobs(</span><br><span class="line">    n_samples=n_samples, cluster_std=[<span class="number">1.0</span>, <span class="number">2.5</span>, <span class="number">0.5</span>], random_state=random_state</span><br><span class="line">)</span><br><span class="line">y_pred = KMeans(n_clusters=<span class="number">3</span>, random_state=random_state).fit_predict(X_varied)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">223</span>)</span><br><span class="line">plt.scatter(X_varied[:, <span class="number">0</span>], X_varied[:, <span class="number">1</span>], c=y_pred)</span><br><span class="line">plt.title(<span class="string">&quot;Unequal Variance&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Unevenly sized blobs</span></span><br><span class="line">X_filtered = np.vstack((X[y == <span class="number">0</span>][:<span class="number">500</span>], X[y == <span class="number">1</span>][:<span class="number">100</span>], X[y == <span class="number">2</span>][:<span class="number">10</span>]))</span><br><span class="line">y_pred = KMeans(n_clusters=<span class="number">3</span>, random_state=random_state).fit_predict(X_filtered)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">224</span>)</span><br><span class="line">plt.scatter(X_filtered[:, <span class="number">0</span>], X_filtered[:, <span class="number">1</span>], c=y_pred)</span><br><span class="line">plt.title(<span class="string">&quot;Unevenly Sized Blobs&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204175246141.png"alt="image-20230204175246141" /><figcaption aria-hidden="true">image-20230204175246141</figcaption></figure><h3 id="kmeans-处理图像数据集">3.kmeans++ 处理图像数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">=========== ========================================================</span></span><br><span class="line"><span class="string">Shorthand    full name</span></span><br><span class="line"><span class="string">=========== ========================================================</span></span><br><span class="line"><span class="string">homo         homogeneity score</span></span><br><span class="line"><span class="string">compl        completeness score</span></span><br><span class="line"><span class="string">v-meas       V measure</span></span><br><span class="line"><span class="string">ARI          adjusted Rand index</span></span><br><span class="line"><span class="string">AMI          adjusted mutual information</span></span><br><span class="line"><span class="string">silhouette   silhouette coefficient</span></span><br><span class="line"><span class="string">=========== ========================================================</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># %%</span></span><br><span class="line"><span class="comment"># Load the dataset</span></span><br><span class="line"><span class="comment"># ----------------</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># We will start by loading the `digits` dataset. This dataset contains</span></span><br><span class="line"><span class="comment"># handwritten digits from 0 to 9. In the context of clustering, one would like</span></span><br><span class="line"><span class="comment"># to group images such that the handwritten digits on the image are the same.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_digits</span><br><span class="line"></span><br><span class="line">data, labels = load_digits(return_X_y=<span class="literal">True</span>)</span><br><span class="line">(n_samples, n_features), n_digits = data.shape, np.unique(labels).size</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;# digits: <span class="subst">&#123;n_digits&#125;</span>; # samples: <span class="subst">&#123;n_samples&#125;</span>; # features <span class="subst">&#123;n_features&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># %%</span></span><br><span class="line"><span class="comment"># Define our evaluation benchmark</span></span><br><span class="line"><span class="comment"># -------------------------------</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># We will first our evaluation benchmark. During this benchmark, we intend to</span></span><br><span class="line"><span class="comment"># compare different initialization methods for KMeans. Our benchmark will:</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># * create a pipeline which will scale the data using a</span></span><br><span class="line"><span class="comment">#   :class:`~sklearn.preprocessing.StandardScaler`;</span></span><br><span class="line"><span class="comment"># * train and time the pipeline fitting;</span></span><br><span class="line"><span class="comment"># * measure the performance of the clustering obtained via different metrics.</span></span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> make_pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">bench_k_means</span>(<span class="params">kmeans, name, data, labels</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Benchmark to evaluate the KMeans initialization methods.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    kmeans : KMeans instance</span></span><br><span class="line"><span class="string">        A :class:`~sklearn.cluster.KMeans` instance with the initialization</span></span><br><span class="line"><span class="string">        already set.</span></span><br><span class="line"><span class="string">    name : str</span></span><br><span class="line"><span class="string">        Name given to the strategy. It will be used to show the results in a</span></span><br><span class="line"><span class="string">        table.</span></span><br><span class="line"><span class="string">    data : ndarray of shape (n_samples, n_features)</span></span><br><span class="line"><span class="string">        The data to cluster.</span></span><br><span class="line"><span class="string">    labels : ndarray of shape (n_samples,)</span></span><br><span class="line"><span class="string">        The labels used to compute the clustering metrics which requires some</span></span><br><span class="line"><span class="string">        supervision.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    t0 = time()</span><br><span class="line">    estimator = make_pipeline(StandardScaler(), kmeans).fit(data)</span><br><span class="line">    fit_time = time() - t0</span><br><span class="line">    <span class="comment"># 这里的源码是有问题的，estimator作为pipelinem不支持使用index，</span></span><br><span class="line">    <span class="comment"># 我通过debug找到了要的变量</span></span><br><span class="line">    <span class="comment"># 这一点我觉得是可以理解的，从流的角度上看pipeline使用index就相当于截取一段水流</span></span><br><span class="line">    results = [name, fit_time, estimator.named_steps[<span class="string">&#x27;kmeans&#x27;</span>].inertia_]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Define the metrics which require only the true labels and estimator</span></span><br><span class="line">    <span class="comment"># labels</span></span><br><span class="line">    clustering_metrics = [</span><br><span class="line">        metrics.homogeneity_score,</span><br><span class="line">        metrics.completeness_score,</span><br><span class="line">        metrics.v_measure_score,</span><br><span class="line">        metrics.adjusted_rand_score,</span><br><span class="line">        metrics.adjusted_mutual_info_score,</span><br><span class="line">    ]</span><br><span class="line">    results += [m(labels, estimator.named_steps[<span class="string">&#x27;kmeans&#x27;</span>].labels_) <span class="keyword">for</span> m <span class="keyword">in</span> clustering_metrics]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># The silhouette score requires the full dataset</span></span><br><span class="line">    results += [</span><br><span class="line">        metrics.silhouette_score(</span><br><span class="line">            data,</span><br><span class="line">            estimator.named_steps[<span class="string">&#x27;kmeans&#x27;</span>].labels_,</span><br><span class="line">            metric=<span class="string">&quot;euclidean&quot;</span>,</span><br><span class="line">            sample_size=<span class="number">300</span>,</span><br><span class="line">        )</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Show the results</span></span><br><span class="line">    formatter_result = (</span><br><span class="line">        <span class="string">&quot;&#123;:9s&#125;\t&#123;:.3f&#125;s\t&#123;:.0f&#125;\t&#123;:.3f&#125;\t&#123;:.3f&#125;\t&#123;:.3f&#125;\t&#123;:.3f&#125;\t&#123;:.3f&#125;\t&#123;:.3f&#125;&quot;</span></span><br><span class="line">    )</span><br><span class="line">    <span class="built_in">print</span>(formatter_result.<span class="built_in">format</span>(*results))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># %%</span></span><br><span class="line"><span class="comment"># Run the benchmark</span></span><br><span class="line"><span class="comment"># -----------------</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># We will compare three approaches:</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># * an initialization using `kmeans++`. This method is stochastic and we will</span></span><br><span class="line"><span class="comment">#   run the initialization 4 times;</span></span><br><span class="line"><span class="comment"># * a random initialization. This method is stochastic as well and we will run</span></span><br><span class="line"><span class="comment">#   the initialization 4 times;</span></span><br><span class="line"><span class="comment"># * an initialization based on a :class:`~sklearn.decomposition.PCA`</span></span><br><span class="line"><span class="comment">#   projection. Indeed, we will use the components of the</span></span><br><span class="line"><span class="comment">#   :class:`~sklearn.decomposition.PCA` to initialize KMeans. This method is</span></span><br><span class="line"><span class="comment">#   deterministic and a single initialization suffice.</span></span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="number">82</span> * <span class="string">&quot;_&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsilhouette&quot;</span>)</span><br><span class="line"></span><br><span class="line">kmeans = KMeans(init=<span class="string">&quot;k-means++&quot;</span>, n_clusters=n_digits, n_init=<span class="number">4</span>, random_state=<span class="number">0</span>)</span><br><span class="line">bench_k_means(kmeans=kmeans, name=<span class="string">&quot;k-means++&quot;</span>, data=data, labels=labels)</span><br><span class="line"></span><br><span class="line">kmeans = KMeans(init=<span class="string">&quot;random&quot;</span>, n_clusters=n_digits, n_init=<span class="number">4</span>, random_state=<span class="number">0</span>)</span><br><span class="line">bench_k_means(kmeans=kmeans, name=<span class="string">&quot;random&quot;</span>, data=data, labels=labels)</span><br><span class="line"></span><br><span class="line">pca = PCA(n_components=n_digits).fit(data)</span><br><span class="line">kmeans = KMeans(init=pca.components_, n_clusters=n_digits, n_init=<span class="number">1</span>)</span><br><span class="line">bench_k_means(kmeans=kmeans, name=<span class="string">&quot;PCA-based&quot;</span>, data=data, labels=labels)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="number">82</span> * <span class="string">&quot;_&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># %%</span></span><br><span class="line"><span class="comment"># Visualize the results on PCA-reduced data</span></span><br><span class="line"><span class="comment"># -----------------------------------------</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># :class:`~sklearn.decomposition.PCA` allows to project the data from the</span></span><br><span class="line"><span class="comment"># original 64-dimensional space into a lower dimensional space. Subsequently,</span></span><br><span class="line"><span class="comment"># we can use :class:`~sklearn.decomposition.PCA` to project into a</span></span><br><span class="line"><span class="comment"># 2-dimensional space and plot the data and the clusters in this new space.</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">reduced_data = PCA(n_components=<span class="number">2</span>).fit_transform(data)</span><br><span class="line">kmeans = KMeans(init=<span class="string">&quot;k-means++&quot;</span>, n_clusters=n_digits, n_init=<span class="number">4</span>)</span><br><span class="line">kmeans.fit(reduced_data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step size of the mesh. Decrease to increase the quality of the VQ.</span></span><br><span class="line">h = <span class="number">0.02</span>  <span class="comment"># point in the mesh [x_min, x_max]x[y_min, y_max].</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot the decision boundary. For that, we will assign a color to each</span></span><br><span class="line">x_min, x_max = reduced_data[:, <span class="number">0</span>].<span class="built_in">min</span>() - <span class="number">1</span>, reduced_data[:, <span class="number">0</span>].<span class="built_in">max</span>() + <span class="number">1</span></span><br><span class="line">y_min, y_max = reduced_data[:, <span class="number">1</span>].<span class="built_in">min</span>() - <span class="number">1</span>, reduced_data[:, <span class="number">1</span>].<span class="built_in">max</span>() + <span class="number">1</span></span><br><span class="line">xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Obtain labels for each point in mesh. Use last trained model.</span></span><br><span class="line">Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Put the result into a color plot</span></span><br><span class="line">Z = Z.reshape(xx.shape)</span><br><span class="line">plt.figure(<span class="number">1</span>)</span><br><span class="line">plt.clf()</span><br><span class="line">plt.imshow(</span><br><span class="line">    Z,</span><br><span class="line">    interpolation=<span class="string">&quot;nearest&quot;</span>,</span><br><span class="line">    extent=(xx.<span class="built_in">min</span>(), xx.<span class="built_in">max</span>(), yy.<span class="built_in">min</span>(), yy.<span class="built_in">max</span>()),</span><br><span class="line">    cmap=plt.cm.Paired,</span><br><span class="line">    aspect=<span class="string">&quot;auto&quot;</span>,</span><br><span class="line">    origin=<span class="string">&quot;lower&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">plt.plot(reduced_data[:, <span class="number">0</span>], reduced_data[:, <span class="number">1</span>], <span class="string">&quot;k.&quot;</span>, markersize=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># Plot the centroids as a white X</span></span><br><span class="line">centroids = kmeans.cluster_centers_</span><br><span class="line">plt.scatter(</span><br><span class="line">    centroids[:, <span class="number">0</span>],</span><br><span class="line">    centroids[:, <span class="number">1</span>],</span><br><span class="line">    marker=<span class="string">&quot;x&quot;</span>,</span><br><span class="line">    s=<span class="number">169</span>,</span><br><span class="line">    linewidths=<span class="number">3</span>,</span><br><span class="line">    color=<span class="string">&quot;w&quot;</span>,</span><br><span class="line">    zorder=<span class="number">10</span>,</span><br><span class="line">)</span><br><span class="line">plt.title(</span><br><span class="line">    <span class="string">&quot;K-means clustering on the digits dataset (PCA-reduced data)\n&quot;</span></span><br><span class="line">    <span class="string">&quot;Centroids are marked with white cross&quot;</span></span><br><span class="line">)</span><br><span class="line">plt.xlim(x_min, x_max)</span><br><span class="line">plt.ylim(y_min, y_max)</span><br><span class="line">plt.xticks(())</span><br><span class="line">plt.yticks(())</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204175455318.png"alt="image-20230204175455318" /><figcaption aria-hidden="true">image-20230204175455318</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204175505770.png"alt="image-20230204175505770" /><figcaption aria-hidden="true">image-20230204175505770</figcaption></figure><h2 id="总结-5">总结</h2><p>kmeans算法具有速度快，易理解的特点，但是同时也有初始点选点的问题。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 数据分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>极限速成pytorch</title>
      <link href="/2024/02/19/%E6%9E%81%E9%99%90%E9%80%9F%E6%88%90pytorch/"/>
      <url>/2024/02/19/%E6%9E%81%E9%99%90%E9%80%9F%E6%88%90pytorch/</url>
      
        <content type="html"><![CDATA[<h2 id="极限速成pytorch">极限速成pytorch</h2><p>最近在准备搞搞这个自己的毕业设计，复现两篇论文什么的，于是要重新捡起好久不写的pytorch，于是决定简单写一个速成教程。首先，我得讲一下我的速成思想：对比学习+调整，还有速成不等于质量差，仅仅代表高效。</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/721a1c5b0493d503a0a59e8f076f9c81b60b4183.jpg" alt="img" style="zoom: 25%;" /></p><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="100%" height="86" src="//music.163.com/outchain/player?type=2&amp;id=2099560293&amp;auto=0&amp;height=66"></iframe><blockquote><p>焚电子高香，敲电子木鱼</p><p>炼赛博丹药，成赛博神仙</p></blockquote><h3 id="数据操作">数据操作</h3><p>这里我们以<code>numpy</code>作为原本的模板，只指出差异，不处理相同部分，减少学习成本</p><p>很好，我们通过看文档发现貌似没什么不一样的，只是把原来的<code>np</code>改为<code>torch</code>。</p><p>下面不解释的罗列：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">torch.arrange(n)    <span class="comment"># 生成从0到n的整数</span></span><br><span class="line">torch.shape         <span class="comment"># 查看形状</span></span><br><span class="line">torch.reshape(Size) <span class="comment"># 改变形状</span></span><br><span class="line">torch.zeros(Size)   <span class="comment"># 全0矩阵</span></span><br><span class="line">torch.ones(Size)    <span class="comment"># 全1矩阵</span></span><br><span class="line">torch.randn(Size)   <span class="comment"># 正态分布随机数，对应的np.random.randn()</span></span><br></pre></td></tr></table></figure><p>同样的，<code>torch</code>中也有<code>numpy</code>中类似的初始化方法，其使用方式与<code>numpy</code>一致:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">np.array()</span><br><span class="line">torch.tensor()</span><br></pre></td></tr></table></figure><p>两者具有完全一致的基本运算、广播机制、索引和切片，所以这块直接可以不学。</p><p>转换语法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X.numpy()</span><br><span class="line">torch.tensor(ndarray)</span><br></pre></td></tr></table></figure><p><code>pandas</code>转换为<code>tensor</code>格式</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = pd.read_csv(<span class="string">&quot;you.csv&quot;</span>)</span><br><span class="line">my_array = np.array(a)</span><br><span class="line">my_tensor = torch.tensor(my_array)</span><br></pre></td></tr></table></figure><h3 id="线性代数">线性代数</h3><p>其实各种运算和numpy还是基本一样的，除了两个特定的乘法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 矩阵对向量乘法</span></span><br><span class="line">torch.mv(A,x)</span><br><span class="line"><span class="comment"># 矩阵对矩阵乘法，非dot，非hadamard</span></span><br><span class="line">torch.mm(A,B)</span><br></pre></td></tr></table></figure><p>然后我们研究一点一点不一样的东西，也是会对写网络有帮助的，不同于我们在使用<code>numpy</code>手搓时，<code>pytorch</code>是以批为单位进网络训练，所以对轴的操作非常频繁，我以前理解轴，表示非常难记住，然后我查资料发现：<strong>轴实际上就是Shape这个list的下标</strong>。</p><h3 id="自动微分">自动微分</h3><p>y1s1，这应该是<code>pytorch</code>中最重要的功能了，自动微分提供了一个很大的便利，那就是不在需要人手去写<code>backward</code>函数，我们也不去纠结什么计算图什么玩意，我们直接上例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="comment"># 设置一个变量x，实际上呢这句话已经可以简化了</span></span><br><span class="line">x=Variable(torch.ones(<span class="number">2</span>,<span class="number">2</span>),requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># x=torch。ones(2,2,requires_grad=True)</span></span><br><span class="line">y=x+<span class="number">2</span></span><br><span class="line"><span class="comment"># 这句就是在查看梯度函数的入口</span></span><br><span class="line">y.grad_fn </span><br><span class="line">z=y*y*<span class="number">3</span></span><br><span class="line">out=z.mean()</span><br><span class="line"><span class="comment"># 这就是自动微分的神奇之处了</span></span><br><span class="line">out.backward()</span><br><span class="line">x.grad</span><br></pre></td></tr></table></figure><p>原理什么的我们不去细究，甚至连参数列表我们也不去细究，就先了解到这儿，知道他很神奇就够了（毕竟一时半会儿也不用）</p><h3 id="神经网络">神经网络</h3><p>看到这儿除了对自动微分可能有点懵，肯定觉得，<code>pytorch</code>就这？其实<code>pytorch</code>是出了名的接口简单，but重头戏才刚开始。这里呢，我么使用我们的传统艺能，拟合sin曲线，来走一个全部的流程，然后就能理解如何操作了</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"></span><br><span class="line"><span class="comment"># 先来一个我抄我自己，生成数据集</span></span><br><span class="line"><span class="comment"># 创建数据</span></span><br><span class="line">x = torch.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line">y = torch.sin(<span class="number">2</span> * np.pi * x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加随机噪声</span></span><br><span class="line">np.random.seed(<span class="number">20</span>)</span><br><span class="line">y_noisy = y + <span class="number">0.05</span> * torch.randn(size=x.shape)</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(x, y, label=<span class="string">&#x27;True function&#x27;</span>, color=<span class="string">&#x27;g&#x27;</span>)</span><br><span class="line">plt.scatter(x, y_noisy, edgecolor=<span class="string">&#x27;b&#x27;</span>, s=<span class="number">20</span>, label=<span class="string">&#x27;Noisy samples&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240221223054399.png"alt="image-20240221223054399" /><figcaption aria-hidden="true">image-20240221223054399</figcaption></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net,self).__init__()</span><br><span class="line">        self.fc=nn.Linear(<span class="number">100</span>,<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        output=F.tanh(x)</span><br><span class="line">        output=self.fc(output)</span><br><span class="line">        output= output[<span class="number">0</span>]+output[<span class="number">1</span>]*x+output[<span class="number">2</span>]*x**<span class="number">2</span>+output[<span class="number">3</span>]*x**<span class="number">3</span>+output[<span class="number">4</span>]*x**<span class="number">4</span></span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line">    </span><br><span class="line">net=Net()</span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">30000</span>):</span><br><span class="line">    y_pred=net(x)</span><br><span class="line"></span><br><span class="line">    loss=criterion(y_pred,y)</span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">2000</span> == <span class="number">1999</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;epoch:&#123;&#125;,mse:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(i+<span class="number">1</span>,loss.item()))</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure><pre><code>epoch:2000,mse:0.10116397589445114epoch:4000,mse:0.05751330405473709epoch:6000,mse:0.034589387476444244epoch:8000,mse:0.02254333905875683epoch:10000,mse:0.016206299886107445epoch:12000,mse:0.012865572236478329epoch:14000,mse:0.011097476817667484epoch:16000,mse:0.010154816322028637epoch:18000,mse:0.009645464830100536epoch:20000,mse:0.009363631717860699epoch:22000,mse:0.009201298467814922epoch:24000,mse:0.0091018071398139epoch:26000,mse:0.009035366587340832epoch:28000,mse:0.008986384607851505epoch:30000,mse:0.008946665562689304</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">x_test=torch.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line">y_pred=net(x_test)</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(x_test.detach().numpy(), y_pred.detach().numpy(), label=<span class="string">&#x27;Regressor&#x27;</span>, color=<span class="string">&#x27;#FFA628&#x27;</span>)</span><br><span class="line">plt.plot(x, y, label=<span class="string">&#x27;True function&#x27;</span>, color=<span class="string">&#x27;g&#x27;</span>)</span><br><span class="line">plt.scatter(x, y_noisy, edgecolor=<span class="string">&#x27;b&#x27;</span>, s=<span class="number">20</span>, label=<span class="string">&#x27;Noisy samples&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>​ <imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240221223015717.png"alt="image-20240221223015717" /></p><p>再要加强的话，就要去学习一些dataloarder等一些包，目前来说就足够了</p><h3 id="参考资料">参考资料</h3><p><ahref="https://zh-v2.d2l.ai/d2l-zh-pytorch.pdf">zh-v2.d2l.ai/d2l-zh-pytorch.pdf</a></p><p><ahref="https://blog.csdn.net/qq_40691189/article/details/129433004">PyTorch的自动微分(autograd)_pytorch自动微分-CSDN博客</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>搓OS-day9</title>
      <link href="/2024/02/12/%E6%90%93OS-day9/"/>
      <url>/2024/02/12/%E6%90%93OS-day9/</url>
      
        <content type="html"><![CDATA[<h2 id="手搓os-day9">手搓OS-day9</h2><p>重量级难度，分配内存与回收（内核开始了），终于快一半了（折磨）</p><p>要求：</p><ul><li>边界对齐到<span class="math inline">\(2^i\)</span></li><li>不够分配时返回NULL(0)</li><li>拒绝超过16MiB的分配</li><li>不必初始化内存，可以全赋值为零</li><li>允许多处理器并行使用</li></ul><h3 id="c语言的面向对象">C语言的面向对象</h3><p>虽然很早之前老师就已经提过这个C语言的骚操作，嗯，还是有点难以接受</p><p>首先要介绍一个函数指针的概念，这个类似的概念实际上在Python里是接触过的，只是没有明确的提出来，当时令人感到很神奇（同时也感到很鸡肋）</p><h4 id="函数指针">函数指针</h4><p><strong>声明</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">return_type (*ptr)(parameter_type1,parameter_type2,……);</span><br></pre></td></tr></table></figure><p>这样我们就声明了一个指向某个函数入口的一个指针，当然指针指向的函数需要初始化，一个小栗子：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span> a,<span class="type">int</span> b)</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> (*ptr)(<span class="type">int</span>,<span class="type">int</span>);</span><br><span class="line"></span><br><span class="line">    ptr=add;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> result=ptr(<span class="number">10</span>,<span class="number">20</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;result=%d\n&quot;</span>,result);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span> a,<span class="type">int</span> b)</span>&#123;</span><br><span class="line">    <span class="keyword">return</span> a+b;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面这个就是我们在Python中的常用方法了（回调函数）：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">typedef</span> <span class="title function_">int</span> <span class="params">(*Operation)</span><span class="params">(<span class="type">int</span>, <span class="type">int</span>)</span>;</span><br><span class="line"> </span><br><span class="line"><span class="type">int</span> <span class="title function_">performOperation</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b, Operation op)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> op(a, b);</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="type">int</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> a + b;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="type">int</span> <span class="title function_">subtract</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> a - b;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">int</span> result;</span><br><span class="line"> </span><br><span class="line">    result = performOperation(<span class="number">10</span>, <span class="number">5</span>, add);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Add Result: %d\n&quot;</span>, result);</span><br><span class="line"> </span><br><span class="line">    result = performOperation(<span class="number">10</span>, <span class="number">5</span>, subtract);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Subtract Result: %d\n&quot;</span>, result);</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="c语言面向对象">C语言面向对象</h4><p>虽然C++已经很好的做好了面向对象编程的，但是秉持着<del>闲的蛋疼</del>努力学习的精神，我们还是有必要了解如何用C语言实现面向对象编程的。面向对象三大特征：</p><ul><li><p>封装：<del>这也叫特征</del>（当然是），其重要思想在于不能随便更改对象的内容。</p></li><li><p>继承：从而某个类继承相对应的属性和方法</p></li><li><p>多态：其实就是子类的重写</p></li></ul><p>封装对于C语言并不难实现，我们可以用结构体平替，那么怎么实现继承呢？鉴于接下来的文件结构比较抽象，请稍微记忆一下<del>(写完发现并不复杂，没事了)</del></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// shape.h</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifndef</span> SHAPE_H</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> SHAPE_H</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdint.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    <span class="type">int16_t</span> x;</span><br><span class="line">    <span class="type">int16_t</span> y;</span><br><span class="line">&#125;Shape;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">Shape_ctor</span><span class="params">(Shape * <span class="type">const</span> me, <span class="type">int16_t</span> x, <span class="type">int16_t</span> y)</span>;</span><br><span class="line"><span class="type">void</span> <span class="title function_">Shape_moveBy</span><span class="params">(Shape * <span class="type">const</span> me, <span class="type">int16_t</span> dx, <span class="type">int16_t</span> dy)</span>;</span><br><span class="line"><span class="type">int16_t</span> <span class="title function_">Shape_getX</span><span class="params">(Shape <span class="type">const</span> * <span class="type">const</span> me)</span>;</span><br><span class="line"><span class="type">int16_t</span> <span class="title function_">Shape_getY</span><span class="params">(Shape <span class="type">const</span> * <span class="type">const</span> me)</span>;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="meta">#<span class="keyword">endif</span> <span class="comment">/* SHAPE_H */</span></span></span><br></pre></td></tr></table></figure><p>这里我们假设所有的接口函数都已经实现了（稍微好理解一点</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// rectangle.h</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifndef</span> RECT_H</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> RECT_H</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;shape.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span>&#123;</span></span><br><span class="line">    Shape super;</span><br><span class="line">    </span><br><span class="line">    <span class="type">uint16_t</span> width;</span><br><span class="line">    <span class="type">uint16_t</span> height;</span><br><span class="line">&#125;Rectangle;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 构造函数</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">Rectangle_ctor</span><span class="params">(Retangle *<span class="type">const</span> me,<span class="type">int16_t</span> x,<span class="type">int16_t</span> y,<span class="type">uint16_t</span> width,<span class="type">uint16_t</span> height)</span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span> <span class="comment">/* RECT_H */</span></span></span><br></pre></td></tr></table></figure><p>然后就是关于多态的实现这就很麻烦了</p><blockquote><p>在C++中，如果一个父类中定义了虚函数，那么编译器就会在这个内存中开辟一块空间放置虚表，这张表里的每一个item都是一个函数指针，然后在父类的内存模型中放一个虚表指针，指向上面这个虚表。</p></blockquote><ul><li>好消息：知道大概怎么回事了</li><li>坏消息：虚函数是什么玩意来着</li></ul><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240213212324586.png" alt="image-20240213212324586" style="zoom: 67%;" /></p><p>哦，原来虚函数就是可重写的函数（还是Java事儿少），那没事了。来实现吧，首先重写一下shape类</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// shape.h</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifndef</span> SHAPE_H</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> SHAPE_H</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdint.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ShapeVtbl</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span> </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">ShapeVtbl</span> <span class="title">const</span> *<span class="title">vptr</span>;</span></span><br><span class="line">    <span class="type">int16_t</span> x;</span><br><span class="line">    <span class="type">int16_t</span> y;</span><br><span class="line">&#125;Shape;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 虚表定义</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ShapeVtbl</span> &#123;</span></span><br><span class="line">    <span class="type">uint32_t</span> (*area)(Shape <span class="type">const</span> * <span class="type">const</span> me); <span class="comment">// 虚函数指针</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 接口函数</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">Shape_ctor</span><span class="params">(Shape * <span class="type">const</span> me, <span class="type">int16_t</span> x, <span class="type">int16_t</span> y)</span>;</span><br><span class="line"><span class="type">void</span> <span class="title function_">Shape_moveBy</span><span class="params">(Shape * <span class="type">const</span> me, <span class="type">int16_t</span> dx, <span class="type">int16_t</span> dy)</span>;</span><br><span class="line"><span class="type">int16_t</span> <span class="title function_">Shape_getX</span><span class="params">(Shape <span class="type">const</span> * <span class="type">const</span> me)</span>;</span><br><span class="line"><span class="type">int16_t</span> <span class="title function_">Shape_getY</span><span class="params">(Shape <span class="type">const</span> * <span class="type">const</span> me)</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="keyword">inline</span> <span class="type">uint32_t</span> <span class="title function_">Shape_area</span><span class="params">(Shape <span class="type">const</span> * <span class="type">const</span> me)</span> </span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">return</span> (*me-&gt;vptr-&gt;area)(me);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"><span class="meta">#<span class="keyword">endif</span> <span class="comment">/* SHAPE_H */</span></span></span><br></pre></td></tr></table></figure><p>ok，然后写一下这个<code>rect.h</code>的实现</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// rect.c</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;rect.h&quot;</span>  </span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span> </span></span><br><span class="line"><span class="comment">// 继承来的虚函数</span></span><br><span class="line"><span class="type">static</span> <span class="type">uint32_t</span> <span class="title function_">Rectangle_area_</span><span class="params">(Shape <span class="type">const</span>* <span class="type">const</span> me)</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 构造函数</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">Rectangle_ctor</span><span class="params">(Rectangle * <span class="type">const</span> me, <span class="type">int16_t</span> x, <span class="type">int16_t</span> y,</span></span><br><span class="line"><span class="params">                    <span class="type">uint16_t</span> width, <span class="type">uint16_t</span> height)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">ShapeVtbl</span> <span class="title">const</span> <span class="title">vtbl</span> =</span> </span><br><span class="line">    &#123;</span><br><span class="line">        &amp;Rectangle_area_</span><br><span class="line">    &#125;;</span><br><span class="line">    Shape_ctor(&amp;me-&gt;super, x, y); <span class="comment">// 调用基类的构造函数</span></span><br><span class="line">    me-&gt;super.vptr = &amp;vtbl;           <span class="comment">// 重载 vptr</span></span><br><span class="line">    me-&gt;width = width;</span><br><span class="line">    me-&gt;height = height;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 虚函数实现</span></span><br><span class="line"><span class="type">static</span> <span class="type">uint32_t</span> <span class="title function_">Rectangle_area_</span><span class="params">(Shape <span class="type">const</span>* <span class="type">const</span> me)</span>&#123;</span><br><span class="line">    Rectangle <span class="type">const</span>* <span class="type">const</span> me_ = (Rectangle <span class="type">const</span>*)me;</span><br><span class="line">    <span class="keyword">return</span> (<span class="type">uint32_t</span>)me_-&gt;width *(<span class="type">uint32_t</span>)me_-&gt;height;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="记录">记录</h3><p>编译一个镜像要了半条命，缓缓</p><h4 id="编译运行坑">编译运行坑</h4><ol type="1"><li><p>qemu模拟器现在包已经变了，应该下载的是：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install qemu-system-x86</span><br></pre></td></tr></table></figure></li><li><p>要在各种乱七八糟的Makefile里边手动添加一个变量<code>AM_HEMO_</code>，不过这个可能直接加在最外边的Makefile应该也是可以实现的</p></li><li><p>一些自己的写的头文件如果找不到就要用从根路径过来的全路径来引用，而且要是双引号</p></li></ol><p><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240214151608435.png" /></p><p>太感人了<code>😭😭😭😭😭</code></p><h4 id="printf实现"><code>printf</code>实现</h4><p>不说很难，至少很恶心代码量很大，尝试分析：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/%E5%B0%9D%E8%AF%95%E5%88%86%E6%9E%90.jpg" style="zoom: 67%;" /></p><p>还是能分析出来的，回忆一下这个函数的用法：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;format&quot;</span>,data, ...);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;string&quot;</span>);</span><br></pre></td></tr></table></figure><p>嗯，很显然我们需要一个和Python中<code>argv</code>类似性质的一个玩意来帮忙，然后要做的就是识别是否有后边的参数。其次我们还需要能够切分前面的字符串以识别其中的<code>%d,%f</code>等参数，并获取参数对应的<code>argv</code>中的参数。</p><p>果然，C语言中是有这种玩意的：<code>&lt;stdarg.h&gt;</code>，抄一个用法示例（）：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdarg.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">VarArgFunc</span><span class="params">(<span class="type">int</span> dwFixedArg, ...)</span>&#123; <span class="comment">//以固定参数的地址为起点依次确定各变参的内存起始地址</span></span><br><span class="line"></span><br><span class="line">    va_list pArgs = <span class="literal">NULL</span>;  <span class="comment">//定义va_list类型的指针pArgs，用于存储参数地址</span></span><br><span class="line"></span><br><span class="line">    va_start(pArgs, dwFixedArg); <span class="comment">//初始化pArgs指针，使其指向第一个可变参数。该宏第二个参数是变参列表的前一个参数，即最后一个固定参数</span></span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> dwVarArg = va_arg(pArgs, <span class="type">int</span>); <span class="comment">//该宏返回变参列表中的当前变参值并使pArgs指向列表中的下个变参。该宏第二个参数是要返回的当前变参类型</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//若函数有多个可变参数，则依次调用va_arg宏获取各个变参</span></span><br><span class="line"></span><br><span class="line">    va_end(pArgs);  <span class="comment">//将指针pArgs置为无效，结束变参的获取</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Code Block using variable arguments */</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//可在头文件中声明函数为extern int VarArgFunc(int dwFixedArg, ...);，调用时用VarArgFunc(FixedArg, VarArg);</span></span><br></pre></td></tr></table></figure><p>开编，注意到我们现在实际上只有一个<code>putch()</code>函数来输出单个字符</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">printf</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *fmt, ...)</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">if</span> (fmt == <span class="literal">NULL</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 定义返回字符串的数目</span></span><br><span class="line">  <span class="type">int</span> ret_num = <span class="number">0</span>;</span><br><span class="line">  <span class="comment">// 获取自由变量</span></span><br><span class="line">  va_list va_l;</span><br><span class="line">  va_start(va_l, fmt);</span><br><span class="line">  <span class="comment">// 获取字符</span></span><br><span class="line">  <span class="type">char</span> *pstr = (<span class="type">char</span> *)fmt;</span><br><span class="line">  <span class="comment">// 循环遍历</span></span><br><span class="line">  <span class="keyword">while</span> (*pstr != <span class="string">&#x27;\0&#x27;</span>)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">if</span> (*pstr == <span class="string">&#x27;%&#x27;</span>)</span><br><span class="line">    &#123;</span><br><span class="line">      pstr++;</span><br><span class="line">      <span class="keyword">switch</span> (*pstr)</span><br><span class="line">      &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="string">&#x27;d&#x27;</span>:</span><br><span class="line">        <span class="type">int</span> var1 = va_arg(va_l, <span class="type">int</span>);</span><br><span class="line">        ret_num++;</span><br><span class="line">        putch(var1);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">case</span> <span class="string">&#x27;s&#x27;</span>:</span><br><span class="line">        <span class="type">char</span>* var2 = va_arg(va_l, <span class="type">char</span> *);</span><br><span class="line">        ret_num++;</span><br><span class="line">        putch(*var2);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">case</span> <span class="string">&#x27;%&#x27;</span>:</span><br><span class="line">        putch(<span class="string">&#x27;%&#x27;</span>);</span><br><span class="line">        ret_num++;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">default</span>:</span><br><span class="line">        putch(<span class="string">&#x27; &#x27;</span>);</span><br><span class="line">        ret_num++;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    putch(*pstr);</span><br><span class="line">    ret_num++;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> ret_num;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>写了一个简陋的，但是显然不是很成功（<del>思想对了，嗯</del>，想看正确的可以看参考链接）</p><p><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240214202527832.png" /></p><p>另外由于在内核编译的Makefile中有这样一句话：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CFLAGS  += -m64 -fPIC -mno -sse</span><br></pre></td></tr></table></figure><p>因此我在编译内核时任何的浮点操作都是不被允许的。</p><h4 id="kallockfree实现"><code>kalloc、kfree</code>实现</h4><p>实现内容今天貌似是写不完了，简单记录一下思路，就是和前边实现字符串的一些操作是一致的，但是会涉及一些内存的管理问题，用结构体就能解决，区别主要是实现策略问题，然后就是要对齐，如何对齐呢，写个循环算好阶乘就行了。然后<code>kfree</code>的实现就比较简明了把维护的指针收回就行，剩下的明天续上。</p><h3 id="参考链接">参考链接</h3><p><ahref="https://blog.csdn.net/weixin_68551689/article/details/132844392">什么是函数指针？如何使用函数指针？-CSDN博客</a></p><p><a href="https://blog.csdn.net/onlyshi/article/details/81672279">C语言实现面向对象编程_void rectangle_construct(rectangle_t* shape,const-CSDN博客</a></p><p><ahref="https://blog.csdn.net/qq_44078824/article/details/118440458">手把手教你实现printf函数（C语言方式）_printf实现-CSDN博客</a></p><p><ahref="https://zhuanlan.zhihu.com/p/643112072">内存分配不再神秘：深入剖析malloc函数实现原理与机制- 知乎 (zhihu.com)</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 搓OS.log </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>手搓OS-番外2</title>
      <link href="/2024/02/10/%E6%90%93OS-%E7%95%AA%E5%A4%962/"/>
      <url>/2024/02/10/%E6%90%93OS-%E7%95%AA%E5%A4%962/</url>
      
        <content type="html"><![CDATA[<h2 id="手搓os-makefile">手搓OS-Makefile</h2><p>我们在生活中常常会遇到这样的问题：为了查看修改后的代码效果，一遍又一遍的编译，敲一行又一行的命令，现在让Makefile解放你的双手。（误）</p><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="100%" height="86" src="//music.163.com/outchain/player?type=2&amp;id=2103741649&amp;auto=1&amp;height=66"></iframe><h3 id="关于c语言">关于C语言</h3><p>在之前关于baremetal的学习中，我们已经基本理解C语言编译运行的原理，也就是编译库+编译源文件，链接形成一个可执行文件。</p><p>罗列出编译静态库与动态库的方式：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">静态库</span></span><br><span class="line">gcc -r [name.a] [.o] [.o]</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">链接为可执行文件</span></span><br><span class="line">gcc [.c] [.a] -o [自定义输出文件名]</span><br><span class="line">gcc [.c] -o [自定义输出文件名] -l[库名] -L[库所在路径]</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">动态库</span></span><br><span class="line">gcc -c -fpic [.c/.cpp][.c/.cpp]... </span><br><span class="line">gcc -shared [.o][.o]... -o [lib自定义库名.so]</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">上面两条合并也是可以的</span></span><br><span class="line">gcc [.c/.cpp] -o [自定义可执行文件名]  -l[库名] -L[库路径] -Wl,-rpath=[库路径]</span><br></pre></td></tr></table></figure><p>记不住对吧，我也是（），不过记不住也问题不大，多写写就记住了。</p><h3 id="makefile">Makefile</h3><h4 id="格式">格式</h4><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">targets:prerequisties</span></span><br><span class="line">command</span><br></pre></td></tr></table></figure><p>targets：草率一点，就是make指令后的一个标志，代表了下面一串命令执行后的结果</p><p>prerequisite：依赖，需要的文件，或者需要事先执行的targets</p><p>command：命令</p><p><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/%E6%89%94%E6%8E%89%E8%84%91%E5%AD%90.gif" /></p><p>我们扔掉脑子，开玩儿：</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">hello: </span></span><br><span class="line">@echo <span class="string">&quot;hello world&quot;</span></span><br></pre></td></tr></table></figure><p><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240211101558263.png" /></p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">bye:</span></span><br><span class="line">sudo rm -rf /*</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/b6d4f8aa58841f6e8674c3bd46126e5f8ad5fc7f.jpg" style="zoom: 25%;" /></p><blockquote><p>删库一念起，顿觉天地宽</p></blockquote><h4 id="运行规则">运行规则</h4><ol type="1"><li>make在当前目录下查找Makefile文件</li><li>找到文件中的第一个target文件作为最终目标</li><li>根据不同情况来执行command（这儿理不理解的吧，道理上还是要减少不必要的编译）</li></ol><h4 id="phony">.PHONY</h4><p>当文件夹中有文件或文件夹有与target重名的问题，采用这样一条</p><p>代码来声明运行的是target：</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"><span class="keyword">.PHONY</span>:hello</span></span><br></pre></td></tr></table></figure><p>这样我们就学完了大概makefile是怎么玩儿的了，接下来需要一点点细节……</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/%E4%B8%80%E7%82%B9.jpg" style="zoom: 33%;" /></p><h4 id="小细节">小细节</h4><p>下面其实就和大多数编程语言差不了多少了，但是依旧是很有用的</p><h5 id="变量">变量</h5><p>在makefile中变量只能是字符串，这个也是挺好理解的吧，毕竟在Makefile中变量实际上都是一些文件什么的</p><p><strong>定义</strong></p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">file :=src/main.c</span><br></pre></td></tr></table></figure><p><strong>引用</strong>：用<code>$&#123;&#125;</code>或<code>$()</code></p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cp :=src/main.c</span><br><span class="line">obj :=objs/main.o</span><br><span class="line"></span><br><span class="line"><span class="variable">$(obj)</span>:$&#123;cp&#125;</span><br><span class="line">@gcc -o $&#123;obj&#125; <span class="variable">$(cp)</span></span><br><span class="line">compile : $&#123;obj&#125;</span><br></pre></td></tr></table></figure><p>使用变量还有一些高阶方法，后边再说，先说赋值</p><p><strong>赋值</strong></p><table><thead><tr class="header"><th>赋值符号</th><th>含义</th></tr></thead><tbody><tr class="odd"><td>:=</td><td>简单赋值，没啥含义，通用赋值</td></tr><tr class="even"><td>=</td><td>递归赋值，可能会影响多个值，不受赋值顺序影响</td></tr><tr class="odd"><td>?=</td><td>条件赋值，空的才赋值</td></tr><tr class="even"><td>+=</td><td>追加赋值，用空格隔开，加一个变量</td></tr></tbody></table><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x = foo</span><br><span class="line">y = <span class="variable">$(x)</span>b</span><br><span class="line">x = new</span><br><span class="line"></span><br><span class="line">test :</span><br><span class="line">@echo <span class="string">&quot;x =&gt; <span class="variable">$(x)</span>&quot;</span></span><br><span class="line">@echo <span class="string">&quot;y =&gt; <span class="variable">$(y)</span>&quot;</span></span><br></pre></td></tr></table></figure><p><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240211211130750.png" /></p><p><strong>自动变量</strong></p><ul><li><code>$@</code>：target的完整名称</li><li><code>$&lt;</code>：第一个依赖文件名称</li><li><code>$^</code>：所有依赖文件</li></ul><h5 id="有用的小符号">有用的小符号</h5><table><thead><tr class="header"><th>符号</th><th>含义</th></tr></thead><tbody><tr class="odd"><td>\</td><td>换号符，在换行的结尾加上</td></tr><tr class="even"><td>*</td><td>通配符，表示任意字符串，用于文件名</td></tr><tr class="odd"><td>%</td><td>通配符，表示任意字符串，用于匹配字符串用于变量</td></tr></tbody></table><h5 id="函数">函数</h5><p><strong>shell：shell命令</strong></p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$(<span class="built_in">shell</span> &lt;command&gt;)</span></span><br></pre></td></tr></table></figure><p><strong>subst：字符串替换</strong></p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$(<span class="built_in">subst</span> &lt;from&gt;,&lt;to&gt;,&lt;text&gt;)</span></span><br></pre></td></tr></table></figure><p><strong>patsubst：模式匹配替换</strong></p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$(<span class="built_in">patsubst</span> &lt;pattern&gt;,&lt;replacement&gt;,&lt;text&gt;)</span></span><br></pre></td></tr></table></figure><p>剩下的常用的函数就参考链接吧（，只有一点细节</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240211222748769.png" style="zoom:33%;" /></p><h5 id="模板">模板</h5><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">.PHONLY :all cl cla</span><br><span class="line">src = <span class="variable">$(<span class="built_in">wildcard</span> ./*.c)</span></span><br><span class="line">targetc = <span class="variable">$(<span class="built_in">patsubst</span> %.c, % ,<span class="variable">$(src)</span>)</span></span><br><span class="line">objc = <span class="variable">$(<span class="built_in">patsubst</span> %.c, %.o, <span class="variable">$(src)</span>)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#srcpp = $(wildcard ./*.cpp)</span></span><br><span class="line"><span class="comment">#targetcpp = $(patsubst %.cpp, %, $(srcpp))</span></span><br><span class="line"><span class="comment">#objcpp = $(patsubst %.o, %.cpp, $(srcpp))</span></span><br><span class="line"></span><br><span class="line">CC = gcc</span><br><span class="line"><span class="comment">#PP = g++</span></span><br><span class="line"></span><br><span class="line">CFLAGS = -g -Wall </span><br><span class="line">CPPFLAGS = -I ./</span><br><span class="line"></span><br><span class="line"><span class="keyword">ifeq</span> (<span class="variable">$(<span class="built_in">findstring</span> .c, <span class="variable">$(src)</span>)</span>, .c)</span><br><span class="line"><span class="section">all:<span class="variable">$(targetc)</span></span></span><br><span class="line"><span class="variable">$(targetc)</span>:%:%.o</span><br><span class="line"><span class="variable">$(CC)</span> <span class="variable">$&lt;</span> -o <span class="variable">$@</span></span><br><span class="line"><span class="variable">$(objc)</span>:%.o:%.c</span><br><span class="line"><span class="variable">$(CC)</span> -c <span class="variable">$&lt;</span> </span><br><span class="line"><span class="keyword">endif</span></span><br><span class="line"></span><br><span class="line"><span class="section">cl:</span></span><br><span class="line">rm -rf <span class="variable">$(objc)</span></span><br><span class="line"><span class="section">cla:</span></span><br><span class="line">rm -rf <span class="variable">$(objc)</span></span><br><span class="line">rm -rf <span class="variable">$(targetc)</span></span><br><span class="line">rm -rf a.out</span><br></pre></td></tr></table></figure><h3 id="参考链接">参考链接</h3><p><ahref="https://github.com/WohimLee/GNC-Tutorial/blob/main/3.Makefile-Tutorial/4.Functions.md">GNC-Tutorial/3.Makefile-Tutorial/4.Functions.mdat main · WohimLee/GNC-Tutorial (github.com)</a></p><p>https://blog.csdn.net/qq_43630810/article/details/105942231</p>]]></content>
      
      
      
        <tags>
            
            <tag> 搓OS.log </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文阅读1-TFDNet</title>
      <link href="/2024/02/04/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB1/"/>
      <url>/2024/02/04/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB1/</url>
      
        <content type="html"><![CDATA[<h2 id="论文阅读-tfdnet">论文阅读-TFDNet</h2><p>作者表示在看了这么多文章，发现现有模型没有充分学习timefrequency信息，并且认为时域和频域的学习都相当重要。然后提出了这个模型叫做TIme-FrequencyEnhanced Decomposed Network。</p><p>文章中还提到了一个<code>channel wise effects</code>的东西，简答查了一下，是从卷积的颗粒度来的，就是维度更小了</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240206123340086.png"alt="image-20240206123340086" /><figcaption aria-hidden="true">image-20240206123340086</figcaption></figure><p>结构非常简单：</p><ol type="1"><li><p>第一部分：预处理，分解序列并归一化归一化采用了一种叫做可逆示例归一化的方法（RevIN） 论文链接：<ahref="https://openreview.net/pdf?id=cGDAkQo1C0p">pdf(openreview.net)</a></p></li><li><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240206214534524.png"alt="image-20240206214534524" /><figcaption aria-hidden="true">image-20240206214534524</figcaption></figure><p><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240206214518454.png"alt="image-20240206214518454" />分解公式比较简单，分成了趋势和季节趋势： <imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240206214715000.png"alt="image-20240206214715000" /></p><p>AvgPool表示移动平滑操作，Padding使原时间序列长度保持不变</p></li><li><p>下面一层设计用来捕获两种分解的时间序列的多分辨率的时域特征和频域特征：<imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240206215107201.png"alt="image-20240206215107201" /> 其<spanclass="math inline">\(S_1……S_n\)</span>代表不同窗口的长度，也就是不同分辨率<img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240206221126879.png" alt="image-20240206221126879" />STFT(短期傅里叶变换)：<imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240207001603403.png"alt="image-20240207001603403" /> <spanclass="math inline">\(X\)</span>为归一化后的序列，<spanclass="math inline">\(Window\)</span>​是窗函数，用于将信号切分成较短的时间段，然后就看不太懂了Time-frequency Block（TFB)：<imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240207125307235.png"alt="image-20240207125307235" /><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240207125530318.png"alt="image-20240207125530318" />设计了两种季节的TFB，分别应对不同的通道相关模式</p><p>Frequency Feed ForwardNetwork（Frequency-FFN)：全连接层，激活函数为Tanh InverseSTFT：</p></li><li><p>逆实例归一化预测</p></li></ol><p>论文链接：[<a href="https://arxiv.org/abs/2308.13386">2308.13386]TFDNet: Time-Frequency Enhanced Decomposed Network for Long-term TimeSeries Forecasting (arxiv.org)</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 读论文吧 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>搓OS-day8</title>
      <link href="/2024/02/04/%E6%90%93OS-day8/"/>
      <url>/2024/02/04/%E6%90%93OS-day8/</url>
      
        <content type="html"><![CDATA[<h2 id="手搓os-day8">手搓OS-day8</h2><h3 id="同步">同步</h3><p>本篇仅仅是实现同步问题，如果你问同步问题是什么，在应付考研的时候怎么搞，我也不介意写一手（）</p><p>在OS中同步的理解是非常抽象的，抽象就抽象在和我们日常的理解完全不一样。在我们日常生活中讲同步，往往是这样一个情景；</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/bili_v_1707558407748.gif"alt="同步率100%" /><figcaption aria-hidden="true">同步率100%</figcaption></figure><p>嗯，所以在计算机领域中，我们也会习惯性的认为同步嘛，就是两个某种主体做着一样的动作（好怪），而在计算机领域中我们平时理解的同步其实是一种比较特殊的并行。</p><p>先来一个别扭且不恰当的比喻，首先必须说明我们生活中的活动有些是瞬间完成的，有些是需要一定时间的，下面是不太正常比喻：（①）有一个前来买瓜，（②）该人询问这瓜多少钱并（③）表示“你这瓜是瓜皮子是金子做的还是瓜粒子是金子做的“，（④）然后一刀捅穿了瓜摊老板，（⑤）传出了阵阵”萨日朗“。</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240210195115716.png"alt="火红的萨日朗" /><figcaption aria-hidden="true">火红的萨日朗</figcaption></figure><p>上面的小故事由五个步骤组成，所有的情节发生都是有因果关系的，因此不能出现顺序的变化，不可能在捅穿老板之前就传出“萨日朗”，也不能在找茬之前就捅穿（不许抬杠），这种必须按照一定顺序去执行（需要完全执行一步，才能执行下一步）的故（程）事（序），就是同步。</p><p>说同步就不得不说一下异步，在生活中往往同步和异步是同时存在的。在一串串有逻辑相关的同步中，往往存在着异步。引用从知乎上看到的比喻：异步就是在你蒸饭期间去炒菜，也就是不必等待蒸饭结束的过程。</p><p>OK，那么为什么要提出同步和异步的问题呢？</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/WQwhQnXTwU8O3QIIIOEErvBWzIYlzF1O.JPEG" style="zoom: 25%;" /></p><p>这就不得不提一下我们之前研究过的并发技术了，因为为了榨干每一滴处理机，计算机科学家机智的想出来了用程序对处理机进行车轮战。但是这种车轮战是不可控的，我们不知道什么时候哪个程序会占用处理机，所以当处理需要必要的逻辑顺序时，同步的问题就很重要了。而异步是因为有了一大串同步，干等着又不符合计算机科学家喜欢榨干处理机的风格，因此又提出了异步问题。</p><h3 id="实现与简单介绍">实现与简单介绍</h3><h4 id="生产者-消费者问题">生产者-消费者问题</h4><p>问题我不太会介绍，于是我决定直接剽窃一个问题介绍：</p><blockquote><p>Dijkstra wrote about the unbounded buffer case: "We consider twoprocesses, which are called the 'producer' and the 'consumer'respectively. The producer is a cyclic process and each time it goesthrough its cycle it produces a certain portion of information, that hasto be processed by the consumer. The consumer is also a cyclic processand each time it goes through its cycle, it can process the next portionof information, as has been produced by the producer ... We assume thetwo processes to be connected for this purpose via a buffer withunbounded capacity."</p></blockquote><p>没错就是那个Dijkstra，由于我是懒狗，所以我决定翻译也交给chatGPT（虽然我相信大家是能直接看懂的）：</p><blockquote><p>迪杰斯特拉（Dijkstra）描述了无界缓冲区的情况：“我们考虑两个进程，分别称为’生产者’和’消费者’。生产者是一个循环过程，每次经过循环会产生一定量的信息，这些信息需要消费者进行处理。消费者也是一个循环过程，每次经过循环时，可以处理生产者产生的下一个信息部分…为此，我们假设这两个进程通过一个容量无限的缓冲区连接在一起。”</p></blockquote><p>学过操作系统的都知道，解决同步问题用的是信号量机制。所以我们也就不去走弯路了，直奔信号量机制（当然直接调用管程也是可以的）。</p><p>停，这里他用了一个很骚的操作：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> n,count=<span class="number">0</span>;</span><br><span class="line"><span class="type">mutex_t</span> lk=MUTEX_INIT();</span><br><span class="line"><span class="type">cond_t</span> cv=COND_INIT();</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CAN_PRODUCE (count&lt;n)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CAN_CONSUME (count&gt;n)</span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">Tproduce</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        mutex_lock(&amp;lk);</span><br><span class="line">        <span class="keyword">while</span> (!CAN_PRODUCE)</span><br><span class="line">        &#123;</span><br><span class="line">            cond_wait(&amp;cv,&amp;lk);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;(&quot;</span>);</span><br><span class="line">        count++;</span><br><span class="line">        cond_broadcast(&amp;cv);</span><br><span class="line">        mutex_unlock(&amp;lk);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">Tconsume</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    mutex_lock(&amp;lk);</span><br><span class="line">    <span class="keyword">while</span> (!CAN_CONSUME) &#123;</span><br><span class="line">      cond_wait(&amp;cv, &amp;lk);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;)&quot;</span>); count--;</span><br><span class="line">    cond_broadcast(&amp;cv);</span><br><span class="line">    mutex_unlock(&amp;lk);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这种方法称为条件变量法，有没有感觉他和前面Peterson算法的flag很像，其实就是很像，作为一个标志来放行。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">sem_t</span> fill, empty;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">Tproduce</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    P(&amp;empty);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;(&quot;</span>);</span><br><span class="line">    V(&amp;fill);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">Tconsume</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    P(&amp;fill);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;)&quot;</span>);</span><br><span class="line">    V(&amp;empty);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>不细说，好理解，下一个</p><h4 id="哲学家就餐问题">哲学家就餐问题</h4><p>省流：操作的时候无脑mutex住，就不会出死锁bug</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">sem_t</span> chopsticks[<span class="number">5</span>]=&#123;<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>&#125;;</span><br><span class="line"><span class="type">mutex_t</span> lk=MUTEX_INIT();</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">philosopher</span><span class="params">(<span class="type">int</span> i)</span> &#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    mutex_lock(&amp;lk);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;搞哲♂学&quot;</span>);</span><br><span class="line">    P(&amp;chopsticks[i+<span class="number">1</span>]%<span class="number">5</span>);</span><br><span class="line">    P(&amp;chopsticks[i])</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;吃&quot;</span>);</span><br><span class="line">    V(&amp;chopsticks[i+<span class="number">1</span>]%<span class="number">5</span>);</span><br><span class="line">    V(&amp;chopsticks[i])</span><br><span class="line">    mutex_unlock(&amp;lk);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="总结">总结</h3><p>有用但不难，平时考察很频繁，记住要点很重要：</p><ol type="1"><li>分析什么是互斥访问的</li><li>互斥加锁</li><li>分析什么是同步访问的</li><li>同步访问涉及什么资源，需要什么p什么v什么</li><li>添加对应的信号量</li><li>检查是否死锁，死锁则调整互斥锁与pv操作的顺序</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 搓OS.log </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>手搓OS-番外1</title>
      <link href="/2024/02/04/%E6%90%93OS-%E7%95%AA%E5%A4%961/"/>
      <url>/2024/02/04/%E6%90%93OS-%E7%95%AA%E5%A4%961/</url>
      
        <content type="html"><![CDATA[<h2 id="手搓os-内联汇编">手搓OS-内联汇编</h2><p>有一说一（起手式），虽然我们在平时写代码时几乎就不会写什么汇编（毕竟咱是写软件的，什么底层，什么硬件就该交给专业的人去搞），但是这对我们阅读代码，理解运行还是很有必要的（<del>我就是想学会</del>）</p><h3 id="汇编语言">汇编语言</h3><p>首先，简单回忆一下汇编语言，虽然这块是真的多，简单总结一下吧。</p><p>为了能理解汇编语言的作用方式，我们需要先回忆C语言的运行方式，这个在之前粗浅的写过，C语言要经过<code>预处理-编译-汇编-链接</code>多个步骤，才能形成一个可执行的二进制程序代码。这次不搞helloworld了，换个简单易读的，我们来写一个两个数求和的程序：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">int</span> a=<span class="number">0</span>,b=<span class="number">0</span>;</span><br><span class="line">    a=b+<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这套玩法我们其实已经非常熟悉了，编译但不链接，然后反编译：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"> 0:   f3 0f 1e fa             endbr64 </span><br><span class="line"> 4:   55                      push   %rbp</span><br><span class="line"> 5:   48 89 e5                mov    %rsp,%rbp</span><br><span class="line"> 8:   c7 45 f8 00 00 00 00    movl   $0x0,-0x8(%rbp)</span><br><span class="line"> f:   c7 45 fc 00 00 00 00    movl   $0x0,-0x4(%rbp)</span><br><span class="line">16:   8b 45 fc                mov    -0x4(%rbp),%eax</span><br><span class="line">19:   83 c0 01                add    $0x1,%eax</span><br><span class="line">1c:   89 45 f8                mov    %eax,-0x8(%rbp)</span><br><span class="line">1f:   b8 00 00 00 00          mov    $0x0,%eax</span><br><span class="line">24:   5d                      pop    %rbp</span><br><span class="line">25:   c3                      ret    </span><br></pre></td></tr></table></figure><p>因为没有链接，所以实际上程序并没有装入实际内存中，那么拿到的所有内存地址等，都是虚拟的（是一个相对的关系）。跑题了，这个可以后边仔细解释的，先观察整体结构，从左到右，分别是内存地址（姑且这么认为），二进制代码，汇编代码。</p><p>汇编语言有很强的平台相关性，也就是换了一个硬件，这个代码的书写方式就完全变了，目前比较流行的有两种格式，分别是intel格式和AT&amp;T格式，我们先不做区分，继续从整体上认识他。</p><p>我们知道程序无非是在处理数据，那么我们就可以开始遐（<del>瞎</del>）想了。既然是处理数据，那么数据怎么来，怎么处理，放哪儿处理，怎么处理，处理之后又放哪儿，OK，这下就要去看组成原理了，完结。（bushi）而这种考虑的思路返回到汇编指令上，就形成了这样的一种大体上的汇编指令的格式：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INS SRC DES</span><br></pre></td></tr></table></figure><p>也就是指令+源操作数+目的操作数的一种指令格式，拿来源操作数和目的操作数，加一点神秘的魔法处理，然后把结果送到目的操作数的位置。</p><p>接下来，解密操作的数都从哪儿来，当然是——各种各样的寄存器和内存，寄存器包括但不限于：通用寄存器，PC，PSW，栈；</p><p>有了这些基本的知识，可以来尝试一下阅读上面的代码了，我们只需要分析这一部分接可以了（用注释给出分析）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"> 8:   c7 45 f8 00 00 00 00    movl   $0x0,-0x8(%rbp)  // rbp的前半段存储一个0，实际上就是a变量</span><br><span class="line"> f:   c7 45 fc 00 00 00 00    movl   $0x0,-0x4(%rbp)  // rbp的后半段存储一个0，实际上就是b变量</span><br><span class="line">16:   8b 45 fc                mov    -0x4(%rbp),%eax  // 把后半段变脸赋值给通用寄存器eax，即b</span><br><span class="line">19:   83 c0 01                add    $0x1,%eax        // 将通用寄存器eax中的值与1相加，并存储到eax中，即b+1的过程</span><br><span class="line">1c:   89 45 f8                mov    %eax,-0x8(%rbp)  // 将eax的值移动到rbp的前半段，a=b+1</span><br><span class="line">1f:   b8 00 00 00 00          mov    $0x0,%eax        // eax置0</span><br></pre></td></tr></table></figure><p>OK，我知道你看到这里肯定是依旧一头雾水，那就对了，在这里我忽略了所有寄存器细节介绍，也选择性忽略了如何设计直接手写汇编程序，因为这些玩意并不需要我们去写，我们只需要能够读懂就好了。而细节的寄存器的介绍，数据的寻址的介绍，大家可以去看看参考链接的文章，或者去阅读一下指令系统的相关介绍。</p><h3 id="内联汇编">内联汇编</h3><p>进入正题，内联汇编（Inlineassembly）是部分编译器（刚好GCC就支持）支持的一种功能。其将非常低端的汇编语言内嵌在高级语言源始码中。</p><p>再开始内联汇编学习前，我们想起来有一种玩意叫做内联函数，内联函数是通过声明（<code>inline</code>）要求编译器在运行时，直接将内联函数的代码复制到调用位置，是一种类似宏的运行方式。内联汇编大抵也如此，不过使用汇编语言写的，声明是<code>asm</code>。</p><p>GCC的汇编格式为AT&amp;T格式，具体不再详述，与上面我们所分析的一致。GCC支持两种内联汇编：基本内联汇编和扩展内联汇编</p><h4 id="基本内联汇编">基本内联汇编</h4><p>基本内联汇编的格式比较简明：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">asm</span>[<span class="keyword">volatile</span>](<span class="string">&quot;assembly code&quot;</span>);</span><br></pre></td></tr></table></figure><p>需要说明的几点：</p><ol type="1"><li>超过一条指令必须通过<code>\n\t</code>来进行分割</li><li><code>volatile</code>为可选关键字，后面再介绍</li><li><code>asm</code>可以换为<code>__asm__</code>，当<code>asm</code>与程序变量有冲突时必须替换</li></ol><p>ok，我们先扔掉脑子，来简单玩一玩这个内联汇编</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/%E6%89%94%E6%8E%89%E8%84%91%E5%AD%90.gif"alt="扔掉脑子" /><figcaption aria-hidden="true">扔掉脑子</figcaption></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">asm</span>(<span class="string">&quot;nop&quot;</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;hello\n&quot;</span>);</span><br><span class="line">    <span class="keyword">asm</span>(<span class="string">&quot;nop\n\tnop\n\t&quot;</span></span><br><span class="line">    <span class="string">&quot;nop&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>一看这个程序就挺抽象的，直接观察结果一定是看不出来的，所以我们还是那一套操作，我们来反编译看汇编代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> 8:   90                      nop</span><br><span class="line"> 9:   48 8d 05 00 00 00 00    lea    0x0(%rip),%rax        # 10 &lt;main+0x10&gt;</span><br><span class="line">10:   48 89 c7                mov    %rax,%rdi</span><br><span class="line">13:   e8 00 00 00 00          call   18 &lt;main+0x18&gt;  // 经典调用指令,这里是调用printf</span><br><span class="line">18:   90                      nop</span><br><span class="line">19:   90                      nop</span><br><span class="line">1a:   90                      nop  </span><br></pre></td></tr></table></figure><p>发现很成功，我们写入的四个气泡指令都在里边，但是什么都不做肯定不是我们编程的初衷，现在我们要玩儿点大的，操作一下变量，玩玩寄存器：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> a=<span class="number">1</span>,b=<span class="number">2</span>,c;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">asm</span>(<span class="string">&quot;movl a,%eax\n\t&quot;</span></span><br><span class="line">    <span class="string">&quot;addl b,%eax\n\t&quot;</span></span><br><span class="line">    <span class="string">&quot;movl %eax,c&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;c=%d&quot;</span>,c);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>老规矩：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"> 8:   8b 04 25 00 00 00 00    mov    0x0,%eax</span><br><span class="line"> f:   03 04 25 00 00 00 00    add    0x0,%eax</span><br><span class="line">16:   89 04 25 00 00 00 00    mov    %eax,0x0</span><br><span class="line">1d:   8b 05 00 00 00 00       mov    0x0(%rip),%eax        # 23 &lt;main+0x23&gt;</span><br><span class="line">23:   89 c6                   mov    %eax,%esi</span><br><span class="line">25:   48 8d 05 00 00 00 00    lea    0x0(%rip),%rax        # 2c &lt;main+0x2c&gt;</span><br><span class="line">2c:   48 89 c7                mov    %rax,%rdi</span><br><span class="line">2f:   b8 00 00 00 00          mov    $0x0,%eax</span><br><span class="line">34:   e8 00 00 00 00          call   39 &lt;main+0x39&gt;</span><br></pre></td></tr></table></figure><p>可以很清晰的看到我们写的汇编在里边，但是怎么没有数儿呢，因为这些全局变量在内存中和函数并不处于一个区域中。</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/20190913192521450.png"alt="盗了一张图，不想自己画了" /><figcaption aria-hidden="true">盗了一张图，不想自己画了</figcaption></figure><p>但是，但是，但是（重要的事情说三遍），有一个很大的问题，因为汇编语言直接操作的是寄存器之类的，如果随随便便更改了某个寄存器的值，而且还没有返回，那么这个程序和你肯定要爆一个。<strong>所以一般不用基本内联汇编去搞什么寄存器，而是用扩展内联汇编。</strong></p><h4 id="扩展内联汇编">扩展内联汇编</h4><p>格式：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">asm [volatile](&quot;汇编指令&quot;: &quot;输出操作数列表&quot; : &quot;输入操作数列表&quot; : &quot;改动的寄存器&quot;)</span><br></pre></td></tr></table></figure><p>啧，看不懂了，这时候需要一些说明：</p><ol type="1"><li>汇编指令：与基本内联汇编格式相同，扩展asm格式中，寄存器前面必须写 2个%；</li><li>输出操作数列表：汇编代码如何把处理结果传递给C代码</li><li>输入操作数列表：C代码如何把数据传递给汇编代码</li><li>改动的寄存器：使用了哪些寄存器，告诉编译器不要再用这个寄存器，可以省略</li></ol><p>先看一个例子：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> a=<span class="number">10</span>, b;</span><br><span class="line"><span class="keyword">asm</span> ( <span class="string">&quot;movl %1, %%eax\n\tmovl %%eax, %0&quot;</span></span><br><span class="line">          :<span class="string">&quot;=r&quot;</span>(b)           <span class="comment">/* output */</span></span><br><span class="line">          :<span class="string">&quot;r&quot;</span>(a)              <span class="comment">/* input */</span></span><br><span class="line">          :<span class="string">&quot;%eax&quot;</span>         <span class="comment">/* clobbered register */</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>ok，现在我们满脑子疑问，我们要带着这些问题接着去学了：</p><ol type="1"><li>"b"是什么？</li><li>“r”是什么？</li><li>“=r”是什么？</li></ol><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/%E8%BF%B7%E6%83%91.gif" alt="迷惑" style="zoom:67%;" /></p><h5 id="操作数列表">操作数列表</h5><p><code>asm</code>内部使用C语言字符串作为操作数，操作数都要放在双引号中且输出操作数要通过“=”修饰。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;constraint&quot;</span> (C expression) <span class="comment">//&quot;=r&quot;(result)</span></span><br></pre></td></tr></table></figure><p>constraint主要用来指定操作数的寻址类型，也用来指明使用哪个寄存器。</p><p>与其说是操作数列表，更不如说他是操作数数组，因为在汇编指令中所有的操作数都是以下标的形式给出的（感觉完全可以这么理解）</p><h5 id="约束constraints">约束（constraints）</h5><table><thead><tr class="header"><th>使用寄存器or内存</th><th>Constraint</th></tr></thead><tbody><tr class="odd"><td>eax</td><td>a</td></tr><tr class="even"><td>ebx</td><td>b</td></tr><tr class="odd"><td>ecx</td><td>c</td></tr><tr class="even"><td>edx</td><td>d</td></tr><tr class="odd"><td>任何通用寄存器</td><td>r</td></tr><tr class="even"><td>使用变量的内存位置</td><td>m</td></tr></tbody></table><h5 id="约束修饰符constraint-modifiers">约束修饰符（ConstraintModifiers）</h5><table><thead><tr class="header"><th>符号</th><th>含义</th></tr></thead><tbody><tr class="odd"><td>=</td><td>只写</td></tr><tr class="even"><td>+</td><td>可读写</td></tr><tr class="odd"><td>%</td><td>可以和下一个操作数互换</td></tr><tr class="even"><td>&amp;</td><td>在内联函数完成之前，可以删除或者重新使用被修饰的操作数</td></tr></tbody></table><p>ok，又到了扔掉脑子的阶段~</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/%E6%89%94%E6%8E%89%E8%84%91%E5%AD%90.gif"alt="扔掉脑子" /><figcaption aria-hidden="true">扔掉脑子</figcaption></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> data1 = <span class="number">1</span>;</span><br><span class="line">    <span class="type">int</span> data2 = <span class="number">2</span>;</span><br><span class="line">    <span class="type">int</span> data3;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//扩展asm格式中，寄存器前面必须写 2 个%；</span></span><br><span class="line">    <span class="keyword">asm</span>(<span class="string">&quot;movl %%ebx, %%eax\n\t&quot;</span></span><br><span class="line">        <span class="string">&quot;addl %%ecx, %%eax&quot;</span></span><br><span class="line">        : <span class="string">&quot;=a&quot;</span>(data3)</span><br><span class="line">        : <span class="string">&quot;b&quot;</span>(data1),<span class="string">&quot;c&quot;</span>(data2));</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;data3 = %d \n&quot;</span>, data3);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>老一套，再来一遍，不过这次应该会有明显的区别，大家可以猜一下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"> d:   c7 45 e4 01 00 00 00    movl   $0x1,-0x1c(%rbp)</span><br><span class="line">14:   c7 45 e8 02 00 00 00    movl   $0x2,-0x18(%rbp)</span><br><span class="line">1b:   8b 45 e4                mov    -0x1c(%rbp),%eax</span><br><span class="line">1e:   8b 55 e8                mov    -0x18(%rbp),%edx</span><br><span class="line">21:   89 c3                   mov    %eax,%ebx</span><br><span class="line">23:   89 d1                   mov    %edx,%ecx</span><br><span class="line">25:   89 d8                   mov    %ebx,%eax</span><br><span class="line">27:   01 c8                   add    %ecx,%eax</span><br><span class="line">29:   89 45 ec                mov    %eax,-0x14(%rbp)</span><br><span class="line">2c:   8b 45 ec                mov    -0x14(%rbp),%eax</span><br><span class="line">2f:   89 c6                   mov    %eax,%esi</span><br><span class="line">31:   48 8d 05 00 00 00 00    lea    0x0(%rip),%rax        # 38 &lt;main+0x38&gt;</span><br><span class="line">38:   48 89 c7                mov    %rax,%rdi</span><br><span class="line">3b:   b8 00 00 00 00          mov    $0x0,%eax</span><br><span class="line">40:   e8 00 00 00 00          call   45 &lt;main+0x45&gt;</span><br><span class="line">45:   b8 00 00 00 00          mov    $0x0,%eax</span><br><span class="line">4a:   48 8b 5d f8             mov    -0x8(%rbp),%rbx</span><br></pre></td></tr></table></figure><p>我们仔细看这几句：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1b:   8b 45 e4                mov    -0x1c(%rbp),%eax</span><br><span class="line">1e:   8b 55 e8                mov    -0x18(%rbp),%edx</span><br><span class="line">21:   89 c3                   mov    %eax,%ebx</span><br><span class="line">23:   89 d1                   mov    %edx,%ecx</span><br></pre></td></tr></table></figure><p>虽然GCC的编译状态和我的精神状态一样堪忧，但是很明显啊，这对应的过程就是把data传给我们制定的两个寄存器上，而变化估计大家也能猜到，里边有数据了，大体的原理也应该理解了。</p><p>再来玩儿一个内存的：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> data1 = <span class="number">1</span>;</span><br><span class="line">    <span class="type">int</span> data2 = <span class="number">2</span>;</span><br><span class="line">    <span class="type">int</span> data3;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">asm</span>(<span class="string">&quot;movl %1, %%eax\n\t&quot;</span></span><br><span class="line">        <span class="string">&quot;addl %2, %%eax\n\t&quot;</span></span><br><span class="line">        <span class="string">&quot;movl %%eax, %0&quot;</span></span><br><span class="line">        : <span class="string">&quot;=m&quot;</span>(data3)</span><br><span class="line">        : <span class="string">&quot;m&quot;</span>(data1),<span class="string">&quot;m&quot;</span>(data2));</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;data3 = %d \n&quot;</span>, data3);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>先来尝试分析一下：</p><ol type="1"><li>把<code>data1</code>的数据移到<code>eax</code>中</li><li>把<code>data2</code>的数据与<code>eax</code>中的数据相加并存储到<code>eax</code></li><li>把<code>eax</code>里的数据移到<code>data3</code>中</li></ol><p>再来看一看汇编代码是不是这么一回事：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">1b:   c7 45 ec 01 00 00 00    movl   $0x1,-0x14(%rbp)</span><br><span class="line">22:   c7 45 f0 02 00 00 00    movl   $0x2,-0x10(%rbp)</span><br><span class="line">29:   8b 45 ec                mov    -0x14(%rbp),%eax</span><br><span class="line">2c:   03 45 f0                add    -0x10(%rbp),%eax</span><br><span class="line">2f:   89 45 f4                mov    %eax,-0xc(%rbp)</span><br><span class="line">32:   8b 45 f4                mov    -0xc(%rbp),%eax</span><br><span class="line">35:   89 c6                   mov    %eax,%esi</span><br><span class="line">37:   48 8d 05 00 00 00 00    lea    0x0(%rip),%rax        # 3e &lt;main+0x3e&gt;</span><br><span class="line">3e:   48 89 c7                mov    %rax,%rdi</span><br><span class="line">41:   b8 00 00 00 00          mov    $0x0,%eax</span><br><span class="line">46:   e8 00 00 00 00          call   4b &lt;main+0x4b&gt;</span><br><span class="line">4b:   b8 00 00 00 00          mov    $0x0,%eax</span><br><span class="line">50:   48 8b 55 f8             mov    -0x8(%rbp),%rdx</span><br><span class="line">54:   64 48 2b 14 25 28 00    sub    %fs:0x28,%rdx</span><br><span class="line">5b:   00 00 </span><br><span class="line">5d:   74 05                   je     64 &lt;main+0x64&gt;</span><br><span class="line">5f:   e8 00 00 00 00          call   64 &lt;main+0x64&gt;</span><br></pre></td></tr></table></figure>还真是，ok，道爷我悟了（癫）<center class="half"><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/v2-57b2d8a8e5bf42b63e4450ea10261fe1_720w.webp" alt="img" style="zoom: 67%;" /><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/v2-e38e7f9332a9987f810ca98ddf2abf34_720w.webp" alt="img" style="zoom: 33%;" /></center><h4 id="volatile">volatile</h4><p>还是那个很典的<code>volatie</code>，一句话：用了volatile保证了顺序性，不给GCC优化</p><h3 id="总结">总结</h3><p>在一个毫无汇编经验的人从0看完，应该对汇编有了大致的了解，而且对于内联汇编这个可以直接玩儿寄存器的玩意也有了一个大概的认识，那就够了，剩下的咱慢慢补（</p><h3 id="参考链接">参考链接</h3><p><a href="https://zhuanlan.zhihu.com/p/469950256">快速入门汇编语言 -知乎 (zhihu.com)</a></p><p><a href="https://www.jianshu.com/p/1782e14a0766">GCC内联汇编基础 -简书 (jianshu.com)</a></p><p><a href="https://zhuanlan.zhihu.com/p/618634622">内联汇编 - 知乎(zhihu.com)</a></p><p><ahref="https://zhuanlan.zhihu.com/p/674807570">内联汇编很可怕吗？看完这篇文章，终结它！- 知乎 (zhihu.com)</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 搓OS.log </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>搓OS-day7</title>
      <link href="/2024/01/31/%E6%90%93OS-day7/"/>
      <url>/2024/01/31/%E6%90%93OS-day7/</url>
      
        <content type="html"><![CDATA[<h2 id="手搓os-day7">手搓OS-day7</h2><h3 id="现代处理器互斥实现">现代处理器互斥实现</h3><p>互斥（mutual exclusion）就不必多说了，简单点说就是不能同时访问。</p><p>实现互斥的基本假设：</p><ul><li>不能同时读写内存</li><li>指令为不可打断的原子指令</li><li>函数通过内存屏障顺序不可优化</li></ul><h4 id="自旋锁spinlock">自旋锁（Spinlock）</h4><p>自旋可以认为是一种循环等待的状态，即为忙等，维基百科是这么说的：</p><p><code>In software engineering, a spinlock is a lock that causes a thread trying to acquire it to simply wait in a loop ("spin") while repeatedly checking whether the lock is available.</code></p><p>我们在之前学习操作系统的时候，貌似记得忙等并不是一种很好的策略，忙等会让CPU无效工作，导致CPU利用率降低。</p><p>然而，我们之前学习时并没有提到其优点，因为一直是忙等（即运行态）所以线程不会进入阻塞态，也就没有了切换的上下文开销。</p><p>OK，现在基本的概念问题解决了，下面就要开始深入实现了，结合之前的互斥实现的基本假设，开始阅读代码：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;thread.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> N 100000000</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> M 10</span></span><br><span class="line"></span><br><span class="line"><span class="type">long</span> sum = <span class="number">0</span>;</span><br><span class="line"><span class="comment">// 总之函数实现了一个原子的交换函数</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">xchg</span><span class="params">(<span class="type">int</span> <span class="keyword">volatile</span> *ptr, <span class="type">int</span> newval)</span> &#123;</span><br><span class="line">  <span class="type">int</span> result;</span><br><span class="line">  <span class="comment">// 内联汇编</span></span><br><span class="line">  <span class="keyword">asm</span> <span class="title function_">volatile</span><span class="params">(</span></span><br><span class="line"><span class="params">    <span class="string">&quot;lock xchgl %0, %1&quot;</span>  <span class="comment">// lock前缀确保原子性</span></span></span><br><span class="line"><span class="params">    : <span class="string">&quot;+m&quot;</span>(*ptr),        <span class="comment">// 输出操作数，ptr处的内存又是输入又是输出</span></span></span><br><span class="line"><span class="params">    <span class="string">&quot;=a&quot;</span>(result)         <span class="comment">// 输出操作数：result接收内存位置上的前值</span></span></span><br><span class="line"><span class="params">    : <span class="string">&quot;1&quot;</span>(newval)        <span class="comment">// 输入操作数：newval是要交换的目标值</span></span></span><br><span class="line"><span class="params">    : <span class="string">&quot;memory&quot;</span>           <span class="comment">// 制约操作数：表示内联汇编代码会修改内存</span></span></span><br><span class="line"><span class="params">  )</span>;</span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> locked = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">lock</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="keyword">while</span> (xchg(&amp;locked, <span class="number">1</span>)) ;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">unlock</span><span class="params">()</span> &#123;</span><br><span class="line">  xchg(&amp;locked, <span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>貌似这个实现也没啥（雾），当然这个东西还可以更加深入，比如如何分配等待序列，让其更公平。参考下面的拓展阅读。</p><h4 id="无锁算法">无锁算法</h4><p>无锁编程，即不使用锁的情</p><p>况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步。</p><p>Compare and exchange【CAS】(" test and set ")</p><p><code>(lock) cmpxchg SRC, DEST</code></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">TEMP = DEST</span><br><span class="line"><span class="keyword">if</span> accumulator == TEMP:</span><br><span class="line">    ZF = <span class="number">1</span></span><br><span class="line">    DEST = SRC</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    ZF = <span class="number">0</span></span><br><span class="line">    accumulator = TEMP</span><br></pre></td></tr></table></figure><p>上面是一个CAS的指令已经实现的一种伪代码（类似），比起自旋锁，CAS多了一个比较过程。</p><h4 id="使用场景">使用场景</h4><p>自旋锁：临界区能够很快速的使用结束，操作系统内核的并发数据结构(短临界区)。</p><p>互斥锁：通过系统调用获取，实现线程+长临界区互斥。</p><h3 id="参考链接">参考链接</h3><p>【今日学习】<ahref="https://jyywiki.cn/OS/2023/build/lect7.ipynb.html">7.并发控制：互斥 (jyywiki.cn)</a></p><p><ahref="https://cloud.tencent.com/developer/article/1169074">面试必备之深入理解自旋锁-腾讯云开发者社区-腾讯云(tencent.com)</a></p><p><a href="https://en.wikipedia.org/wiki/Spinlock">Spinlock -Wikipedia</a></p><p><a href="https://www.cnblogs.com/zyf-yxm/p/12049292.html">CAS无锁算法- 宇枫 - 博客园 (cnblogs.com)</a></p><h3 id="拓展阅读">拓展阅读</h3><p><ahref="https://zhuanlan.zhihu.com/p/551234849">万字长文丨深入理解Linux自旋锁- 知乎 (zhihu.com)</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 搓OS.log </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>不得不知道的实用数据结构算法（二）</title>
      <link href="/2024/01/18/%E4%B8%8D%E5%BE%97%E4%B8%8D%E7%9F%A5%E9%81%93%E7%9A%84%E5%AE%9E%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AE%97%E6%B3%95%EF%BC%88%E4%BA%8C%EF%BC%89/"/>
      <url>/2024/01/18/%E4%B8%8D%E5%BE%97%E4%B8%8D%E7%9F%A5%E9%81%93%E7%9A%84%E5%AE%9E%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AE%97%E6%B3%95%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h2id="不得不知道的实用数据结构算法二">不得不知道的实用数据结构算法（二）</h2><p>依旧是简单总结，主要还是一个思路上的应对问题，不去探讨实现细节，有机会单独讨论实现细节（毕竟我忘得差不多了）。</p><h3 id="链表">链表</h3><p>首先先回忆链表的定义，以及其基本操作：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">Node</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    <span class="type">int</span> data;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">Node</span>* <span class="title">next</span>;</span></span><br><span class="line">&#125;Node;</span><br></pre></td></tr></table></figure><p>我们经常会去比较顺序表与链表的优劣，令我们印象最深刻的往往是插入算法的比较，下面列个表格比较一下基本操作的时间复杂度：</p><table><thead><tr class="header"><th></th><th>顺序表</th><th>链表</th></tr></thead><tbody><tr class="odd"><td>随机存取</td><td>O(1)</td><td>不能实现</td></tr><tr class="even"><td>插入</td><td>O(n)</td><td>O(1)</td></tr><tr class="odd"><td>删除</td><td>O(n)</td><td>O(1)</td></tr><tr class="even"><td>遍历</td><td>O(n)</td><td>O(n)</td></tr></tbody></table><p>相对顺序表而言，链表的操作貌似更快，但是也更有挑战性，因为没有了随机存取的特性，导致链表在获取元素时是很麻烦的，但是，往往这种拧巴的东西就很喜欢出题。</p><h3 id="技巧一双多指针">技巧一：双（多）指针</h3><p>这个方法与其说叫做一种技巧，不如说是一种实现的思路。我们考虑单向带头结点的有序链表，下面开始分类说明：</p><p><code>储存</code>：当我们需要在某个元素前插入一个新的节点，那么我在找到该节点时还需要这个节点的前一个节点，这时候我们就需要一个双指针。不要小看这个思路，储存好数据能做很多事情（但是我不太会举例子）</p><p><code>不同链表</code>：比如合并两个有序链表，我们也需要使用多个指针</p><p><code>二分查找、快速排序</code>：这是从排序和查找中拿来的思路，一般都是比较容易看出的，但是用在链表上并不都快，二分查找只有在随机存取下才快；快排的分治的思路是在链表上很常应用的</p><p><code>对撞指针</code>：就是首尾指针，双向遍历，但是要注意这里要求就必须是双向链表了</p><h3 id="技巧二快慢指针">技巧二：快慢指针</h3><p>这个就比较链表了，解决的问题主要有：</p><p><code>有公共节点的链表</code>：</p><p><code>有环的链表</code>：</p><p><code>分块位置关系的链表</code></p><h3 id="技巧三就地逆置">技巧三：就地逆置</h3><p>这个实际上就是头插法的灵活使用，其解决的问题与前面提过的顺序表是一致的。</p><h3 id="参考链接">参考链接</h3><p><ahref="https://blog.csdn.net/qq_54773252/article/details/122836179">双指针算法-CSDN博客</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> C语言 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>搓OS-day6</title>
      <link href="/2024/01/18/%E6%90%93OS-day6/"/>
      <url>/2024/01/18/%E6%90%93OS-day6/</url>
      
        <content type="html"><![CDATA[<h2 id="手搓os-day6">手搓OS-day6</h2><h3 id="并行实验">并行实验</h3><h4 id="最长公共子序列lcs问题">最长公共子序列（LCS）问题</h4><p>区分子序列与子串：子序列是可以剔除部分中间不相等的部分，而子串必须是连续的。</p><p>这个问题是不能采用暴力遍历的，因为时间复杂度高的可怕，要采用动态规划的方法，而动态规划的最重要的就是找到状态转移函数</p><h5 id="性质以及状态转移函数">性质以及状态转移函数</h5><p>现有两个序列<code>X[]</code>和<code>Y[]</code>，长度分别为<code>m</code>和<code>n</code>，<code>lcs()</code>函数为求最长公共子序列长度的函数。</p><p><strong>性质1：</strong>如果串的最后一个元素相同，例如：<code>if (X[m-1]==Y[n-1])</code>，那么其最长子序列长度，则在剩余的<code>m-1</code>与<code>n-1</code>个元素的最长子序列加一，公式表现为：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>(X[m<span class="number">-1</span>]==Y[n<span class="number">-1</span>])  lcs(X,Y,m,n)=lcs(X,Y,m<span class="number">-1</span>,n<span class="number">-1</span>)+<span class="number">1</span>;</span><br></pre></td></tr></table></figure><p><strong>性质2</strong>：如果串的最后一个元素不相同，例如，<code>if(X[m-1]!=Y[n-1])</code>，则取下面两种情况的最大值：</p><ol type="1"><li>删除<code>X</code>的最后一个元素，然后求<code>X</code>和<code>Y</code>的子序列长度</li><li>删除<code>Y</code>的最后一个元素，然后求<code>X</code>和<code>Y</code></li></ol><p>从公式上表达为：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>(X[m<span class="number">-1</span>]!=Y[n<span class="number">-1</span>])</span><br><span class="line">lcs(X,Y,m,n)=max(lcs(X,Y,m<span class="number">-1</span>,n),lcs(X,Y,m,n<span class="number">-1</span>));</span><br></pre></td></tr></table></figure><p>递归方法能发现其计算了一些重复值，于是考虑通过动态规划的方式来存储已经计算过的结果，下面是其表中作业的形式：</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240201101422361.png"alt="图源自参考链接1" /><figcaption aria-hidden="true">图源自参考链接1</figcaption></figure><h5 id="输出lcs序列">输出LCS序列</h5><p>实际上，上面表的生成是可以看做一个有向无环图，每一个数的生成都依赖一个或两个数，于是我们从表的右下角起步，对其进行某种拓扑排序，就能得到一个LCS序列</p><h4 id="并行思路">并行思路</h4><p>老师的网站上的图不是非常清晰，但是第一个网站里的一张图并结合上面的依赖，会非常清晰：</p><figure><imgsrc="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20240201103544330.png"alt="侵删" /><figcaption aria-hidden="true">侵删</figcaption></figure><p>如果建立在动态规划上，每一条计算的分支都是可以并行的，那么我们就可以开始尝试了，下面还有一个升级版的并行方案，在最后一个链接，菜，实现了一个非常简单的并行（甚至可能不如单独算快），核心要点是要保护对角上的元素的访问，这个对角比较广义，核心的一条代码就是这样子的：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">spin_lock(&amp;result_lock);</span><br><span class="line">result = MAX(result, dp[N - <span class="number">1</span>][M - <span class="number">1</span>]);</span><br><span class="line">spin_unlock(&amp;result_lock);</span><br></pre></td></tr></table></figure><h3 id="总结">总结</h3><p>给我小小的编程经历带来了大大的并行震撼，还得补一下高性能计算（哎，又是坑）</p><h3 id="参考链接">参考链接</h3><p><ahref="https://www.enjoyalgorithms.com/blog/longest-common-subsequence">LongestCommon Subsequence (enjoyalgorithms.com)（这个性质解释的清楚）</a></p><p><ahref="https://blog.csdn.net/c2434525400/article/details/123573955">最长公共子序列(LCS)过程图解_最长子序列-CSDN博客（这个过程解释的清楚）</a></p><p><a href="https://jyywiki.cn/OS/2023/labs/M2.html">M2: 并行 LongestCommon Subsequence (plcs) (jyywiki.cn)</a></p><p><ahref="https://www.iaeng.org/publication/WCE2010/WCE2010_pp499-504.pdf">WCE2010_pp499-504.pdf(iaeng.org)</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 搓OS.log </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>搓OS-day5</title>
      <link href="/2024/01/14/%E6%90%93OS-day5/"/>
      <url>/2024/01/14/%E6%90%93OS-day5/</url>
      
        <content type="html"><![CDATA[<h2 id="手搓os-day5">手搓OS-day5</h2><p>咕咕，做一个老鸽子真的是太舒服了（雾）。这里我先提出一个操作系统公共厕所说（）。众所周知，厕所是一种紧俏资源（CPU计算资源），只能独占，这里我们做一个抽（恶）象（心）的假设，人们是可以容忍临时换人的（状态机），有了这个现（逆）实（天）模型，后面就容易理解了。</p><h3 id="复习">复习</h3><h4 id="并发">并发</h4><p>并发，指的是一个时间段内两个进程同时运行（往往是交替的），而不是完全的同时，以人类视角来看并发是相当恶心的，带入一下上边的模型就能体会到。</p><p>而与并发常混淆的是<code>并行</code>，并行是我们可以理解的，也就是两个不同的进程（不只是进程）在同时刻处于运行态，但是放在上面的模型中，如果只有一个坑位，显然并行也是不行的，这也就是一般操作系统课程中常常考虑的单处理机。</p><p>这里画一个图就懂了：</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240114221544023.png"alt="并发与并行" /><figcaption aria-hidden="true">并发与并行</figcaption></figure><p>可能有些基础薄弱的同学要问了，处理机和CPU有什么区别吗？</p><p>这个还是有一点区别的，处理机，顾名思义，是个处理什么玩意的机器，所以他是处理什么的呢，处理的是数据和程序，实际上，处理机是一个除去外设的一个计算机，而处理器就是CPU，处理机包含处理器：</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240114222149946.png"alt="image-20240114222149946" /><figcaption aria-hidden="true">image-20240114222149946</figcaption></figure><p>这个说法在课本上多次提到，我个人认为是很大程度上为我们理解增加了障碍，在操作系统中我们其实就可以狭隘的理解成分配了计算资源（CPU）就好。</p><h4 id="并发带来的问题">并发带来的问题</h4><p>在上一篇的实验中其实已经能够看出来，由于并发的程序相当随机，所以会出现输出并不符合预期的情况，一般有两种情况：运行顺序不好，访问共同资源，分别对应两种问题：同步与互斥。</p><p>今天先来解决互斥问题。</p><h3 id="peterson算法">Peterson算法</h3><h4 id="理论">理论</h4><p>这个算法相当奇怪，但是是一个礼貌的算法，我们回到上面的厕所模型。厕所里关了（<del>被阿姨锁门且关灯</del>）甲乙两人，甲乙两人都可能想进入厕所（想进厕所是随机的），那怎么才能保证厕所仅仅被一人使用呢？</p><p><code>甲：我想去厕所，但是我得看看乙在不在里边</code></p><p>于是，甲大声且自信的说出，我要去厕所啦，你在用吗，然后乙回复：我正在用，并且听到乙在一直说：我要上厕所，于是甲决定等一会儿，只听见乙还在叫嚷（</p><p>没错这个算法就是这么诡异的状况，但是很礼貌，现在我们把这个过程对应到变量上：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = <span class="number">1</span>; # 甲表示我要上厕所</span><br><span class="line">turn = B; # 我先问问乙在不在</span><br><span class="line"><span class="keyword">while</span>(y &amp;&amp; turn==B); # 那甲先等会儿</span><br><span class="line"># 否则</span><br><span class="line">x = <span class="number">0</span>; # 甲愉快的进入厕所，并结束</span><br></pre></td></tr></table></figure><p>这就是Peterson算法的基本流程，如果将其写的更加全面一点：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">TA</span><span class="params">()</span> &#123; <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line"><span class="comment">/* ❶ */</span>  x = <span class="number">1</span>;</span><br><span class="line"><span class="comment">/* ❷ */</span>  turn = B;</span><br><span class="line"><span class="comment">/* ❸ */</span>  <span class="keyword">while</span> (y &amp;&amp; turn == B) ;</span><br><span class="line"><span class="comment">/* ❹ */</span>  x = <span class="number">0</span>; &#125; &#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">TB</span><span class="params">()</span> &#123; <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line"><span class="comment">/* ① */</span>  y = <span class="number">1</span>;</span><br><span class="line"><span class="comment">/* ② */</span>  turn = A;</span><br><span class="line"><span class="comment">/* ③ */</span>  <span class="keyword">while</span> (x &amp;&amp; turn == A) ;</span><br><span class="line"><span class="comment">/* ④ */</span>  y = <span class="number">0</span>; &#125; &#125;</span><br></pre></td></tr></table></figure><h4 id="volatile和编译器屏障顺序性">volatile和编译器屏障（顺序性）</h4><h5 id="编译器指令重排">编译器指令重排</h5><p>根据上一篇的认识，我们已经知道在现代计算机上，程序的执行并不具有原子性，机器语言的顺序与我们写出的高级语言的顺序也会不一致。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> a,b;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">foo</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    a=b+<span class="number">1</span>;</span><br><span class="line">    b=<span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过我们之前的编译操作和反编译操作：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">gcc -c -o compile1.o  compile_demo.c</span> </span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">0000000000000000 &lt;foo&gt;:</span><br><span class="line">   0:   f3 0f 1e fa             endbr64 </span><br><span class="line">   4:   55                      push   %rbp</span><br><span class="line">   5:   48 89 e5                mov    %rsp,%rbp</span><br><span class="line">   8:   8b 05 00 00 00 00       mov    0x0(%rip),%eax        # e &lt;foo+0xe&gt;</span><br><span class="line">   e:   83 c0 01                add    $0x1,%eax</span><br><span class="line">  11:   89 05 00 00 00 00       mov    %eax,0x0(%rip)        # 17 &lt;foo+0x17&gt;</span><br><span class="line">  17:   c7 05 00 00 00 00 00    movl   $0x0,0x0(%rip)        # 21 &lt;foo+0x21&gt; b=0</span><br><span class="line">  1e:   00 00 00 </span><br><span class="line">  21:   90                      nop</span><br><span class="line">  22:   5d                      pop    %rbp</span><br><span class="line">  23:   c3                      ret    </span><br></pre></td></tr></table></figure><p>如果我们采用O2级别的编译优化：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">gcc -c -O2  -o compile2.o compile_demo.c</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">0000000000000000 &lt;foo&gt;:</span><br><span class="line">   0:   f3 0f 1e fa             endbr64 </span><br><span class="line">   4:   8b 05 00 00 00 00       mov    0x0(%rip),%eax        # a &lt;foo+0xa&gt;</span><br><span class="line">   a:   c7 05 00 00 00 00 00    movl   $0x0,0x0(%rip)        # 14 &lt;foo+0x14&gt; b=0</span><br><span class="line">  11:   00 00 00 </span><br><span class="line">  14:   83 c0 01                add    $0x1,%eax</span><br><span class="line">  17:   89 05 00 00 00 00       mov    %eax,0x0(%rip)        # 1d &lt;foo+0x1d&gt;</span><br><span class="line">  1d:   c3                      ret    </span><br></pre></td></tr></table></figure><p>可以摁着头皮尝试阅读一下，其实也不难看懂（我写了一句注释<code>b=0</code>），可以看出，<code>b=0与a=b+1</code>两句话在不同的编译优化上，表现出的位置实际上是不同的，这是因为在单线程下，a与b的赋值顺序在编译器看来其实无关痛痒，但在多线程并发下很可能会出问题，就比如上面的Peterson算法，如果编译器调换了循环等待与其他语句的顺序，那么Peterson算法将不再成立。</p><p>对于这个问题也存在对应的解决方案：</p><h5 id="显式编译屏障">显式编译屏障</h5><p>编译器提供了编译器屏障（compiler barriers），用来告知不可重排</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> barrier() asm volatile(<span class="string">&quot;&quot;</span>:::<span class="string">&quot;memory&quot;</span>)</span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> a,b;</span><br><span class="line"><span class="type">void</span>()</span><br><span class="line">&#123;</span><br><span class="line">    a=b+<span class="number">1</span>;</span><br><span class="line">    barrier()</span><br><span class="line">    b=<span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>显然这个宏定义也超出我的知识范围了，问问chatgpt吧：</p><p><code>具体而言，这个宏的定义中包含了一个内联汇编语句,这个汇编语句的作用是告诉编译器在这里插入一个内存屏障，确保前面的内存操作（读或写）和后面的内存操作在执行时的顺序不能被重排。 memory是一个内存屏障的类型，表示在这个位置之前和之后的所有内存访问不能被重排。</code></p><p>再次编译，反编译：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">0000000000000000 &lt;foo&gt;:</span><br><span class="line">   0:   f3 0f 1e fa             endbr64 </span><br><span class="line">   4:   8b 05 00 00 00 00       mov    0x0(%rip),%eax        # a &lt;foo+0xa&gt;</span><br><span class="line">   a:   83 c0 01                add    $0x1,%eax</span><br><span class="line">   d:   89 05 00 00 00 00       mov    %eax,0x0(%rip)        # 13 &lt;foo+0x13&gt;</span><br><span class="line">  13:   c7 05 00 00 00 00 00    movl   $0x0,0x0(%rip)        # 1d &lt;foo+0x1d&gt;  b=0</span><br><span class="line">  1a:   00 00 00 </span><br><span class="line">  1d:   c3                      ret    </span><br></pre></td></tr></table></figure><h5 id="隐式编译屏障">隐式编译屏障</h5><p>当某个函数包含屏障时，调用该函数也有屏障的作用</p><h4 id="实现">实现</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;thread.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> A 1</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> B 2</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> BARRIER __sync_synchronize() <span class="comment">// GCC 内建的同步内存屏障函数</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">atomic_int</span> nested; <span class="comment">// atomic_int 是 C 标准中 &lt;stdatomic.h&gt; 头文件中定义的原子类型</span></span><br><span class="line"><span class="type">atomic_long</span> count;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">critical_section</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">long</span> cnt = atomic_fetch_add(&amp;count, <span class="number">1</span>); <span class="comment">// 原子加法</span></span><br><span class="line">    <span class="type">int</span> i = atomic_fetch_add(&amp;nested, <span class="number">1</span>) + <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">if</span> (i != <span class="number">1</span>) <span class="comment">// 进入临界区的线程不能多于两个</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d thread in the critical section @ count=%ld\n&quot;</span>, i, cnt);</span><br><span class="line">        assert(<span class="number">0</span>); <span class="comment">// 断言，上一次学过了，因此只要这个程序不停止，证明就正常跑起来了</span></span><br><span class="line">    &#125;</span><br><span class="line">    atomic_fetch_add(&amp;nested, <span class="number">-1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="keyword">volatile</span> x = <span class="number">0</span>, y = <span class="number">0</span>, turn; </span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">chatGPT:</span></span><br><span class="line"><span class="comment">volatile 是一个关键字，用于告诉编译器不要对这些变量进行优化，以确保每次访问都从内存中读取或写入变量的值，而不使用缓存。</span></span><br><span class="line"><span class="comment">在多线程编程中，volatile 通常用于标记多个线程之间共享的变量，以确保对这些变量的访问是可见的。</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">TA</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        x=<span class="number">1</span>;</span><br><span class="line">        BARRIER;</span><br><span class="line">        turn=B;</span><br><span class="line">        BARRIER;</span><br><span class="line">        <span class="keyword">while</span> (<span class="number">1</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (!y) <span class="keyword">break</span>;</span><br><span class="line">            BARRIER;</span><br><span class="line">            <span class="keyword">if</span> (turn!=B) <span class="keyword">break</span>;</span><br><span class="line">            BARRIER;</span><br><span class="line">        &#125;</span><br><span class="line">        critical_section();</span><br><span class="line">        x=<span class="number">0</span>;</span><br><span class="line">        BARRIER;</span><br><span class="line">    &#125;    </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">TB</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        y=<span class="number">1</span>;</span><br><span class="line">        BARRIER;</span><br><span class="line">        turn=A;</span><br><span class="line">        BARRIER;</span><br><span class="line">        <span class="keyword">while</span> (<span class="number">1</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (!x) <span class="keyword">break</span>;</span><br><span class="line">            BARRIER;</span><br><span class="line">            <span class="keyword">if</span> (turn!=A) <span class="keyword">break</span>;</span><br><span class="line">            BARRIER;</span><br><span class="line">        &#125;</span><br><span class="line">        critical_section();</span><br><span class="line">        y=<span class="number">0</span>;</span><br><span class="line">        BARRIER;</span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    create(TA);</span><br><span class="line">    create(TB);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="实现多线程求和原子性">实现多线程求和（原子性）</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;thread.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> N 100000000</span></span><br><span class="line"></span><br><span class="line"><span class="type">long</span> sum =<span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">atomic_inc</span><span class="params">(<span class="type">long</span> *ptr)</span>&#123;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">    内联汇编，俺不会，功能是原子自增</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="keyword">asm</span> <span class="title function_">volatile</span><span class="params">(</span></span><br><span class="line"><span class="params">        <span class="string">&quot;lock incq %0&quot;</span>  <span class="comment">// Atomic + memory fence</span></span></span><br><span class="line"><span class="params">        :<span class="string">&quot;+m&quot;</span>(*ptr)</span></span><br><span class="line"><span class="params">        :</span></span><br><span class="line"><span class="params">        :<span class="string">&quot;memory&quot;</span> <span class="comment">// 内存屏障</span></span></span><br><span class="line"><span class="params">    )</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">Tsum</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">atomic_inc</span>(&amp;sum);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    create(Tsum);</span><br><span class="line">    create(Tsum);</span><br><span class="line">    join();  <span class="comment">// 结束进程</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;sum=%ld\n&quot;</span>,sum);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="总结">总结</h3><p>并发提供了新的功能，但确确实实带来了极大的实现挑战，注意理解顺序性，原子性在实现中的必要性，要明白我们写的高级代码，在运行时会出很多幺蛾子,从而更好地理解并发的进程同步。</p><h3 id="参考链接">参考链接</h3><p><ahref="https://blog.csdn.net/wll1228/article/details/121875525">volatile和编译器屏障_asmvolatile("yield" ::: "memory");-CSDN博客</a></p><p><a href="https://jyywiki.cn/OS/2023/build/lect6.ipynb.html">6.并发控制基础 (jyywiki.cn)</a></p><p><ahref="https://pages.cs.wisc.edu/~remzi/OSTEP/threads-api.pdf">single.dvi(wisc.edu)课本阅读材料</a></p><p><a href="https://godbolt.org/">Compiler Explorer (godbolt.org)很好玩的编译网站</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 搓OS.log </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>不得不知道的实用数据结构算法（一）</title>
      <link href="/2024/01/13/%E4%B8%8D%E5%BE%97%E4%B8%8D%E7%9F%A5%E9%81%93%E7%9A%84%E5%AE%9E%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AE%97%E6%B3%95%EF%BC%88%E4%B8%80%EF%BC%89/"/>
      <url>/2024/01/13/%E4%B8%8D%E5%BE%97%E4%B8%8D%E7%9F%A5%E9%81%93%E7%9A%84%E5%AE%9E%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AE%97%E6%B3%95%EF%BC%88%E4%B8%80%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h2id="不得不知道的实用数据结构算法一">不得不知道的实用数据结构算法（一）</h2><p>新坑说开就开，就是这么随（不）心（知）所（死）欲（活），这个系列实际上是针对数据结构中的一些低时间复杂度的常用模板or思考方式的总结，ok，今天先进行的是线性表。</p><h3 id="线性表">线性表</h3><p>定义：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># <span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="keyword">typedef</span> ElemType <span class="type">int</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">typedef</span> <span class="title">SeqList</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    ElemType  *data;  <span class="comment">// 按道理这里应该有很多实现方法，比如直接上一个数组，通过宏定义最大数组长度</span></span><br><span class="line">    <span class="type">int</span> size;</span><br><span class="line">    <span class="type">int</span> capacity;</span><br><span class="line">&#125;SeqList;</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># <span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta"># <span class="keyword">define</span> MAXSIZE 100</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> ElemType <span class="type">int</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">typedef</span> <span class="title">SeqList</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    ElemType  data[MAXSIZE];</span><br><span class="line">    <span class="type">int</span> length;</span><br><span class="line">&#125;SeqList;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">init</span><span class="params">(SeqList *l)</span></span><br><span class="line">&#123;</span><br><span class="line">    l-&gt;length=<span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>秉承着不给自己找麻烦，后边就不用动态分配空间的代码了，虽然在我初学的时候觉得动态分配真的很优雅（起码不怕爆了）</p><p>OK，然后迅速的过一下基本操作以及其操作的流程以及弊端（懒得写了）：</p><p><code>删除</code>：删除一个元素，要将后边的元素都移过来，实际上也就是说复杂度是O(n)</p><p><code>遍历</code>：这不必多说，自然O(n)</p><p><code>随机存取</code>：这是顺序表的强项</p><p><code>插入</code>：和删除其实一致，但是要求后移后面的元素</p><p>然而很多算法题会颠覆你对基本操作的认识，也就是会让你优化一种插入操作or删除操作，使一个本来暴力解时间复杂度为O(n<sup>2</sup>)的算法优化为时间复杂度为O(n)的算法</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/e61190ef76c6a7ef54f88818eeaa655af2de6689.jpeg@f_auto"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>我们先举个例子：</p><p><code>现在有一个顺序表，其中有元素n个，现在我希望删除其中的所有偶数元素</code></p><p>我们从直觉上很容易写出这样一个代码：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">dele_even</span><span class="params">(SeqList *l)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> (l==<span class="literal">NULL</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;顺序表未初始化&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> ;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; l-&gt;length; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (l-&gt;data[i]%<span class="number">2</span>==<span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            delete(l,i); #时间复杂度是O(n)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>简单瞅一眼，很明显可以看出这是个O(n<sup>2</sup>)的时间复杂度的算法，但是有没有一种可能，这个算法可以被优化到O(n)，这就是技巧一：有效的循环合并</p><h3 id="技巧一有效的循环合并">技巧一：有效的循环合并</h3><p>我们可以分析一下刚才删除的过程，其实有一些动作是多余的，我们其实没有必要去移动一个可能会被删除的元素：当我们找到一个偶数时，实际上后边的元素中依旧可能存在偶数，那么我们将这些偶数移动到前面就是一个多余的动作，因为以后依旧要被删除，其后边的元素仍旧面临的再一次循环的境地，因此我们是不是可以通过某种手段避免无效的遍历移动呢？</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">dele_even_good</span><span class="params">(SeqList *l)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> (l==<span class="literal">NULL</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;顺序表未初始化&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> ;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> m=<span class="number">0</span>; <span class="comment">//用于存储找到了多少偶数</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; l-&gt;length; i++)</span><br><span class="line">    &#123;</span><br><span class="line">         <span class="keyword">if</span> (m!=<span class="number">0</span> &amp;&amp; i-m&gt;<span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            l-&gt;data[i-m]=l-&gt;data[i];</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (l-&gt;data[i]%<span class="number">2</span>==<span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            m++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    l-&gt;length=l-&gt;length-m;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里采用了一边删除一边寻找的方式，将两个循环合并到了一起，从而有效的降低了时间复杂度。这种思想很适合于使用在处理一些你想无脑调API的时候的优化。</p><h3id="技巧二为什么不试试多次就地逆置呢">技巧二：为什么不试试多次就地逆置呢</h3><p>众所周知，就地逆置是处理一些奇奇怪怪需要一大堆循环的题目的利器，比如互换两块顺序表的位置：</p><p>有一个数组A[m+n]，要求将这前m个元素和后n个元素前后互换那么就地逆置就很有用了，我们只需要整体一次，再局部两次：</p><p><code>（1,2,3,……,m,m+1,……,m+n）</code></p><p>第一次就地逆置：<code>（m+n,……,m+1,m,……,3,2,1）</code></p><p>第二次局部逆置：<code>（m+1,……,m+n,m,……,3,2,1）</code></p><p>第三次局部逆置：<code>（m+1,……,m+n,1,2,3,……,m）</code></p><p>漂亮！</p><h3id="技巧三空间换时间随机存取之光">技巧三：空间换时间，随机存取之光</h3><p>随机存取就是一个很爽的性质，这意味着只要我们找到了元素的index就可以迅速的锁定元素，比如现在需要给一个顺序剔除重复元素，那么我怎么知道元素重复了呢？我们可以再来一个顺序表通过哈希的方式得到，举个例子：</p><p>假如我们扫描到了一个元素3，那么我们就将hash[3]=1（即新创建的顺序表）的位置，以此类推，那么当我们每扫描到一个元素的时候，只需要其比较hash[data]是否值为1，如果为1那么就重复了，再去执行我们前面做好的删除算法即可。</p><h3 id="总结">总结</h3><p>还有一些顺序表的算法题目，就比较没规律了，需要通过画图，手动运算一下，来找一下其中的规律，嗯，这些应付普通考试已经够了，剩下等我刷刷Leecode再行总结。</p>]]></content>
      
      
      
        <tags>
            
            <tag> C语言 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>搓OS-day4</title>
      <link href="/2024/01/12/%E6%90%93OS-day4/"/>
      <url>/2024/01/12/%E6%90%93OS-day4/</url>
      
        <content type="html"><![CDATA[<h2 id="手搓os-day4">手搓OS-day4</h2><p>今天才是真真的操作系统的部分，并发控制，今天要学习的是多线程编程库（没怎么看，少更）。</p><h3 id="复习进程与线程">复习：进程与线程</h3><p><code>进程</code>：运行的一个程序以及其已经在计算机中的所拥有的资源的和（理解型说法，并不准确），进程是<code>资源分配</code>的基本单位。PCB用于标志进程的存在。此外关于进程还存在<code>进程间通信问题</code>,<code>进程特性</code>，<code>进程切换</code>等问题。</p><p>就我个人理解为何要引入进程概念，是为了管理资源分配的问题，不只是空间资源还有计算资源，因为计算机的资源是紧俏的（当然也有机制限制），并不能满足所有的所有的程序<code>同时</code>运行（当然这里限制在单核处理器）。但是由于应用有要求，需要发展出能在人难以感知的情况下”同时“运行（并发），而进程恰好通过把资源与程序进行耦合（不知道用词好不好，类似一个搭积木的感觉）既保护了程序状态，又实现了程序运行的切换。</p><p>当人们线程用出来了甜头，想要进一步榨干计算机资源（bushi），然后就有了线程，线程就是榨干计算资源的（），但是线程并不是资源分配的单位。</p><h3 id="多线程编程">多线程编程</h3><p>貌似并不难</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;thread.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">Thello</span><span class="params">(<span class="type">int</span> id)</span> &#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%c&quot;</span>, <span class="string">&quot;_ABCDEFGHIJKLMNOPQRSTUVWXYZ&quot;</span>[id]);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">    create(Thello);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>很好玩，使命令行爆炸。</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240112211838011.png"alt="image-20240112211838011" /><figcaption aria-hidden="true">image-20240112211838011</figcaption></figure><p>这下很有并发的魅力（不是），但是联系底层让人后背发凉，细一想貌似也没什么大不了的</p><p><code>“处理器一次执行一条指令” 的基本假设在今天的计算机系统上不再成立</code>，虽然但是这是不难理解的，两条程序由于并发or并行很可能会出现共享区的变量出现问题</p><p>后面的故事，还是读参考链接吧，如果有操作系统基础的同学一定明白，进程同步互斥的问题都是从这里衍生出来的。</p><h3 id="参考链接">参考链接</h3><p><a href="https://jyywiki.cn/OS/2023/build/lect5.ipynb.html">5.多处理器编程：从入门到放弃 (jyywiki.cn)</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 搓OS.log </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>搓OS-day3</title>
      <link href="/2024/01/10/%E6%90%93OS-day3/"/>
      <url>/2024/01/10/%E6%90%93OS-day3/</url>
      
        <content type="html"><![CDATA[<h2 id="手搓os-day3">手搓OS-day3</h2><p>挺过了昨天的抽（硬）象（件）玩意，今天终于要迎来美丽的实战了（<del>很能绷的住</del>），下面我们要迎接大量的操作系统概念，虽然俺可能描述不清楚，但是我相信代码的力量，从现在要挑战编程能力惹。我尽可能拆开代码记录我的编程心路（<u><strong>阿门</strong></u>worship）</p><h3 id="架构">架构</h3><p>这里老师采用了一个分层的方式设计的架构，在硬件上通过一个AbstractMachine抽象出了部分API，这好处是显而易见的，就类似一个虚拟平台，对跨硬件是很有帮助的，显然Abstract的很多汇编我是不会写的，但是老师帮忙搭建好了（感恩）</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240111095855963.png"alt="简单架构" /><figcaption aria-hidden="true">简单架构</figcaption></figure><p>搓不动了，先放一放，研究一下设备无关编程（菜，哭）</p><h3 id="断言的重要性">断言的重要性</h3><p>这个和我们在JAVA中接触过的单元测试有些相似，说他重要体现在快速定位错误（不是运行错误）的重要性上</p><p>断言基本用法：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;assert.h&gt;</span></span></span><br><span class="line"></span><br><span class="line">assert(<span class="type">bool</span> exppression) <span class="comment">//显然这里传入一个bool量，但想起int中0和非0分别代表false和true</span></span><br></pre></td></tr></table></figure><p>使用场景：</p><ol type="1"><li><p>在函数入口做合法性检查</p></li><li><p>将<code>assert(0)</code>放在绝对不会出现的地方</p></li><li><p>放在需要一些条件必须满足的地方</p></li></ol><p>使用原则：</p><ol type="1"><li>一个断言检查一个条件</li><li>断言不能代替<code>if else</code></li><li>可以用开关条件编译打开或关闭断言，一般debug模式打开而在release模式下关闭。</li></ol><h3 id="linux中proc文件中的进程">Linux中proc文件中的进程</h3><h4 id="c语言文件操作">C语言文件操作</h4><p>用一个<code>FILE*</code>的一个指针来指定一个<code>FILE</code>格式的结构体。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FILE *fp;</span><br></pre></td></tr></table></figure><h5 id="打开和关闭">打开和关闭</h5><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">FILE *<span class="title function_">fopen</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *filename,<span class="type">const</span> <span class="type">char</span> *model)</span>;</span><br><span class="line"><span class="comment">// 文件名和打开参数</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">fclose</span><span class="params">(FILE *stream)</span>;</span><br><span class="line"><span class="comment">// 传入指针</span></span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line"><span class="comment">//打开名为test.txt的文件，打开方式w为只读</span></span><br><span class="line">FILE* pf = fopen(<span class="string">&quot;test.txt&quot;</span>, <span class="string">&quot;w&quot;</span>);  <span class="comment">//接收返回的文件信息区指针 (如果文件不存在，会自动创建)</span></span><br><span class="line"><span class="comment">//如果文件打开失败（例如文件不存在），会返回NULL</span></span><br><span class="line"><span class="keyword">if</span> (pf == <span class="literal">NULL</span>) &#123;</span><br><span class="line">perror(<span class="string">&quot;fopen\n&quot;</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//关闭文件</span></span><br><span class="line">fclose(pf);</span><br><span class="line"><span class="comment">//还需要将指针置空</span></span><br><span class="line">pf = <span class="literal">NULL</span>;</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="文件顺序读写">文件顺序读写</h5><p>字符输入</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">fgetc(<span class="string">&#x27;A&#x27;</span>,pf);</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i=<span class="number">0</span>; i&lt;<span class="number">26</span>;i++)&#123;</span><br><span class="line">    fputc(<span class="string">&#x27;a&#x27;</span>+i,pf);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>字符输出：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ch=fgetc(pf);</span><br></pre></td></tr></table></figure><p>按行写入：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">fputs</span>(<span class="string">&quot;hello\n&quot;</span>,pf)</span><br></pre></td></tr></table></figure><p>按行读取：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">char</span> *arr;</span><br><span class="line">fgets(arr,<span class="number">5</span>,pf);</span><br></pre></td></tr></table></figure><p>格式化输入：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">fprintf</span>(pf,<span class="string">&quot;%s %d %f&quot;</span>,s.name,s.age,s.height)；</span><br></pre></td></tr></table></figure><p>格式化读入：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">fscanf</span>(pf,<span class="string">&quot;%s %d %f&quot;</span>,s.name,&amp;(s.age),&amp;(s.height));</span><br></pre></td></tr></table></figure><h4 id="linux-proc进程文件含义">Linux Proc进程文件含义</h4><ul><li>comm：进程名</li><li>cwd：当前工作目录，是个软链接，指向实际的路径</li><li>environ：环境变量</li><li>exe：进程启动的二进制，也是个软链接，指向实际的文件路径</li><li>fd：进程打开的文件描述符，每个描述符也是个软链接，指向打开的文件，如果涉及到socket，则会显示socket的inode号fdinfo/：进程打开文件时的一些属性</li><li>root：根路径</li><li>stat：进程的状态信息，包括ppid、进程名、进程启动时间等（这个是有用的）</li><li>status：进程的一些参数信息，包括uid、gid、虚拟内存、capability等</li><li>task/：进程的子线程，每个子目录就是一个线程的信息</li></ul><p>其余见下链接</p><h3 id="总结">总结</h3><p>嗯，今天编程的难度有点大，导致总结难产，主要看的内容也在参考链接里贴出来了，C语言好难（我好菜），<del>明天预告maybe更难产</del></p><h3 id="参考链接">参考链接</h3><p><ahref="https://zhuanlan.zhihu.com/p/619966043?utm_id=0">Linux内核：进程管理——进程文件系统/proc详解 - 知乎 (zhihu.com)</a></p><p><a href="https://jyywiki.cn/OS/2023/labs/M1.html">M1: 打印进程树(pstree) (jyywiki.cn)</a></p><p><ahref="https://blog.csdn.net/RongLin02/article/details/116244719">Linux学习之打印进程树_利用/proc进行进程树的打印-CSDN博客</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 搓OS.log </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>搓OS-day2</title>
      <link href="/2024/01/10/%E6%90%93OS-day2/"/>
      <url>/2024/01/10/%E6%90%93OS-day2/</url>
      
        <content type="html"><![CDATA[<h2 id="手搓os-day2">手搓OS-day2</h2><p>今天看的东西全都围绕这两个C语言代码展开</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// say.c</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">putch</span><span class="params">(<span class="type">char</span> ch)</span>;</span><br><span class="line"><span class="type">int</span> <span class="title function_">putchar</span><span class="params">(<span class="type">int</span> ch)</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">say</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *s)</span> &#123;</span><br><span class="line">  <span class="keyword">for</span> (; *s; s++) &#123;</span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> __ARCH__</span></span><br><span class="line">    putch(*s); <span class="comment">// AbstractMachine，没有 libc，调用 TRM API 打印字符</span></span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">    <span class="built_in">putchar</span>(*s); <span class="comment">// 操作系统，调用 libc 打印字符</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// main.c</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">say</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *s)</span>;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">  say(<span class="string">&quot;hello\n&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="操作系统上的c程序">操作系统上的C程序</h3><h4 id="编译过程的一些参数含义">编译过程的一些参数含义</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">gcc -c -O2 -o main.o main.c</span><br><span class="line">gcc -c -O2 -o say.o say.c</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-c 表示生成目标文件而不进行链接</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-O2 表示使用优化级别为O2</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-o main.o 表示生成的指定文件的名称为main.o</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">file say.o main.o</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">用于查看目标文件类型</span></span><br></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">say.o:  ELF 64-bit LSB relocatable, x86-64, version 1 (SYSV), not stripped</span><br><span class="line">main.o: ELF 64-bit LSB relocatable, x86-64, version 1 (SYSV), not stripped</span><br></pre></td></tr></table></figure><p>表明两个文件都是64位的ELF格式可重定位文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">objdump -d main.o</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">objdump GNU工具，用于显示二进制文件信息</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-d 表示显示目标文件的汇编代码（反编译）</span></span><br></pre></td></tr></table></figure><p>汇编代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">0000000000000000 &lt;main&gt;:</span><br><span class="line">   0:   f3 0f 1e fa             endbr64 </span><br><span class="line">   4:   48 83 ec 08             sub    $0x8,%rsp</span><br><span class="line">   8:   48 8d 3d 00 00 00 00    lea    0x0(%rip),%rdi        # f &lt;main+0xf&gt;</span><br><span class="line">   f:   e8 00 00 00 00          call   14 &lt;main+0x14&gt;</span><br><span class="line">  14:   31 c0                   xor    %eax,%eax</span><br><span class="line">  16:   48 83 c4 08             add    $0x8,%rsp</span><br><span class="line">  1a:   c3                      ret    </span><br></pre></td></tr></table></figure><p>发现地址是从0开始的（<del>死去的组成原理开始袭击我</del>），可以看出这是一个CISC指令集，采用小端存储，系统地址按字节编址，<code>call</code>指令对应机器码为：<code>0xe8H</code>，可以看见偏移量现在是0，因为并不知道从哪儿调用</p><p><code>lea</code>是获取调用say参数的指令</p><h4 id="链接">链接</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">gcc main.o say.o</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">./a.out</span> </span><br><span class="line">hello</span><br></pre></td></tr></table></figure><p>这里不能直接用<code>ld</code>进行链接，这其实可以理解的，因为我们并没有对<code>putchar</code>做任何定义。而真正的链接流程与下面的加载流程的2中的细节其实是完全对应的（这也不难理解，链接好后加载到内存是很合理的吧）</p><p>同理这里也可用使用<code>objdump</code>来查看文件内容</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">objdump -d a.out</span></span><br></pre></td></tr></table></figure><h4 id="加载">加载</h4><p>流程：</p><ol type="1"><li>Shell接受命令后使用<code>fork()</code>创建一个新进程</li><li>在子进程中使用<code>execve()</code>加载<code>a.out</code>，在这里做出必要的内存映射：</li></ol><p>​ ① 执行动态链接库</p><p>​ ②跳转到<code>a.out</code>的<code>_start</code>运行，初始化C语言运行环境</p><p>​ ③ 执行<code>main</code></p><ol start="3" type="1"><li>如需要输入输出会使用特殊指令进行系统调用</li></ol><p><u><strong>补漏</strong></u>：</p><p>gdb指令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb) starti #运行到第一条指令便停止</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb) bt f  # backtrace full 打印堆栈信息</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb)info inferiors # 打印线程/进程信息</span><br></pre></td></tr></table></figure><p>Linux指令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!cat /proc/&#123;PID&#125;/maps #打印进程内存信息</span><br></pre></td></tr></table></figure><p>具体流程我也没看懂，后边看懂了再补</p><h3 id="bare-metal上的c程序">Bare-Metal上的C程序</h3><p>Bare-Metal就是一块纯铁（bushi），就是类似一个没有</p><p>操作系统的情况下（我先这么理解），续：通常用来描述在没有操作系统或软件层的支持的情况下运行的计算机系统（chatGPT如是说）。</p><p><del>唉，还是要写Makefile</del></p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">NAME := hello</span><br><span class="line">SRCS := main.c say.c</span><br><span class="line"><span class="keyword">include</span> <span class="variable">$(AM_HOME)</span>/Makefile.app</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make -nB ARCH=x86_64-qemu</span><br></pre></td></tr></table></figure><h4 id="编译">编译</h4><p>在之前C语言的部分上研究过，编译就是对.c文件翻译为可重定位的（relocatabel）的二进制目标文件（.o）。没有操作系统意味着所有的系统调用都是不成立的，所以没啥太大区别（）。需要加一个参数。</p><h4 id="链接-1">链接</h4><p>链接命令（<del>看着吓人</del>）：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ld -melf_x86_64 -N -Ttext-segment=0x00100000 -o build/hello-x86_64-qemu.o \</span><br><span class="line">  main.o say.o am-x86_64-qemu.a klib-x86_64-qemu.a</span><br></pre></td></tr></table></figure><p><code>-melf_x86_64</code>：指定链接为<code>x86_64 ELF</code>格式</p><p><code>-N</code>：没看懂（）</p><p><code>-Ttext-segment=0x00100000</code>：设置加载地址</p><p>后边给出了要链接的文件，分别是<code>main.o</code>,<code>say.o</code>和必要的库函数（AbstractMachine和klib）</p><p>总结一下，这个链接后的文件并不能直接在操作系统上正常运行（不能不能跑，而是会报错），原因在于会非法访问，需要在bare-mental上运行，要创建一个镜像文件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">( cat abstract-machine/am/src/x86/qemu/boot/mbr \</span><br><span class="line">  head -c 1024 /dev/zero \</span><br><span class="line">  cat build/hello-x86_64-qemu.o ) \</span><br><span class="line"><span class="meta prompt_">  &gt; </span><span class="language-bash">/tmp/hello/build/hello-x86_64-qemu</span></span><br></pre></td></tr></table></figure><p>镜像由一个512字节的MBR（主引导记录），1024字节的空文件和hello-x86_64-qemu.o组成</p><p>这里提一下qemu的含义：QUEM（QuickEmulator）是一款开源的模拟器和虚拟机监视器，支持模拟多种体系结构（包括x86、ARM、MIPS 等）以及在不同操作系统上运行。</p><p>启动qemu的方式：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">qemu-system-x86_64 -hda your_disk_image.img </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">后面某个磁盘映像</span></span><br></pre></td></tr></table></figure><h4 id="加载-1">加载</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">qemu-system-x86_64 -S -s -serial none -nographic hello-x86_64-qemu</span></span><br></pre></td></tr></table></figure><p>这也是在启动镜像文件，其中加了不少参数，具体含义：</p><p><code>-S</code>：在模拟器初始化完成（CPU Reset）后暂停</p><p><code>-s</code>：启动gdb调试服务</p><p><code>-serial none</code>：忽略串口输入输出</p><p><code>-nographic</code>：不启动图形化界面</p><h5 id="cpu-reset">CPU Reset</h5><p>运行完成后采用<code>info registers</code>查看寄存器状态。这里关心两个状态：</p><ul><li><p><code>CR0=60000010</code>：先解释CR0是个什么玩意（<del>毕竟我也不知道</del>），CR0是x86架构中的控制寄存器，是控制处理器行为的一个寄存器，关键位有：</p><table><colgroup><col style="width: 37%" /><col style="width: 11%" /><col style="width: 50%" /></colgroup><thead><tr class="header"><th>关键位</th><th>位置</th><th>作用</th></tr></thead><tbody><tr class="odd"><td>PE（Protection Enable）</td><td>最低位</td><td>PE=1时为保护模式 PE=0时为实模式</td></tr><tr class="even"><td>MP（Monitor Coprocessor）</td><td>通常不用</td><td>控制是否启用监视协处理器监视</td></tr><tr class="odd"><td>EM（Emulation）</td><td></td><td>控制x87浮点指令</td></tr><tr class="even"><td>TS（Task Switched）</td><td></td><td>任务切换位</td></tr><tr class="odd"><td>ET（Extension Type）</td><td></td><td>用于标识处理器支持的浮点单元类型</td></tr><tr class="even"><td>NE（Number Error）</td><td></td><td>浮点异常</td></tr></tbody></table></li><li><p><code>%cs = 0xf000</code>,<code>%ip = 0xfff0</code>,相当于PC指针位于<code>0xfff0</code></p><p>这里还是得解释：</p><p><code>CS</code>寄存器标识的是代码段寄存器，根据内存分段式存储的原理，这里存储的代码的起始地址，那么我们猜一猜也能猜出这个<code>IP</code>(instructionpoint)实际上代表的就是偏移量，因此能够算出实际的<code>PC=CS+IP</code>（此处需要做一个逻辑扩展，当然算数扩展也无所谓），<del>死去的组成原理和操作系统疯狂攻击</del></p></li></ul><h5 id="firmware加载master-boot-record">Firmware：加载Master BootRecord</h5><p>下面会相对亲切一点，这就是操作系统启动的过程</p><ol type="1"><li>CPU从一个特定主存地址（BIOS中断向量，这个东西就是我们上面刚才算出的PC）开始，取指令，执行ROM中的引导程序，这里会进行硬件自检</li><li>读入主引导记录（Master BootRecord），执行磁盘引导程序，扫描分区表</li><li>从主分区（活动分区）读入分区引导记录，执行程序</li><li>从根目录下找到操作系统初始化程序并执行</li></ol><h5 id="boot-loader解析并加载-elf-文件">Boot Loader：解析并加载 ELF文件</h5><p>这块属实看太不懂，总结一手就是我们通过某种程序将我们要运行的ELF文件加载到了MBR，并通过启动操作系统的类似的方法，成功将程序放入了内存</p><h3 id="总结">总结</h3><p>这下是确实深入了解操作系统了，我们通过阅读这个在裸机上的如何实现一个C语言程序的运行，比较透彻的理解了C语言的编译链接，以及具体在启动过程中的一些细节，最重要的是，理解操作系统实际上建立在一个AbstractMachine上的一个程序，在链接程序时表现的尤其明显。（这里有大量细节推荐去看老师的课程主页，链接贴在下面了，点查看原文可看）</p><h3 id="参考链接">参考链接</h3><p><a href="https://jyywiki.cn/AbstractMachine/AM_Programs.html">为Bare-Metal 编程：编译、链接与加载 (jyywiki.cn)</a></p><p>感谢chatGPT的友情回答（<del>麻木.jpg</del>）</p>]]></content>
      
      
      
        <tags>
            
            <tag> 搓OS.log </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>搓OS-day1</title>
      <link href="/2024/01/09/%E6%90%93OS-day1/"/>
      <url>/2024/01/09/%E6%90%93OS-day1/</url>
      
        <content type="html"><![CDATA[<h2 id="手搓os-day1">手搓OS-day1</h2><p>今天进入正式开搓的阶段（<del>霉比</del>maybe），今天比较大的阻碍还是代码障碍比较大，需要回顾和总结大量的基础，所以会显得人比较菜（其实就是菜），还有一个比较好的调试方式。然后就是对老师口中的玩具的分析（==<del>好难玩的玩具</del>==），从中结合我们学过的基本的操作系统的知识进行结合，体会其中状态机和程序的概念。</p><h3 id="python部分">Python部分</h3><h4 id="generator函数生成器">Generator（函数生成器）</h4><p>其中的重要关键字<code>yield</code>（生产，生成的意思<del>考研词汇</del>），代码运行到<code>yield</code>关键字后会自动保存</p><p>一个弯弯绕的小栗子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">number_generator</span>():</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        a=i+<span class="number">10</span></span><br><span class="line">        <span class="keyword">yield</span> a</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_generator</span>():</span><br><span class="line">    f=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        a=i+<span class="number">10</span>+f</span><br><span class="line">        <span class="built_in">print</span>(a)</span><br><span class="line">        f=<span class="keyword">yield</span> a</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    generator_1=number_generator() <span class="comment"># 接收生成器对象</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        <span class="built_in">print</span>(generator_1.__next__())</span><br><span class="line">    </span><br><span class="line">    generator_2=add_generator()</span><br><span class="line">    <span class="comment"># 直接调用next</span></span><br><span class="line">    <span class="built_in">next</span>(generator_2)</span><br><span class="line">    <span class="comment"># 采用send方式</span></span><br><span class="line">    generator_2.send(<span class="number">10</span>)  <span class="comment">#  按道理这里应该是11，但通过send函数改变f的值后变为21</span></span><br></pre></td></tr></table></figure><p>另外第一次启动生成器是不能使用send方法，会报错：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TypeError: can&#x27;t send non-None value to a just-started generator</span><br></pre></td></tr></table></figure><p>对此有两种解决方案： ① 第一次启动是使用<code>next()</code>函数</p><p>② 第一次传入<code>send()</code>的值为<code>None</code></p><h4 id="match函数">match函数</h4><p>match语句是 Python 3.10中引入的一种结构模式匹配的特性，允许在数据结构中匹配复杂的模式。基本形式如下（==这个真挺好用的==）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">match a,args:</span><br><span class="line">case <span class="string">&quot;haha&quot;</span>,xs:</span><br><span class="line">        <span class="built_in">print</span>(xs)</span><br><span class="line">    case <span class="string">&quot;lala&quot;</span>,(f,args):</span><br><span class="line">        .....</span><br></pre></td></tr></table></figure><p>有一些接受函数返回参数的技巧：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">syscall,args,*_=self._func.send(self.retval)</span><br></pre></td></tr></table></figure><p><code>*_</code>和<code>_</code>可以有效的扔掉不想要的变量，保留有效变量</p><h4 id="运算符">:= 运算符</h4><p><code>:=</code>运算符是Python3.10中的新特性，提供在赋值的同时并运算：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">t:=<span class="number">1</span>+<span class="number">2</span></span><br><span class="line"><span class="comment"># 等价于</span></span><br><span class="line">t=<span class="number">1</span></span><br><span class="line">t+<span class="number">2</span></span><br></pre></td></tr></table></figure><h4 id="exec-函数">exec 函数</h4><p>exec函数是Python标准库中的函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">exec</span>(<span class="built_in">str</span>,variables)</span><br></pre></td></tr></table></figure><p><code>str</code>是一段代码，<code>exec</code>执行该段代码，将运行后的函数接口传递到variable字典</p><p>一个小栗子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">code = <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">def greet(name):</span></span><br><span class="line"><span class="string">    print(f&quot;Hello, &#123;name&#125;!&quot;)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">greet(&quot;John&quot;)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行字符串中的代码</span></span><br><span class="line"><span class="built_in">exec</span>(code)</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建一个全局字典，以方便调用</span></span><br><span class="line">globals_dict = &#123;&#125;</span><br><span class="line"><span class="built_in">exec</span>(code, globals_dict)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从 globals_dict 中获取 greet 函数</span></span><br><span class="line">greet_func = globals_dict[<span class="string">&#x27;greet&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用 greet 函数</span></span><br><span class="line">greet_func(<span class="string">&quot;111&quot;</span>)</span><br></pre></td></tr></table></figure><h4 id="sys包">SYS包</h4><p>sys，就是system的简写，秉承着用多少学多少的理念我们先补一点，以后遇到了再补（<del>懒狗</del>）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sys.avg <span class="comment">#读取命令行中参数</span></span><br><span class="line"><span class="comment">#此外还有常用的path，先摆了</span></span><br></pre></td></tr></table></figure><h3 id="gdb">GDB</h3><p>还是秉承用多少学多少，gdb是一种命令行调试工具，那就意味着没有IDE要用命令行打断点。</p><p>可以类比使用IDE的debug，程序在debug的模式下运行，同理在用gdb调试时也就要在gdb模式下调试，步骤如下：</p><ol type="1"><li>编译要调试的代码：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -g -o tst tst.c</span><br></pre></td></tr></table></figure><p>这里要提的是，<code>-g</code>使得能够在栈帧中查看代码和对应行号，具体对于栈帧的描述可以去查一下内存的虚拟映射，</p><ol start="2" type="1"><li>在gdb下运行：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gdb ./tst</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240109185527196.png" alt="运行结果" style="zoom:67%;" /></p><ol start="3" type="1"><li>然后就可以用gdb指令进行调试了，下面罗列指令并且给出执行效果</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看代码</span></span><br><span class="line">list</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">或者</span></span><br><span class="line">l</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240109185757649.png" alt="ls查看代码" style="zoom:67%;" /></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">运行</span></span><br><span class="line">run </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">或者</span></span><br><span class="line">r</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240109185933173.png"alt="运行" /><figcaption aria-hidden="true">运行</figcaption></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">打断点</span></span><br><span class="line">break n # n为行号 或者用</span><br><span class="line">b n</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看断点</span></span><br><span class="line">info b</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">禁用断点</span></span><br><span class="line">disable b</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">重新启用</span></span><br><span class="line">enable b</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">执行下一条指令，但不进入函数体</span></span><br><span class="line">next # 或者</span><br><span class="line">n</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">进入函数体</span></span><br><span class="line">step</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">监视变量值</span></span><br><span class="line">print # 或者</span><br><span class="line">p</span><br></pre></td></tr></table></figure><p>剩下的功能用到再学（<del>咕咕</del>）</p><h3 id="vscode的一种调试方式">VScode的一种调试方式</h3><p>因为要运行一个类似这样的指令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python os-model.py hello.py</span><br></pre></td></tr></table></figure><p>才能运行整个程序，所以这给调试带来了困扰，因为我并不知道如何在debug的同时输入命令行，这里我想到了两个解决方案：</p><p>①通过再写一个Python文件，通过os包执行指令就可以打上断点（<del>天才</del>），结果就是路径始终对不上</p><p>② 如下：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240109191717359.png" alt="添加配置" style="zoom:67%;" /></p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240109191821830.png" alt="添加参数args" style="zoom:67%;" /></p><p>这个args就代表的是命令中的参数</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python xx.py paramter</span><br></pre></td></tr></table></figure><p>于是就可以顺利调试了。</p><h3 id="os玩具模型">OS玩具模型</h3><p>这里还是简单画个图：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240109193054392.png" alt="OS模型" style="zoom:67%;" /></p><p>简单解释一下，step提供了一个获取运行线程的下一步指令的功能，而run函数提供了一个将下一步指令转化为机器指令（可执行）的功能，而run中也就提供了各种系统调用的接口：比如随机切换线程，线程休眠，读写调用等等。</p><p>在实现中采用了一个很精妙的方法，通过对待运行文件的内容读取，并修改其中的系统调用为一个生成器函数，转入OS系统的栈中存储函数入口，然后通过OS运行就得到了运行结果（妙啊~），这里建议大家去看看代码。</p><p>Makefile先不写了，用到再写（<del>咕咕</del>）</p><h3 id="参考链接">参考链接</h3><hr /><p>今日无</p>]]></content>
      
      
      
        <tags>
            
            <tag> 搓OS.log </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>搓OS-day0</title>
      <link href="/2024/01/08/%E6%90%93OS-day0/"/>
      <url>/2024/01/08/%E6%90%93OS-day0/</url>
      
        <content type="html"><![CDATA[<h2 id="手搓os-day0">手搓OS-day0</h2><p>今天，俺开了一个新的巨坑，我要手搓一个操作系统的模拟，主要参考的是南京大学的蒋老师的课程，最后附课程链接（需要的同学点查看原文即可看到链接），目前已经上手两天，嗯，怎么评价呢，很难，这个新坑也主要是记录我的心路历程和中间遇到的一些问题，因为涉及的技术奇多无比，其中有许多我不掌握的语法，因此可能会显得比较啰嗦。</p><p><strong>day0</strong>主要做的都是准备工作，但是准备工作也相当难做，下面简单记录一下：</p><h3 id="配置一台linux机器">配置一台Linux机器</h3><p>已经头大了开始，这次配置因为服务器到期了，于是选择了一个很新的配置方式：WSL</p><p>WSL全名是Windows Subsystem ForLinux（大概是，意思应该是对的），也就是Windows自带的一个子系统，同时兼容了Windows与Linux，好处就是切换自由，占用资源少，缺点就是稍微慢一点（但是也无所谓其实，毕竟我们不需要超级高的响应速度，能动就行）。</p><p>大概的配置流程不是很复杂（真的吗？）：</p><ol type="1"><li>启用Windows中的WSL服务（在管理员模式下的powershell中运行）</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart</span><br></pre></td></tr></table></figure><ol start="2" type="1"><li>启动虚拟化</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart</span><br></pre></td></tr></table></figure><ol start="3" type="1"><li>下载WSL2并安装【<ahref="https://wslstorestorage.blob.core.windows.net/wslblob/wsl_update_x64.msi">链接</a>（点了就会自动下载哦，阅读原文可以点链接）】</li><li>设置默认版本为WSL2</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wsl --set-default-version 2</span><br></pre></td></tr></table></figure><ol start="5" type="1"><li>从应用商店下载Ubantu，如下：</li></ol><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240108232817639.png" alt="应用商店" style="zoom:50%;" /></p><ol start="6" type="1"><li>安装后直接运行，根据提示设置账号密码</li><li>设置root密码：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo passwd</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240108233254220.png" alt="终端界面" style="zoom:67%;" /></p><ol start="8" type="1"><li>如果不考虑图形化界面的话（<del>图形化界面崩溃了</del>），到这里基本就Ok了，然后就是连接Vscode，基本不需要怎么配置直接在终端运行即可：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">code.</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240108233413032.png" alt="接入VScode" style="zoom:67%;" /></p><h3 id="配置anaconda">配置Anaconda</h3><p>习惯上为了有一个舒适的Python的环境体验，还是配置了一个Anaconda，这里要记录一下拉取方式的Anaconda下载方式：</p><ol type="1"><li>拉取下载</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-5.3.1-Linux-x86_64.sh</span><br></pre></td></tr></table></figure><p>或者采用下面的源</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-2023.07-2-Linux-x86_64.sh</span><br></pre></td></tr></table></figure><ol start="2" type="1"><li>运行安装</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash Anaconda3-5.3.1-Linux-x86_64.s</span><br></pre></td></tr></table></figure><p>无脑同意，小心不要跳过太多。</p><ol start="3" type="1"><li>配置路径（这步貌似不做也没啥问题）</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">打开配置文件</span></span><br><span class="line">sudo gedit ~/.bashrc</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">最后一行添加路径</span></span><br><span class="line">export PATH=&quot;/home/用户名/anaconda3/bin:$PATH&quot;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">保存后更新</span></span><br><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure><h3 id="c与c-简单配置">C与C<sup>++</sup> 简单配置</h3><p>为了能跑C和C<sup>++</sup> 的代码，要简单配置一下二者的编译环境</p><p>C语言（配置好后也就是gcc编译，之前的文章有提过）：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install build-essential</span><br></pre></td></tr></table></figure><p>C<sup>++</sup> 环境：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install g++</span><br></pre></td></tr></table></figure><p>实际上g++貌似并不怎么用，在VScode里有gcc就够了，后边还有调试断点用的GDB，有点复杂（<del>还没看完</del>明天再写）,虽然但是这些东西都是一月七号做的（），明天再写今天的工作。</p><h3 id="参考链接">参考链接：</h3><p>[1] <ahref="https://blog.csdn.net/dally2/article/details/108206234">【Linux系统下载Anaconda3】_anacondalinux下载-CSDN博客</a></p><p>[2] <ahref="https://www.cnblogs.com/dwingzone/p/12619781.html">实验四Linux系统搭建C语言编程环境 - Dwingzone - 博客园 (cnblogs.com)</a></p><p>[3] <ahref="https://zhuanlan.zhihu.com/p/386590591">史上最全的WSL安装教程 -知乎 (zhihu.com)</a></p><p>[4] <ahref="https://jyywiki.cn/OS/2023/index.html">操作系统：设计与实现 (2023春季学期) (jyywiki.cn)</a></p><p>[5] <ahref="https://zhuanlan.zhihu.com/p/409547049">WSL+VSCode食用指南 - 知乎(zhihu.com)</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 搓OS.log </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux常用命令</title>
      <link href="/2024/01/06/linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
      <url>/2024/01/06/linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<h2id="linux常用命令以及备忘自用略乱">linux常用命令以及备忘（自用略乱）</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">命令格式：命令[-选项][参数]</span><br></pre></td></tr></table></figure><p>选项：操作、参数：对象</p><h3 id="文件相关">文件相关</h3><h4 id="vim">vim</h4><p>ESC：退出编辑模式</p><p>i：进入编辑</p><p>:q 退出vim</p><p>:w 写回</p><p>:wq 写回并退出vim</p><p>vim filename.type 创建文件</p><h4 id="mkdir">mkdir</h4><p>创建文件夹</p><h4 id="cd">cd</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd .. #回到上一层</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /目录 #打开某文件夹</span><br></pre></td></tr></table></figure><h4 id="ls">ls</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls #显示当前目录下的所有文件名</span><br></pre></td></tr></table></figure><h4 id="mv">mv</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv oldname.txt newname.txt #改名</span><br></pre></td></tr></table></figure><p>但也具有功能移动</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv hello.txt hello # 文件 + 目录</span><br></pre></td></tr></table></figure><h4 id="cp">cp</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp -rp[原文件或目录][目标目录]  # -r 复制目录 -p 保留文件属性</span><br></pre></td></tr></table></figure><h4 id="cat">cat</h4><h3 id="gcc命令">gcc命令</h3><h3 id="g命令">g++命令</h3>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>图神经网络——gnn</title>
      <link href="/2023/09/03/gnn/"/>
      <url>/2023/09/03/gnn/</url>
      
        <content type="html"><![CDATA[<h1 id="图神经网络gnn初步">图神经网络——GNN初步</h1><h2id="最简单的图神经网络着眼于节点">最简单的图神经网络——着眼于节点</h2><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/%E9%A1%B5-1(2).png"alt="页-1(2)" /><figcaption aria-hidden="true">页-1(2)</figcaption></figure><p>这张图就挺清楚了，但是我们还有一些问题没有说清楚，数据是什么，数据在哪儿，数据怎么运算，目的是什么</p><p>从派别上，更像是频率派，实际上是在分析各个节点之间的一个关系。</p><h3 id="target节点嵌入隐状态h_v">target：节点嵌入(隐)状态（<spanclass="math inline">\(h_v\)</span>）</h3><h3 id="数学表达">数学表达：</h3><p>节点邻居：</p><ul><li>点集：<span class="math inline">\(co[v]\)</span></li><li>边集：<span class="math inline">\(ne[v]\)</span></li></ul><p>节点嵌入：<span class="math inline">\(x_v\)</span></p><p>输出嵌入：<span class="math inline">\(o_v\)</span></p><p>局部转移函数： <span class="math display">\[h_v=f(x_v,x_{co[v]},h_{ne[v]},x_{ne[v]})\]</span> 局部输出函数： <span class="math display">\[o_v=g(h_v,x_v)\]</span> 学习方法：梯度下降 <span class="math display">\[loss=\sum_{i=1}^{p}{(t_i-o_i)}\]</span> p是所有的目标节点的数目</p><h3 id="缺点">缺点</h3><p>缺点实际上是相当显然的</p><ol type="1"><li>缺乏对边的学习</li><li>传递效率低</li><li>梯度消失</li><li>多次迭代后点的值是固定的、平滑的，fixednode，导致整个图的区分意义不大</li></ol><h2 id="gcn着眼全图">GCN——着眼全图</h2><h3 id="傅里叶变换">傅里叶变换</h3><p>通俗来讲，我们平时见到的连续可导函数，都是建立在时域，傅里叶变换就要要将他变换到频域</p><p>那么频域又是什么东西？</p><p>频域首先要有频率，那么是什么出现的频率，比如是周期函数才有频率，最经典的周期函数正是三角函数，傅里叶很开创的搞出来了所有的函数都可以用三角函数来分解的一个变换，就是傅里叶变换。</p><p>空间域：空域，又称图像空间，说白了就是像素级处理。</p><h3 id="图谱理论">图谱理论</h3><h4 id="拉普拉斯算子">拉普拉斯算子</h4><p>一个多元函数的所有二阶偏导数 <span class="math display">\[\Delta f=\sum^{n}_{i}{\frac{\part^2 f }{\part x_i^2}}\]</span> 考虑一个二元函数<spanclass="math inline">\(f(x,y)\)</span>，则拉普拉斯算子可以表示为： <spanclass="math display">\[\Delta f=\frac{\part^2f}{\part x^2}+\frac{\part^2f}{\part y^2}\]</span> 可以从单侧差分公式中有： <span class="math display">\[\Delta f \approx \frac{f(x+\Delta x,y)+f(x-\Delta x,y)-2f(x,y)}{(\Deltax)^2}+\frac{f(x,y+\Delta y)+f(x,y-\Delta y)-2f(x,y)}{(\Delta y)^2}\]</span> 对二元函数离散化采样： <span class="math display">\[\begin{bmatrix}  f(x_1,y_1)&amp;f(x_2,y_1)  &amp;\cdot\cdot\cdot  &amp; f(x_n,y_1)\\   f(x_1,y_2)&amp; f(x_2,y_2)  &amp;\cdot\cdot\cdot  &amp;f(x_n,y_2) \\\cdot\cdot\cdot&amp;\cdot\cdot\cdot  &amp;\cdot\cdot\cdot  &amp;\cdot\cdot\cdot \\  f(x_1,y_n)&amp; f(x_2,y_n)  &amp;\cdot\cdot\cdot  &amp;f(x_n,y_n)\end{bmatrix}\]</span> 令<span class="math inline">\(\Delta x=x_{i+1}-x_i=1,\Deltay=y_{i+1}-y_i=1\)</span></p><p>则点<spanclass="math inline">\((x_i,y_i)\)</span>的laplace算子可以如下公式近似计算：<span class="math display">\[\frac{f(x_i+\Delta x,y_i)+f(x_i-\Delta x,y_j)-2f(x_i,y_j)}{(\Deltax)^2}+\frac{f(x_i,y_j+\Delta y)+f(x_i,y_j-\Delta y)-2f(x_i,y_j)}{(\Deltay)^2}\]</span></p><p><span class="math display">\[=\frac{f(x_{i+1},y_j)+f(x_{i-1},y_j)-2f(x_i,y_j)}{1^2}+\frac{f(x_i,y_{j+1})+f(x_i,y_{j-1})-2f(x_i,y_j)}{1^2}\]</span></p><p><span class="math display">\[=f(x_{i+1},y_j)+f(x_{i-1},y_j)+f(x_i,y_{j+1})+f(x_i,y_{j-1})-4f(x_i,y_j)\]</span></p><p>于是他就变成了一个离散的一个中心和四个相邻节点的图的结构，将laplace算子离散化表示：<span class="math display">\[\Delta f=\sum_{(k,l)\in N(i,j)}^{}{(f(x_k,y_l)-f(x_i,y_j))}\]</span> 很惊喜的发现，卷积出现了！</p><p><ahref="https://zhuanlan.zhihu.com/p/81502804">谱聚类方法推导和对拉普拉斯矩阵的理解- 知乎 (zhihu.com)</a></p><h4 id="laplace-矩阵">laplace 矩阵</h4><p>有无向图<span class="math inline">\(G=（E,V）\)</span>,<spanclass="math inline">\(V\)</span>有n个节点，邻接矩阵为W，加权度矩阵D，将lapace算子扩展到图上：<span class="math display">\[\Delta f_i=\sum_{j \in N_i}{w_{ij}(f_i-f_j)}\]</span> 那么我们可以改写成矩阵形式： <span class="math display">\[\Delta f=\begin{bmatrix}\Delta f_1 \\\cdot \cdot \cdot \\\Delta f_n \\\end{bmatrix}=\begin{bmatrix}d_1f_1-w_1f \\\cdot \cdot \cdot \\d_nf_n-w_nf\\\end{bmatrix}=\begin{bmatrix}d_1 &amp;&amp; &amp;&amp; \\&amp;&amp; \cdot \cdot \cdot&amp;&amp;\\&amp;&amp; &amp;&amp;d_n\\\end{bmatrix}\begin{bmatrix}f1 \\\cdot \cdot \cdot \\f2\\\end{bmatrix}-\begin{bmatrix}w_1\\\cdot \cdot \cdot \\w_2\\\end{bmatrix}\begin{bmatrix}f_1\\\cdot \cdot \cdot \\f_2\\\end{bmatrix}\]</span></p><p><span class="math display">\[=\mathbf{(D-W)f}\]</span></p><p>那么就有laplace矩阵 <span class="math display">\[\mathbf{L}=\mathbf{D-W}\]</span> 性质：</p><ol type="1"><li>对任意向量<span class="math inline">\(f \in\mathbb{R^n}\)</span>，有<span class="math inline">\(\mathbf{f^TLf}=\frac{1}{2}\sum_{i=1}^{n}{\sum_{j=1}^{n}{w_{ij}(f_i-f_j)^2}}\)</span></li><li>laplace矩阵时半正定矩阵</li><li>laplace矩阵的最小特征值为0，其对应的特征向量常向量1，级所有分量为1</li><li>laplace矩阵有n个非负实数特征值。</li></ol><h4 id="归一化laplace矩阵">归一化laplace矩阵</h4><p>对称归一化： <span class="math display">\[L=D^{-1/2}LD^{-1/2}=I-D^{-1/2}WD^{-1/2}\]</span> 随机漫步归一化： <span class="math display">\[L_{rw}=D^{-1}L=I-D^{-1}W\]</span></p><h3 id="谱网络到gcn">谱网络到GCN</h3><p>谱网络通过对归一化laplace进行特征分解在频域上建立了卷积核： <spanclass="math display">\[g_{\theta} *x=Ug_{\theta}(\Lambda) U^Tx\]</span> 其中<spanclass="math inline">\(U\)</span>是对称归一化的laplace矩阵进行特征值分解后的特征向量，<spanclass="math inline">\(\Lambda\)</span>是相对应的特征值</p><p>很显然此运算极其复杂，包括一个很大的矩阵函数，而且卷积核规模受限，因此引入了多项式进行逼近截断：<span class="math display">\[g_{\theta}(\Lambda)\approx \sum_{k=0}^{K}{\theta_k \Lambda^k}\]</span> ChebNet引入了切比雪夫多项式 <spanclass="math inline">\(T_k\)</span>对 <spanclass="math inline">\(g_\theta\)</span>进行拟合。切比雪夫多项式有个重要性质: <span class="math display">\[T_n(cos(\theta))=cos(n\theta)\]</span> <imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230905113021320.png"alt="image-20230905113021320" /></p><p><spanclass="math inline">\(\tilde{\Lambda}=2\frac{\Lambda}{\lambda_{max}}-I\)</span>，那么卷积核就转化为：<span class="math display">\[g_{\theta} *x=\sum_{k=0}^{K}{\theta_K^`UT_{k}(\tilde \Lambda) U^Tx}\]</span> 令K=1，则 <span class="math display">\[g_{\theta} *x=\sum_{k=0}^{1}{\theta_K^`UT_{k}(\tilde \Lambda)U^Tx}=\theta_0x+\theta_1(\frac{2}{\lambda_{max}}L-I_N)x\]</span> 由于正则化后的拉普拉斯矩阵特征值最大不超过2，令<spanclass="math inline">\(\lambda_{max}=2\)</span> <spanclass="math display">\[g_{\theta} *x=\theta_0x+\theta_1(\frac{2}{\lambda_{max}}L-I_N)x=\theta_0x+\theta_1(L-I_N)x\]</span> 又因为： <span class="math display">\[L=D^{-1/2}LD^{-1/2}=I-D^{-1/2}WD^{-1/2}\]</span> 因此： <span class="math display">\[g_{\theta} *x=\theta_0x-\theta_1D^{-1/2}WD^{-1/2}x\]</span> 令<spanclass="math inline">\(\theta=\theta_0=-\theta_1\)</span>，共享参数得：<span class="math display">\[g_{\theta} *x\approx\theta(I_N-D^{-1/2}WD^{-1/2})x=\theta(D^{-1/2}\tildeWD^{-1/2})x\]</span> 堆叠卷积层，并进行重整化（或者叫重正则化）： <spanclass="math display">\[H^{(l+1)}=\sigma(\mathbf{\tilde {D}^{-1/2}\tilde {A}\tilde{D}^{-1/2}H^{(l)}W^{(l)} })\]</span></p><p>over</p><h3 id="空间方法">空间方法</h3><h4 id="neural-fps">neural FPS</h4><p><span class="math display">\[x=h_v^{t-1}+\sum_{i=1}^{|N_v|}{h_i^{t-1}} \\h_v^t=\sigma(xW_t^{|N_v|})\]</span></p><p>还是简单介绍一下，h是节点嵌入或者叫隐层状态，w是某个节点有多少个邻居的权重</p><h4 id="patchy-san">PATCHY-SAN</h4><ol type="1"><li>节点序列选择</li><li>选择邻居节点作为感受野，共选择k个</li><li>图标准化，为感受野节点排序，映射到向量空间</li><li>采用CNN架构进行卷积运算</li></ol><h4 id="dcnn">DCNN</h4><p>扩散卷积神经网络，用于节点分类： <span class="math display">\[\mathbf{H}=\sigma(\mathbf{W^c} \odot P*X)\]</span></p><h4 id="dgcn">DGCN</h4><p>dual graph convolutional network（DGCN），</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230905123536601.png"alt="image-20230905123536601" /><figcaption aria-hidden="true">image-20230905123536601</figcaption></figure><p>网络架构如上，上面一层采用了最基本的GCN来做运算，在下一层用PPMI矩阵P代替正则化邻接矩阵。其目的是为了统合局部一致性和全局一致性。</p><p>PMI是一种来衡量两种事物之间相似性的指标： <spanclass="math display">\[PMI(x,y)=ln\frac{p(xy)}{p(x)p(y)}\]</span> 令不相关和负相关的PMI值都为0，即得矩阵<spanclass="math inline">\(P\)</span></p><p>这是一个很巧妙的构思，实际上将其转变成了一个很经典的loss函数，可以应用各种正则化技巧。</p><h4 id="lgcn">LGCN</h4><p>learnable graph convolution networks</p><p>这个网络是基于可学习网络卷积层和子图训练策略</p><p>可学习网络卷积层，利用CNN作为聚合器，通过邻接矩阵获得前k个特征元素，然后利用一维CNN计算隐层：<span class="math display">\[\hat{H}_t=g(H_t,A,k)\\H_{t+1}=c(\hat{H}_t)\]</span> 其中<spanclass="math inline">\(g(\cdot)\)</span>函数为获取特征元素</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230905151902605.png"alt="image-20230905151902605" /><figcaption aria-hidden="true">image-20230905151902605</figcaption></figure><h2 id="挑战">挑战：</h2><p>如果从股票价格入手，难以构造一个图，其次如何构造一个动态的图，如何有GNN来学习这个动态的图，都很具有挑战性</p>]]></content>
      
      
      
        <tags>
            
            <tag> 图神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C语言文件框架与运行</title>
      <link href="/2023/08/05/cFrame/"/>
      <url>/2023/08/05/cFrame/</url>
      
        <content type="html"><![CDATA[<h1 id="c语言文件框架与运行">C语言文件框架与运行</h1><p>不知道大家有没有一种感觉，当你初学c语言运用（仅仅是运用）到熟练的时候，会明显感受到一些疑惑：这个头文件我好像从来没写过、这个多文件我好像也从来没用过、这个多文件的C语言程序又是怎么跑起来的</p><h2 id="c语言的文件框架">C语言的文件框架</h2><h3 id="没有框架">没有框架</h3><p>最简单的结构是什么？就是没有结构，一个单一的<code>XX.c</code>文件配合gcc工具编译就可以运行。</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230807120653069.png" alt="无框架示例" style="zoom:50%;" /></p><p>这里简单介绍一下gcc，gcc是GUN中的一个编译工具，在C语言中的指令（该顺序也就是c语言运行的顺序）主要有：</p><ol type="1"><li>预处理，进行宏展开等,生成代码文件为<code>helloworld.i</code></li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -E helloworld.c</span><br></pre></td></tr></table></figure><ol start="2" type="1"><li>编译，生成汇编代码，生成代码文件为<code>helloworld.s</code></li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -S helloworld.c</span><br></pre></td></tr></table></figure><ol start="3" type="1"><li>汇编，生成机器码，生成代码文件为<code>helloworld.o</code></li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -c helloworld.c</span><br></pre></td></tr></table></figure><ol start="4" type="1"><li>链接，实际上直接链接能够运行以上所有的步骤，生成的是一个名为helloworld的可执行文件</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -o helloworld helloworld.c</span><br></pre></td></tr></table></figure><p>在命令行中运行c语言程序的方式：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.\helloworld</span><br></pre></td></tr></table></figure><p>实际上就是运行我们刚刚链接出来的可执行文件，中间的部分是我们的命名，命名为<code>helloworld</code></p><h3 id="头文件源文件结构">头文件+源文件结构</h3><p>我作为一个半路出家的C语言使用者（以前是使用JAVA和Python），简单使用是并不难的，但是当我想做多文件结构的时候我发现我并不会，C语言并没有像JAVA和Python一样的导入方法，但是其实是有的，就是我们在单文件编程时不怎么搭理的头文件。</p><h4 id="头文件">头文件</h4><p>首先说说头文件，头文件是什么，我们先从名字上来说：头文件，头是什么？头在哪儿？头位于人的最顶端，是人脑所在的地方负责思考获取知识。C语言中的头文件也是，头文件就是C语言main程序中的最顶端，负责获取知识（程序接口）。</p><p>那么头文件又该如何定义，细节又是如何？</p><p>我们先举个例子直观理解：</p><p>众所周知，C语言是面向过程的语言，其中函数是面向过程语言的精髓，下面我们首先定义一个函数：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">helloworld</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;hello,World!\n&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>众所周知，当程序员定义完用户程序后，main函数想要调用需要事先声明：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">helloworld</span><span class="params">()</span>; <span class="comment">// 声明函数</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    helloworld();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">helloworld</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;hello,World!\n&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>现在请大家想象一个情况，如果现在我们有1万个函数要声明，那是不很麻烦，而且会有极高的耦合度，且不方便阅读。而头文件就代替了声明加函数定义的部分。</p><p>于是我们可以拆一下，分为这样的结构：</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230807140743646.png"alt="文件结构" /><figcaption aria-hidden="true">文件结构</figcaption></figure><p>其中<code>helloworld.c</code>中为</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">helloworld</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;hello,World!\n&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>helloworld.h</code>中为：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> EXAMPLE_HELLOWORLD_H</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> EXAMPLE_HELLOWORLD_H</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">helloworld</span><span class="params">()</span>;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span> <span class="comment">//EXAMPLE_HELLOWORLD_H</span></span></span><br></pre></td></tr></table></figure><p><code>main.c</code>中为：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helloworld.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    helloworld();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样就将整个文件模块化了，但是其中依旧存在一些问题没有讲清楚，比如这个头文件到底怎么写，里边的内容都有什么含义？下面我们先解释一些前置的知识，慢慢道来。</p><h4 id="include命令"><code>#include</code>命令</h4><p><code>#include</code>命令实际上很简单，可以等同为<code>import</code>语句，其叫做文件包含命令，用来引入对应的头文件，其工作原理就是将头文件的内容插入到当前命令所在的位置上，连接成一整个源文件。</p><p><code>#include</code>命令分为两种：</p><ol type="1"><li><p>一种是<code>#include&lt;&gt;</code>，引用的是编译器的类库路径里面的头文件，其用于导入官方标准头文件</p></li><li><p>另一种是<code>#include""</code>，引用的是你程序目录的相对路径中的头文件，如果在程序目录没有找到引用的头文件则到编译器的类库路径的目录下找该头文件，其用于导入自定义的头文件</p></li></ol><p>也就是说引用系统标准库都可以，但第一种更快；引用自己定义的头文件只能用第二种。</p><h4 id="宏定义">宏定义</h4><p>#define叫做宏定义命令它也是C语言预处理命令的一种，所谓宏定义，就是用一个标识符来表示一个字符串。</p><p>宏定义的形式为：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> 宏名 字符串</span></span><br></pre></td></tr></table></figure><p>宏名就是一种标识符，而字符串可以是数字、表达式、if语句、函数等。</p><p>tips：</p><ul><li><p>宏定义仅仅是替换，并不计算</p></li><li><p>宏定义的处理步骤是上面的预处理阶段，因此是否正确要等到编译阶段</p></li><li><p>宏定义可以拥有定义域</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> PI 3.1415</span></span><br><span class="line">———————作用域——————</span><br><span class="line"><span class="meta">#<span class="keyword">undef</span> PI</span></span><br></pre></td></tr></table></figure></li><li><p>习惯上，宏定义用大写</p></li></ul><p>常见的预处理命令有：</p><table><thead><tr class="header"><th style="text-align: center;">命令</th><th style="text-align: center;">说明</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">#</td><td style="text-align: center;">空指令</td></tr><tr class="even"><td style="text-align: center;">#include</td><td style="text-align: center;">引入头文件</td></tr><tr class="odd"><td style="text-align: center;">#define</td><td style="text-align: center;">定义宏</td></tr><tr class="even"><td style="text-align: center;">#undef</td><td style="text-align: center;">取消宏</td></tr><tr class="odd"><td style="text-align: center;">#if</td><td style="text-align: center;">如果条件为真，则编译if内的代码</td></tr><tr class="even"><td style="text-align: center;">#ifdef</td><td style="text-align: center;">如果宏已经定义，则编译if内的代码</td></tr><tr class="odd"><td style="text-align: center;">#ifundef</td><td style="text-align: center;">如果宏未定义，则编译if内的代码</td></tr><tr class="even"><td style="text-align: center;">#elif</td><tdstyle="text-align: center;">如果前面的#if条件为假，当前条件为真，则编译</td></tr><tr class="odd"><td style="text-align: center;">#endif</td><td style="text-align: center;">结束一个#if</td></tr></tbody></table><h4 id="头文件编写">头文件编写</h4><p>现在前置知识都已经补足了，我们来说一声头文件编写的规范：</p><ul><li>建议把所有的常量、宏、系统全局变量和函数原型写在头文件中，在需要的时候随时引用这些头文件</li><li>源文件的名字可以不和头文件一样，但是为了好管理，一般头文件名和源文件名一样</li><li>不管是标准头文件，还是自定义头文件，都只能包含变量和函数的声明，不能包含定义，<strong>否则在多次引入时会引起重复定义错误</strong>（重定义）</li></ul><p>这里也就可以解释为什么头文件要有这个程序段了：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> EXAMPLE_HELLOWORLD_H</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> EXAMPLE_HELLOWORLD_H</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">helloworld</span><span class="params">()</span>;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span> <span class="comment">//EXAMPLE_HELLOWORLD_H</span></span></span><br></pre></td></tr></table></figure><p>一旦该头文件被重复引用，那么就会检测到有这个宏定义了已经，那么就不会再次编译这个头文件，从而避免了重定义错误。</p><h2 id="关于gccmake与cmake">关于gcc、make与CMake</h2><p>建议参考：<ahref="https://blog.csdn.net/wuzheyan2008/article/details/119026007">关于gcc、make和CMake的区别_cmake和gcc的区别_ericwzy945的博客-CSDN博客</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> C语言 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python之IDE</title>
      <link href="/2023/07/23/IDE/"/>
      <url>/2023/07/23/IDE/</url>
      
        <content type="html"><![CDATA[<h2 id="python入门之ide">Python入门之IDE</h2><p>想必大家都在什么某抖、某b或者某些不太懂的电视剧里看到过黑客大佬（可能是）一块命令行敲代码敲一天，对此我的评价是：要么是纯粹演的，要么是真大佬。</p><p>命令行是可以解决所有编程问题，例如Python也自带有IDLE，或者Python的交互式页面，其都是在命令行窗口进行编程的，但是显而易见，这种方式我写个十八行代码，两三个变量还是可行的，一旦代码变复杂，记住变量都成为了一个困难的工作。因此IDE最基本要解决的问题就出现了。</p><p>这里简单介绍两个Python常用的IDE，以及下载安装。</p><h2 id="pycharm">Pycharm</h2><p>Pycharm是由JetBrains开发的一个专门的Python集成开发环境，由于其极其亲民，简单上手闻名。当然目前业界的许多IDE都是由JetBrains开发的，并且安卓开发的著名名言kotlin也是由JetBrains主导研发的。</p><h3 id="下载">下载</h3><p>这里是Pycharm下载的官方网站（<ahref="https://www.jetbrains.com/pycharm/">官网</a>），如下图，在红色框框中就可以下载了</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230724000324453.png"alt="image-20230724000324453" /><figcaption aria-hidden="true">image-20230724000324453</figcaption></figure><p>Pycharm分为Free Community（免费社区版）和Professional（专业版）</p><p>在点击下载后，显示在最上边的是专业版，是需要付费的</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230724000717317.png"alt="专业版" /><figcaption aria-hidden="true">专业版</figcaption></figure><p>向下滚动，看到社区版本，如果囊中羞涩（但是确实贵），社区版也是足够我们学习使用的。</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230724001208274.png"alt="这还是刚才的网页只是下拉了" /><figcaption aria-hidden="true">这还是刚才的网页只是下拉了</figcaption></figure><p><strong>但是</strong>，我们是学生，我们可以<strong>白嫖</strong></p><h3id="专业版白嫖需要学校邮箱或者学信网">专业版白嫖（需要学校邮箱或者学信网）</h3><p>还是在这个网页，在右上角有一个小人头，点进去</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230724002352976.png"alt="image-20230724002352976" /><figcaption aria-hidden="true">image-20230724002352976</figcaption></figure><p>这时候会蹦出来一个让你登陆的界面，如果你有账号那就登陆就好了，如果没有请注册一个，<strong>并且务必记住账号密码</strong>。</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230724002741727.png"alt="image-20230724002741727" /><figcaption aria-hidden="true">image-20230724002741727</figcaption></figure><p>我已经有账号就直接登陆了，但为了更好的演示我注册一个新的账号，注册很简单，登陆后页面是这样的：</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230724003726451.png"alt="image-20230724003726451" /><figcaption aria-hidden="true">image-20230724003726451</figcaption></figure><p>这个页面的意思是说你目前没有任何许可证，他告诉你你可以如何获得许可证：买一个，找公司要一个，学生或老师免费</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230724003835700.png"alt="image-20230724003835700" /><figcaption aria-hidden="true">image-20230724003835700</figcaption></figure><p>好了，第三个就是我们想要的，那么我们点进去，一直往下划</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230724004035867.png"alt="image-20230724004035867" /><figcaption aria-hidden="true">image-20230724004035867</figcaption></figure><p>点击红框里的Applynow，进去后我们会看到一个页面，这时我们可以选择切换为中文，当然不换也行。</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230724004131577.png"alt="image-20230724004131577" /><figcaption aria-hidden="true">image-20230724004131577</figcaption></figure><p>简单说明一下各个需要填什么：</p><ul><li>我是学生</li><li>就读</li><li>是否就读计算机科学，随便选无所谓</li><li>邮箱地址：<strong>务必填写正确的学校邮箱地址</strong>，以我的为例<code>202011@stu.neu.edu.cn</code>,这非常重要，因为学校邮箱是证明学生在读的重要东西。</li><li>姓名正常填写</li><li>后边除了接受协议必须勾选，其余都如实填写就行</li></ul><p>然后点击提交，会跳转出如下的界面：</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230724004923274.png"alt="image-20230724004923274" /><figcaption aria-hidden="true">image-20230724004923274</figcaption></figure><p>这个界面的意思是说，去你的学校邮箱等待JetBrains发的邮件，这时候打开学校邮箱等待就行了</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230724005119114.png"alt="image-20230724005119114" /><figcaption aria-hidden="true">image-20230724005119114</figcaption></figure><p>接到邮件后，点击他发给你的链接，阅读后续协议并同意，然后你就能够获得：</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230724005400501.png"alt="image-20230724005400501" /><figcaption aria-hidden="true">image-20230724005400501</figcaption></figure><p>JetBrains几乎所有产品的专业版许可证！</p><h3 id="安装">安装</h3><p>安装没有什么难度，列举几个重要的点：</p><ul><li>要记得加入path路径勾选</li><li>要记得切换安装路径，尽量不装C盘</li></ul><p>安装结束后，打开Pycharm界面：</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230724005711445.png"alt="image-20230724005711445" /><figcaption aria-hidden="true">image-20230724005711445</figcaption></figure><p>正常登陆就可以美美的使用Pycharm了</p><h2 id="vscode">Vscode</h2><p>Vscode作为一个轻量级的IDE，其最大的优点就是快，相比Pycharm要开个几分钟，Vscode几乎是瞬间打开，但是Vscode的各项设置并不是很傻瓜，需要自己配置或者安装插件，有些功能的集成也不如Pycharm。</p><p>Vscode的安装就不再详细的描述了，这里简单描述一下安装Python插件</p><ul><li>进入插件市场，点击左边的红框：</li></ul><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230724010109565.png"alt="image-20230724010109565" /><figcaption aria-hidden="true">image-20230724010109565</figcaption></figure><ul><li>在最上角搜索Python</li></ul><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230724010237254.png"alt="image-20230724010237254" /><figcaption aria-hidden="true">image-20230724010237254</figcaption></figure><ul><li>直接下载这个就可以用了</li></ul><h2 id="总结">总结</h2><p>完成乱七八糟的下载后就可以开始体验一下鸟枪换炮的快感了，用完应该只有一句话“这是飞一样的感觉~”。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Anaconda从入门到入土</title>
      <link href="/2023/07/22/Anaconda/"/>
      <url>/2023/07/22/Anaconda/</url>
      
        <content type="html"><![CDATA[<h1 id="anaconda从入门到入土">Anaconda——从入门到入土</h1><h2 id="引入">引入</h2><p>刚刚入门Python的同学可能对环境配置并没有什么感觉，毕竟就是一个pip的事，这时候我们设想一下，现在你在Github上下载了一个Python项目，然而这个项目需要你的numpy版本为1.12，而你的numpy版本是1.11，那么你是不是就要删除再安装？这仅仅是一个项目，而在日常编程中经常面对这种问题，而Anaconda就解决了这个问题。</p><h3 id="python环境">Python环境</h3><p>这里我随便打开了一个我电脑上的Python的源文件：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230722214308903.png" alt="朴素的Python目录" style="zoom: 67%;" /></p><p>在这里Lib中存放了Python的官方包和第三方包，所有的第三方包都在site-packages中，这其中就有我们常用的matplotlib。</p><center class="half"><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230722214809310.png" alt="image-20230722214809310" width="400"/><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230722215158542.png" alt="image-20230722215158542" width="400"/></center><h2 id="anaconda">Anaconda</h2><p>Anaconda(<ahref="https://www.anaconda.com/download/#macos">官网</a>）就是可以便捷获取包且对包能够进行管理，同时对环境可以统一管理的发行版本。Anaconda包含了conda、Python在内的超过180个科学包及其依赖项。</p><h3 id="下载">下载</h3><p>下载一般是没有什么难度的一步一步的走下去就行，这里简单提一下，Anaconda有标准版和mini版，如果你的电脑内存吃紧，那可以考虑安装mini-conda，功能上只是没有图形化界面，但是真的小很多。</p><h3 id="配置环境变量">配置环境变量</h3><p>在<code>控制面板\系统和安全\系统\高级系统设置\环境变量\用户变量\PATH</code>中添加 anaconda的安装目录的Scripts文件夹,比如我的路径是<code>F:\miniconda3\Scripts</code>,看个人安装路径不同需要自己调整。</p><p>这个学习过Java的同学应该对这套工作已经很熟悉了。配置完成后，就可以在你的shell界面(win+R输入<code>cmd</code>，也就是命令行界面)输入命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda --version</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230722222040833.png"alt="image-20230722222040833" /><figcaption aria-hidden="true">image-20230722222040833</figcaption></figure><p>显示出你的Anaconda版本即表示配置成功。</p><p>Anaconda本身是自带一个<code>Anaconda Powershell Prompt</code>的命令行工具，</p><p>为了避免可能发生的错误,我们先把所有工具包进行升级，在命令行输入：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda upgrade --all</span><br></pre></td></tr></table></figure><h3 id="anaconda与虚拟环境">Anaconda与虚拟环境</h3><p>首先回顾一个操作系统中的概念：虚拟。</p><p>操作系统中的虚拟性是指通过软件技术将一个物理资源分割为多个逻辑资源，是的多个应用程序可以同时使用这些逻辑资源，从而提高系统的利用率和效率。</p><p>这里我们用人话描述一下就是把一整块资源转化成好多个逻辑资源，但实际上还是这些资源，虚拟环境也是这样的思路。具体的原理大家可以参见<ahref="https://whiteboxml.com/blog/the-definitive-guide-to-python-virtual-environments-with-conda">[Theguide to Python virtual environments withconda]</a>这篇博客，写的非常详细。</p><h3 id="anaconda常用命令">Anaconda常用命令</h3><h4 id="进入环境-activate">进入环境 activate</h4><p>activate （意为：激活，学过神经网络的懂都懂），在shell中输入：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda activate</span><br></pre></td></tr></table></figure><p><strong>最新版的Anaconda已经将activate指令从conda中移除，新版命令为：</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source activate</span><br></pre></td></tr></table></figure><p>就可以直接进入Anaconda自带的base环境中，如果这时候输入Python那么就进入的当下base环境中的Python，而不是原来电脑中的Python。</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230722230729568.png"alt="image-20230722230729568" /><figcaption aria-hidden="true">image-20230722230729568</figcaption></figure><h4 id="创建环境-create">创建环境 create</h4><p>创建虚拟环境的命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n ml python=3.7</span><br></pre></td></tr></table></figure><p>上面的命令的含义简单介绍一下，-n表示要写入他的名字也就是name，Python=3.7指下载3.7版本的Python</p><h4 id="切换环境-activate">切换环境 activate</h4><p>其实还是进入，只不过从真实到虚拟和虚拟到虚拟，所以我一直将这个命令叫做激活。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda activate ml</span><br></pre></td></tr></table></figure><p>这样就切换到了ml的虚拟环境中，这里特别强调一点，如果环境名记不住的话，写错了是切换不进去的，所以我们还有下面这条命令。</p><h4 id="查看环境-env-list">查看环境 env list</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda env list </span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230722231424466.png"alt="image-20230722231424466" /><figcaption aria-hidden="true">image-20230722231424466</figcaption></figure><h4 id="安装第三方包-install">安装第三方包 install</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install requests</span><br></pre></td></tr></table></figure><p>conda命令的安装好处就在于会直接帮你安装好依赖，但是坏处是慢，不稳定，而且有时候会不如pip下载灵活。因此，只要能切换到虚拟环境中去，那么依然可以使用pip命令进行安装。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install request</span><br></pre></td></tr></table></figure><h4 id="卸载第三方包-remove">卸载第三方包 remove</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda remove requests</span><br></pre></td></tr></table></figure><p>或者</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip uninstall requests</span><br></pre></td></tr></table></figure><h4 id="导入导出环境">导入导出环境</h4><p>导出当前环境的包信息可以用命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda env export &gt; name.yaml</span><br></pre></td></tr></table></figure><p>将包信息存入yaml文件中，当需要重新创建一个相同的虚拟环境时可以用：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda env create -f name.yaml</span><br></pre></td></tr></table></figure><h2 id="连接到pycharm">连接到Pycharm</h2><p>Pycharm相对更为方便，在<code>Setting =&gt; Project =&gt; Project Interpreter</code>里面修改 Project Interpreter。可能是一个小齿轮，也可能是Addinterpreter。</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230723001703414.png" alt="image-20230723001703414" style="zoom: 50%;" /></p><p>然后在里边设置你的conda本地路径，就可以使用了。</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230723001842057.png" alt="image-20230723001842057" style="zoom:67%;" /></p><h2 id="连接到vscode">连接到Vscode</h2><ol type="1"><li>安装Python插件</li></ol><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230723000208886.png"alt="image-20230723000208886" /><figcaption aria-hidden="true">image-20230723000208886</figcaption></figure><ol start="2" type="1"><li><p>配置Python解释器</p><ul><li>按Ctrl+Shift+P，输入python，选择解释器</li><li>添加解释器路径</li></ul></li></ol><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230723000957655.png"alt="添加成功后的情况" /><figcaption aria-hidden="true">添加成功后的情况</figcaption></figure><h2 id="最后">最后</h2><p>Anaconda 是一个非常好用的包管理软件，比如在Anaconda上使用jupyternotebook等，快速切换包，以及他的一些数据分析包。</p><h2 id="推荐阅读">推荐阅读</h2><p><ahref="https://research.computing.yale.edu/sites/default/files/files/anaconda.pdf">Introductionto Anaconda (yale.edu)</a> 耶鲁大学的一个PPT</p>]]></content>
      
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>yolov5</title>
      <link href="/2023/07/05/yolov5/"/>
      <url>/2023/07/05/yolov5/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>yolo系列基础学习</title>
      <link href="/2023/07/04/yoloV3/"/>
      <url>/2023/07/04/yoloV3/</url>
      
        <content type="html"><![CDATA[<h1 id="yolov1">Yolov1</h1><h2 id="核心内容">核心内容</h2><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230704171038267.png"alt="分而治之" /><figcaption aria-hidden="true">分而治之</figcaption></figure><p>①分而治之，其类似卷积神经网络，目的是通过分块找到物体中心，其核心思路就是一个莽，全都用CNN莽出来</p><p>②leaky ReLu <span class="math display">\[y=\begin{array}{l}  \left\{\begin{matrix}  x,x&gt;0 \\0.1x,otherwise\end{matrix}\right.    \end{array}\]</span> ③ 端到端训练</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/20180910130225149"alt="端到端训练" /><figcaption aria-hidden="true">端到端训练</figcaption></figure><h1 id="yolov2">Yolov2</h1><h2 id="同比v1的改进">同比v1的改进</h2><p><strong>tradeoff：折中</strong></p><p>batch normalization：某种正则化手段，BN</p><p>high resolution classifier：微调与训练模型</p><p>Convolutional With Anchor Boxes：anchor机制</p><ul><li><p>Dimension Clusters：选择anchorprior需要手动设置，采用k-means聚类找到一个合适的大小</p></li><li><p>Direct location prediction: 解决不稳定，相对位置预测</p></li></ul><p>Fine-Grained Features: 调整后的yolo将在13*13的特征上做检测任务</p><p>multi-scale training：多标准化输入训练</p><p>Darknet-19：backbone网络</p><h1 id="yolov3">Yolov3</h1><h2 id="基本流程">基本流程</h2><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/24215864-83d220ef29016abf"alt="基本组件" /><figcaption aria-hidden="true">基本组件</figcaption></figure><h2 id="保留部分">保留部分</h2><ul><li>分割检测</li><li>leaky ReLu</li><li>端到端训练，loss function 不变</li><li>BN正则化不变，放在leaky ReLu和每一层卷积后</li><li>mult scale training</li></ul><h2 id="基本组件">基本组件</h2><p>CBL：Yolov3网络结构的最小组件，由Conv+Bn+Leaky_relu组成</p><p>Res unit：借鉴Resnet网络中的残差结构，让网络可以构建的更深。</p><p>ResX：由一个CBL和X个残差组件构成</p><h2 id="基础操作">基础操作</h2><p>Concat：拼接</p><p>Add：张量相加，与shortcut功能一致</p><h2 id="backbone">backbone</h2><p>v3中没有池化层和全连接层，尺寸变换通过改变卷积和步长</p><p>backbone会将输入图片的尺寸缩短到原来的<spanclass="math inline">\(\frac{1}{32}\)</span>,所以要求输入图片得是32的倍数</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/24215864-e67c9e615638e745"alt="尺寸变换比较" /><figcaption aria-hidden="true">尺寸变换比较</figcaption></figure><p>这里要注意Darknet-19是要比Darknet-53快的，因此v3还提供了tinynet</p><h2 id="perdictions-across-scales">Perdictions across scales</h2><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230705105112921.png"alt="image-20230705105112921" /><figcaption aria-hidden="true">image-20230705105112921</figcaption></figure><p>这个借鉴了FPN(feature pyramidnetworks)，采用多尺度来对不同size的目标进行检测，越精细的gridcell就可以检测出越精细的物体。规律为1:2:4</p>]]></content>
      
      
      
        <tags>
            
            <tag> 视觉 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python高维数据分析实验报告</title>
      <link href="/2023/04/23/pythonHighDeminsion/"/>
      <url>/2023/04/23/pythonHighDeminsion/</url>
      
        <content type="html"><![CDATA[<h1 id="实验一-python基础语法学习总结">实验一Python基础语法学习总结</h1><h2 id="实验目的">实验目的</h2><p>学习Python基本语法</p><h2 id="实验场地与设备">实验场地与设备</h2><p>线上</p><h2 id="实验方式">实验方式</h2><p>阅读教程与程序设计</p><h2 id="实验设计">实验设计</h2><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/Python%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80.png"alt="Python语言基础" /><figcaption aria-hidden="true">Python语言基础</figcaption></figure><p><span class="math display">\[图1.1 Python基础语法学习实验设计\]</span></p><h2 id="实验内容">实验内容</h2><h3 id="python语法总结">1. Python语法总结</h3><h4 id="python基本语法">1.1 Python基本语法</h4><h4 id="基本语句">（1） 基本语句</h4><p>①首先是输入输出语句，输入语句比较简单为<code>name=input()</code>，基本输出语句为<code>print()</code>,拼接输出使用逗号。</p><p>② 注释采用<code>#</code> 进行书写</p><p>③代码风格：Python采用的是缩进式代码风格，所以对于复制粘贴比较不友好</p><p>④条件判断语句：<code>if 条件1 :...elif 条件2 : ... else : ...</code></p><p>⑤ 循环语句：</p><p>第一种是<code>for</code>循环：<code>for x in []:</code><code>for x in ...:</code>循环就是把每个元素代入变量x，然后执行缩进块的语句</p><p>第二种是<code>while</code>循环：<code>while 条件判断语句 :</code><code>break</code>、<code>continue</code>和java中用法相同</p><h4 id="数据类型">（2） 数据类型</h4><p><strong>①整数：</strong>对于很大的数，很难数清楚0的个数。Python允许在数字中间以_分隔。</p><p><strong>② 浮点数：</strong>允许使用科学计数法定义</p><p><strong>③字符串：</strong>在Python没有严格要求<code>''</code>和<code>""</code>的区别在，也就是说没有区分字符和字符串使用二者没有任何区别。</p><ul><li>转义符和Java中保持一致</li><li>Python允许用<code>r''</code>表示<code>''</code>内部的字符串默认不转义</li></ul><p><strong>④ 布尔值：</strong></p><p>在Python中要注意：<code>True</code>、<code>False</code>要注意开头首字母大写。可以进行与、或、非的运算，运算符分别为：<code>and</code>，<code>or</code>，<code>not</code></p><p><strong>⑤空值：</strong>空值用<code>None</code>表示，意义与Java中的<code>null</code>相同。</p><p><strong>⑥ list：</strong></p><p>list是Python内置的一种数据类型，list是一种有序的集合，可以随时添加和删除其中的元素。此数据类型在Java的实用类中有封装。list和数组很像，声明方式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">classname = [<span class="string">&#x27;老六&#x27;</span>,<span class="string">&#x27;老八&#x27;</span>,<span class="string">&#x27;老九&#x27;</span>]</span><br></pre></td></tr></table></figure><p>想要调取其中的某个元素也和数组一致，赋值修改等也相同<br />下面列举一下list的ADT</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">list:</span><br><span class="line">append(&#x27;Elem&#x27;)  # 在末尾添加新的元素</span><br><span class="line">insert(i,&#x27;Elem&#x27;) # 将元素插入指定位置</span><br><span class="line">pop() # 删除末尾元素</span><br><span class="line">pop(i) # 删除i处的元素</span><br><span class="line">len(list) # list列表的长度</span><br></pre></td></tr></table></figure><p>list允许混合类型，也允许list嵌套，从而出现多维数组。</p><p><strong>⑦ tuple</strong></p><p>tuple被称为元组，其最大的特点就是不可修改，声明方式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">classname = (<span class="string">&#x27;老六&#x27;</span>,<span class="string">&#x27;老八&#x27;</span>,<span class="string">&#x27;老九&#x27;</span>)</span><br></pre></td></tr></table></figure><p>tuple在定义时要确定元素个数，这里有一个问题，在定义只有一个元素的tuple时，Python语法会认为这是一个小括号，因此在定义一个元组的tuple时，要加一个<code>,</code>避免歧义。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t=(<span class="number">1</span>,)</span><br></pre></td></tr></table></figure><p><strong>⑧ 字典（dict）</strong></p><p>字典全称为dictionary，在Java实用类中叫hashmap。其由键值对（key-value）组成，查找速度快。下面是一种初始化方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d = &#123;<span class="string">&#x27;Michael&#x27;</span>: <span class="number">95</span>, <span class="string">&#x27;Bob&#x27;</span>: <span class="number">75</span>, <span class="string">&#x27;Tracy&#x27;</span>: <span class="number">85</span>&#125;</span><br></pre></td></tr></table></figure><p>也可以放入指定的key中：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d[<span class="string">&#x27;Adam&#x27;</span>] = <span class="number">67</span></span><br></pre></td></tr></table></figure><p>查找value:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d[<span class="string">&#x27;Adam&#x27;</span>]</span><br></pre></td></tr></table></figure><p>key与value是多对一的关系，key需要是一个不可变对象保证key做hash运算后的唯一性。如果多次对某个key赋值，后边的value会覆盖前面的value提供了几个函数：</p><ol type="1"><li>通过<code>in</code>来判断key是否在dict中，返回值为布尔值，格式为：<code>key in dict</code></li><li>get()方法，<code>dict.get('key',空返回值)</code>key不存在时返回空返回值，空返回值可自定义，如果没有定义的话返回None</li><li>pop()方法，删除key，如果有value也一并删除，格式为<code>pop('key')</code></li></ol><p><strong>⑨ 集合（set）</strong></p><p>set是一组key的集合,集合特点；无序性、确定性、互异性要创建一个set，需要提供一个list作为输入集合：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="built_in">set</span>([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure><ul><li>方法： <code>add(key)</code>添加一个新的元素<code>remove(key)</code>删除一个元素</li><li>两个set可以做交运算和并运算： 交运算：<code>s1&amp;s2</code>并运算：<code>s1|s2</code></li></ul><h4 id="理解变量">（3） 理解变量</h4><p>在Python中变量仅仅是一个一个字母，变量与所对应的值之间的关系靠指针联系起来的。所以很重要的一点就是：<strong>当我们使用变量时，更多的要关注变量指向的东西，他可能是值，也可能是一个函数，也可能是一个变量</strong></p><h4 id="模块">1.2 模块</h4><h4 id="模块导入">（1） 模块导入</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><h4 id="模块下载">（2） 模块下载</h4><p>模块下载有比较复杂的方法，也有比较傻瓜式的。先说复杂的，使用Python中自带的pip包管理工具，用命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install numpy</span><br></pre></td></tr></table></figure><p>但是使用pip需要事先了解要导的包的名字，而且不能批量导入，而且在Python编程里也有编程一分钟，导包一小时的说法。pip下载第三方库的源可能会很慢或者失效，需要会自己添加国内的高速镜像。</p><p>傻瓜式的导包，例如在pycharm中可以直接在代码中写出自己需要的包，然后交给pycharm自己去下载，或者用Anaconda提前构建好的Python的库环境。</p><h4 id="函数式编程">1.3 函数式编程</h4><h4 id="函数">（1） 函数</h4><p><strong>① 函数定义</strong></p><p>在Python中定义函数为，<code>def 函数名(参数):</code>然后，在缩进块中编写函数体，函数的返回值用<code>return</code>语句返回。<br />如果没有return语句，函数执行完毕后也会返回结果，只是结果为None。returnNone可以简写为return。</p><p>1）空函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">nop</span>():</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>在这里<code>pass</code>作为占位符，表示跳过，也可以用在<code>if</code>的缩进块。</p><p>2）参数限制：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(x, (<span class="built_in">int</span>, <span class="built_in">float</span>)):</span><br><span class="line">      <span class="keyword">raise</span> TypeError(<span class="string">&#x27;bad operand type&#x27;</span>)</span><br></pre></td></tr></table></figure><p>实际上参数限制就是定义一个报错，<code>isinstance()</code>判断数据类型，如果不是就提出一个错误。<strong>作为一个弱类型语言，定义这一步是很有必要的，有助于读懂代码。</strong></p><p>3）返回值：</p><p>Python允许返回多个值，其返回的实际上是一个tuple元组，但是也可以用两个变量接收。</p><p><strong>② 参数定义</strong></p><p>在Python中函数参数的定义也比较灵活，提供位置参数、默认参数、可变参数、关键字（key）参数等</p><p>1）位置参数：位置参数指的是参数在传入时，实参和形参有着严格的位置对应关系，为常用参数形式。</p><p>2）默认参数：默认参数是指在位置参数的基础上为其添加默认值，有默认值的参数为默认参数，没有默认值的参数为必选参数基本定义形式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">my_def</span>(<span class="params">a,b=<span class="number">1</span></span>):</span><br><span class="line">    a=b+<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> </span><br></pre></td></tr></table></figure><p>需要注意的是：</p><ul><li>默认参数必须在必选参数后边，否则会无法辨认是否输入必选参数，从而报错。</li><li>默认参数的默认值一定是<strong>不变对象</strong>，由于Python中的变量定义为指针指向，会导致可变对象值发生变化</li></ul><p>3）不可变对象有：数值类型、字符串、tuple元组、None等</p><p>4）可变参数：可变参数指的是参数的数目不固定，定义形式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">my_function</span>(<span class="params">*v</span>):</span><br><span class="line">    <span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> vi <span class="keyword">in</span> v:</span><br><span class="line">        <span class="built_in">sum</span>+=vi</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span></span><br></pre></td></tr></table></figure><p>在可变参数中传入的所有参数将作为一个tuple被接收，该tuple的变量名为函数在定义时的形参名，定义时的需要在参数名前加一个<code>*</code>。</p><p>5）关键字（key）参数</p><p>此处的关键字和c语言中的关键字并不是一个意义，而是在dict中的key的意义。即在传递参数时，同时传递键（key）和值(value),Python会自动封装为一个dict。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">my_function</span>(<span class="params">**v</span>):</span><br><span class="line">    <span class="built_in">print</span>(v)</span><br><span class="line">    <span class="keyword">return</span> </span><br></pre></td></tr></table></figure><p>6）命名关键字参数</p><p>在关键字参数上，进一步限制传入的key的命名，就有了命名关键词参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">person</span>(<span class="params">name, age, *, city, job</span>):</span><br><span class="line">    <span class="built_in">print</span>(name, age, city, job)</span><br></pre></td></tr></table></figure><p>这里需要一个<code>*</code>区分位置参数与命名关键字参数，如果在这之前有可变参数，那么就不需要加<code>*</code>。<br />命名关键字参数必须传入参数名，这和位置参数不同。如果没有传入参数名，调用将报错：</p><p>7）参数组合</p><p>在一个函数中使用多个参数要保证其中的顺序，依次为：必选参数、默认参数、可变参数、命名关键字参数和关键字参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">onefunction</span>(<span class="params">a,b,c=<span class="number">0</span>,*args,job,city,**kw</span>):</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>tips：</p><ul><li>使用<code>*args</code>和<code>**kw</code>是Python的习惯写法。</li><li>可变参数和关键字参数有一点层级的感觉，中间包裹的是命名关键字参数这个比较尴尬的参数。</li></ul><p><strong>③ 递归函数</strong></p><p>写法与Java相同。</p><h4 id="实用方法">（2） 实用方法</h4><p><strong>① 切片</strong></p><p>切片是一个针对tuple和list方便地取元素的方法，语法规则：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">L[起始坐标:终止坐标:步长]</span><br></pre></td></tr></table></figure><p>当起始坐标为0时可以省略；步长为1时可以省略。</p><p><strong>② 迭代</strong></p><p>迭代是循环的增强，但是想要弄清迭代，需要知道两件事：一个是能不能迭代，一个是迭代出的数据是什么</p><p>想要知道一个数据能否迭代可以通过一个函数来完成：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections.abc <span class="keyword">import</span> Iterable</span><br><span class="line">L=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line"><span class="built_in">isinstance</span>(L,Iterable)</span><br></pre></td></tr></table></figure><p>迭代出的是什么，和要迭代的对象的储存方式，要特殊记忆一下dic。</p><p><strong>③ 列表生成器</strong></p><p>一种快捷生成list的方式，一个例子如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[x * x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>)]</span><br></pre></td></tr></table></figure><p>如果想要筛选生成的值，可以在<code>for</code>后加上<code>if</code>作为<strong>筛选条件</strong>，注意这里是筛选条件，因此这里和平时的<code>if else</code>并不是一个东西。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[x * x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>) <span class="keyword">if</span> x % <span class="number">2</span> == <span class="number">0</span>]</span><br></pre></td></tr></table></figure><p><strong>④ 生成器</strong></p><p>生成器是一种惰性的计算方式。包含<code>yield</code>关键字，当一个函数包含<code>yield</code>关键字时，他就成了一个generator函数。<code>yield</code>在generator函数中起到了一个return的作用，即到<code>yield</code>便返回。在调用时，使用一个变量接受一个generator对象。使用<code>next()</code>函数依次获得下一个返回值。</p><p><strong>⑤ 迭代器</strong></p><p>区分<code>Iterable</code>和<code>Iterator</code></p><p><code>Iterable</code>是可迭代的，是直接可用于<code>for</code>循环的。包括dict、list、tuple、set、str、grenerator。<code>Iterator</code>是迭代器，是直接可用于<code>next()</code>函数的，生成器都是<code>Iterator</code>对象，集合数据类型可以通过<code>iter()</code>获取<code>Interator</code>对象。</p><h4 id="函数式编程-1">（3） 函数式编程</h4><p>函数式编程是一种面向过程的编程思想，实际上是将复杂问题转化为一个个函数。</p><p>在Java的函数定义中，除去<code>void</code>类型不返回值，其余的都需要返回值。因此也就经常存在，使用一个变量接受函数值：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">function</span><span class="params">(x,y)</span>&#123;</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> a=function(x,y);</span><br></pre></td></tr></table></figure><p>那么是不是存在一种可能，我们可以将函数嵌套，让函数调用函数，让函数返回函数，彻底抛弃变量？</p><p>抛弃变量、只有函数就是彻底的函数式编程</p><p><strong>① 理解高阶函数</strong></p><p>之前有过变量名和值的理解，在Python中变量名和值是一个指针指向的关系。同理，函数名和函数也是这样的，函数名也是一个变量。也就是说，我们可以通过函数名，拿到函数体。也就是说函数名是什么并不重要，我们看中的是函数体。</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/%E7%BB%98%E5%9B%BE1.png"alt="绘图1" /><figcaption aria-hidden="true">绘图1</figcaption></figure><p>那么设想一种情况，现在我们定义了函数f2，那么我可以随便写一个函数，然后返回一个变量f2，那么实际上我就拿到了函数体。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">f2</span>(<span class="params">a,b</span>):</span><br><span class="line">    <span class="keyword">return</span> a+b</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">f3</span>():</span><br><span class="line">    <span class="keyword">return</span> f2</span><br><span class="line"><span class="built_in">print</span>(f3()(<span class="number">1</span>,<span class="number">2</span>))</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20220909173741530.png"alt="image-20220909173741530" /><figcaption aria-hidden="true">image-20220909173741530</figcaption></figure><p>然后我们在设想另一种情况，现在我们定义了另一种情况，我们在一个函数中写了一个f1作为局部变量，那么我就可以传入变量f2，然后就相当于传入了函数体。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">f2</span>(<span class="params">a,b</span>):</span><br><span class="line">    <span class="keyword">return</span> a+b</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">f1</span>(<span class="params">a,b,f</span>):</span><br><span class="line">    <span class="keyword">return</span> f(a,b)</span><br><span class="line"><span class="built_in">print</span>(f1(<span class="number">1</span>,<span class="number">2</span>,f2))</span><br></pre></td></tr></table></figure><p>现在就可以进行一个区分：</p><ul><li><code>f</code>代表函数名，是变量</li><li><code>f()</code>代表数值，是函数的返回值，返回值是一个量</li></ul><p>高阶函数，就是让函数的参数能够接收别的函数。</p><p>实用的几个函数，有必要查表即可</p><p><strong>② 返回函数</strong></p><p>同上文理解，只不过是将一个函数嵌套入了另一个函数</p><p><strong>③ lambda表达式</strong></p><p>与Java中语法相同，目的是为了简化返回函数嵌套</p><h4 id="面向对象编程">1.4 面向对象编程</h4><h4 id="类和对象">（1）类和对象</h4><p>创建类：语法如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">类名</span>(<span class="title class_ inherited__">继承的类</span>):</span><br></pre></td></tr></table></figure><p>python的类非常随意，几乎可以不定义就能用。在类中自带有一个构造函数<code>__init__()</code>,此函数可以重新定义</p><p>生成对象：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a=A()</span><br></pre></td></tr></table></figure><h4 id="访问权限">（2）访问权限</h4><p>如果要让内部属性不被外部访问，可以把属性的名称前加上两个下划线<code>__</code>，在Python中，实例的变量名如果以<code>__</code>开头，就变成了一个私有变量（private），只有内部可以访问，外部不能访问。</p><p>此外，<code>__ __</code>这种变量都是特殊变量，在不清楚的时候不要随便乱改</p><h4 id="继承和多态">（3）继承和多态</h4><p>和Java中的思想完全相同</p><h4 id="常用变量和方法">（4）常用变量和方法</h4><p>① <code>__slots__</code></p><p>用这个变量可以起到参数列表的功能，可以在一定程度上限制参数的变量名，用turple进行限定</p><p>② <code>@property</code></p><p>注解编程，可以起到一个简化定义setter和getter函数的作用。<spanclass="citation"data-cites="property注解在getter方法上">@property注解在getter方法上</span>，然后会自动生成<span class="citation" data-cites="函数名.setter">@函数名.setter</span>的注解，但是要注意的一点是，在getter中就不能使用函数名作为自身的调用值，否则会出现无限的调用，产生爆栈。</p><p>③ 多继承</p><p>与Java相同</p><p>⑤ <code>__str__</code>:和Java中的toString方法相同</p><h4 id="错误调试">1.5 错误调试</h4><h4 id="错误处理">（1）错误处理</h4><p>参照Java中，对比来学习即可：</p><p>两种方法，一是尝试，二是抛出，尝试采用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line"><span class="keyword">pass</span></span><br><span class="line"><span class="keyword">except</span> baseexception  :</span><br><span class="line"><span class="keyword">pass</span></span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line"><span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>抛出采用<code>raise</code>关键字</p><h4 id="测试">（2）测试</h4><p>①断言：<code>assert</code>的意思是，表达式<code>n != 0</code>应该是<code>True</code>，否则，根据程序运行的逻辑，后面的代码肯定会出错。</p><p>如果断言失败，<code>assert</code>语句本身就会抛出<code>AssertionError</code></p><p>② 断点：在强大IDE的辅助下，使用断点调试应该是最简单的。</p><h3 id="实践">2.实践</h3><h4 id="石头剪子布">2.1 石头剪子布</h4><p>使用random包中的random函数和条件控制语句，模拟两个电脑互相猜拳：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">win</span>(<span class="params">pc,cc</span>):</span><br><span class="line">    <span class="keyword">if</span> (cc==<span class="number">1</span> <span class="keyword">and</span> pc==<span class="number">2</span>) <span class="keyword">or</span> (cc==<span class="number">2</span> <span class="keyword">and</span> pc==<span class="number">3</span>)<span class="keyword">or</span>(cc==<span class="number">3</span> <span class="keyword">and</span> pc==<span class="number">1</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;电脑一输&quot;</span>)</span><br><span class="line">    <span class="keyword">elif</span> pc==cc:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;平&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;电脑二输&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">computer_choice</span>():</span><br><span class="line">    cc=random.randint(<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">return</span> cc</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show</span>(<span class="params">pc,cc</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;电脑一的出招为&quot;</span>,pc)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;电脑二的出招为&quot;</span>,cc)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">        pc=computer_choice()</span><br><span class="line">        cc=computer_choice()</span><br><span class="line">        show(pc,cc)</span><br><span class="line">        win(pc,cc)</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20220914212607801.png"alt="image-20220914212607801" /><figcaption aria-hidden="true">image-20220914212607801</figcaption></figure><p>改进提升一下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">win</span>(<span class="params">pc,cc</span>):</span><br><span class="line">    <span class="keyword">if</span> (cc==<span class="number">1</span> <span class="keyword">and</span> pc==<span class="number">2</span>) <span class="keyword">or</span> (cc==<span class="number">2</span> <span class="keyword">and</span> pc==<span class="number">3</span>)<span class="keyword">or</span>(cc==<span class="number">3</span> <span class="keyword">and</span> pc==<span class="number">1</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;玩家输&quot;</span>)</span><br><span class="line">    <span class="keyword">elif</span> pc==cc:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;平&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;玩家赢&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">computer_choice</span>():</span><br><span class="line">    cc=random.randint(<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">return</span> cc</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">str</span>(<span class="params">cc</span>):</span><br><span class="line">    <span class="keyword">if</span> cc==<span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;石头&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> cc==<span class="number">2</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;剪刀&#x27;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;布&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show</span>(<span class="params">f,pc,cc</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;电脑一的出招为&quot;</span>,f(pc))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;电脑二的出招为&quot;</span>,f(cc))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">        cc=computer_choice()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;请输入：1.石头 2.剪刀 3.布&quot;</span>)</span><br><span class="line">        pc=<span class="built_in">input</span>()</span><br><span class="line">        show(<span class="built_in">str</span>,pc,cc)</span><br><span class="line">        win(pc,cc)</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20220914213324805.png"alt="image-20220914213324805" /><figcaption aria-hidden="true">image-20220914213324805</figcaption></figure><h4 id="atm模拟">2.2 ATM模拟</h4><p>通过类和对象简单的设计了一个ATM取钱模拟器</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> Account</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ATM</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,money,accounts</span>):</span><br><span class="line">        self.money=money</span><br><span class="line">        self.accounts=accounts</span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">money</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self._money;</span><br><span class="line"><span class="meta">    @money.setter</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">money</span>(<span class="params">self,value</span>):</span><br><span class="line">        self._money=value</span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">accounts</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self._accounts</span><br><span class="line"><span class="meta">    @accounts.setter</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">accounts</span>(<span class="params">self,value</span>):</span><br><span class="line">        self._accounts=value</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">searchId</span>(<span class="params">self,<span class="built_in">id</span></span>):</span><br><span class="line">        <span class="keyword">for</span> account <span class="keyword">in</span> self.accounts:</span><br><span class="line">            <span class="keyword">if</span> account.<span class="built_in">id</span>==<span class="built_in">id</span>:</span><br><span class="line">                <span class="keyword">return</span> account</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">lode</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;请输入账号id&#x27;</span>)</span><br><span class="line">        <span class="built_in">id</span> = <span class="built_in">input</span>()</span><br><span class="line">        account1 = self.searchId(<span class="built_in">id</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;请输入密码&#x27;</span>)</span><br><span class="line">        password = <span class="built_in">input</span>()</span><br><span class="line">        <span class="keyword">if</span> password == account1.password:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;欢迎&quot;</span>, account1.name)</span><br><span class="line">        <span class="keyword">return</span> account1</span><br><span class="line">    <span class="comment"># 存钱</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">save_money</span>(<span class="params">self</span>):</span><br><span class="line">        account=self.lode();</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;请输入要存入的数目&quot;</span>)</span><br><span class="line">        saveMneyValue=<span class="built_in">input</span>()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;存款成功&#x27;</span>)</span><br><span class="line">        account.remain=<span class="built_in">int</span>(account.remain)+<span class="built_in">int</span>(saveMneyValue)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;您的账户余额为&#x27;</span>,account.remain)</span><br><span class="line">        self.money=self.money+<span class="built_in">int</span>(saveMneyValue)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 取钱</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">withdraw_money</span>(<span class="params">self</span>):</span><br><span class="line">        account=self.lode()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;请输入要取出的数目&#x27;</span>)</span><br><span class="line">        withdrawMoneyValue=<span class="built_in">input</span>()</span><br><span class="line">        <span class="keyword">if</span> account.remain &gt; withdrawMoneyValue:</span><br><span class="line">            account.remain=<span class="built_in">int</span>(account.remain)-<span class="built_in">int</span>(withdrawMoneyValue)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;取款成功，您的账户余额为&#x27;</span>,account.remain)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;您的账户余额不足&#x27;</span>)</span><br><span class="line">        self.money=<span class="built_in">int</span>(self.money)-<span class="built_in">int</span>(withdrawMoneyValue)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__str__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;当前ATM中有金额&quot;</span>,self.money,<span class="string">&quot;元&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># atm1=ATM(1000)</span></span><br><span class="line">    <span class="comment"># atm1.__str__()</span></span><br><span class="line">    <span class="comment"># atm1.ave_money(200)</span></span><br><span class="line">    <span class="comment"># atm1.__str__()</span></span><br><span class="line">    <span class="comment"># atm1.withdraw_money(200)</span></span><br><span class="line">    <span class="comment"># atm1.__str__()</span></span><br><span class="line">    accounts=[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        name=<span class="built_in">input</span>()</span><br><span class="line">        <span class="built_in">id</span> = <span class="built_in">input</span>()</span><br><span class="line">        password=<span class="built_in">input</span>()</span><br><span class="line">        remain=<span class="built_in">input</span>()</span><br><span class="line">        accounts.append(Account.account(name, <span class="built_in">id</span>, password, remain))</span><br><span class="line">    atm2=ATM(<span class="number">10000</span>,accounts)</span><br><span class="line">    atm2.save_money()</span><br><span class="line">    atm2.withdraw_money()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">account</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,name,<span class="built_in">id</span>,password,remain</span>):</span><br><span class="line">        self.name=name</span><br><span class="line">        self.remain=remain</span><br><span class="line">        self.password=password</span><br><span class="line">        self.<span class="built_in">id</span>=<span class="built_in">id</span></span><br><span class="line"></span><br><span class="line">    __slots__ = (<span class="string">&#x27;name&#x27;</span>,<span class="string">&#x27;remain&#x27;</span>,<span class="string">&#x27;password&#x27;</span>,<span class="string">&#x27;id&#x27;</span>)</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20220914214759256.png"alt="image-20220914214759256" /><figcaption aria-hidden="true">image-20220914214759256</figcaption></figure><h4 id="圣诞树画图">2.3 圣诞树画图</h4><p>使用Python自带的turtle包，进行圣诞树绘制：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> turtle</span><br><span class="line"></span><br><span class="line">screen = turtle.Screen()</span><br><span class="line">screen.setup(<span class="number">375</span>, <span class="number">700</span>)</span><br><span class="line"></span><br><span class="line">circle = turtle.Turtle()</span><br><span class="line">circle.shape(<span class="string">&#x27;circle&#x27;</span>)</span><br><span class="line">circle.color(<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">circle.speed(<span class="string">&#x27;fastest&#x27;</span>)</span><br><span class="line">circle.up()</span><br><span class="line"></span><br><span class="line">square = turtle.Turtle()</span><br><span class="line">square.shape(<span class="string">&#x27;square&#x27;</span>)</span><br><span class="line">square.color(<span class="string">&#x27;green&#x27;</span>)</span><br><span class="line">square.speed(<span class="string">&#x27;fastest&#x27;</span>)</span><br><span class="line">square.up()</span><br><span class="line"></span><br><span class="line">circle.goto(<span class="number">0</span>, <span class="number">280</span>)</span><br><span class="line">circle.stamp()</span><br><span class="line"></span><br><span class="line">k = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">13</span>):</span><br><span class="line">    y = <span class="number">30</span> * i</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i - k):</span><br><span class="line">        x = <span class="number">30</span> * j</span><br><span class="line">        square.goto(x, -y + <span class="number">280</span>)</span><br><span class="line">        square.stamp()</span><br><span class="line">        square.goto(-x, -y + <span class="number">280</span>)</span><br><span class="line">        square.stamp()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">4</span> == <span class="number">0</span>:</span><br><span class="line">        x = <span class="number">30</span> * (j + <span class="number">1</span>)</span><br><span class="line">        circle.color(<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">        circle.goto(-x, -y + <span class="number">280</span>)</span><br><span class="line">        circle.stamp()</span><br><span class="line">        circle.goto(x, -y + <span class="number">280</span>)</span><br><span class="line">        circle.stamp()</span><br><span class="line">        k += <span class="number">3</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">4</span> == <span class="number">3</span>:</span><br><span class="line">        x = <span class="number">30</span> * (j + <span class="number">1</span>)</span><br><span class="line">        circle.color(<span class="string">&#x27;yellow&#x27;</span>)</span><br><span class="line">        circle.goto(-x, -y + <span class="number">280</span>)</span><br><span class="line">        circle.stamp()</span><br><span class="line">        circle.goto(x, -y + <span class="number">280</span>)</span><br><span class="line">        circle.stamp()</span><br><span class="line"></span><br><span class="line">square.color(<span class="string">&#x27;brown&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">13</span>, <span class="number">17</span>):</span><br><span class="line">    y = <span class="number">30</span> * i</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">        x = <span class="number">30</span> * j</span><br><span class="line">        square.goto(x, -y + <span class="number">280</span>)</span><br><span class="line">        square.stamp()</span><br><span class="line">        square.goto(-x, -y + <span class="number">280</span>)</span><br><span class="line">        square.stamp()</span><br><span class="line">turtle.mainloop()</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20220914215352995.png"alt="image-20220914215352995" /><figcaption aria-hidden="true">image-20220914215352995</figcaption></figure><h2 id="总结">3.总结</h2><p>Python作为一个弱类型语言，是有他的弊端的，在一些需要数据类型转换和严格控制数据类型的情况下，会非常难受。而Python最大的优势在于有大量的库，这些库在特定的编程领域会非常便利。Python本身的语言具有极强的灵活性，而灵活性的言外之意就是规范性很难确定。因此，Python的重点是将第三方包为我所用，在数值计算中发挥他最大的作用。</p><h1 id="实验二-python科学计算库和高维数据导入方法">实验二PYTHON科学计算库和高维数据导入方法</h1><h2 id="实验目的-1">实验目的</h2><ol type="1"><li>掌握基本的numpy对象及其对应方法</li><li>掌握常用的numpy数学函数，学习查找numpy帮助文档</li><li>重点学习numpy线性代数方法</li><li>掌握matplotlib的绘图对象关系</li><li>掌握基本的绘制图形的方法，包括绘制、属性设置、子图</li><li>能够通过查阅文档、示例，画出复杂图像</li><li>导入mat数据集</li></ol><h2 id="实验场地与设备-1">实验场地与设备</h2><p>实验室4074</p><h2 id="实验方式-1">实验方式</h2><p>阅读教程与程序设计</p><h2 id="实验设计-1">实验设计</h2><p>使用corn数据集进行学习</p><h2 id="实验内容-1">实验内容</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">data=sio.loadmat(<span class="string">&quot;NIRcorn.mat&quot;</span>)</span><br><span class="line"><span class="comment"># 首先输出data观察一下data的组成</span></span><br><span class="line"><span class="comment"># print(data)</span></span><br><span class="line"><span class="comment"># 观察到下面的数据实际上是一个dict,那么就可以通过k-v进行取值。</span></span><br><span class="line"><span class="comment"># print(data.keys())</span></span><br><span class="line"><span class="comment"># 输出结果如下</span></span><br><span class="line"><span class="comment"># &#x27;__header__&#x27;, &#x27;__version__&#x27;, &#x27;__globals__&#x27;, &#x27;m5spec&#x27;, &#x27;cornspect&#x27;,</span></span><br><span class="line"><span class="comment"># &#x27;cornwavelength&#x27;, &#x27;propvals&#x27;, &#x27;cornprop&#x27;, &#x27;NIRcoin&#x27;, &#x27;information&#x27;,</span></span><br><span class="line"><span class="comment"># &#x27;mp5spec&#x27;, &#x27;mp6spec&#x27;, &#x27;m5nbs&#x27;, &#x27;mp5nbs&#x27;, &#x27;mp6nbs&#x27;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">首先debug，观察变量信息，发现header、version、global都没有什么实际用处，应该是数据集作者做的标注</span></span><br><span class="line"><span class="string">通过查找原数据集页面，得知：</span></span><br><span class="line"><span class="string">information:Information about the data,数据说明</span></span><br><span class="line"><span class="string">以下都是根据NBS的玻璃标准划分的仪器信息</span></span><br><span class="line"><span class="string">    m5nbs:NBS glass stds on m5 </span></span><br><span class="line"><span class="string">    mp5nbs:NBS glass stds on mp5 </span></span><br><span class="line"><span class="string">    mp6nbs:NBS glass stds on mp6</span></span><br><span class="line"><span class="string">这些和玉米都没有关系</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">查阅翻译：</span></span><br><span class="line"><span class="string">cornspect：吸光率数值</span></span><br><span class="line"><span class="string">cornwavelength：玉米波长</span></span><br><span class="line"><span class="string">cornprop：玉米的一些属性</span></span><br><span class="line"><span class="string">propvals:Property values for samples，这个里边有 &#x27;Moisture&#x27;,&#x27;Oil&#x27;,&#x27;Protein &#x27;,&#x27;Starch&#x27;  </span></span><br><span class="line"><span class="string">下面这些是从三台不同的仪器上获得的光谱：</span></span><br><span class="line"><span class="string">    m5spec:Spectra on instrument m5 </span></span><br><span class="line"><span class="string">    mp5spec:Spectra on instrument mp5</span></span><br><span class="line"><span class="string">    mp6spec:Spectra on instrument mp6 </span></span><br><span class="line"><span class="string">观察provals和cornprop的值，我们可以发现，这二者数据一模一样，所以只需要使用conprop即可。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">a=data[&#x27;m5spec&#x27;]</span></span><br><span class="line"><span class="string">print(type(a))</span></span><br><span class="line"><span class="string">print(a)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># print(a)</span></span><br><span class="line"><span class="comment"># 经过测试是可行的，但是里边还有一些其他的组成</span></span><br><span class="line"><span class="comment"># debug观察，发现a中只有一个元素就是我们所输出的</span></span><br><span class="line"><span class="comment"># 并且该数据的数据类型为&lt;class &#x27;numpy.ndarray&#x27;&gt;</span></span><br><span class="line"><span class="comment"># 又观察到内部实际上存在几个“表头”，所以他实际上是一个结构数组，</span></span><br><span class="line"><span class="comment"># 转到MATLAB观察原数据，发现确实是一个结构体，在读取时自动转化为了结构数组</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># m5spec=data[&#x27;m5spec&#x27;]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面开始正式分析画图：</span></span><br><span class="line">cornwavelength=data[<span class="string">&quot;cornwavelength&quot;</span>]</span><br><span class="line">x=[]</span><br><span class="line"><span class="comment"># 输出观察发现，是一个ndarray组成的list所以只取第一个元素</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(cornwavelength)):</span><br><span class="line">    x.append(cornwavelength[i][<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 获取吸光率</span></span><br><span class="line">cornspect = data[<span class="string">&#x27;cornspect&#x27;</span>]</span><br><span class="line"><span class="comment"># 随机取出五组透光率</span></span><br><span class="line"><span class="comment"># 先随机生成五组数据</span></span><br><span class="line">rd=np.random.randint(<span class="number">0</span>,<span class="number">80</span>,<span class="number">5</span>)</span><br><span class="line"><span class="comment"># 存储透光率数据</span></span><br><span class="line">y1 = []</span><br><span class="line">y2 = []</span><br><span class="line">y3 = []</span><br><span class="line">y4 = []</span><br><span class="line">y5 = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">700</span>):</span><br><span class="line">    y1.append(cornspect[rd[<span class="number">0</span>], i])</span><br><span class="line">    y2.append(cornspect[rd[<span class="number">1</span>], i])</span><br><span class="line">    y3.append(cornspect[rd[<span class="number">2</span>], i])</span><br><span class="line">    y4.append(cornspect[rd[<span class="number">3</span>], i])</span><br><span class="line">    y5.append(cornspect[rd[<span class="number">4</span>], i])</span><br><span class="line"><span class="comment"># 导入字体</span></span><br><span class="line">matplotlib.rc(<span class="string">&quot;font&quot;</span>,family=<span class="string">&#x27;DengXian&#x27;</span>)</span><br><span class="line"><span class="comment"># 绘制图像</span></span><br><span class="line">fig=plt.figure(<span class="number">1</span>)</span><br><span class="line">plt.plot(x,y1,label=<span class="built_in">str</span>(rd[<span class="number">0</span>])+<span class="string">&#x27;号样本&#x27;</span>)</span><br><span class="line">plt.plot(x,y2,label=<span class="built_in">str</span>(rd[<span class="number">1</span>])+<span class="string">&#x27;号样本&#x27;</span>)</span><br><span class="line">plt.plot(x,y3,label=<span class="built_in">str</span>(rd[<span class="number">2</span>])+<span class="string">&#x27;号样本&#x27;</span>)</span><br><span class="line">plt.plot(x,y4,label=<span class="built_in">str</span>(rd[<span class="number">3</span>])+<span class="string">&#x27;号样本&#x27;</span>)</span><br><span class="line">plt.plot(x,y5,label=<span class="built_in">str</span>(rd[<span class="number">4</span>])+<span class="string">&#x27;号样本&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加图例</span></span><br><span class="line">plt.legend()</span><br><span class="line"><span class="comment"># 添加网格</span></span><br><span class="line">plt.grid(linestyle=<span class="string">&#x27;-.&#x27;</span>)</span><br><span class="line"><span class="comment"># 添加坐标轴名称</span></span><br><span class="line">plt.xlabel(<span class="string">&quot;波长/nm&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;吸光率&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># 绘制蛋白质等</span></span><br><span class="line">plt.clf()</span><br><span class="line"><span class="comment"># 导入玉米特征矩阵</span></span><br><span class="line">cornprop=data[<span class="string">&#x27;cornprop&#x27;</span>]</span><br><span class="line"><span class="comment"># 水分</span></span><br><span class="line">Moisture=cornprop[:,<span class="number">0</span>]</span><br><span class="line"><span class="comment"># 油脂</span></span><br><span class="line">Oil=cornprop[:,<span class="number">1</span>]</span><br><span class="line"><span class="comment"># 蛋白质</span></span><br><span class="line">Protein=cornprop[:,<span class="number">2</span>]</span><br><span class="line"><span class="comment"># 淀粉</span></span><br><span class="line">Starch=cornprop[:,<span class="number">3</span>]</span><br><span class="line"><span class="comment"># 随机抽取绘制饼图</span></span><br><span class="line">plt.pie(cornprop[rd[<span class="number">4</span>],:],labels=[<span class="string">&#x27;Moisture&#x27;</span>,<span class="string">&#x27;Oil&#x27;</span>,<span class="string">&#x27;Protein &#x27;</span>,<span class="string">&#x27;Starch&#x27;</span>],explode=(<span class="number">0</span>, <span class="number">0.2</span>, <span class="number">0</span>, <span class="number">0</span>),autopct=<span class="string">&#x27;%.2f%%&#x27;</span>)</span><br><span class="line">plt.title(<span class="built_in">str</span>(rd[<span class="number">4</span>])+<span class="string">&#x27;号样本的化学成分饼图&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.clf()</span><br><span class="line"><span class="comment"># 生成一个序号</span></span><br><span class="line">x=np.linspace(<span class="number">1</span>,<span class="number">80</span>,<span class="number">80</span>)</span><br><span class="line"><span class="comment"># 绘制不同化学成分的比较</span></span><br><span class="line">plt.plot(x,Moisture,label=<span class="string">&#x27;水分&#x27;</span>)</span><br><span class="line">plt.plot(x,Oil,label=<span class="string">&#x27;油脂&#x27;</span>)</span><br><span class="line">plt.plot(x,Protein,label=<span class="string">&#x27;蛋白质&#x27;</span>)</span><br><span class="line">plt.plot(x,Starch,label=<span class="string">&#x27;淀粉&#x27;</span>)</span><br><span class="line"><span class="comment"># 添加标题</span></span><br><span class="line">plt.title(<span class="string">&#x27;化学成分对比图&#x27;</span>)</span><br><span class="line"><span class="comment"># 添加坐标轴</span></span><br><span class="line">plt.xlabel(<span class="string">&#x27;X&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Y&#x27;</span>)</span><br><span class="line"><span class="comment"># 添加图例</span></span><br><span class="line">plt.legend(loc=<span class="string">&#x27;right&#x27;</span>)</span><br><span class="line"><span class="comment"># 添加网格</span></span><br><span class="line">plt.grid(linestyle=<span class="string">&#x27;-.&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">plt.clf()</span><br><span class="line"><span class="comment"># 求各个属性均值</span></span><br><span class="line">Moisture_ave=np.mean(Moisture)</span><br><span class="line">Oil_ave=np.mean(Oil)</span><br><span class="line">Protein_ave=np.mean(Protein)</span><br><span class="line">Starch_ave=np.mean(Starch)</span><br><span class="line"><span class="comment"># 设置权重</span></span><br><span class="line">weight=[Moisture_ave,Oil_ave,Protein_ave,Starch_ave]</span><br><span class="line"><span class="comment"># 设置序列点</span></span><br><span class="line">x=np.linspace(<span class="number">0</span>,<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line"><span class="comment"># 绘制柱状图</span></span><br><span class="line">plt.barh(x,weight,tick_label=[<span class="string">&#x27;Moisture&#x27;</span>,<span class="string">&#x27;Oil&#x27;</span>,<span class="string">&#x27;Protein &#x27;</span>,<span class="string">&#x27;Starch&#x27;</span>])</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Attribute&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Attribute_mean&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;各属性均值图&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>根据样本，可大概观察出1400波长以上透光率相对变化比较明显</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221002234045488.png" alt="image-20221002234045488"  /><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221002234758742.png" alt="image-20221002234758742"  /></p><p>各属性对比饼图，属性均值图：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221002234112149.png" alt="image-20221002234112149"  /></p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221002234218414.png" alt="image-20221002234218414"  /></p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221003002332397.png"alt="image-20221003002332397" /><figcaption aria-hidden="true">image-20221003002332397</figcaption></figure><h2 id="总结-1">总结</h2><p>mat数据集中可能存在结构体，通过scipy导入后，会自动将结构体转换为ndarray的结构数组；会将所有属性统一封装成dict，通过k-v取出。</p><h1 id="实验三-python矩阵运算">实验三 Python矩阵运算</h1><h2 id="实验目的-2">实验目的</h2><ol type="1"><li>掌握Python中的矩阵运算</li><li>尝试使用特征值分解协方差矩阵的方式进行降维</li></ol><h2 id="实验场地与设备-2">实验场地与设备</h2><p>实验室4074</p><h2 id="实验方式-2">实验方式</h2><p>程序设计</p><h2 id="实验设计-2">实验设计</h2><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/%E5%AE%9E%E9%AA%8C%E4%B8%89.png"alt="实验三" /><figcaption aria-hidden="true">实验三</figcaption></figure><h2 id="实验内容-2">实验内容</h2><h3 id="矩阵乘积">矩阵乘积</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">基本矩阵运算练习</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 矩阵乘法</span></span><br><span class="line">x=np.linspace(<span class="number">0</span>,<span class="number">8</span>,<span class="number">9</span>).reshape(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">y=np.linspace(<span class="number">1</span>,<span class="number">9</span>,<span class="number">9</span>).reshape(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"><span class="comment"># 内积</span></span><br><span class="line">innerZ=np.inner(x,y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;矩阵内积：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(innerZ)</span><br><span class="line"><span class="comment"># 张量积</span></span><br><span class="line">outerZ=np.outer(x,y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;矩阵张量积：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(outerZ)</span><br><span class="line"><span class="comment"># 线性代数矩阵乘法</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;线性代数矩阵乘法&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(np.dot(x,y))</span><br></pre></td></tr></table></figure><p>运行结果：<img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221016202747098.png" alt="image-20221016202747098" style="zoom: 67%;" /></p><h3 id="范数">范数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 范数</span></span><br><span class="line"><span class="comment"># 初始化一个向量</span></span><br><span class="line">a=np.linspace(<span class="number">0</span>,<span class="number">9</span>,<span class="number">10</span>)</span><br><span class="line"><span class="comment"># 向量二范数</span></span><br><span class="line">a_norm = np.linalg.norm(a,<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;向量a的二范数为&quot;</span>,a_norm)</span><br><span class="line"><span class="comment"># 矩阵二范数</span></span><br><span class="line">x_norm =np.linalg.norm(x,<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;矩阵x的二范数为&quot;</span>,x_norm)</span><br><span class="line"><span class="comment"># 向量p范数</span></span><br><span class="line">a_norm = np.linalg.norm(a,np.inf) <span class="comment">#调用np中的变量inf表示无穷</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;向量a的p范数为&quot;</span>,a_norm)</span><br><span class="line"><span class="comment"># 矩阵p范数</span></span><br><span class="line">x_norm =np.linalg.norm(x,np.inf)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;矩阵x的二范数为&quot;</span>,x_norm)</span><br></pre></td></tr></table></figure><p>运行结果为：<imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221016202949373.png"alt="image-20221016202949373" /></p><h3 id="迹">迹</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 矩阵的迹</span></span><br><span class="line">x_trace = np.trace(x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;矩阵x的迹:&quot;</span>,x_trace)</span><br></pre></td></tr></table></figure><p>运行结果为：<imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221016203045259.png"alt="image-20221016203045259" /></p><h3 id="奇异值分解">奇异值分解</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入数据集</span></span><br><span class="line">data=sio.loadmat(<span class="string">&quot;NIRcorn.mat&quot;</span>)</span><br><span class="line"><span class="comment"># 获取玉米化学成分含量数据</span></span><br><span class="line">cornprop=data[<span class="string">&#x27;cornprop&#x27;</span>]</span><br><span class="line">cornprop=np.array(cornprop)</span><br><span class="line"><span class="comment"># 数据标准化</span></span><br><span class="line">scaler = StandardScaler(copy=<span class="literal">True</span>)</span><br><span class="line">cornprop=scaler.fit_transform(cornprop)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机抽样</span></span><br><span class="line"><span class="comment"># 随机抽取6个样本</span></span><br><span class="line">ran=np.random.randint(<span class="number">0</span>,<span class="number">80</span>,<span class="number">6</span>)</span><br><span class="line">cornpropSample1=cornprop[ran][:]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;随机抽取6个样本结果&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(cornpropSample1)</span><br><span class="line"><span class="comment"># 奇异值分解</span></span><br><span class="line">u1,e1,v1=np.linalg.svd(cornpropSample1)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;左矩阵U：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(u1)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;奇异值为：&quot;</span>,e1)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;右矩阵V^T：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(np.transpose(v1))</span><br></pre></td></tr></table></figure><p>运行结果为：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221016203239743.png" alt="image-20221016203239743" style="zoom:67%;" /></p><h3 id="特征值和奇异值比较">特征值和奇异值比较</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">随机抽取四个样本，对奇异值和特征值进行对比</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 随机抽取4个</span></span><br><span class="line">ran1=np.random.randint(<span class="number">0</span>,<span class="number">80</span>,<span class="number">4</span>)</span><br><span class="line">cornpropSample2=cornprop[ran1][:]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;随机抽取4个样本结果&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(cornpropSample2)</span><br><span class="line"><span class="comment"># 奇异值分解</span></span><br><span class="line">u2,e2,v2=np.linalg.svd(cornpropSample2)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;奇异值：&quot;</span>,e2)</span><br><span class="line"><span class="comment"># 判断是否能做特征分解</span></span><br><span class="line"><span class="comment"># 验证rank是否为4</span></span><br><span class="line"><span class="keyword">if</span> np.linalg.matrix_rank(cornpropSample2)==<span class="number">4</span>:</span><br><span class="line">    evalue=np.linalg.eigvals(cornpropSample2)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;特征值：&quot;</span>,evalue)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;秩为：&quot;</span>,np.linalg.matrix_rank(cornpropSample2))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;为不满秩矩阵，无法进行特征分解&quot;</span>)</span><br></pre></td></tr></table></figure><p>运行结果为：<img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221016203500623.png" alt="image-20221016203500623" style="zoom:80%;" /><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221016203531499.png" alt="image-20221016203531499" style="zoom:80%;" /></p><p>结果表明，不是任何一个方阵都能使得奇异值和特征值，奇异值代表的是最大范围的线性变换程度，特征值代表的线性变换时的方向不变量。</p><h3 id="相关性分析">相关性分析</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">进行各个化学成分间的相关性分析</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 求协方差矩阵</span></span><br><span class="line">cov=np.cov(cornprop.transpose())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;协方差矩阵&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(cov)</span><br><span class="line"><span class="comment"># 可视化</span></span><br><span class="line">plt.figure(dpi=<span class="number">120</span>)</span><br><span class="line">sns.heatmap(data=cov,</span><br><span class="line">            cmap=plt.get_cmap(<span class="string">&#x27;Greens_r&#x27;</span>),</span><br><span class="line">            xticklabels=[<span class="string">&#x27;Moisture&#x27;</span>,<span class="string">&#x27;Oil&#x27;</span>,<span class="string">&#x27;Protein &#x27;</span>,<span class="string">&#x27;Starch&#x27;</span>],</span><br><span class="line">            yticklabels=[<span class="string">&#x27;Moisture&#x27;</span>,<span class="string">&#x27;Oil&#x27;</span>,<span class="string">&#x27;Protein &#x27;</span>,<span class="string">&#x27;Starch&#x27;</span>]</span><br><span class="line">           )</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>输出结果为：</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221016204408714.png"alt="image-20221016204408714" /><figcaption aria-hidden="true">image-20221016204408714</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221016204333850.png"alt="image-20221016204333850" /><figcaption aria-hidden="true">image-20221016204333850</figcaption></figure><p>简单观察，可以看出淀粉和蛋白质的呈现负相关且比较强烈，蛋白质和油脂之间的关系呈现正相关。</p><h3 id="pca的初步尝试">PCA的初步尝试</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">协方差可进一步深度挖掘，结合各种矩阵运算进行PCA</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 对协方差矩阵进行特征值分解</span></span><br><span class="line">cov_evalue,cov_vectors = np.linalg.eig(cov)</span><br><span class="line"><span class="comment"># 然后选取前几个维度进行降维即可</span></span><br><span class="line"><span class="comment"># 构造特征矩阵</span></span><br><span class="line">smat = np.zeros((<span class="number">4</span>, <span class="number">4</span>))</span><br><span class="line">smat = np.diag(cov_evalue)</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">p=np.dot(cov_vectors[:<span class="number">2</span>,:],cornpropSample2)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;降维后结果：&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(p)</span><br></pre></td></tr></table></figure><p>输出结果：</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221016204707495.png"alt="image-20221016204707495" /><figcaption aria-hidden="true">image-20221016204707495</figcaption></figure><h2 id="总结-2">总结</h2><p>本次实验为下一节的PCA进行铺垫，也是绝大部分算法的基础。在学习奇异值分解和特征分解的时候，我通过查阅资料终于找到了解决从特征值到特征矩阵构建的方法，非常有成就感。</p><h1 id="实验三-最小二乘法">实验三 最小二乘法</h1><h2 id="实验目的-3">实验目的</h2><ol type="1"><li>生成正定矩阵联系线性回归</li><li>选取部分属性进行最小二乘算法</li><li>掌握最小二乘法</li></ol><h2 id="实验场地与设备-3">实验场地与设备</h2><p>实验室4074</p><h2 id="实验方式-3">实验方式</h2><p>程序设计</p><h2 id="实验设计-3">实验设计</h2><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204184750871.png" alt="image-20230204184750871" style="zoom: 50%;" /></p><h2 id="实验内容-3">实验内容</h2><h3 id="生成正定矩阵使用最小二乘">生成正定矩阵使用最小二乘</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">1.尝试网站代码应用</span></span><br><span class="line"><span class="string">2.理解源代码</span></span><br><span class="line"><span class="string">3.回归源码转化伪代码、流程图</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 导入必要库</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets, linear_model</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error, r2_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入数据集</span></span><br><span class="line">diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 简单分析数据集</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x&quot;</span>,diabetes_X) <span class="comment"># 442*10</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y&quot;</span>,diabetes_y) <span class="comment"># 1*442</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用一个x的特征</span></span><br><span class="line">diabetes_X = diabetes_X[:, np.newaxis, <span class="number">2</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分训练集和测试集</span></span><br><span class="line"><span class="comment"># x</span></span><br><span class="line">diabetes_X_train = diabetes_X[:-<span class="number">20</span>]</span><br><span class="line">diabetes_X_test = diabetes_X[-<span class="number">20</span>:]</span><br><span class="line"><span class="comment"># y</span></span><br><span class="line">diabetes_y_train = diabetes_y[:-<span class="number">20</span>]</span><br><span class="line">diabetes_y_test = diabetes_y[-<span class="number">20</span>:]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建线性回归对象</span></span><br><span class="line">regr = linear_model.LinearRegression()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练线性回归模型</span></span><br><span class="line">regr.fit(diabetes_X_train, diabetes_y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试集预测</span></span><br><span class="line">diabetes_y_pred = regr.predict(diabetes_X_test)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">应该是某种误差，具体得看源码</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># The coefficients</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Coefficients: \n&quot;</span>, regr.coef_)</span><br><span class="line"><span class="comment"># The mean squared error</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Mean squared error: %.2f&quot;</span> % mean_squared_error(diabetes_y_test, diabetes_y_pred))</span><br><span class="line"><span class="comment"># The coefficient of determination: 1 is perfect prediction</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Coefficient of determination: %.2f&quot;</span> % r2_score(diabetes_y_test, diabetes_y_pred))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.scatter(diabetes_X_test, diabetes_y_test, color=<span class="string">&quot;black&quot;</span>)</span><br><span class="line">plt.plot(diabetes_X_test, diabetes_y_pred, color=<span class="string">&quot;blue&quot;</span>, linewidth=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">plt.xticks(())</span><br><span class="line">plt.yticks(())</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204182023479.png"alt="image-20230204182023479" /><figcaption aria-hidden="true">image-20230204182023479</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204182051171.png"alt="image-20230204182051171" /><figcaption aria-hidden="true">image-20230204182051171</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204184117890.png"alt="image-20230204184117890" /><figcaption aria-hidden="true">image-20230204184117890</figcaption></figure><h3 id="选取部分属性进行最小二乘算法">选取部分属性进行最小二乘算法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error, r2_score</span><br><span class="line"></span><br><span class="line">data=sio.loadmat(<span class="string">&quot;../NIRcorn.mat&quot;</span>)</span><br><span class="line"></span><br><span class="line">cornprop = data[<span class="string">&quot;cornprop&quot;</span>][:,<span class="number">0</span>].reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">m5spec=data[<span class="string">&#x27;m5spec&#x27;</span>][<span class="string">&#x27;data&#x27;</span>][<span class="number">0</span>][<span class="number">0</span>][:,<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建线性回归对象</span></span><br><span class="line">regr = linear_model.LinearRegression()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练线性回归模型</span></span><br><span class="line">regr.fit(cornprop,m5spec)</span><br><span class="line">y_pred = regr.predict(cornprop)</span><br><span class="line">plt.scatter(cornprop, m5spec, color=<span class="string">&quot;black&quot;</span>)</span><br><span class="line">plt.plot(cornprop, y_pred, color=<span class="string">&quot;blue&quot;</span>, linewidth=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">plt.xticks(())</span><br><span class="line">plt.yticks(())</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204184257098.png"alt="image-20230204184257098" /><figcaption aria-hidden="true">image-20230204184257098</figcaption></figure><h2 id="总结-3">总结</h2><p>最小二乘法作为线性回归的基础，其数学推导十分重要，深刻理解了最小二乘才能初步理解高维空间中的空间变换以及相关的几何意义。</p><h1 id="实验四-主成分分析">实验四 主成分分析</h1><h2 id="实验目的-4">实验目的</h2><ol type="1"><li>掌握PCA算法原理</li><li>用python实现PCA降维</li><li>体会python面向对象的灵活</li></ol><h2 id="实验场地与设备-4">实验场地与设备</h2><p>实验室4074</p><h2 id="实验方式-4">实验方式</h2><p>程序设计</p><h2 id="实验设计-4">实验设计</h2><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204185133692.png"alt="image-20230204185133692" /><figcaption aria-hidden="true">image-20230204185133692</figcaption></figure><h2 id="实验内容-4">实验内容</h2><h3 id="伪代码">伪代码</h3><figure class="highlight pascal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">input：data,n_components</span><br><span class="line">output：U，S</span><br><span class="line">-----------------------------------------</span><br><span class="line">Data_mean=np.mean(data)</span><br><span class="line">Data=np.substract(data,Data_mean)</span><br><span class="line">cov_X=np.cov(np.transpose(Data))</span><br><span class="line">U,S,V=np.linalg.svd(cov_X)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="python实现">python实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br><span class="line"><span class="keyword">from</span> sklearn.utils.extmath <span class="keyword">import</span> svd_flip</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PCA</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="comment"># 初始化</span></span><br><span class="line">    np.set_printoptions(suppress=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,components</span>):</span><br><span class="line">        self.components=components</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self,X</span>):</span><br><span class="line">        X_mean=np.mean(X)</span><br><span class="line">        X=np.subtract(X,X_mean)</span><br><span class="line">        cov_X=np.cov(np.transpose(X))</span><br><span class="line">        <span class="keyword">if</span> np.linalg.matrix_rank(cov_X)&lt;np.shape(cov_X)[<span class="number">0</span>]:</span><br><span class="line">            U,S,V=np.linalg.svd(cov_X)</span><br><span class="line">            U, V = svd_flip(U, V)</span><br><span class="line">            U=np.array(U[:self.components]).T</span><br><span class="line">            U *= S[:self.components]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            explained_variance_ = (S * S.T) / (np.shape(X)[<span class="number">0</span>] - <span class="number">1</span>)</span><br><span class="line">            total_var = explained_variance_.<span class="built_in">sum</span>()</span><br><span class="line">            explained_variance_ratio_ = explained_variance_ / total_var</span><br><span class="line">            self.explained_variance_ratio_ = explained_variance_ratio_[:self.components]</span><br><span class="line">            <span class="keyword">return</span> U,S</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            eigValue,eigVector=np.linalg.eig(cov_X)</span><br><span class="line">            index = np.argsort(-eigValue)</span><br><span class="line">            <span class="keyword">if</span> self.components &gt; np.shape(X)[<span class="number">1</span>]:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;features is lower than commponents&#x27;</span>)</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                T = np.array(eigVector[index[:self.components]]).T</span><br><span class="line">                P = np.dot(X,T)</span><br><span class="line">                <span class="comment"># 求解解释变量</span></span><br><span class="line">                <span class="comment"># 要不要根据对抽样统计做方差的无偏估计</span></span><br><span class="line">                <span class="comment"># 使用特征值分解一旦不满秩，就会出现复数解</span></span><br><span class="line">                explained_variance_ = (eigValue * eigValue.T)/(np.shape(X)[<span class="number">0</span>]-<span class="number">1</span>)</span><br><span class="line">                total_var = explained_variance_.<span class="built_in">sum</span>()</span><br><span class="line">                explained_variance_ratio_ = explained_variance_ / total_var</span><br><span class="line">                self.explained_variance_ratio_=explained_variance_ratio_[:self.components]</span><br><span class="line">                <span class="keyword">return</span> P,T</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    data = sio.loadmat(<span class="string">&quot;../NIRcorn.mat&quot;</span>)</span><br><span class="line"></span><br><span class="line">    cornprop = data[<span class="string">&quot;cornprop&quot;</span>]</span><br><span class="line">    m5spec = data[<span class="string">&#x27;m5spec&#x27;</span>][<span class="string">&#x27;data&#x27;</span>][<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">    y = data[<span class="string">&#x27;cornprop&#x27;</span>][:, [<span class="number">0</span>]]</span><br><span class="line">    x = m5spec</span><br><span class="line"></span><br><span class="line">    pca=PCA(<span class="number">2</span>)</span><br><span class="line">    U,S=pca.fit(x)</span><br><span class="line">    <span class="built_in">print</span>(</span><br><span class="line">        <span class="string">&quot;explained variance ratio (first two components): %s&quot;</span></span><br><span class="line">        % <span class="built_in">str</span>(pca.explained_variance_ratio_)</span><br><span class="line">    )</span><br></pre></td></tr></table></figure><p>explained variance ratio (first two components): [0.999940010.00005929]</p><h3 id="调用pca降维鸢尾花">调用PCA降维鸢尾花</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line"></span><br><span class="line">X = iris.data</span><br><span class="line">y = iris.target</span><br><span class="line">target_names = iris.target_names</span><br><span class="line"></span><br><span class="line">pca = PCA(n_components=<span class="number">2</span>)</span><br><span class="line">X_r = pca.fit(X).transform(X)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Percentage of variance explained for each components</span></span><br><span class="line"><span class="built_in">print</span>(</span><br><span class="line">    <span class="string">&quot;explained variance ratio (first two components): %s&quot;</span></span><br><span class="line">    % <span class="built_in">str</span>(pca.explained_variance_ratio_)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">colors = [<span class="string">&quot;navy&quot;</span>, <span class="string">&quot;turquoise&quot;</span>, <span class="string">&quot;darkorange&quot;</span>]</span><br><span class="line">lw = <span class="number">2</span></span><br><span class="line"><span class="keyword">for</span> color, i, target_name <span class="keyword">in</span> <span class="built_in">zip</span>(colors, [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], target_names):</span><br><span class="line">    plt.scatter(</span><br><span class="line">        <span class="comment"># y==i是一个推导式，本质上是返回一个布尔数组，从而达成筛选的目的</span></span><br><span class="line">        X_r[y == i, <span class="number">0</span>], X_r[y == i, <span class="number">1</span>], color=color, alpha=<span class="number">0.8</span>, lw=lw, label=target_name</span><br><span class="line">    )</span><br><span class="line">plt.legend(loc=<span class="string">&quot;best&quot;</span>, shadow=<span class="literal">False</span>, scatterpoints=<span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">&quot;PCA of IRIS dataset&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204185710362.png"alt="image-20230204185710362" /><figcaption aria-hidden="true">image-20230204185710362</figcaption></figure><h3 id="调用pca降维nircorn">调用pca降维NIRcorn</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"></span><br><span class="line">data=sio.loadmat(<span class="string">&quot;../NIRcorn.mat&quot;</span>)</span><br><span class="line"></span><br><span class="line">cornprop = data[<span class="string">&quot;cornprop&quot;</span>]</span><br><span class="line">m5spec=data[<span class="string">&#x27;m5spec&#x27;</span>][<span class="string">&#x27;data&#x27;</span>][<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># x_mean=np.mean(m5spec)</span></span><br><span class="line"><span class="comment"># x_center=np.subtract(m5spec,x_mean)</span></span><br><span class="line"></span><br><span class="line">pca = PCA(n_components=<span class="number">2</span>)</span><br><span class="line">x = pca.fit(m5spec).transform(m5spec)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(</span><br><span class="line">    <span class="string">&quot;explained variance ratio (first two components): %s&quot;</span></span><br><span class="line">    % <span class="built_in">str</span>(pca.explained_variance_ratio_)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">plt.scatter(x[:,<span class="number">0</span>],x[:,<span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204185800726.png" /></p><h2 id="总结-4">总结</h2><p>主成分分析是基于投影的方法，而衡量投影距离的就是协方差矩阵。而对于协方差矩阵的分解方式就显得尤为重要，我自己实现的PCA与sklearn种出现显著差异的原因就是在奇异值分解的方式。sklearn采用的是随机奇异值分解。</p><h1 id="实验五-主成分回归">实验五 主成分回归</h1><h2 id="实验目的-5">实验目的</h2><ol type="1"><li>掌握PCR算法原理</li><li>掌握交叉验证算法应用；</li><li>体会python面向对象的灵活</li></ol><h2 id="实验场地与设备-5">实验场地与设备</h2><p>实验室4074</p><h2 id="实验方式-5">实验方式</h2><p>程序设计</p><h2 id="实验设计-5">实验设计</h2><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204194417158.png" alt="image-20230204194417158" style="zoom:50%;" /></p><h2 id="实验内容-5">实验内容</h2><h3 id="伪代码-1">伪代码</h3><figure class="highlight pascal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">PCR.fit</span><br><span class="line">-----------------------------</span><br><span class="line">input:X,y,n_components</span><br><span class="line">output:P,b</span><br><span class="line">------------------------------</span><br><span class="line">P = PCA(X,n_components)</span><br><span class="line">T = X*P</span><br><span class="line">b = LS.fit(T,y)</span><br></pre></td></tr></table></figure><figure class="highlight pascal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">PCR.predict</span><br><span class="line">-----------------------------</span><br><span class="line">input:X,P,b</span><br><span class="line">output:y_predict</span><br><span class="line">-----------------------------</span><br><span class="line">T = X*P</span><br><span class="line">y_predict = T*b</span><br></pre></td></tr></table></figure><figure class="highlight pascal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">PCR.cv</span><br><span class="line">-----------------------------</span><br><span class="line">input:X,y,max_pcs,k</span><br><span class="line">output:best_pcs</span><br><span class="line">-----------------------------X_train,X_val,y_train,y_val = cross validation.split(X,y,k)</span><br><span class="line">  <span class="keyword">for</span> n_pcs <span class="keyword">in</span> range(<span class="number">2</span>,max_pcs+<span class="number">1</span>):</span><br><span class="line">   y_predict = [ ]</span><br><span class="line">   <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,k):</span><br><span class="line">   P,b = PCR.fit(X_train=X_k≠i,y_train=y_k≠i,n_pcs)</span><br><span class="line">   ypre = PCR.predict(X_val=X_k=i,P,b)</span><br><span class="line">   y_predict.append(ypre)</span><br><span class="line">   RMSE(y,y_predict,len(y))</span><br><span class="line">  best_pcs = RMSE.<span class="keyword">index</span>(min(RMSE))</span><br><span class="line"> return best_pcs</span><br></pre></td></tr></table></figure><h3 id="python实现-1"><strong>Python实现</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> cross_validation</span><br><span class="line"><span class="comment"># from sklearn.decomposition import PCA</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Cross_Validation</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, x, y, n_folds, max_components</span>):</span><br><span class="line">        self.x = x</span><br><span class="line">        self.y = y</span><br><span class="line">        self.n_folds = n_folds</span><br><span class="line">        self.max_components = max_components</span><br><span class="line">        self.n = x.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">CV</span>(<span class="params">self</span>):</span><br><span class="line">        kf = cross_validation.KFold(self.n, self.n_folds)</span><br><span class="line">        x_train=[]</span><br><span class="line">        x_test=[]</span><br><span class="line">        y_train=[]</span><br><span class="line">        y_test=[]</span><br><span class="line">        <span class="keyword">for</span> train_index,test_index <span class="keyword">in</span> kf:</span><br><span class="line">            xtr, xte = self.x[train_index], self.x[test_index]</span><br><span class="line">            ytr, yte = self.y[train_index], self.y[test_index]</span><br><span class="line">            x_train.append(xtr)</span><br><span class="line">            x_test.append(xte)</span><br><span class="line">            y_train.append(ytr)</span><br><span class="line">            y_test.append(yte)</span><br><span class="line">        <span class="keyword">return</span> x_train, x_test, y_train, y_test</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br><span class="line"><span class="keyword">from</span> Cross_Validation <span class="keyword">import</span> Cross_Validation</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PCR</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, max_components</span>):</span><br><span class="line">        self.max_components=max_components</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self,X,y,best_components</span>):</span><br><span class="line">        self.x_mean = np.mean(X, axis=<span class="number">0</span>)</span><br><span class="line">        self.y_mean = np.mean(y, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># sklearn中的pca自带中心化处理</span></span><br><span class="line">        pca=PCA(n_components=best_components)</span><br><span class="line">        pca=pca.fit(X)</span><br><span class="line">        X_r=pca.transform(X)</span><br><span class="line">        b=np.linalg.lstsq(X_r,np.subtract(y,self.y_mean))[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">return</span> b,pca</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">pridict</span>(<span class="params">self,b,X,pca</span>):</span><br><span class="line">        T=pca.transform(X)</span><br><span class="line">        y_pre = np.dot(T, b)</span><br><span class="line">        y_predict = np.add(y_pre, self.y_mean)</span><br><span class="line">        <span class="keyword">return</span> y_predict</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">cv_pridict</span>(<span class="params">self,X,y,n_fold,</span>):</span><br><span class="line">        cv = Cross_Validation(X,y,n_fold,self.max_components)</span><br><span class="line">        X_train, X_test, y_train, y_test = cv.CV()</span><br><span class="line">        y_allPredict=np.ones((<span class="number">1</span>,self.max_components))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_fold):</span><br><span class="line">            y_predict=np.zeros((y_test[i].shape[<span class="number">0</span>],self.max_components))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(self.max_components):</span><br><span class="line">                b,pca=self.fit(X_train[i],y_train[i],j+<span class="number">1</span>)</span><br><span class="line">                y_pre=self.pridict(b,X_test[i],pca)</span><br><span class="line">                y_predict[:,j]=y_pre.ravel()</span><br><span class="line"></span><br><span class="line">            y_allPredict=np.vstack((y_allPredict,y_predict))</span><br><span class="line">        y_allPredict=y_allPredict[<span class="number">1</span>:]</span><br><span class="line">        <span class="keyword">return</span> y_allPredict,cv</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">RMSE_CV</span>(<span class="params">self,y_allPredict, y_measure,cv</span>):</span><br><span class="line">        press = np.square(np.subtract(y_allPredict, y_measure))</span><br><span class="line">        press_all = np.<span class="built_in">sum</span>(press, axis=<span class="number">0</span>)</span><br><span class="line">        RMSECV = np.sqrt(press_all / cv.n)</span><br><span class="line">        min_RMSECV = <span class="built_in">min</span>(RMSECV)</span><br><span class="line">        comp_array = RMSECV.argsort()</span><br><span class="line">        comp_best = comp_array[<span class="number">0</span>] + <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> RMSECV, min_RMSECV, comp_best</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">show_Select_comp</span>(<span class="params">self,RMSECV</span>):</span><br><span class="line">        x=np.linspace(<span class="number">1</span>,<span class="number">20</span>,<span class="number">20</span>)</span><br><span class="line">        plt.figure()</span><br><span class="line">        plt.plot(x,RMSECV)</span><br><span class="line">        plt.ylabel(RMSECV)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;n_comp&#x27;</span>)</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    data = sio.loadmat(<span class="string">&quot;../NIRcorn.mat&quot;</span>)</span><br><span class="line"></span><br><span class="line">    cornprop = data[<span class="string">&quot;cornprop&quot;</span>]</span><br><span class="line">    m5spec = data[<span class="string">&#x27;m5spec&#x27;</span>][<span class="string">&#x27;data&#x27;</span>][<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">    y = data[<span class="string">&#x27;cornprop&#x27;</span>][:, [<span class="number">0</span>]]</span><br><span class="line">    x=m5spec</span><br><span class="line">    y_mean=np.mean(y,axis=<span class="number">0</span>)</span><br><span class="line">    pcr=PCR(<span class="number">20</span>)</span><br><span class="line">    b,pca=pcr.fit(x,y,<span class="number">14</span>)</span><br><span class="line">    y_pre=pcr.pridict(b,x,pca)</span><br><span class="line">    <span class="built_in">print</span>(y)</span><br><span class="line">    <span class="built_in">print</span>(y_pre)</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    # 预测图显示</span></span><br><span class="line"><span class="string">    plt.figure()</span></span><br><span class="line"><span class="string">    plt.scatter(np.linspace(1,80,80),y_pre)</span></span><br><span class="line"><span class="string">    plt.scatter(np.linspace(1, 80, 80),y)</span></span><br><span class="line"><span class="string">    plt.show()</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    y_pre,cv=pcr.cv_pridict(x,y,<span class="number">10</span>)</span><br><span class="line">    <span class="built_in">print</span>(y_pre)</span><br><span class="line">    RMSEcv,min_RMSEcv,best_comp=pcr.RMSE_CV(y_pre,cv.y,cv)</span><br><span class="line">    <span class="built_in">print</span>(RMSEcv)</span><br><span class="line">    pcr.show_Select_comp(RMSEcv)</span><br><span class="line"><span class="comment"># &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>参数选择：<imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204192233033.png"alt="image-20230204192233033" /></p><p>预测结果：</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204192338375.png"alt="image-20230204192338375" /><figcaption aria-hidden="true">image-20230204192338375</figcaption></figure><h2 id="总结-5">总结</h2><p>主成分回归分析(PCR)，以主成分为自变量进行的回归分析。是分析多元共线性问题的一种方法，当自变量存在复共线性刚，用于改进最小二乘回归的统计分析方法。霍特林1933年首先用主成分分析相关结构，1965年马西提出主成分回归。</p><p>基本步骤：</p><p>（1）将自变量转换为标准分；</p><p>（2）求出这此标准分的主成分，去掉特征根很小的主成分；</p><p>（3）用最小二乘法作因变量对保留的主成分的回归；</p><p>（4）将回归方程中的主成分换成标准分的线性组合，得到由标准分给出的回归方程</p><p>在实现过程中，注意到一点，self在python面向对象的活用，可以大幅度减少变量定义，而且可以作为全局变量跳出循环中，非常好用。</p><h1 id="实验六-偏最小二乘算法">实验六 偏最小二乘算法</h1><h2 id="实验目的-6">实验目的</h2><ol type="1"><li>实现NIPALS算法并对nircorn数据集进行预测</li><li>掌握交叉验证算法应用；</li><li>实现PLS算法</li></ol><h2 id="实验场地与设备-6">实验场地与设备</h2><p>实验室4074</p><h2 id="实验方式-6">实验方式</h2><p>程序设计</p><h2 id="实验设计-6">实验设计</h2><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204194521892.png" alt="image-20230204194521892" style="zoom:50%;" /></p><h2 id="实验内容-6">实验内容</h2><h3 id="nipls伪代码">NIPLS伪代码</h3><figure class="highlight pascal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">NIPALS.py</span><br><span class="line">--------------------------------------------</span><br><span class="line">input: X,Y,n_comp</span><br><span class="line">output:P,Q,T,U,W,C</span><br><span class="line">--------------------------------------------</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(n_comp):</span><br><span class="line">    u_new=Y[i+<span class="number">1</span>]</span><br><span class="line">    u_old=np.ones((Y.shape[i+<span class="number">1</span>],<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> || u_new-u_old ||&gt;=<span class="number">0.0001</span>(极小值):</span><br><span class="line">        u_old=u_new</span><br><span class="line">        w = X^T * u_new / ( u_old^T * u_old )</span><br><span class="line">        w = w / sqrt(w^T * w)</span><br><span class="line">        t = X * w</span><br><span class="line">        c = Y * t /( t^T * t )</span><br><span class="line">        c = c / sqrt(c^T * c)</span><br><span class="line">        u_new = Y * c</span><br><span class="line"></span><br><span class="line">    p = X * t / ( t^T * t )</span><br><span class="line">    q = Y * c / ( c^T * c )</span><br><span class="line">    X1 = X - t * p^T</span><br><span class="line">    b1 = u_new^T * t / ( t^T * t )</span><br><span class="line">    Y1 = Y - b * t * q^T</span><br><span class="line"></span><br><span class="line">    B[n_comp,:]=b</span><br><span class="line">    P[:,n_comp]=p</span><br><span class="line">    Q[:,n_comp]=q</span><br><span class="line">    T[:,n_comp]=t</span><br><span class="line">    U[:,n_comp]=u_new</span><br><span class="line">    W[:,n_comp]=w</span><br><span class="line">    C[:,n_comp]=c</span><br><span class="line">--------------------------------------------</span><br></pre></td></tr></table></figure><h3 id="nipls实现">NIPLS实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> linalg</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NIPALS</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, max_pcs, sigma=<span class="number">0.0001</span></span>):</span><br><span class="line"></span><br><span class="line">        self.max_pcs = max_pcs</span><br><span class="line">        self.sigma = sigma</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, X, Y</span>):</span><br><span class="line">        E, F = X, Y</span><br><span class="line">        P = np.mat(np.ones((X.shape[<span class="number">1</span>], self.max_pcs)))  <span class="comment"># X载荷矩阵——P</span></span><br><span class="line">        T = np.mat(np.ones((X.shape[<span class="number">0</span>], self.max_pcs)))  <span class="comment"># X得分矩阵——T</span></span><br><span class="line">        W = np.mat(np.ones((X.shape[<span class="number">1</span>], self.max_pcs)))  <span class="comment"># X权重矩阵——W</span></span><br><span class="line">        Q = np.mat(np.ones((Y.shape[<span class="number">1</span>], self.max_pcs)))  <span class="comment"># Y载荷矩阵——Q</span></span><br><span class="line">        U = np.mat(np.ones((X.shape[<span class="number">0</span>], self.max_pcs)))  <span class="comment"># Y得分矩阵——U</span></span><br><span class="line">        C = np.mat(np.ones((Y.shape[<span class="number">1</span>], self.max_pcs)))  <span class="comment"># Y权重矩阵C</span></span><br><span class="line">        B = np.ones((self.max_pcs, X.shape[<span class="number">1</span>], Y.shape[<span class="number">1</span>]))</span><br><span class="line">        <span class="keyword">for</span> pcs <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, self.max_pcs):</span><br><span class="line"></span><br><span class="line">            t_old, t_new = np.zeros((X.shape[<span class="number">0</span>], <span class="number">1</span>)), np.ones((X.shape[<span class="number">0</span>], <span class="number">1</span>))  <span class="comment"># (64,1)</span></span><br><span class="line">            p_old, p_new = np.ones((X.shape[<span class="number">1</span>], <span class="number">1</span>)), np.ones((X.shape[<span class="number">1</span>], <span class="number">1</span>))  <span class="comment"># (700,1)</span></span><br><span class="line">            w_old, w_new = np.ones((X.shape[<span class="number">1</span>], <span class="number">1</span>)), np.ones((X.shape[<span class="number">1</span>], <span class="number">1</span>))  <span class="comment"># (700,1)</span></span><br><span class="line">            q_old, q_new = np.ones((Y.shape[<span class="number">1</span>], <span class="number">1</span>)), np.ones((Y.shape[<span class="number">1</span>], <span class="number">1</span>))  <span class="comment"># (4,1)</span></span><br><span class="line">            u_old, u_new = np.mat(Y[:, <span class="number">0</span>]).T, np.ones((X.shape[<span class="number">0</span>], <span class="number">1</span>))  <span class="comment"># (64,1)</span></span><br><span class="line">            <span class="keyword">while</span> (np.sqrt(np.<span class="built_in">sum</span>(np.square(np.subtract(t_new, t_old)) / t_new.shape[<span class="number">0</span>])) &gt; self.sigma):</span><br><span class="line">                t_old = t_new</span><br><span class="line">                w_old = (np.dot(u_old.T, X) / np.dot(u_old.T, u_old)).T</span><br><span class="line">                w_new = (w_old.T / np.sqrt(np.dot(w_old.T, w_old))).T</span><br><span class="line">                t_new = np.dot(X, w_new) / np.dot(w_new.T, w_new)</span><br><span class="line">                q_old = (np.dot(t_new.T, Y) / np.dot(t_new.T, t_new)).T</span><br><span class="line">                q_new = (q_old.T / np.linalg.norm(q_old.T)).T</span><br><span class="line">                u_new = np.dot(Y, q_new) / np.dot(q_new.T, q_new)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (Y.shape[<span class="number">1</span>] == <span class="number">1</span>):  <span class="comment"># 判断Y是否是一维</span></span><br><span class="line">                p_old = (np.dot(t_new.T, X) / np.dot(t_new.T, t_new)).T</span><br><span class="line">                p_new = (p_old.T / np.linalg.norm(p_old.T)).T</span><br><span class="line">                t_new = t_old * np.linalg.norm(p_old.T)</span><br><span class="line">                w_new = (w_old.T * np.linalg.norm(p_old.T)).T</span><br><span class="line"></span><br><span class="line">            b = np.dot(np.dot(w_new, linalg.inv(np.dot(p_new.T, w_new))), q_new.T)</span><br><span class="line"></span><br><span class="line">            P[:, pcs] = p_new  <span class="comment"># 保存p</span></span><br><span class="line">            T[:, pcs] = t_new  <span class="comment"># 保存t</span></span><br><span class="line">            W[:, pcs] = w_new  <span class="comment"># 保存w</span></span><br><span class="line">            B[pcs, ::] = b  <span class="comment"># 保存b</span></span><br><span class="line">            Q[:, pcs] = q_new  <span class="comment"># 保存q</span></span><br><span class="line">            U[:, pcs] = u_new  <span class="comment"># 保存u</span></span><br><span class="line">            E = E - np.dot(t_new, p_new.T)</span><br><span class="line">            F = F - np.dot(t_new, q_new.T)</span><br><span class="line">            self.X = E</span><br><span class="line">            self.Y = F</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> P, T, W, Q, U, B</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, X, B, best_pcs</span>):</span><br><span class="line">        B_new = np.zeros((B[<span class="number">0</span>].shape[<span class="number">0</span>], B[<span class="number">0</span>].shape[<span class="number">1</span>]))</span><br><span class="line">        B_new[:] = B[best_pcs - <span class="number">1</span>]</span><br><span class="line">        Y_predict = np.dot(X, B_new)</span><br><span class="line">        <span class="keyword">return</span> Y_predict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">RMSE</span>(<span class="params">y, y_predict, k</span>):</span><br><span class="line">    press = np.square(np.subtract(y, y_predict))</span><br><span class="line">    press_all = np.<span class="built_in">sum</span>(press, axis=<span class="number">0</span>)</span><br><span class="line">    RMSE = np.sqrt(press_all / k)</span><br><span class="line">    <span class="keyword">return</span> RMSE</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 导入数据</span></span><br><span class="line">    data = sio.loadmat(<span class="string">&quot;../NIRcorn.mat&quot;</span>)</span><br><span class="line">    cornprop = data[<span class="string">&quot;cornprop&quot;</span>]</span><br><span class="line">    Y = cornprop</span><br><span class="line">    <span class="built_in">print</span>(np.shape(Y))</span><br><span class="line">    A = data[<span class="string">&quot;m5spec&quot;</span>]</span><br><span class="line">    m5spec = A[<span class="string">&quot;data&quot;</span>][<span class="number">0</span>][<span class="number">0</span>]  <span class="comment"># 80*700矩阵</span></span><br><span class="line">    <span class="comment"># 划分数据集</span></span><br><span class="line">    X_train, X_test, y_train, y_test = train_test_split(m5spec, Y, test_size=<span class="number">0.2</span>, random_state=<span class="number">0</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;X_train:&quot;</span>, X_train.shape)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;X_test:&quot;</span>, X_test.shape)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;y_train:&quot;</span>, y_train.shape)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;y_test:&quot;</span>, y_test.shape)</span><br><span class="line">    <span class="comment"># 将训练集中心化</span></span><br><span class="line">    X_mean = np.mean(X_train, axis=<span class="number">0</span>)</span><br><span class="line">    X_center = np.subtract(X_train, X_mean)</span><br><span class="line">    Y_mean = np.mean(y_train, axis=<span class="number">0</span>)</span><br><span class="line">    Y_center = np.subtract(y_train, Y_mean)</span><br><span class="line">    X_test_mean = np.mean(X_test, axis=<span class="number">0</span>)</span><br><span class="line">    X_test_center = np.subtract(X_test, X_test_mean)</span><br><span class="line">    pls = NIPALS(<span class="number">5</span>)</span><br><span class="line">    P, T, W, Q, U, B = pls.fit(X_center, Y_center)</span><br><span class="line">    Y_predict = pls.predict(X_test_center, B, <span class="number">2</span>)</span><br><span class="line">    Ypre = Y_predict + Y_mean</span><br><span class="line">    rmse = RMSE(y_test.ravel(), Ypre.ravel(), Y_center.shape[<span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Y_predict:&quot;</span>, Ypre)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;rmse:&quot;</span>, rmse)</span><br></pre></td></tr></table></figure><p>rmse: 0.5119355259810657</p><h3 id="pls实现">PLS实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cross_decomposition <span class="keyword">import</span> PLSRegression</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> Cross_Validation <span class="keyword">import</span> Cross_Validation</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">pls</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,max_comp</span>):</span><br><span class="line">        self.max_comp=max_comp</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self,X,Y,n_comp</span>):</span><br><span class="line">        pls=PLSRegression(n_components=n_comp)</span><br><span class="line">        pls.fit(X,Y)</span><br><span class="line">        <span class="keyword">return</span> pls</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self,X,pls</span>):</span><br><span class="line">        <span class="keyword">return</span> pls.predict(X)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">cv_predict</span>(<span class="params">self,X,y,n_fold</span>):</span><br><span class="line">        cv = Cross_Validation(X, y, n_fold, self.max_comp)</span><br><span class="line">        X_train, X_test, y_train, y_test = cv.CV()</span><br><span class="line">        y_allPredict = np.ones((<span class="number">1</span>, self.max_comp))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_fold):</span><br><span class="line">            y_predict = np.zeros((y_test[i].shape[<span class="number">0</span>], self.max_comp))</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(self.max_comp):</span><br><span class="line">                pls=self.fit(X_train[i],y_train[i],j+<span class="number">1</span>)</span><br><span class="line">                y_pre=self.predict(X_test[i],pls)</span><br><span class="line">                y_predict[:,j]=y_pre.ravel()</span><br><span class="line">            y_allPredict = np.vstack((y_allPredict, y_predict))</span><br><span class="line">        y_allPredict = y_allPredict[<span class="number">1</span>:]</span><br><span class="line">        <span class="keyword">return</span> y_allPredict, cv,y_test,y_train,X_test,X_train</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">RMSE_CV</span>(<span class="params">self, y_allPredict, y_measure, cv</span>):</span><br><span class="line">        press = np.square(np.subtract(y_allPredict, y_measure))</span><br><span class="line">        press_all = np.<span class="built_in">sum</span>(press, axis=<span class="number">0</span>)</span><br><span class="line">        RMSECV = np.sqrt(press_all / cv.n)</span><br><span class="line">        min_RMSECV = <span class="built_in">min</span>(RMSECV)</span><br><span class="line">        comp_array = RMSECV.argsort()</span><br><span class="line">        comp_best = comp_array[<span class="number">0</span>] + <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> RMSECV, min_RMSECV, comp_best</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">show_Select_comp</span>(<span class="params">self,RMSECV</span>):</span><br><span class="line">        x=np.linspace(<span class="number">1</span>,<span class="number">20</span>,<span class="number">20</span>)</span><br><span class="line">        plt.figure()</span><br><span class="line">        plt.plot(x,RMSECV,marker=<span class="string">&#x27;^&#x27;</span>,markersize=<span class="number">10</span>,markerfacecolor=<span class="string">&#x27;orange&#x27;</span>,color=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;num_components&#x27;</span>)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;RMSECV&#x27;</span>)</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">show_predict</span>(<span class="params">self,y</span>):</span><br><span class="line">        plt.figure()</span><br><span class="line">        plt.plot([<span class="built_in">min</span>(y), <span class="built_in">max</span>(y)], [<span class="built_in">min</span>(y), <span class="built_in">max</span>(y)], label=<span class="string">&#x27;y=x&#x27;</span>, color=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">        plt.scatter(y, y_pre, color=<span class="string">&#x27;red&#x27;</span>, label=<span class="string">&#x27;y_all&#x27;</span>)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;measure value&#x27;</span>)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;predict value&#x27;</span>)</span><br><span class="line">        plt.legend()</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">show_predict</span>(<span class="params">self,y,y_pre</span>):</span><br><span class="line">        plt.figure()</span><br><span class="line">        plt.plot([<span class="built_in">min</span>(y), <span class="built_in">max</span>(y)], [<span class="built_in">min</span>(y), <span class="built_in">max</span>(y)], label=<span class="string">&#x27;y=x&#x27;</span>, color=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">        plt.scatter(y, y_pre, color=<span class="string">&#x27;red&#x27;</span>, label=<span class="string">&#x27;y_all&#x27;</span>)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;measure value&#x27;</span>)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;predict value&#x27;</span>)</span><br><span class="line">        plt.legend()</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">show_cv_predict</span>(<span class="params">self,y,x_test,y_test,y_train,x_train,pls</span>):</span><br><span class="line">        plt.figure()</span><br><span class="line">        plt.plot([<span class="built_in">min</span>(y), <span class="built_in">max</span>(y)], [<span class="built_in">min</span>(y), <span class="built_in">max</span>(y)], label=<span class="string">&#x27;y=x&#x27;</span>, color=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">        plt.scatter(y_test[<span class="number">0</span>],self.predict(x_test[<span class="number">0</span>],pls), color=<span class="string">&#x27;red&#x27;</span>, label=<span class="string">&#x27;test set&#x27;</span>)</span><br><span class="line">        plt.scatter(y_train[<span class="number">0</span>],self.predict(x_train[<span class="number">0</span>],pls), color=<span class="string">&#x27;blue&#x27;</span>, label=<span class="string">&#x27;train set&#x27;</span>)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;measure value&#x27;</span>)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;predict value&#x27;</span>)</span><br><span class="line">        plt.legend()</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    data = sio.loadmat(<span class="string">&quot;../NIRcorn.mat&quot;</span>)</span><br><span class="line"></span><br><span class="line">    cornprop = data[<span class="string">&quot;cornprop&quot;</span>]</span><br><span class="line">    m5spec = data[<span class="string">&#x27;m5spec&#x27;</span>][<span class="string">&#x27;data&#x27;</span>][<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">    y = data[<span class="string">&#x27;cornprop&#x27;</span>][:, [<span class="number">0</span>]]</span><br><span class="line">    x=m5spec</span><br><span class="line"></span><br><span class="line">    pls=pls(<span class="number">20</span>)</span><br><span class="line">    pls1=pls.fit(x,y,<span class="number">14</span>)</span><br><span class="line">    y_pre=pls.predict(x,pls1)</span><br><span class="line">    <span class="built_in">print</span>(y)</span><br><span class="line">    <span class="built_in">print</span>(y_pre)</span><br><span class="line"></span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.plot([<span class="built_in">min</span>(y), <span class="built_in">max</span>(y)],[<span class="built_in">min</span>(y), <span class="built_in">max</span>(y)],label=<span class="string">&#x27;y=x&#x27;</span>,color=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">    plt.scatter(y, y_pre,color=<span class="string">&#x27;red&#x27;</span>,label=<span class="string">&#x27;y_all&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;measure value&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;predict value&#x27;</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">    y_pre, cv,y_test,y_train,x_test,x_train = pls.cv_predict(x, y, <span class="number">10</span>)</span><br><span class="line">    <span class="built_in">print</span>(y_pre)</span><br><span class="line">    RMSEcv, min_RMSEcv, best_comp = pls.RMSE_CV(y_pre, cv.y, cv)</span><br><span class="line">    <span class="built_in">print</span>(RMSEcv)</span><br><span class="line">    pls.show_Select_comp(RMSEcv)</span><br><span class="line"></span><br><span class="line">    pls.show_cv_predict(y,x_test,y_test,y_train,x_train,pls1)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> cross_validation</span><br><span class="line"><span class="comment"># from sklearn.decomposition import PCA</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Cross_Validation</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, x, y, n_folds, max_components</span>):</span><br><span class="line">        self.x = x</span><br><span class="line">        self.y = y</span><br><span class="line">        self.n_folds = n_folds</span><br><span class="line">        self.max_components = max_components</span><br><span class="line">        self.n = x.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">CV</span>(<span class="params">self</span>):</span><br><span class="line">        kf = cross_validation.KFold(self.n, self.n_folds)</span><br><span class="line">        x_train=[]</span><br><span class="line">        x_test=[]</span><br><span class="line">        y_train=[]</span><br><span class="line">        y_test=[]</span><br><span class="line">        <span class="keyword">for</span> train_index,test_index <span class="keyword">in</span> kf:</span><br><span class="line">            xtr, xte = self.x[train_index], self.x[test_index]</span><br><span class="line">            ytr, yte = self.y[train_index], self.y[test_index]</span><br><span class="line">            x_train.append(xtr)</span><br><span class="line">            x_test.append(xte)</span><br><span class="line">            y_train.append(ytr)</span><br><span class="line">            y_test.append(yte)</span><br><span class="line">        <span class="keyword">return</span> x_train, x_test, y_train, y_test</span><br></pre></td></tr></table></figure><p>预测结果：</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204193337549.png"alt="image-20230204193337549" /><figcaption aria-hidden="true">image-20230204193337549</figcaption></figure><p>参数选择：<imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204193345363.png"alt="image-20230204193345363" /></p><p>拟合效果：</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204193435252.png"alt="image-20230204193435252" /><figcaption aria-hidden="true">image-20230204193435252</figcaption></figure><h2 id="总结-6">总结</h2><p>PLS的代码实现总体上和PCR类似，其核心区别就在于PLS的fit和predict函数发生了改变，</p><h1 id="实验七-岭回归">实验七 岭回归</h1><h2 id="实验目的-7">实验目的</h2><ol type="1"><li>实现RR算法</li><li>掌握交叉验证算法应用；</li><li>观察岭脊</li></ol><h2 id="实验场地与设备-7">实验场地与设备</h2><p>实验室4074</p><h2 id="实验方式-7">实验方式</h2><p>程序设计</p><h2 id="实验设计-7">实验设计</h2><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204194615350.png" alt="image-20230204194615350" style="zoom:50%;" /></p><h2 id="实验内容-7">实验内容</h2><h3 id="岭迹">岭迹</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"></span><br><span class="line"><span class="comment"># X is the 10x10 Hilbert matrix</span></span><br><span class="line">X = <span class="number">1.0</span> / (np.arange(<span class="number">1</span>, <span class="number">11</span>) + np.arange(<span class="number">0</span>, <span class="number">10</span>)[:, np.newaxis])</span><br><span class="line">y = np.ones(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">n_alphas = <span class="number">200</span></span><br><span class="line">alphas = np.logspace(-<span class="number">10</span>, -<span class="number">2</span>, n_alphas)</span><br><span class="line"></span><br><span class="line">coefs = []</span><br><span class="line"><span class="keyword">for</span> a <span class="keyword">in</span> alphas:</span><br><span class="line">    ridge = linear_model.Ridge(alpha=a, fit_intercept=<span class="literal">False</span>)</span><br><span class="line">    ridge.fit(X, y)</span><br><span class="line">    coefs.append(ridge.coef_)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(alphas)</span><br><span class="line">ax = plt.gca()</span><br><span class="line"></span><br><span class="line">ax.plot(alphas, coefs)</span><br><span class="line"><span class="comment"># ax.set_xscale(&quot;log&quot;)</span></span><br><span class="line"><span class="comment"># ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis</span></span><br><span class="line">plt.xlabel(<span class="string">&quot;alpha&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;weights&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Ridge coefficients as a function of the regularization&quot;</span>)</span><br><span class="line">plt.axis(<span class="string">&quot;tight&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>算术坐标尺度<imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204193803654.png"alt="image-20230204193803654" /></p><p>对数坐标尺度<imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204193817727.png"alt="image-20230204193817727" /></p><h3 id="rr实现">RR实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge</span><br><span class="line"><span class="keyword">from</span> Cross_Validation <span class="keyword">import</span> Cross_Validation</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RidgeRegression</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,n_lambda</span>):</span><br><span class="line">        self.n_lambda=n_lambda</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self,X,y,best_lambda</span>):</span><br><span class="line">        c=np.dot(X.T,X)</span><br><span class="line">        I=np.eye(np.shape(c)[<span class="number">0</span>])</span><br><span class="line">        d=np.dot(best_lambda,I)</span><br><span class="line">        e=(c+d)</span><br><span class="line">        e=np.linalg.inv(e)</span><br><span class="line">        b = np.dot(X.T, y)</span><br><span class="line">        b=np.dot(e,b)</span><br><span class="line">        self.b=b</span><br><span class="line">        <span class="keyword">return</span> b</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">pridict</span>(<span class="params">self,x</span>):</span><br><span class="line">        y_pri=np.dot(x,self.b)</span><br><span class="line">        <span class="keyword">return</span> y_pri</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">cv_pridict</span>(<span class="params">self,X,y,n_fold</span>):</span><br><span class="line">        cv = Cross_Validation(X, y, n_fold, self.n_lambda)</span><br><span class="line">        X_train, X_test, y_train, y_test = cv.CV()</span><br><span class="line">        y_allPredict = np.ones((<span class="number">1</span>, self.n_lambda))</span><br><span class="line">        lambda1=np.logspace(-<span class="number">10</span>,-<span class="number">2</span>,self.n_lambda)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_fold):</span><br><span class="line">            y_predict = np.zeros((y_test[i].shape[<span class="number">0</span>], self.n_lambda))</span><br><span class="line">            k=<span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> j  <span class="keyword">in</span> np.nditer(lambda1) :</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;第&#x27;</span>,k+<span class="number">1</span>+self.n_lambda*i,<span class="string">&#x27;次:&#x27;</span>,j)</span><br><span class="line">                pls = self.fit(X_train[i], y_train[i], j)</span><br><span class="line">                y_pre = self.pridict(X_test[i])</span><br><span class="line">                y_predict[:, k] = y_pre.ravel()</span><br><span class="line">                k=k+<span class="number">1</span></span><br><span class="line">            y_allPredict = np.vstack((y_allPredict, y_predict))</span><br><span class="line">        y_allPredict = y_allPredict[<span class="number">1</span>:]</span><br><span class="line">        <span class="keyword">return</span> y_allPredict, cv, y_test, y_train, X_test, X_train</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">RMSE_CV</span>(<span class="params">self, y_allPredict, y_measure, cv</span>):</span><br><span class="line">        press = np.square(np.subtract(y_allPredict, y_measure))</span><br><span class="line">        press_all = np.<span class="built_in">sum</span>(press, axis=<span class="number">0</span>)</span><br><span class="line">        RMSECV = np.sqrt(press_all / cv.n)</span><br><span class="line">        lambda_best= <span class="built_in">min</span>(RMSECV)</span><br><span class="line">        <span class="keyword">return</span> RMSECV, lambda_best</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">show_Select_lambda</span>(<span class="params">self,RMSECV</span>):</span><br><span class="line">        x=np.logspace(-<span class="number">10</span>,-<span class="number">2</span>,self.n_lambda)</span><br><span class="line">        plt.figure()</span><br><span class="line">        plt.plot(x,RMSECV,marker=<span class="string">&#x27;^&#x27;</span>,markersize=<span class="number">10</span>,markerfacecolor=<span class="string">&#x27;orange&#x27;</span>,color=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;lambda&#x27;</span>)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;RMSECV&#x27;</span>)</span><br><span class="line">        ax = plt.gca()</span><br><span class="line">        ax.set_xscale(<span class="string">&quot;log&quot;</span>)</span><br><span class="line">        ax.set_xlim(ax.get_xlim()[::-<span class="number">1</span>])</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">show_cv_predict</span>(<span class="params">self, y, x_test, y_test, y_train, x_train</span>):</span><br><span class="line">        plt.figure()</span><br><span class="line">        plt.plot([<span class="built_in">min</span>(y), <span class="built_in">max</span>(y)], [<span class="built_in">min</span>(y), <span class="built_in">max</span>(y)], label=<span class="string">&#x27;y=x&#x27;</span>, color=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">        plt.scatter(y_test[<span class="number">0</span>], self.pridict(x_test[<span class="number">0</span>]), color=<span class="string">&#x27;red&#x27;</span>, label=<span class="string">&#x27;test set&#x27;</span>)</span><br><span class="line">        plt.scatter(y_train[<span class="number">0</span>], self.pridict(x_train[<span class="number">0</span>]), color=<span class="string">&#x27;blue&#x27;</span>, label=<span class="string">&#x27;train set&#x27;</span>)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;measure value&#x27;</span>)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;predict value&#x27;</span>)</span><br><span class="line">        plt.legend()</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ ==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    data = sio.loadmat(<span class="string">&quot;../NIRcorn.mat&quot;</span>)</span><br><span class="line"></span><br><span class="line">    cornprop = data[<span class="string">&quot;cornprop&quot;</span>]</span><br><span class="line">    m5spec = data[<span class="string">&#x27;m5spec&#x27;</span>][<span class="string">&#x27;data&#x27;</span>][<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">    y = data[<span class="string">&#x27;cornprop&#x27;</span>][:, [<span class="number">0</span>]]</span><br><span class="line">    x = m5spec</span><br><span class="line"></span><br><span class="line">    rr=RidgeRegression(<span class="number">50</span>)</span><br><span class="line">    rr.fit(x,y,<span class="number">0.335641904424</span>)</span><br><span class="line">    y_pri=rr.pridict(x)</span><br><span class="line"></span><br><span class="line">    y_allPredict, cv, y_test, y_train, X_test, X_train=rr.cv_pridict(x,y,<span class="number">20</span>)</span><br><span class="line">    RMSECV, best_lambda =rr.RMSE_CV(y_allPredict,cv.y,cv)</span><br><span class="line">    rr.show_Select_lambda(RMSECV)</span><br><span class="line">    <span class="built_in">print</span>(best_lambda)</span><br><span class="line"></span><br><span class="line">    rr.show_cv_predict(y, X_test, y_test, y_train, X_train)</span><br><span class="line">    <span class="built_in">print</span>(y_train[<span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(rr.pridict(X_train[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> cross_validation</span><br><span class="line"><span class="comment"># from sklearn.decomposition import PCA</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Cross_Validation</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, x, y, n_folds, max_lambda</span>):</span><br><span class="line">        self.x = x</span><br><span class="line">        self.y = y</span><br><span class="line">        self.n_folds = n_folds</span><br><span class="line">        self.n = x.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">CV</span>(<span class="params">self</span>):</span><br><span class="line">        kf = cross_validation.KFold(self.n, self.n_folds)</span><br><span class="line">        x_train=[]</span><br><span class="line">        x_test=[]</span><br><span class="line">        y_train=[]</span><br><span class="line">        y_test=[]</span><br><span class="line">        <span class="keyword">for</span> train_index,test_index <span class="keyword">in</span> kf:</span><br><span class="line">            xtr, xte = self.x[train_index], self.x[test_index]</span><br><span class="line">            ytr, yte = self.y[train_index], self.y[test_index]</span><br><span class="line">            x_train.append(xtr)</span><br><span class="line">            x_test.append(xte)</span><br><span class="line">            y_train.append(ytr)</span><br><span class="line">            y_test.append(yte)</span><br><span class="line">        <span class="keyword">return</span> x_train, x_test, y_train, y_test</span><br></pre></td></tr></table></figure><p>正则化参数选择图像<imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204194028992.png"alt="image-20230204194028992" /></p><p>拟合效果图像</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204194101069.png"alt="image-20230204194101069" /><figcaption aria-hidden="true">image-20230204194101069</figcaption></figure><p>可以发现最后回归系数都分布在10左右，比较平均，有很强的抗扰动。</p><h2 id="总结-7">总结</h2><p>岭回归对于模型的特征控制有着很好的效果，形成的回归系数相对平均有很强的抗干扰左右，而且能解决多重共线性，解决布满秩的情况。有很强的应用价值。</p>]]></content>
      
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习作业</title>
      <link href="/2023/04/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BD%9C%E4%B8%9A/"/>
      <url>/2023/04/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BD%9C%E4%B8%9A/</url>
      
        <content type="html"><![CDATA[<h1 id="作业九-反向传播算法bp">作业九 反向传播算法（BP）</h1><h2 id="算法推导">算法推导</h2><p><img src="G:\专业学习\第六学期\机器学习\神经网络.png" alt="神经网络" style="zoom: 25%;" /></p><p>令input layer 到hidden layer的权重为<spanclass="math inline">\(w_{ih}\)</span>，hidden layer和outputlayer的权重为<span class="math inline">\(w_{ho}\)</span></p><p>前向算法伪代码：</p><table><colgroup><col style="width: 100%" /></colgroup><thead><tr class="header"><th>Algorithm1: forward</th></tr></thead><tbody><tr class="odd"><td>input: X</td></tr><tr class="even"><td>output: <span class="math inline">\(y\)</span></td></tr><tr class="odd"><td>1. hidden_in=<span class="math inline">\(w_{ih}X+b_1\)</span><br/>2. hidden_out=<spanclass="math inline">\(\sigma(hidden\_in)\)</span><br/>3. output_in=<spanclass="math inline">\(w_{ho}X+b_2\)</span><br/>4. output_out=<spanclass="math inline">\(\sigma(output\_out)\)</span>#根据情况可有可无，无的话则output_in即为output_out<br/>5.y=output_out<br />6.<br/>7. return <spanclass="math inline">\(y\)</span></td></tr></tbody></table><p>output的输出结果为：<spanclass="math inline">\(y_j\)</span>，目标结果为<spanclass="math inline">\(t_j\)</span></p><p>令误差函数为<spanclass="math inline">\(E=\frac{1}{2}\sum_{j=0}^{n}{(y_j-t_j)^2}\)</span>，其中<spanclass="math inline">\(i\)</span>为output layer的神经元个数</p><p>下面给出反向传播的伪代码：</p><table><colgroup><col style="width: 100%" /></colgroup><thead><tr class="header"><th>Algorithm1: backprop</th></tr></thead><tbody><tr class="odd"><td>input: X,t,y,learn_rate</td></tr><tr class="even"><td>output: null</td></tr><tr class="odd"><td>1. <spanclass="math inline">\(\delta_1=(y-t)\sigma^{&#39;}(y)\)</span> #outputlayer的梯度<br />2. <spanclass="math inline">\(\delta_2=\sigma^{&#39;}(hidden\_output)\sum_{i=0}^{n}{w_{ho}\delta_1}\)</span>#求解hidden layer的梯度<br />3. <br/>4. <spanclass="math inline">\(w_{ih}-=learn\_rate*\delta_2\)</span><br/>5. <spanclass="math inline">\(w_{ho}-=learn\_rate*\delta_1\)</span><br/>6. <spanclass="math inline">\(b_{2}-=learn\_rate*\delta_2\)</span><br/>7. <spanclass="math inline">\(b_{1}-=learn\_rate*\delta_1\)</span><br/>8.<br/>9. return</td></tr></tbody></table><p>其中梯度求导原因如下： <span class="math display">\[\begin{array}{left}\frac{\partial E}{\partial w_{ij}}=\frac{\partial E}{\partiala{j}}\frac{\partial a_j}{\partial w_{ij}} \\其中：\\E=\frac{1}{2}\sum_{j=0}^{n}{(y_j-t_j)^2}\\a_j=\sum_i{w_{ij}z_i}\\z_j=\sigma(a_j)\\那么：\\\frac{\partial E}{\partial a{j}}=y_j-t_j \\\delta \equiv\frac{\partial E}{\partial a{j}}\\则：\\\frac{\partial E}{\partial w_{ij}}=\delta\frac{\partial a_j}{\partialw_{ij}}=\delta\sigma^{&#39;}(a_j)\end{array}\]</span></p><h2 id="拟合sin曲线">拟合sin曲线</h2><p>在实现中，outputlayer输出时不能采用Sigmoid函数激活，否则无法出现正常结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NN</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_neurons, hidden_neurons, output_neurons, learning_rate, epochs</span>):</span><br><span class="line">        self.input_neurons = input_neurons</span><br><span class="line">        self.hidden_neurons = hidden_neurons</span><br><span class="line">        self.output_neurons = output_neurons</span><br><span class="line">        self.epochs = epochs</span><br><span class="line">        self.lr = learning_rate</span><br><span class="line"></span><br><span class="line">        self.wih = np.random.normal(<span class="number">0</span>, <span class="number">1</span>, (self.hidden_neurons, self.input_neurons))</span><br><span class="line">        self.bih = <span class="number">0</span></span><br><span class="line">        self.who = np.random.normal(<span class="number">0</span>, <span class="number">1</span>, (self.output_neurons, self.hidden_neurons))</span><br><span class="line">        self.bho = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">activation</span>(<span class="params">self, Z</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-Z))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sigmoid_derivative</span>(<span class="params">self, Z</span>):</span><br><span class="line">        <span class="keyword">return</span> self.activation(Z) * (<span class="number">1</span> - self.activation(Z))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 前向传播</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, input_list</span>):</span><br><span class="line">        inputs = np.array(input_list, ndmin=<span class="number">2</span>)</span><br><span class="line">        hidden_inputs = np.dot(self.wih, inputs) + self.bih</span><br><span class="line">        hidden_outputs = self.activation(hidden_inputs)</span><br><span class="line">        final_inputs = np.dot(self.who, hidden_outputs) + self.bho</span><br><span class="line">        final_outputs=final_inputs</span><br><span class="line">        <span class="keyword">return</span> final_outputs</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 反向传播</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">backprop</span>(<span class="params">self, inputs_list, targets_list</span>):</span><br><span class="line">        inputs = np.array(inputs_list, ndmin=<span class="number">2</span>)</span><br><span class="line">        tj = np.array(targets_list, ndmin=<span class="number">2</span>)</span><br><span class="line">        hidden_inputs = np.dot(self.wih, inputs) + self.bih</span><br><span class="line">        hidden_outputs = self.activation(hidden_inputs)</span><br><span class="line">        final_inputs = np.dot(self.who, hidden_outputs) + self.bho</span><br><span class="line">        yj = final_inputs</span><br><span class="line">        output_errors = (yj - tj)</span><br><span class="line">        hidden_errors = np.dot(self.who.T, output_errors)*self.sigmoid_derivative(hidden_outputs)</span><br><span class="line">        self.who -= self.lr * np.dot(output_errors , np.transpose(hidden_outputs))</span><br><span class="line">        self.wih -= self.lr * np.dot(hidden_errors, np.transpose(inputs))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># updating bias</span></span><br><span class="line">        self.bho -= self.lr * output_errors</span><br><span class="line">        self.bih -= self.lr * hidden_errors</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, inputs_list, targets_list</span>):</span><br><span class="line">        loss_list=[]</span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(self.epochs):</span><br><span class="line">            self.backprop(inputs_list, targets_list)</span><br><span class="line">            y_pre=self.predict(inputs_list)</span><br><span class="line">            loss=np.sqrt(np.<span class="built_in">sum</span>(np.square(y_pre-targets_list)))/<span class="number">2</span></span><br><span class="line">            loss_list.append(loss)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Epoch <span class="subst">&#123;epoch&#125;</span>/<span class="subst">&#123;self.epochs&#125;</span> ,loss:<span class="subst">&#123;loss&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> loss_list</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, X</span>):</span><br><span class="line">        outputs = self.forward(X).T</span><br><span class="line">        <span class="keyword">return</span> outputs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line"></span><br><span class="line">    plt.style.use(<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line">    <span class="comment"># 创建数据</span></span><br><span class="line">    x = np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line">    y = np.sin(<span class="number">2</span> * np.pi * x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 添加随机噪声</span></span><br><span class="line">    np.random.seed(<span class="number">20</span>)</span><br><span class="line">    y_noisy = y + <span class="number">0.05</span> * np.random.normal(size=x.shape)</span><br><span class="line">    nn = NN(<span class="number">1</span>, <span class="number">50</span>, <span class="number">1</span>, <span class="number">0.02</span>,<span class="number">200</span>)</span><br><span class="line">    loss=nn.fit(x, y_noisy)</span><br><span class="line"></span><br><span class="line">    x_test = np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line">    y_pred = nn.predict(x_test)</span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.plot(x_test, y_pred, label=<span class="string">&#x27;Regressor&#x27;</span>, color=<span class="string">&#x27;#FFA628&#x27;</span>)</span><br><span class="line">    plt.plot(x, y, label=<span class="string">&#x27;True function&#x27;</span>, color=<span class="string">&#x27;g&#x27;</span>)</span><br><span class="line">    plt.scatter(x, y_noisy, edgecolor=<span class="string">&#x27;b&#x27;</span>, s=<span class="number">20</span>, label=<span class="string">&#x27;Noisy samples&#x27;</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.plot(np.linspace(<span class="number">3</span>,<span class="built_in">len</span>(loss),<span class="built_in">len</span>(loss)-<span class="number">3</span>),loss[<span class="number">3</span>:])</span><br><span class="line">    plt.title(<span class="string">&#x27;loss curve&#x27;</span>)</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p>经过200次迭代后，结果如下：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230507143232977.png" alt="image-20230507143232977" style="zoom:50%;" /></p><p>loss曲线如下：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230507143309196.png" alt="image-20230507143309196" style="zoom:50%;" /></p><p>如果迭代2000次：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/f624b4755450bca033368ecadb12ed7.png" alt="f624b4755450bca033368ecadb12ed7" style="zoom: 67%;" /></p><p>可以看到有明显过拟合。</p><p>如果输出结果，采用Sigmoid函数处理：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230507143624375.png" alt="image-20230507143624375" style="zoom: 50%;" /></p><p>原因很简单，因为Sigmoid函数将数值缩放到了0，导致结果均为0，如果将误差符号反向，那么将得到一条y=1的直线作业八神经网络初步</p><h1 id="作业八-神经网络初步">作业八 神经网络初步</h1><p>sklearn中人工神经网络（ANN）主要提供的是多层感知机（MLP），其中有回归和分类两种，回归感知机还有能够自动实现交叉验证的版本。</p><h2 id="mlpclassifier二分类">MLPClassifier二分类</h2><p>流程如下：</p><ol type="1"><li>导入iris数据，取后两类</li><li>标准化</li><li>PCA得到x_pca，y</li><li>初始化MLP，训练</li><li>绘制分类面</li></ol><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> l1_min_c</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_decision_surface</span>(<span class="params">model, X, y, grid_size=<span class="number">0.02</span></span>):</span><br><span class="line">    <span class="comment"># 获取数据范围</span></span><br><span class="line">    x_min, x_max = X[:, <span class="number">0</span>].<span class="built_in">min</span>() - <span class="number">0.5</span>, X[:, <span class="number">0</span>].<span class="built_in">max</span>() + <span class="number">0.5</span></span><br><span class="line">    y_min, y_max = X[:, <span class="number">1</span>].<span class="built_in">min</span>() - <span class="number">0.5</span>, X[:, <span class="number">1</span>].<span class="built_in">max</span>() + <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 生成网格点</span></span><br><span class="line">    xx, yy = np.meshgrid(np.arange(x_min, x_max, grid_size), np.arange(y_min, y_max, grid_size))</span><br><span class="line">    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])</span><br><span class="line">    Z = Z.reshape(xx.shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 绘制分类面和训练数据</span></span><br><span class="line">    cmap_light = ListedColormap([<span class="string">&#x27;#FFAAAA&#x27;</span>, <span class="string">&#x27;#AAFFAA&#x27;</span>, <span class="string">&#x27;#AAAAFF&#x27;</span>])</span><br><span class="line">    cmap_bold = ListedColormap([<span class="string">&#x27;#FF0000&#x27;</span>, <span class="string">&#x27;#00FF00&#x27;</span>, <span class="string">&#x27;#0000FF&#x27;</span>])</span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)</span><br><span class="line">    plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y, cmap=cmap_bold, edgecolor=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line">    plt.xlim(xx.<span class="built_in">min</span>(), xx.<span class="built_in">max</span>())</span><br><span class="line">    plt.ylim(yy.<span class="built_in">min</span>(), yy.<span class="built_in">max</span>())</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Sepal length&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;Sepal width&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Iris classification using MLP&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">X = iris.data</span><br><span class="line">y = iris.target</span><br><span class="line"></span><br><span class="line">X = X[y != <span class="number">0</span>]</span><br><span class="line">y = y[y != <span class="number">0</span>]</span><br><span class="line"><span class="comment"># 标准化</span></span><br><span class="line">standard=StandardScaler()</span><br><span class="line">X=standard.fit_transform(X)</span><br><span class="line"><span class="comment"># PCA</span></span><br><span class="line">pca=PCA(n_components=<span class="number">2</span>)</span><br><span class="line">x_pca=pca.fit_transform(X)</span><br><span class="line"><span class="comment"># 初始化mlp</span></span><br><span class="line">mlp=MLPClassifier(solver=<span class="string">&#x27;lbfgs&#x27;</span>,hidden_layer_sizes=(<span class="number">5</span>,<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">mlp.fit(x_pca,y)</span><br><span class="line"></span><br><span class="line">plot_decision_surface(mlp, x_pca, y)</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230422220300024.png" alt="image-20230422220300024" style="zoom:50%;" /></p><h2 id="mlpclassifier多分类">MLPClassifier多分类</h2><p>流程如下：</p><ol type="1"><li>导入iris数据</li><li>标准化</li><li>PCA得到x_pca，y</li><li>初始化MLP，训练</li><li>绘制分类面</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> plot_confusion_matrix</span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_decision_surface</span>(<span class="params">model, X, y, grid_size=<span class="number">0.02</span></span>):</span><br><span class="line">    <span class="comment"># 获取数据范围</span></span><br><span class="line">    x_min, x_max = X[:, <span class="number">0</span>].<span class="built_in">min</span>() - <span class="number">0.5</span>, X[:, <span class="number">0</span>].<span class="built_in">max</span>() + <span class="number">0.5</span></span><br><span class="line">    y_min, y_max = X[:, <span class="number">1</span>].<span class="built_in">min</span>() - <span class="number">0.5</span>, X[:, <span class="number">1</span>].<span class="built_in">max</span>() + <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 生成网格点</span></span><br><span class="line">    xx, yy = np.meshgrid(np.arange(x_min, x_max, grid_size), np.arange(y_min, y_max, grid_size))</span><br><span class="line">    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])</span><br><span class="line">    Z = Z.reshape(xx.shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 绘制分类面和训练数据</span></span><br><span class="line">    cmap_light = ListedColormap([<span class="string">&#x27;#FFAAAA&#x27;</span>, <span class="string">&#x27;#AAFFAA&#x27;</span>, <span class="string">&#x27;#AAAAFF&#x27;</span>])</span><br><span class="line">    cmap_bold = ListedColormap([<span class="string">&#x27;#FF0000&#x27;</span>, <span class="string">&#x27;#00FF00&#x27;</span>, <span class="string">&#x27;#0000FF&#x27;</span>])</span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)</span><br><span class="line">    plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y, cmap=cmap_bold, edgecolor=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line">    plt.xlim(xx.<span class="built_in">min</span>(), xx.<span class="built_in">max</span>())</span><br><span class="line">    plt.ylim(yy.<span class="built_in">min</span>(), yy.<span class="built_in">max</span>())</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Sepal length&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;Sepal width&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Iris classification using MLP&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line">iris = load_iris()</span><br><span class="line">X = iris.data[:, :<span class="number">2</span>]  <span class="comment"># 只使用前两个特征</span></span><br><span class="line">y = iris.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分数据集</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建多层感知器模型</span></span><br><span class="line">mlp = MLPClassifier(hidden_layer_sizes=(<span class="number">10</span>,), max_iter=<span class="number">1000</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">mlp.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制分类面</span></span><br><span class="line">plot_decision_surface(mlp, X_train, y_train)</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230422220443459.png" alt="image-20230422220443459" style="zoom:50%;" /></p><h2 id="mlpregressor">MLPRegressor</h2><p>程序流程如下：</p><ol type="1"><li>创建数据X，y</li><li>为y添加随机噪声</li><li>初始化MLP</li><li>训练MLP</li><li>绘制预测效果图</li></ol><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPRegressor</span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line"><span class="comment"># 创建数据</span></span><br><span class="line">x = np.linspace(-<span class="number">5</span>, <span class="number">5</span>, <span class="number">100</span>)</span><br><span class="line">y = np.sin(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加随机噪声</span></span><br><span class="line">np.random.seed(<span class="number">42</span>)</span><br><span class="line">y_noisy = y + <span class="number">0.2</span> * np.random.normal(size=x.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建多层感知器模型</span></span><br><span class="line">mlp = MLPRegressor(hidden_layer_sizes=(<span class="number">50</span>,), max_iter=<span class="number">1000</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">mlp.fit(x.reshape(-<span class="number">1</span>, <span class="number">1</span>), y_noisy)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测并绘制结果</span></span><br><span class="line">x_test = np.linspace(-<span class="number">5.5</span>, <span class="number">5.5</span>, <span class="number">100</span>)</span><br><span class="line">y_pred = mlp.predict(x_test.reshape(-<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">plt.plot(x_test, y_pred, label=<span class="string">&#x27;MLP Regressor&#x27;</span>,color=<span class="string">&#x27;#FFA628&#x27;</span>)</span><br><span class="line">plt.plot(x, y, label=<span class="string">&#x27;True function&#x27;</span>,color=<span class="string">&#x27;g&#x27;</span>)</span><br><span class="line">plt.scatter(x, y_noisy, edgecolor=<span class="string">&#x27;b&#x27;</span>, s=<span class="number">20</span>, label=<span class="string">&#x27;Noisy samples&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.title(<span class="string">&#x27;MLP Regressor&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230422220624823.png" alt="image-20230422220624823" style="zoom:50%;" /></p><h1 id="作业七-逻辑回归分类">作业七 逻辑回归分类</h1><p>由于都是从sklearn中调用，并不涉及什么复杂算法，因此下面采用列表的方式描述程序作用</p><h2 id="二分类逻辑回归">二分类逻辑回归</h2><p>首先说明下面程序的目的：</p><table><thead><tr class="header"><th>1.观察不同惩罚项系数对应参数变化</th></tr></thead><tbody><tr class="odd"><td><strong>2.观察不同惩罚项系数对应错误率</strong></td></tr><tr class="even"><td><strong>3.可视化二分类结果</strong></td></tr></tbody></table><p>流程如下：</p><ol type="1"><li>导入iris数据，取后两类</li><li>标准化</li><li>PCA得到x_pca，y</li><li>初始化逻辑回归</li><li>调整参数c，分别训练逻辑回归得到权重参数和错误率</li><li>绘制错误率和权重参数曲线</li><li>绘制分类面</li></ol><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> l1_min_c</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">X = iris.data</span><br><span class="line">y = iris.target</span><br><span class="line"><span class="comment"># 选出前两类</span></span><br><span class="line">X = X[y != <span class="number">0</span>]</span><br><span class="line">y = y[y != <span class="number">0</span>]</span><br><span class="line"><span class="comment"># 画出图像</span></span><br><span class="line">plt.figure()</span><br><span class="line">plt.scatter(X[y == <span class="number">2</span>, <span class="number">0</span>], X[y == <span class="number">2</span>, <span class="number">1</span>], color=<span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;0&#x27;</span>)</span><br><span class="line">plt.scatter(X[y == <span class="number">1</span>, <span class="number">0</span>], X[y == <span class="number">1</span>, <span class="number">1</span>], color=<span class="string">&#x27;g&#x27;</span>, label=<span class="string">&#x27;1&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># 训练</span></span><br><span class="line">cs = l1_min_c(X, y, loss=<span class="string">&#x27;log&#x27;</span>) * np.logspace(<span class="number">0</span>, <span class="number">7</span>, <span class="number">16</span>)</span><br><span class="line"><span class="comment"># 初始化逻辑回归</span></span><br><span class="line">clf = LogisticRegression(</span><br><span class="line">    penalty=<span class="string">&#x27;l1&#x27;</span>,</span><br><span class="line">    solver=<span class="string">&#x27;liblinear&#x27;</span>,</span><br><span class="line">    tol=<span class="number">1e-6</span>,</span><br><span class="line">    max_iter=<span class="built_in">int</span>(<span class="number">1e6</span>),</span><br><span class="line">    warm_start=<span class="literal">True</span>,</span><br><span class="line">    intercept_scaling=<span class="number">1000.0</span>,</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 错误率</span></span><br><span class="line">errors = []</span><br><span class="line"><span class="comment"># 各个特征对参数</span></span><br><span class="line">coefs_ = []</span><br><span class="line"><span class="comment"># 拟合观察参数</span></span><br><span class="line"><span class="keyword">for</span> c <span class="keyword">in</span> cs:</span><br><span class="line">    clf.set_params(C=c)</span><br><span class="line">    clf.fit(X, y)</span><br><span class="line">    y_pre = clf.predict(X)</span><br><span class="line">    error = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(y)):</span><br><span class="line">        <span class="keyword">if</span> y_pre[i] != y[i]:</span><br><span class="line">            error = error + <span class="number">1</span></span><br><span class="line">    errors.append(error)</span><br><span class="line">    coefs_.append(clf.coef_.ravel().copy())</span><br><span class="line">errors = np.array(errors) / <span class="built_in">len</span>(y)</span><br><span class="line">coefs_ = np.array(coefs_)</span><br><span class="line"><span class="comment"># 绘制参数变化</span></span><br><span class="line">plt.plot(np.log10(cs), coefs_, marker=<span class="string">&quot;o&quot;</span>)</span><br><span class="line">ymin, ymax = plt.ylim()</span><br><span class="line">plt.xlabel(<span class="string">&quot;log(C)&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Coefficients&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Logistic Regression Path&quot;</span>)</span><br><span class="line">plt.axis(<span class="string">&quot;tight&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># 绘制错误率</span></span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(np.log10(cs), errors, marker=<span class="string">&#x27;^&#x27;</span>, color=<span class="string">&#x27;orange&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;error rate&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;log(C)&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># 最优拟合</span></span><br><span class="line">clf.set_params(C=<span class="number">1</span>)</span><br><span class="line">clf.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># PCA可视化</span></span><br><span class="line">pca = PCA(n_components=<span class="number">2</span>)</span><br><span class="line">X1 = pca.fit_transform(X)</span><br><span class="line">clf.set_params(C=<span class="number">1</span>)</span><br><span class="line">clf.fit(X1, y)</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.scatter(X1[y == <span class="number">2</span>, <span class="number">0</span>], X1[y == <span class="number">2</span>, <span class="number">1</span>], color=<span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;2&#x27;</span>)</span><br><span class="line">plt.scatter(X1[y == <span class="number">1</span>, <span class="number">0</span>], X1[y == <span class="number">1</span>, <span class="number">1</span>], color=<span class="string">&#x27;g&#x27;</span>, label=<span class="string">&#x27;1&#x27;</span>)</span><br><span class="line">plt.plot([<span class="built_in">min</span>(X1[:, <span class="number">0</span>]), <span class="built_in">max</span>(X1[:, <span class="number">0</span>])], [-(<span class="built_in">min</span>(X1[:, <span class="number">0</span>]) * clf.coef_[<span class="number">0</span>, <span class="number">0</span>] + clf.intercept_[<span class="number">0</span>]) / clf.coef_[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">                                          -(<span class="built_in">max</span>(X1[:, <span class="number">0</span>]) * clf.coef_[<span class="number">0</span>, <span class="number">0</span>] + clf.intercept_[<span class="number">0</span>]) / clf.coef_[<span class="number">0</span>, <span class="number">1</span>]],</span><br><span class="line">         label=<span class="string">&#x27;classier&#x27;</span>, linewidth=<span class="number">3.0</span>, color=<span class="string">&#x27;black&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.xlabel(<span class="string">&#x27;component 1&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;component 2&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>结果如下：</p><p>不同惩罚项对应的参数变化，可以看出当惩罚项小于1时，对于模型的稀疏化效果较好。</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230422214826267.png" alt="image-20230422214826267" style="zoom:50%;" /></p><p>不同惩罚项系数对应的分类错误率，选择为10时效果较好；</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230422214946938.png" alt="image-20230422214946938" style="zoom:50%;" /></p><p>分类结果效果如图：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230422215101050.png" alt="image-20230422215101050" style="zoom:50%;" /></p><h2 id="多分类逻辑回归">多分类逻辑回归</h2><p>首先说明下面程序的目的：</p><table><thead><tr class="header"><th>1.绘制多分类的分类面</th></tr></thead><tbody></tbody></table><p>流程如下：</p><ol type="1"><li>导入iris数据</li><li>标准化</li><li>PCA得到x_pca，y</li><li>初始化逻辑回归，训练逻辑回归</li><li>绘制分类面</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> l1_min_c</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">X = iris.data</span><br><span class="line">y = iris.target</span><br><span class="line"><span class="comment"># 标准化</span></span><br><span class="line">standard=StandardScaler()</span><br><span class="line">X=standard.fit_transform(X)</span><br><span class="line"><span class="comment"># PCA</span></span><br><span class="line">pca=PCA(n_components=<span class="number">2</span>)</span><br><span class="line">x_pca=pca.fit_transform(X)</span><br><span class="line"><span class="comment"># 初始化逻辑回归</span></span><br><span class="line">clf = LogisticRegression(</span><br><span class="line">    solver=<span class="string">&#x27;liblinear&#x27;</span>,</span><br><span class="line">    max_iter=<span class="built_in">int</span>(<span class="number">1e6</span>),</span><br><span class="line">    warm_start=<span class="literal">True</span>,</span><br><span class="line">    intercept_scaling=<span class="number">1000.0</span></span><br><span class="line">)</span><br><span class="line">clf.fit(x_pca,y)</span><br><span class="line">coef,intercept=np.array(clf.coef_),np.array(clf.intercept_)</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.scatter(x_pca[y == <span class="number">2</span>, <span class="number">0</span>], x_pca[y == <span class="number">2</span>, <span class="number">1</span>], color=<span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;2&#x27;</span>)</span><br><span class="line">plt.scatter(x_pca[y == <span class="number">1</span>, <span class="number">0</span>], x_pca[y == <span class="number">1</span>, <span class="number">1</span>], color=<span class="string">&#x27;g&#x27;</span>, label=<span class="string">&#x27;1&#x27;</span>)</span><br><span class="line">plt.scatter(x_pca[y == <span class="number">0</span>, <span class="number">0</span>], x_pca[y == <span class="number">0</span>, <span class="number">1</span>], color=<span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;0&#x27;</span>)</span><br><span class="line">plt.plot([<span class="built_in">min</span>(x_pca[:, <span class="number">0</span>]), <span class="built_in">max</span>(x_pca[:, <span class="number">0</span>])], [-(<span class="built_in">min</span>(x_pca[:, <span class="number">0</span>]) * coef[<span class="number">0</span>, <span class="number">0</span>] + intercept[<span class="number">0</span>]) / coef[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">                                          -(<span class="built_in">max</span>(x_pca[:, <span class="number">0</span>]) * coef[<span class="number">0</span>, <span class="number">0</span>] + intercept[<span class="number">0</span>]) / coef[<span class="number">0</span>, <span class="number">1</span>]],</span><br><span class="line">         label=<span class="string">&#x27;classier&#x27;</span>, linewidth=<span class="number">3.0</span>, color=<span class="string">&#x27;black&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.plot([<span class="built_in">min</span>(x_pca[:, <span class="number">0</span>]), <span class="built_in">max</span>(x_pca[:, <span class="number">0</span>])], [-(<span class="built_in">min</span>(x_pca[:, <span class="number">0</span>]) * coef[<span class="number">1</span>, <span class="number">0</span>] + intercept[<span class="number">1</span>]) / coef[<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                                          -(<span class="built_in">max</span>(x_pca[:, <span class="number">0</span>]) * coef[<span class="number">1</span>, <span class="number">0</span>] + intercept[<span class="number">1</span>]) / coef[<span class="number">1</span>, <span class="number">1</span>]],</span><br><span class="line">         label=<span class="string">&#x27;classier&#x27;</span>, linewidth=<span class="number">3.0</span>, color=<span class="string">&#x27;black&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">plt.plot([<span class="built_in">min</span>(x_pca[:, <span class="number">0</span>]), <span class="built_in">max</span>(x_pca[:, <span class="number">0</span>])], [-(<span class="built_in">min</span>(x_pca[:, <span class="number">0</span>]) * coef[<span class="number">2</span>, <span class="number">0</span>] + intercept[<span class="number">2</span>]) / coef[<span class="number">2</span>, <span class="number">1</span>],</span><br><span class="line">                                          -(<span class="built_in">max</span>(x_pca[:, <span class="number">0</span>]) * coef[<span class="number">2</span>, <span class="number">0</span>] + intercept[<span class="number">2</span>]) / coef[<span class="number">2</span>, <span class="number">1</span>]],</span><br><span class="line">         label=<span class="string">&#x27;classier&#x27;</span>, linewidth=<span class="number">3.0</span>, color=<span class="string">&#x27;black&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">plt.ylim(-<span class="number">5</span>,<span class="number">5</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.xlabel(<span class="string">&#x27;component 1&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;component 2&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230422215323041.png" alt="image-20230422215323041" style="zoom:50%;" /></p><h1 id="作业六">作业六</h1><h2 id="bayesian-linear-regression">Bayesian Linear Regression</h2><p>所有算法都放在同一个Python文件下，函数算法伪代码如下：</p><table><colgroup><col style="width: 100%" /></colgroup><thead><tr class="header"><th>Algorithm1: fit</th></tr></thead><tbody><tr class="odd"><td>input: X,t,degree, <spanclass="math inline">\(\alpha,\beta,\phi\)</span></td></tr><tr class="even"><td>output: <span class="math inline">\(m_n,S_n\)</span></td></tr><tr class="odd"><td>1. <strong><span class="math inline">\(if\)</span></strong>len(X.shape) == 1: # 预先判断形状<br /> 2. X=X.reshape(-1,1)<br />3.<strong><span class="math inline">\(if\)</span></strong> len(t.shape)==1:<br />4. t=t.reshape(-1,1)<br />5. <spanclass="math inline">\(S_n^{-1}=\alpha I+\beta\phi(X)^T\phi(X)\)</span> #计算协方差的逆<br />6. <spanclass="math inline">\(S_n=\)</span>np.linalg.inv(<spanclass="math inline">\(S_n^{-1}\)</span>)<br />7. <spanclass="math inline">\(m_n=\beta S_n \phi(X)^Tt\)</span> # 计算均值<br />8.<br />9. return <spanclass="math inline">\(m_n,S_n\)</span></td></tr></tbody></table><table><colgroup><col style="width: 100%" /></colgroup><thead><tr class="header"><th>Algorithm2: predict</th></tr></thead><tbody><tr class="odd"><td>input: X, <span class="math inline">\(\phi,m_n,S_n\)</span></td></tr><tr class="even"><td>output: <span class="math inline">\(mean,\sigma^2\)</span></td></tr><tr class="odd"><td>1. <span class="math inline">\(\sigma^2\)</span> = <spanclass="math inline">\(\frac{1}{\beta}+\phi(X)S_n\phi(X)^T\)</span><br />2.mean=<span class="math inline">\(\phi(x)m_n\)</span><br />3.<br/>4.return mean, <span class="math inline">\(\sigma ^2\)</span></td></tr></tbody></table><p>代码实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> multivariate_normal</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> Polyfeature <span class="keyword">import</span> Polyfeature</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BLR</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,n_features,alpha=<span class="number">0</span>,beta=<span class="number">1</span>,phi=<span class="string">&#x27;linear&#x27;</span></span>):</span><br><span class="line">        self.n_features=n_features</span><br><span class="line">        self.alpha=alpha</span><br><span class="line">        self.beta=beta</span><br><span class="line">        self.phi=phi</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    alpha 表示w的先验的精度</span></span><br><span class="line"><span class="string">    beta  表示数据的精度</span></span><br><span class="line"><span class="string">    phi   表示基函数，可选参数为：linear、gaussain、polynomial、sigmoid</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">gaussian</span>(<span class="params">self,x, mu, sigma</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span> / (sigma * np.sqrt(<span class="number">2</span> * np.pi)) * np.exp(-(x - mu) ** <span class="number">2</span> / (<span class="number">2</span> * sigma ** <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self,X,t</span>):</span><br><span class="line">        <span class="comment"># 检查向量是否是二维数组并转化</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(X.shape) == <span class="number">1</span>:</span><br><span class="line">            X=X.reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(t.shape) == <span class="number">1</span>:</span><br><span class="line">            t=t.reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 是否要0均值？</span></span><br><span class="line">        <span class="keyword">global</span> phi_x</span><br><span class="line">        <span class="keyword">global</span> x</span><br><span class="line">        <span class="keyword">if</span> self.phi==<span class="string">&#x27;linear&#x27;</span>:</span><br><span class="line">            phi_x=X</span><br><span class="line">            x=np.dot(phi_x,phi_x.T)</span><br><span class="line">        <span class="keyword">if</span> self.phi==<span class="string">&#x27;polynomial&#x27;</span>:</span><br><span class="line">            polyf=Polyfeature(self.n_features)</span><br><span class="line">            phi_x=polyf.fit_transform(X)</span><br><span class="line">            x=np.dot(phi_x.T,phi_x)</span><br><span class="line">        <span class="comment"># Sn的逆</span></span><br><span class="line">        Sn_inverse=self.alpha*np.eye(x.shape[<span class="number">0</span>])+self.beta*x</span><br><span class="line">        <span class="comment"># 计算期望</span></span><br><span class="line">        mn=self.beta*np.dot(np.dot(np.linalg.inv(Sn_inverse),phi_x.T),t)</span><br><span class="line"></span><br><span class="line">        self.phi_x=phi_x</span><br><span class="line">        self.Sn_inverse=Sn_inverse</span><br><span class="line">        self.mn=mn</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self,X</span>):</span><br><span class="line">        <span class="keyword">if</span> self.phi==<span class="string">&#x27;linear&#x27;</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(X.shape)==<span class="number">1</span>:</span><br><span class="line">                X = X.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">                sigma2=<span class="number">1</span>/self.beta+np.dot(np.dot(self.phi_x.T,np.linalg.inv(self.Sn_inverse)),self.phi_x)</span><br><span class="line">                t_pre=self.gaussian(X,self.mn,np.sqrt(sigma2))</span><br><span class="line">                <span class="keyword">return</span> t_pre</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.phi==<span class="string">&#x27;polynomial&#x27;</span>:</span><br><span class="line">            polyf=Polyfeature(self.n_features)</span><br><span class="line">            X=polyf.fit_transform(X)</span><br><span class="line"></span><br><span class="line">        sigma2 = np.diag(<span class="number">1</span> / self.beta + X @ np.linalg.inv(self.Sn_inverse) @ X.T).reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">        mean=np.dot(X,self.mn)</span><br><span class="line"></span><br><span class="line">        upper = mean + np.sqrt(sigma2)</span><br><span class="line">        lower = mean - np.sqrt(sigma2)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> mean,sigma2,upper,lower</span><br></pre></td></tr></table></figure><p>回归效果：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/90e39f72c8da404c0738ddf8072aae4.png" alt="90e39f72c8da404c0738ddf8072aae4" style="zoom: 67%;" /></p><h2 id="不同样本数量影响拟合效果">不同样本数量影响拟合效果</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">   x_1=np.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">100</span>)</span><br><span class="line">    X_data=[np.array([<span class="number">0.5</span>]),</span><br><span class="line">                     np.array([<span class="number">0.3</span>,<span class="number">0.6</span>]),</span><br><span class="line">                     np.array([<span class="number">0.25</span>,<span class="number">0.5</span>,<span class="number">0.75</span>,<span class="number">0.8</span>]),</span><br><span class="line">                     np.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">60</span>)]</span><br><span class="line">j=<span class="number">1</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">6</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> X_data:</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">2</span>,j)</span><br><span class="line">    t=np.sin(<span class="number">2</span>*np.pi*i)+np.random.normal(loc=<span class="number">0</span>,scale=<span class="number">0.2</span>,size=i.shape)</span><br><span class="line">    <span class="keyword">if</span> j&lt;<span class="number">2</span>:</span><br><span class="line">        blr = BLR(<span class="number">5</span>, phi=<span class="string">&#x27;polynomial&#x27;</span>,alpha=<span class="number">0.2</span>)</span><br><span class="line">        plt.title(<span class="string">&#x27;alpha=0.2&#x27;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        blr = BLR(<span class="number">4</span>, phi=<span class="string">&#x27;polynomial&#x27;</span>)</span><br><span class="line">        plt.title(<span class="string">&#x27;without alpha&#x27;</span>)</span><br><span class="line">    j=j+<span class="number">1</span></span><br><span class="line">    <span class="comment"># 绘制sin原图像</span></span><br><span class="line">    plt.plot(x_1,np.sin(<span class="number">2</span>*np.pi*x_1),label=<span class="string">&#x27;sin(x)&#x27;</span>)</span><br><span class="line">    <span class="comment"># 绘制数据散点</span></span><br><span class="line">    plt.scatter(i, t, color=<span class="string">&#x27;g&#x27;</span>,label=<span class="string">&#x27;samples&#x27;</span>)</span><br><span class="line">    blr.fit(i, t)</span><br><span class="line">    plt.plot(x_1, blr.predict(x_1)[<span class="number">0</span>], color=<span class="string">&#x27;black&#x27;</span>,label=<span class="string">&#x27;prediction&#x27;</span>)</span><br><span class="line">    <span class="comment"># 绘制阴影部分</span></span><br><span class="line">    plt.fill_between(x_1.squeeze(), blr.predict(x_1)[<span class="number">3</span>].squeeze(), blr.predict(x_1)[<span class="number">2</span>].squeeze(), alpha=<span class="number">0.4</span>,label=<span class="string">&#x27;varience&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.xlabel(<span class="string">&#x27;X&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;t&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230408203151173.png"alt="image-20230408203151173" /><figcaption aria-hidden="true">image-20230408203151173</figcaption></figure><p>同时，我调整了样本数量较小时的<spanclass="math inline">\(\alpha\)</span>值，下图是无正则化的情况（样本数量为1时，必须有正则化否则出现奇异矩阵）：</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230408203316307.png"alt="image-20230408203316307" /><figcaption aria-hidden="true">image-20230408203316307</figcaption></figure><h2 id="交叉验证调优">交叉验证调优</h2><p>因为要做调优，所以固定生成数据，设定种子为0。</p><p>在固定<spanclass="math inline">\(\alpha=0,beta=10\)</span>时，首先确定degree：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230408213637573.png" alt="image-20230408213637573" style="zoom:50%;" /></p><p>best degree is 9 min RMSE in test sets: 0.2014522467351943</p><p>接下来在<spanclass="math inline">\(degrer=9\)</span>的情况下，寻找<spanclass="math inline">\(\alpha\)</span>的参数最优情况：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230408221238294.png" alt="image-20230408221238294" style="zoom:50%;" /></p><p>parameter_best is 2.848035868435799e-05</p><p>最后，按以上两种情况搜寻参数<spanclass="math inline">\(\beta\)</span>：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230408221701245.png" alt="image-20230408221701245" style="zoom: 50%;" /></p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230408221719701.png" alt="image-20230408221719701" style="zoom:50%;" /></p><p>beta_best is 14.84968262254465</p><p>最终参数选择结果为：</p><table><thead><tr class="header"><th><span class="math inline">\(\alpha\)</span></th><th>2.848035868435799e-05</th></tr></thead><tbody><tr class="odd"><td><span class="math inline">\(degree\)</span></td><td><strong>9</strong></td></tr><tr class="even"><td><span class="math inline">\(\beta\)</span></td><td><strong>14.84968262254465</strong></td></tr></tbody></table><p>最终拟合结果：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230408222416810.png" alt="image-20230408222416810" style="zoom: 50%;" /></p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230408222947483.png" alt="image-20230408222947483" style="zoom: 50%;" /></p><h2 id="模拟拟合过程似然先验">模拟拟合过程（似然、先验）</h2><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230408233948782.png" alt="image-20230408233948782" style="zoom:67%;" /></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> multivariate_normal, norm</span><br><span class="line"><span class="keyword">from</span> numpy.random <span class="keyword">import</span> seed, uniform, randn</span><br><span class="line"><span class="keyword">from</span> numpy.linalg <span class="keyword">import</span> inv</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">x, a</span>):</span><br><span class="line">    <span class="keyword">return</span> a[<span class="number">0</span>] + a[<span class="number">1</span>] * x</span><br><span class="line"></span><br><span class="line">a = np.array([-<span class="number">0.3</span>, <span class="number">0.5</span>])</span><br><span class="line">N = <span class="number">30</span></span><br><span class="line">sigma = <span class="number">0.2</span></span><br><span class="line">X = uniform(-<span class="number">1</span>, <span class="number">1</span>, (N, <span class="number">1</span>))</span><br><span class="line">T = f(X, a) + randn(N, <span class="number">1</span>) * sigma</span><br><span class="line"></span><br><span class="line">beta = (<span class="number">1</span> / sigma) ** <span class="number">2</span> <span class="comment"># precision</span></span><br><span class="line">alpha = <span class="number">2.0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">posterior_w</span>(<span class="params">phi, t, S0, m0</span>):</span><br><span class="line">    SN = inv(inv(S0) + beta * Phi.T @ Phi)</span><br><span class="line">    mN = SN @ (inv(S0) @ m0 + beta * Phi.T @ t)</span><br><span class="line">    <span class="keyword">return</span> SN, mN</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sample_vals</span>(<span class="params">X, T, ix</span>):</span><br><span class="line">    x_in = X[ix]</span><br><span class="line">    Phi = np.c_[np.ones_like(x_in), x_in]</span><br><span class="line">    t = T[[ix]]</span><br><span class="line">    <span class="keyword">return</span> Phi, t</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_prior</span>(<span class="params">m, S, liminf=-<span class="number">1</span>, limsup=<span class="number">1</span>, step=<span class="number">0.05</span>, ax=plt, **kwargs</span>):</span><br><span class="line">    grid = np.mgrid[liminf:limsup + step:step, liminf:limsup + step:step]</span><br><span class="line">    nx = grid.shape[-<span class="number">1</span>]</span><br><span class="line">    z = multivariate_normal.pdf(grid.T.reshape(-<span class="number">1</span>, <span class="number">2</span>), mean=m.ravel(), cov=S).reshape(nx, nx).T</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ax.contourf(*grid, z, cmap=<span class="string">&#x27;jet&#x27;</span>,interpolation=<span class="string">&#x27;nearest&#x27;</span>,**kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_sample_w</span>(<span class="params">mean, cov, size=<span class="number">10</span>, ax=plt</span>):</span><br><span class="line">    w = np.random.multivariate_normal(mean=mean.ravel(), cov=cov, size=size)</span><br><span class="line">    x = np.linspace(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> wi <span class="keyword">in</span> w:</span><br><span class="line">        ax.plot(x, f(x, wi), c=<span class="string">&quot;tab:blue&quot;</span>, alpha=<span class="number">0.4</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_likelihood_obs</span>(<span class="params">X, T, ix, ax=plt</span>):</span><br><span class="line">    W = np.mgrid[-<span class="number">1</span>:<span class="number">1</span>:<span class="number">0.1</span>, -<span class="number">1</span>:<span class="number">1</span>:<span class="number">0.1</span>]</span><br><span class="line">    x, t = sample_vals(X, T, ix)</span><br><span class="line">    mean = W.T.reshape(-<span class="number">1</span>, <span class="number">2</span>) @ x.T</span><br><span class="line"></span><br><span class="line">    likelihood = norm.pdf(t, loc=mean, scale=np.sqrt(<span class="number">1</span> / beta)).reshape(<span class="number">20</span>, <span class="number">20</span>).T</span><br><span class="line">    ax.contourf(*W, likelihood,cmap=<span class="string">&#x27;jet&#x27;</span>,interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">    ax.scatter(-<span class="number">0.3</span>, <span class="number">0.5</span>, c=<span class="string">&quot;white&quot;</span>, marker=<span class="string">&quot;+&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">SN = np.eye(<span class="number">2</span>) / alpha</span><br><span class="line">mN = np.zeros((<span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">seed(<span class="number">1643</span>)</span><br><span class="line">N = <span class="number">20</span></span><br><span class="line">nobs = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">20</span>]</span><br><span class="line">ix_fig = <span class="number">1</span></span><br><span class="line">fig, ax = plt.subplots(<span class="built_in">len</span>(nobs) + <span class="number">1</span>, <span class="number">3</span>, figsize=(<span class="number">10</span>, <span class="number">12</span>))</span><br><span class="line">plot_prior(mN, SN, ax=ax[<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">1</span>].scatter(-<span class="number">0.3</span>, <span class="number">0.5</span>, c=<span class="string">&quot;white&quot;</span>, marker=<span class="string">&quot;+&quot;</span>)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">0</span>].axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">plot_sample_w(mN, SN, ax=ax[<span class="number">0</span>, <span class="number">2</span>])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, N + <span class="number">1</span>):</span><br><span class="line">    Phi, t = sample_vals(X, T, i)</span><br><span class="line">    SN, mN = posterior_w(Phi, t, SN, mN)</span><br><span class="line">    <span class="keyword">if</span> i + <span class="number">1</span> <span class="keyword">in</span> nobs:</span><br><span class="line">        plot_likelihood_obs(X, T, i, ax=ax[ix_fig, <span class="number">0</span>])</span><br><span class="line">        plot_prior(mN, SN, ax=ax[ix_fig, <span class="number">1</span>])</span><br><span class="line">        ax[ix_fig, <span class="number">1</span>].scatter(-<span class="number">0.3</span>, <span class="number">0.5</span>, c=<span class="string">&quot;white&quot;</span>, marker=<span class="string">&quot;+&quot;</span>)</span><br><span class="line">        ax[ix_fig, <span class="number">2</span>].scatter(X[:i + <span class="number">1</span>], T[:i + <span class="number">1</span>], c=<span class="string">&quot;crimson&quot;</span>)</span><br><span class="line">        ax[ix_fig, <span class="number">2</span>].set_xlim(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        ax[ix_fig, <span class="number">2</span>].set_ylim(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">for</span> l <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">            ax[ix_fig, l].set_xlabel(<span class="string">&quot;$w_0$&quot;</span>)</span><br><span class="line">            ax[ix_fig, l].set_ylabel(<span class="string">&quot;$w_1$&quot;</span>)</span><br><span class="line">        plot_sample_w(mN, SN, ax=ax[ix_fig, <span class="number">2</span>])</span><br><span class="line">        ix_fig += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">titles = [<span class="string">&quot;likelihood&quot;</span>, <span class="string">&quot;prior/posterior&quot;</span>, <span class="string">&quot;data space&quot;</span>]</span><br><span class="line"><span class="keyword">for</span> axi, title <span class="keyword">in</span> <span class="built_in">zip</span>(ax[<span class="number">0</span>], titles):</span><br><span class="line">    axi.set_title(title, size=<span class="number">15</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h1 id="作业五">作业五</h1><h2 id="等价核绘制">等价核绘制</h2><p>首先是高斯核的绘制，下图是一个取值为线性的高斯核函数的图像<img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402182640901.png" alt="image-20230402182640901" style="zoom: 80%;" /></p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402182755965.png" alt="image-20230402182755965" style="zoom:67%;" /></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gaussianLike</span>(<span class="params">mu,sigma,x</span>):</span><br><span class="line">    <span class="keyword">return</span> np.exp((-<span class="number">1</span>/<span class="number">2</span>)*np.matmul(np.matmul((x-mu),np.linalg.inv(sigma)),(x-mu).reshape(<span class="built_in">len</span>(x),<span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gaussianKernel</span>(<span class="params">gaussianLike,x</span>):</span><br><span class="line">    <span class="keyword">return</span> np.dot(gaussianLike(np.zeros(<span class="number">2</span>,),np.eye(<span class="number">2</span>,<span class="number">2</span>),x),gaussianLike(np.zeros(<span class="number">2</span>,),np.eye(<span class="number">2</span>,<span class="number">2</span>),x))</span><br><span class="line"></span><br><span class="line">x=np.linspace(-<span class="number">2</span>,<span class="number">2</span>,<span class="number">100</span>)</span><br><span class="line">y=np.linspace(-<span class="number">2</span>,<span class="number">2</span>,<span class="number">100</span>)</span><br><span class="line">X, Y = np.meshgrid(x, y)</span><br><span class="line">Z=[]</span><br><span class="line">z1=np.ones((<span class="number">100</span>,<span class="number">100</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> x:</span><br><span class="line">    n=<span class="number">0</span></span><br><span class="line">    z=[]</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> y:</span><br><span class="line">        m=<span class="number">0</span></span><br><span class="line">        z.append(gaussianKernel(gaussianLike,[i,j]))</span><br><span class="line">        z1[n,m]=gaussianKernel(gaussianLike,[i,j])</span><br><span class="line">        m+=<span class="number">1</span></span><br><span class="line">    n+=<span class="number">1</span></span><br><span class="line">    Z.append(z)</span><br><span class="line">Z=np.array(Z)</span><br><span class="line"></span><br><span class="line">plt.imshow(Z,cmap=<span class="string">&#x27;hot&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">ax = plt.axes(projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line">ax.plot_surface(X,Y,Z,cmap=<span class="string">&#x27;rainbow&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>下面复现课本的等价核：</p><p><strong>高斯核</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gaussian_kernel</span>(<span class="params">x, y, sigma</span>):</span><br><span class="line">    <span class="keyword">return</span> np.exp(-np.linalg.norm(x - y)**<span class="number">2</span> / (<span class="number">2</span> * (sigma ** <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_kernel_matrix</span>(<span class="params">X, sigma</span>):</span><br><span class="line">    n = X.shape[<span class="number">0</span>]</span><br><span class="line">    K = np.zeros((n, n))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i, n):</span><br><span class="line">            K[i, j] = gaussian_kernel(X[i], X[j], sigma)</span><br><span class="line">            K[j, i] = K[i, j]</span><br><span class="line">    <span class="keyword">return</span> K</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成示例数据集</span></span><br><span class="line">X = np.linspace(-<span class="number">5</span>, <span class="number">5</span>, <span class="number">100</span>).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">y = np.sin(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算不同带宽参数下的高斯等价核矩阵</span></span><br><span class="line">sigmas = [<span class="number">0.1</span>, <span class="number">1</span>, <span class="number">10</span>]</span><br><span class="line"><span class="keyword">for</span> sigma <span class="keyword">in</span> sigmas:</span><br><span class="line">    K = compute_kernel_matrix(X, sigma)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 绘制高斯核形状图像</span></span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.imshow(K, cmap=<span class="string">&#x27;jet&#x27;</span>, interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">r&#x27;Gaussian Kernel with $\sigma=$&#x27;</span> + <span class="built_in">str</span>(sigma))</span><br><span class="line">    plt.colorbar()</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402183003203.png"alt="image-20230402183003203" /><figcaption aria-hidden="true">image-20230402183003203</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402183010833.png"alt="image-20230402183010833" /><figcaption aria-hidden="true">image-20230402183010833</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402183017836.png"alt="image-20230402183017836" /><figcaption aria-hidden="true">image-20230402183017836</figcaption></figure><p><strong>多项式核</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">polynomial_kernel</span>(<span class="params">x, y, degree, coef0=<span class="number">0</span></span>):</span><br><span class="line">    <span class="keyword">return</span> (np.dot(x, y) + coef0) ** degree</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_kernel_matrix</span>(<span class="params">X, degree, coef0=<span class="number">0</span></span>):</span><br><span class="line">    n = X.shape[<span class="number">0</span>]</span><br><span class="line">    K = np.zeros((n, n))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i, n):</span><br><span class="line">            K[i, j] = polynomial_kernel(X[i], X[j], degree, coef0)</span><br><span class="line">            K[j, i] = K[i, j]</span><br><span class="line">    <span class="keyword">return</span> K</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成示例数据集</span></span><br><span class="line">X = np.linspace(-<span class="number">5</span>, <span class="number">5</span>, <span class="number">100</span>).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">y = np.sin(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算不同阶数和常数项参数下的多项式核矩阵</span></span><br><span class="line">degrees = [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">coef0s = [-<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line"><span class="keyword">for</span> degree <span class="keyword">in</span> degrees:</span><br><span class="line">    <span class="keyword">for</span> coef0 <span class="keyword">in</span> coef0s:</span><br><span class="line">        K = compute_kernel_matrix(X, degree, coef0)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 绘制多项式核形状图像</span></span><br><span class="line">        plt.figure()</span><br><span class="line">        plt.imshow(K, cmap=<span class="string">&#x27;jet&#x27;</span>, interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">        plt.title(<span class="string">&#x27;Polynomial Kernel with degree=&#x27;</span> + <span class="built_in">str</span>(degree) + <span class="string">&#x27; and coef0=&#x27;</span> + <span class="built_in">str</span>(coef0))</span><br><span class="line">        plt.colorbar()</span><br><span class="line">        plt.show()</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402183116818.png"alt="image-20230402183116818" /><figcaption aria-hidden="true">image-20230402183116818</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402183128404.png"alt="image-20230402183128404" /><figcaption aria-hidden="true">image-20230402183128404</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402183137656.png"alt="image-20230402183137656" /><figcaption aria-hidden="true">image-20230402183137656</figcaption></figure><p><strong>Sigmoid核</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid_kernel</span>(<span class="params">x, y, alpha, c</span>):</span><br><span class="line">    <span class="keyword">return</span> np.tanh(alpha * np.dot(x, y) + c)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_kernel_matrix</span>(<span class="params">X, alpha, c</span>):</span><br><span class="line">    n = X.shape[<span class="number">0</span>]</span><br><span class="line">    K = np.zeros((n, n))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i, n):</span><br><span class="line">            K[i, j] = sigmoid_kernel(X[i], X[j], alpha, c)</span><br><span class="line">            K[j, i] = K[i, j]</span><br><span class="line">    <span class="keyword">return</span> K</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成示例数据集</span></span><br><span class="line">X = np.linspace(-<span class="number">5</span>, <span class="number">5</span>, <span class="number">100</span>).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">y = np.sin(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算不同超参数下的 Sigmoid 核矩阵</span></span><br><span class="line">alphas = [<span class="number">0.1</span>, <span class="number">0.5</span>, <span class="number">1</span>]</span><br><span class="line">cs = [-<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line"><span class="keyword">for</span> alpha <span class="keyword">in</span> alphas:</span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> cs:</span><br><span class="line">        K = compute_kernel_matrix(X, alpha, c)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 绘制 Sigmoid 核形状图像</span></span><br><span class="line">        plt.figure()</span><br><span class="line">        plt.imshow(K, cmap=<span class="string">&#x27;jet&#x27;</span>, interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">        plt.title(<span class="string">&#x27;Sigmoid Kernel with alpha=&#x27;</span> + <span class="built_in">str</span>(alpha) + <span class="string">&#x27; and c=&#x27;</span> + <span class="built_in">str</span>(c))</span><br><span class="line">        plt.colorbar()</span><br><span class="line">        plt.show()</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402183249517.png"alt="image-20230402183249517" /><figcaption aria-hidden="true">image-20230402183249517</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402183257364.png"alt="image-20230402183257364" /><figcaption aria-hidden="true">image-20230402183257364</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402183304889.png"alt="image-20230402183304889" /><figcaption aria-hidden="true">image-20230402183304889</figcaption></figure><h2 id="似然">似然</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">random.seed(<span class="number">615</span>)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_synth_data</span>(<span class="params">N, beta</span>):</span><br><span class="line">    X_N =np.random.uniform(-<span class="number">1</span>,<span class="number">1</span>, N)</span><br><span class="line">    X_N = np.column_stack((np.ones(N), X_N))</span><br><span class="line">    <span class="comment"># for this example the true function is f(x,a) = a_0 + a_1*x</span></span><br><span class="line">    <span class="comment"># where a_0 = -.3 and a_1 = .5 are the parameters that we</span></span><br><span class="line">    <span class="comment"># are going to estimate</span></span><br><span class="line">    a = np.array([-<span class="number">.3</span>, <span class="number">.5</span>])</span><br><span class="line">    t = np.dot(X_N, a)</span><br><span class="line">    <span class="keyword">return</span> X_N, t + np.random.normal(loc=<span class="number">0.0</span>, scale=np.sqrt(<span class="number">1.</span>/beta), size=N)</span><br><span class="line"></span><br><span class="line">beta_ = <span class="number">25.0</span></span><br><span class="line">alpha = <span class="number">2.0</span></span><br><span class="line">N = <span class="number">20</span></span><br><span class="line">X_N, t_N = get_synth_data(N, beta_)</span><br><span class="line">x = np.linspace(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">70</span>)</span><br><span class="line">y = np.linspace(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">70</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">w0, w1 = np.meshgrid(x, y)</span><br><span class="line">m_0 = [<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">S_0 = <span class="number">1</span>/alpha * np.eye(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">n = <span class="number">1</span></span><br><span class="line">X_n = X_N[<span class="built_in">range</span>(n), :]</span><br><span class="line">t_n = t_N[<span class="built_in">range</span>(n)]</span><br><span class="line">plt.xlim(-<span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line">plt.ylim(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">plt.scatter(X_n[:, <span class="number">1</span>], t_n)</span><br><span class="line">plt.title(<span class="string">&quot;First point in the data set&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>);</span><br><span class="line">plt.ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">likelihood</span>(<span class="params">t_, x, w, beta</span>):</span><br><span class="line">    <span class="keyword">from</span> math <span class="keyword">import</span> sqrt</span><br><span class="line">    <span class="keyword">return</span> stats.norm.pdf(t_,loc=np.dot(w,x), scale=sqrt(<span class="number">1.</span>/beta))</span><br><span class="line"></span><br><span class="line">Z = np.zeros((<span class="built_in">len</span>(y), <span class="built_in">len</span>(x)))</span><br><span class="line"><span class="keyword">for</span> i, w1 <span class="keyword">in</span> <span class="built_in">enumerate</span>(y):</span><br><span class="line">    <span class="keyword">for</span> j, w0 <span class="keyword">in</span> <span class="built_in">enumerate</span>(x):</span><br><span class="line">        Z[i, j] = likelihood(t_n[-<span class="number">1</span>], X_n[-<span class="number">1</span>,:], np.array([w0, w1]), beta_)</span><br><span class="line">extent = (-<span class="number">1</span>,<span class="number">1</span>,-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">plt.imshow(Z, extent=extent, origin=<span class="string">&#x27;lower&#x27;</span>)</span><br><span class="line">plt.plot(-<span class="number">0.3</span>, <span class="number">0.5</span>, <span class="string">&#x27;w+&#x27;</span>, markeredgewidth=<span class="number">2</span>, markersize=<span class="number">12</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Likelihood of the first point in the data set, white cross = true value&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;w0&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;w1&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402184647229.png"alt="image-20230402184647229" /><figcaption aria-hidden="true">image-20230402184647229</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402184827621.png"alt="image-20230402184827621" /><figcaption aria-hidden="true">image-20230402184827621</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402184922104.png"alt="image-20230402184922104" /><figcaption aria-hidden="true">image-20230402184922104</figcaption></figure><h1 id="作业一-多项式拟合">作业一 多项式拟合</h1><h2 id="理论推导">理论推导</h2><p><span class="math display">\[\min ||f(\omega;x)-t||^2\\\sum_{i=0}^{n}{\omega_i*x_i^j}=t\]</span></p><p>写成矩阵形式： <span class="math display">\[XW=T\]</span> 使用平方和最小来衡量，设损失函数： <spanclass="math display">\[L(x)=\frac{1}{2}\sum^{N}_{i=1}{(\sum_{j=0}^{M}{\omega_jx_i^j-y_i)^2}}\]</span> 对损失函数求导，令导数等于0： <span class="math display">\[\begin{array}{l}\frac{\partial L(x;\omega)}{\partial \omega_i}=0 \\\\\frac{1}{2}\sum_{i=1}^{N}{2(\sum^{j=0}_{M}{\omega_jx_i^j-y_i)}\timesx_i^k}=0 \\\\\sum_{i=1}^{N}{\sum^{M}_{j=1}{\omega_ix_i^{j+k}}}=\sum_{j=1}^{M}{x_i^ky_i}(k=0,1,2,3,\cdots,M)\end{array}\]</span> 那么就有： <span class="math display">\[\begin{array}{l}X=\sum^M_{j=1}{x_i^{j+k}} \\W=\omega_i \\Y=\sum_{i=1}^{M}{x_i^ky_i}\\XW=Y\end{array}\]</span> 将以<spanclass="math inline">\(x\)</span>为参数的非线性模型转化为以<spanclass="math inline">\(w\)</span>的线性模型，从而转化为矩阵方程求解问题,需要将方程特征进行组合，实现上使用sklearn，进行多项式特征组合，然后使用线性回归进行预测：</p><p>算法语言描述：</p><ol type="1"><li><p>生成一个（特征数目+1，特征数目+1）的矩阵</p></li><li><p>分别计算0-特征阶数的幂</p></li><li><p>返回特征混合矩阵</p></li><li><p>线性回归</p></li></ol><h2 id="代码实现">代码实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Polyfeature</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,n_features</span>):</span><br><span class="line">        self.n_features=n_features</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 一元特征混合</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, x</span>):</span><br><span class="line">        xf = np.zeros((<span class="built_in">len</span>(x), self.n_features + <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.n_features + <span class="number">1</span>):</span><br><span class="line">            xf[:,i] = np.power(x, i).reshape(np.shape(xf[:,i]))</span><br><span class="line">        self.xf=xf</span><br><span class="line">        <span class="keyword">return</span> xf</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">transform</span>(<span class="params">self,x</span>):</span><br><span class="line">        xf = np.zeros((<span class="built_in">len</span>(x), self.n_features + <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.n_features + <span class="number">1</span>):</span><br><span class="line">            xf[:, i] = np.power(x, i).reshape(np.shape(xf[:, i]))</span><br><span class="line">        self.xf = xf</span><br><span class="line">        <span class="keyword">return</span> xf</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit_transform</span>(<span class="params">self, x</span>):</span><br><span class="line">        xf = np.zeros((<span class="built_in">len</span>(x), self.n_features + <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.n_features + <span class="number">1</span>):</span><br><span class="line">            xf[:, i] = np.power(x, i).reshape(np.shape(xf[:, i]))</span><br><span class="line">            self.xf = xf</span><br><span class="line">        <span class="keyword">return</span> xf</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">linearregression</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self,x,y,Lambda=<span class="number">0</span></span>):</span><br><span class="line">        c = np.dot(x.T, x)</span><br><span class="line">        I = np.eye(np.shape(c)[<span class="number">0</span>])</span><br><span class="line">        d = np.dot(Lambda, I)</span><br><span class="line">        e = (c + d)</span><br><span class="line">        e = np.linalg.inv(e)</span><br><span class="line">        w = np.dot(x.T, y)</span><br><span class="line">        w = np.dot(e, w)</span><br><span class="line">        self.w = w</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self,x</span>):</span><br><span class="line">        y=np.dot(x,self.w)</span><br><span class="line">        <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">polyregression</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,features</span>):</span><br><span class="line">        self.n_features=features</span><br><span class="line">    <span class="comment"># 生成数据</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">create_data</span>(<span class="params">self,n</span>):</span><br><span class="line">        self.n=n</span><br><span class="line">        X=np.random.rand(n,<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 考虑到需要保证高斯白噪声的0均值</span></span><br><span class="line">        noise=<span class="number">0.3</span>*np.random.uniform(low=-<span class="number">1</span>, high=<span class="number">1</span>, size=(n,<span class="number">1</span>))</span><br><span class="line">        t=np.sin(X*<span class="number">2</span>*math.pi)+noise</span><br><span class="line">        self.X=X</span><br><span class="line">        self.t=t</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 划分数据集</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">splitData</span>(<span class="params">self</span>):</span><br><span class="line">        X_train, X_test, T_train, T_test = train_test_split(self.X, self.t, test_size=<span class="number">0.3</span>, random_state=<span class="number">0</span>)</span><br><span class="line">        self.X_train=X_train</span><br><span class="line">        self.X_test=X_test</span><br><span class="line">        self.T_train=T_train</span><br><span class="line">        self.T_test=T_test</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 多项式拟合</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self</span>):</span><br><span class="line">        poly = PolynomialFeatures(self.n_features)</span><br><span class="line">        x_train_poly = poly.fit_transform(self.X_train)</span><br><span class="line"></span><br><span class="line">        lin=LinearRegression()</span><br><span class="line">        lin.fit(x_train_poly,self.T_train)</span><br><span class="line"></span><br><span class="line">        self.lin=lin</span><br><span class="line">        self.poly=poly</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">draw</span>(<span class="params">self</span>):</span><br><span class="line">        plt.style.use(<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line">        plt.figure()</span><br><span class="line">        plt.plot(np.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">50</span>),np.sin(np.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">50</span>)*<span class="number">2</span>*math.pi),color=<span class="string">&#x27;green&#x27;</span>)</span><br><span class="line">        plt.scatter(self.X,self.t,marker=<span class="string">&#x27;o&#x27;</span>,edgecolor=<span class="string">&#x27;blue&#x27;</span>,color=<span class="string">&#x27;white&#x27;</span>,linewidths=<span class="string">&#x27;1.1&#x27;</span>)</span><br><span class="line">        plt.plot(np.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">50</span>),self.lin.predict(self.poly.transform(np.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">50</span>).reshape(-<span class="number">1</span>,<span class="number">1</span>))),color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">        s=<span class="string">&#x27;n_features=&#x27;</span>+<span class="built_in">str</span>(self.n_features)</span><br><span class="line">        plt.text(<span class="number">0.7</span>,<span class="number">1</span>,s)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;X&#x27;</span>)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;Y&#x27;</span>)</span><br><span class="line">        plt.savefig(<span class="string">&#x27;features=&#x27;</span>+<span class="built_in">str</span>(self.n_features)+<span class="string">&#x27; samples=&#x27;</span>+<span class="built_in">str</span>(self.n)+<span class="string">&#x27;.png&#x27;</span>)</span><br><span class="line">        plt.show()</span><br><span class="line">    <span class="comment"># 衡量拟合的标准</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">RSME</span>(<span class="params">self</span>):</span><br><span class="line">        T_test_predict=self.lin.predict(self.poly.transform(self.X_test))</span><br><span class="line">        SSE=np.<span class="built_in">sum</span>(np.square(self.T_test-T_test_predict))</span><br><span class="line">        MSE=SSE/<span class="built_in">len</span>(T_test_predict)</span><br><span class="line">        rsme=np.sqrt(MSE)</span><br><span class="line">        <span class="keyword">return</span> rsme</span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 对不同特征选择的比较</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">features_test</span>():</span><br><span class="line">        RSME=[]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">            poly=polyregression(i)</span><br><span class="line">            poly.create_data(<span class="number">20</span>)</span><br><span class="line">            poly.splitData()</span><br><span class="line">            poly.fit()</span><br><span class="line">            poly.draw()</span><br><span class="line">            RSME.append(poly.RSME())</span><br><span class="line"></span><br><span class="line">        plt.figure()</span><br><span class="line">        plt.plot(np.linspace(<span class="number">0</span>,<span class="number">10</span>,<span class="number">10</span>),RSME,marker=<span class="string">&#x27;^&#x27;</span>,label=<span class="string">&quot;points&quot;</span>)</span><br><span class="line">        plt.show()</span><br><span class="line">    <span class="comment"># 对不同样本数量的比较</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">samples_test</span>():</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> [<span class="number">20</span>,<span class="number">200</span>,<span class="number">500</span>]:</span><br><span class="line">            RSME=[]</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">50</span>):</span><br><span class="line">                poly=polyregression(i)</span><br><span class="line">                poly.create_data(j)</span><br><span class="line">                poly.splitData()</span><br><span class="line">                poly.fit()</span><br><span class="line">                poly.draw()</span><br><span class="line">                RSME.append(poly.RSME())</span><br><span class="line">            plt.figure()</span><br><span class="line">            plt.plot(np.linspace(<span class="number">0</span>,<span class="number">50</span>,<span class="number">50</span>),RSME,marker=<span class="string">&#x27;^&#x27;</span>,label=<span class="string">&quot;points&quot;</span>)</span><br><span class="line">            plt.savefig(<span class="string">&#x27;sample=&#x27;</span>+<span class="built_in">str</span>(j)+<span class="string">&#x27;.png&#x27;</span>)</span><br><span class="line">            plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># features_test()</span></span><br><span class="line">    samples_test()</span><br></pre></td></tr></table></figure><h2 id="结果对比">结果对比</h2><p>不同的特征数量，首先全部针对样本数量为10的情况： <imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/features=0%20samples=10.png"alt="features=0 samples=10" /></p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/features=1%20samples=10.png"alt="features=1 samples=10" /><figcaption aria-hidden="true">features=1 samples=10</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/features=2%20samples=10.png"alt="features=2 samples=10" /><figcaption aria-hidden="true">features=2 samples=10</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/features=3%20samples=10.png"alt="features=3 samples=10" /><figcaption aria-hidden="true">features=3 samples=10</figcaption></figure><figure><imgsrc="G:\专业学习\第六学期\机器学习\实验一\selectF\features=4%20samples=10.png"alt="features=4 samples=10" /><figcaption aria-hidden="true">features=4 samples=10</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/features=5%20samples=10.png"alt="features=5 samples=10" /><figcaption aria-hidden="true">features=5 samples=10</figcaption></figure><p>从中可以大致看出，在选择特征过少时，会出现欠拟合现象，选择过多后则会过拟合，针对样本量为20的情况下，RSME曲线如图：<imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/sample=20.png"alt="sample=20.png" />图上显示的情况，并不是与我们预期中的情况完全吻合，其原因可能是因为测试集样本数量过少，导致无法很好的捕捉曲线拟合的问题，于是我们对其他样本数量进行对比、 <imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/sample=200.png"alt="sample=200.png" /> <imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/sample=500.png"alt="sample=500.png" /><br />可以看出样本数量增多后，特征的选择有明显的趋势。尝试复现使用样本为10的情况：<imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/sample=10.png"alt="sample=10" /> 且样本数量会明显的影响拟合的效果。</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/features=5%20samples=10.png"alt="features=5 samples=10" /><figcaption aria-hidden="true">features=5 samples=10</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/features=5%20samples=20.png"alt="features=5 samples=20" /><figcaption aria-hidden="true">features=5 samples=20</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/features=5%20samples=200.png"alt="features=5 samples=200" /><figcaption aria-hidden="true">features=5 samples=200</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/features=5%20samples=500.png"alt="features=5 samples=500" /><figcaption aria-hidden="true">features=5 samples=500</figcaption></figure><p>针对样本为10，特征为5的情况下进行正则化：</p><p><span class="math inline">\(\lambda\)</span>=0.7740859059011267</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230311220541756.png"alt="image-20230311220541756" /><figcaption aria-hidden="true">image-20230311220541756</figcaption></figure><h1 id="作业二">作业二</h1><h2 id="频率学派与贝叶斯学派">频率学派与贝叶斯学派</h2><ul><li>频率观点认为频率能够趋近概率，模型的参数是一定的，只要采样数目足够多就能逼近参数值，我的理解是其符合大数定律的思想（此为辛钦大数定律）：<span class="math display">\[\lim_{n\to\infty}P\left(\left|\frac{1}{n}\sum_{i=1}^{n}{a_i-\mu}  \right|&lt;\varepsilon\right)=1\]</span></li><li>贝叶斯观点认为模型的参数是在变化的，样本是一定的。 <spanclass="math display">\[p(w|D)=\frac{p(D|w)p(w)}{p(D)}\]</span> 以一元高斯分布为例，解释样本分布问题：</li><li>频率：频率的思想是以样本代替总体，从而得到模型参数，假设有数据集<spanclass="math inline">\(D=\{x_1,x_2,\cdot\cdot\cdot,x_n\}\)</span>，则估计得到的一元高斯分布的参数为<span class="math display">\[\hat\mu=\frac{1}{n}\sum_{i=1}^{n}{x_i}\]</span> <span class="math display">\[\hat{\sigma^2}=\frac{1}{n}\sum_{i=1}^{n}{(x_i-\hat\mu)}^2\]</span>样本分布显然是和总体有差异的，对其求期望可以得到，均值为无偏估计，而方差存在偏差，而偏差随着样本数目n的增大而减小（<spanclass="math inline">\(E(\hat\sigma^2)=\frac{n-1}{n}\sigma^2\)</span>）。</li><li>贝叶斯：贝叶斯的思想认为所有参数都是一个分布，而样本是固定不变的量。所以通过先验尽可能使逼近高斯分布。<span class="math display">\[p(D|w)=\frac{p(w|D)p(D)}{p(w)}\]</span> 有似然函数，其中<spanclass="math inline">\(p(D)\)</span>为一个常数，可被忽略（归一化），根据课本给出的高斯分布求解结果，发现他的方差和均值均为无偏估计。## 公式推导 <imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230421154051248.png"alt="image-20230421154051248" /></li></ul><p>引入先验</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230421154116419.png"alt="image-20230421154116419" /><figcaption aria-hidden="true">image-20230421154116419</figcaption></figure><p>在这里将数据的概率分布进行了归一，认为样本概率为一常数</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230421154257436.png"alt="image-20230421154257436" /><figcaption aria-hidden="true">image-20230421154257436</figcaption></figure><p>然后对<span class="math inline">\(\lnp(\mathbf{w}|\alpha)\)</span>求解：</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230421154321678.png"alt="image-20230421154321678" /><figcaption aria-hidden="true">image-20230421154321678</figcaption></figure><p>取负数：<br /><span class="math display">\[-\ln p(\mathbf{t|x},w,\beta)p(\mathbf{w}|\alpha)=\frac{\beta}{2}\sum_{n=1}^{N}{(x-y_n(x_n,\mathbf{w}))^2 }+\frac{\alpha}{2}\mathbf{w^T}\mathbf{w}-\frac{n}{2}\ln \frac{\beta}{2\pi}-\frac{M+1}{2}\ln \alpha+\frac{M+1}{2}\ln 2\pi\]</span> 后三项均为常数，对最大化没有任何影响，因此损失函数为：</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230421154342936.png"alt="image-20230421154342936" /><figcaption aria-hidden="true">image-20230421154342936</figcaption></figure><h1 id="作业三">作业三</h1><h2 id="基函数图像复现">基函数图像复现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib.ticker <span class="keyword">import</span> MultipleLocator</span><br><span class="line"></span><br><span class="line">x_major_locator=MultipleLocator(<span class="number">1</span>)</span><br><span class="line">y_major_locator=MultipleLocator(<span class="number">0.25</span>)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>,<span class="number">5</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigma</span>(<span class="params">x,b</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>/(np.exp((-x+b)*<span class="number">10</span>)+<span class="number">1</span>)</span><br><span class="line">x=np.linspace(-<span class="number">1</span>,<span class="number">1</span>,<span class="number">100</span>)</span><br><span class="line">b=np.linspace(-<span class="number">1</span>,<span class="number">1</span>,<span class="number">11</span>).tolist()</span><br><span class="line"><span class="keyword">for</span> bi <span class="keyword">in</span> b:</span><br><span class="line">    plt.plot(x,sigma(x,bi))</span><br><span class="line">plt.xlim(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">plt.ylim(<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line">ax=plt.gca()</span><br><span class="line">ax.xaxis.set_major_locator(x_major_locator)</span><br><span class="line">ax.yaxis.set_major_locator(y_major_locator)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">def gaussian(mu,sigma,x,b):</span></span><br><span class="line"><span class="string">    return 1/(np.sqrt(2*np.pi)*sigma)*np.exp(-np.square((x+b)*5-mu)/2*np.square(sigma))</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">plt.subplot(1,3,2)</span></span><br><span class="line"><span class="string">for bi in b:</span></span><br><span class="line"><span class="string">    plt.plot(x,gaussian(0,1,x,bi))</span></span><br><span class="line"><span class="string">plt.xlim(-1,1)</span></span><br><span class="line"><span class="string">plt.ylim(0,0.4)</span></span><br><span class="line"><span class="string">plt.show()</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">poly</span>(<span class="params">x,n</span>):</span><br><span class="line">    <span class="keyword">return</span> np.power(x,n)</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>)</span><br><span class="line">n=np.linspace(<span class="number">1</span>,<span class="number">10</span>,<span class="number">10</span>).tolist()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> n:</span><br><span class="line">    plt.plot(x,poly(x,i))</span><br><span class="line">plt.xlim(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">plt.ylim(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">ax=plt.gca()</span><br><span class="line">y_major_locator1=MultipleLocator(<span class="number">0.5</span>)</span><br><span class="line">ax.xaxis.set_major_locator(x_major_locator)</span><br><span class="line">ax.yaxis.set_major_locator(y_major_locator1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gaussian1</span>(<span class="params">mu,sigma,x,b</span>):</span><br><span class="line">    <span class="keyword">return</span> np.exp(-np.square((x+b)*<span class="number">5</span>-mu)/<span class="number">2</span>*np.square(sigma))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"><span class="keyword">for</span> bi <span class="keyword">in</span> b:</span><br><span class="line">    plt.plot(x,gaussian1(<span class="number">0</span>,<span class="number">1</span>,x,bi))</span><br><span class="line"></span><br><span class="line">ax=plt.gca()</span><br><span class="line">ax.xaxis.set_major_locator(x_major_locator)</span><br><span class="line">ax.yaxis.set_major_locator(y_major_locator)</span><br><span class="line"></span><br><span class="line">plt.xlim(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">plt.ylim(<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230317214519144.png"alt="image-20230317214519144" /><figcaption aria-hidden="true">image-20230317214519144</figcaption></figure><h1 id="作业四-多项式拟合加强版">作业四 多项式拟合（加强版）</h1><h2 id="实验项目结构">实验项目结构</h2><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230326184103754.png" alt="image-20230326184103754" style=" float:left" />/&gt;其中，data储存固化的数据</p><p>将数据生成函数与多项式拟合功能分离，建立createData.py</p><p>交叉验证函数</p><p>线性回归</p><p>多项式特征生成和多项式回归</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">createData.py</span><br><span class="line">__________________</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成数据集</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_data</span>(<span class="params">n,beta</span>):</span><br><span class="line">    n = n</span><br><span class="line">    X = np.linspace(<span class="number">0</span>, <span class="number">1</span>, n).reshape(n, <span class="number">1</span>)</span><br><span class="line">    noise = beta * np.random.uniform(low=-<span class="number">1</span>, high=<span class="number">1</span>, size=(n, <span class="number">1</span>))</span><br><span class="line">    t = np.sin(X * <span class="number">2</span> * np.pi) + noise</span><br><span class="line">    X = X</span><br><span class="line">    t = t</span><br><span class="line">    data=np.hstack((X,t))</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">splitData</span>(<span class="params">X,t</span>):</span><br><span class="line">    X_train, X_test, T_train, T_test = train_test_split(X, t, test_size=<span class="number">0.2</span>, random_state=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> X_train,X_test,T_train,T_test</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据固化</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">tocsv</span>(<span class="params">data</span>):</span><br><span class="line">    df=pd.DataFrame(data)</span><br><span class="line">    df.to_csv(<span class="string">&#x27;.\data\sample=&#x27;</span>+<span class="built_in">str</span>(data.shape[<span class="number">0</span>])+<span class="string">&#x27;.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    data=create_data(<span class="number">10</span>,<span class="number">0.1</span>)</span><br><span class="line">    tocsv(data)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">Cross_Validation.py</span><br><span class="line">_________________________________________</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Cross_Validation</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_folds</span>):</span><br><span class="line">        self.n_folds = n_folds</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">CV</span>(<span class="params">self,x,y</span>):</span><br><span class="line">        kf = KFold(n_splits=self.n_folds)</span><br><span class="line">        x_train=[]</span><br><span class="line">        x_test=[]</span><br><span class="line">        y_train=[]</span><br><span class="line">        y_test=[]</span><br><span class="line">        <span class="keyword">for</span> train_index,test_index <span class="keyword">in</span> kf.split(x):</span><br><span class="line">            xtr, xte = x[train_index], x[test_index]</span><br><span class="line">            ytr, yte = y[train_index], y[test_index]</span><br><span class="line">            x_train.append(xtr)</span><br><span class="line">            x_test.append(xte)</span><br><span class="line">            y_train.append(ytr)</span><br><span class="line">            y_test.append(yte)</span><br><span class="line">        <span class="keyword">return</span> x_train, x_test, y_train, y_test</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">linearregression.py</span><br><span class="line">_______________________</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">linearregression</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self,x,y,Lambda=<span class="number">0</span></span>):</span><br><span class="line">        c = np.dot(x.T, x)</span><br><span class="line">        I = np.eye(np.shape(c)[<span class="number">0</span>])</span><br><span class="line">        d = np.dot(Lambda, I)</span><br><span class="line">        e = (c + d)</span><br><span class="line">        e = np.linalg.inv(e)</span><br><span class="line">        w = np.dot(x.T, y)</span><br><span class="line">        w = np.dot(e, w)</span><br><span class="line">        self.w = w</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self,x</span>):</span><br><span class="line">        y=np.dot(x,self.w)</span><br><span class="line">        <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">Polyfeature.py</span><br><span class="line">____________________</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Polyfeature</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,n_features</span>):</span><br><span class="line">        self.n_features=n_features</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 一元特征混合</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># 单个数字</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(x,<span class="built_in">int</span>):</span><br><span class="line">            x=np.array([x])</span><br><span class="line">        <span class="comment"># 数组计算</span></span><br><span class="line">        xf = np.zeros((<span class="built_in">len</span>(x), self.n_features + <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.n_features + <span class="number">1</span>):</span><br><span class="line">            xf[:,i] = np.power(x, i).reshape(np.shape(xf[:,i]))</span><br><span class="line">        self.xf=xf</span><br><span class="line">        <span class="keyword">return</span> xf</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit_transform</span>(<span class="params">self,x</span>):</span><br><span class="line">        <span class="comment"># 单个数字</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(x, <span class="built_in">int</span>):</span><br><span class="line">            x = np.array([x])</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(x,<span class="built_in">float</span>):</span><br><span class="line">            x = np.array([x])</span><br><span class="line">        <span class="comment"># 数组计算</span></span><br><span class="line">        xf = np.zeros((<span class="built_in">len</span>(x), self.n_features + <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.n_features + <span class="number">1</span>):</span><br><span class="line">            xf[:, i] = np.power(x, i).reshape(np.shape(xf[:, i]))</span><br><span class="line">        <span class="keyword">return</span> xf</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br></pre></td><td class="code"><pre><span class="line">PolyRegress.py</span><br><span class="line">______________________________________</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.ticker <span class="keyword">as</span> mticker</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> Polyfeature <span class="keyword">import</span> Polyfeature</span><br><span class="line"><span class="keyword">from</span> linearregression <span class="keyword">import</span> linearregression</span><br><span class="line"><span class="keyword">from</span> Cross_Validation <span class="keyword">import</span> Cross_Validation</span><br><span class="line"><span class="keyword">from</span> createData <span class="keyword">import</span> create_data</span><br><span class="line"><span class="keyword">from</span> createData <span class="keyword">import</span> splitData</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">polyRegression</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, features, n_lambda</span>):</span><br><span class="line">        self.n_features = features</span><br><span class="line">        self.n_lambda = n_lambda</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 拟合</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self,x,y,l</span>):</span><br><span class="line">        <span class="comment"># 混合特征</span></span><br><span class="line">        pf=Polyfeature(self.n_features)</span><br><span class="line">        pf.fit(x)</span><br><span class="line">        <span class="comment"># 线性回归</span></span><br><span class="line">        lin = linearregression()</span><br><span class="line">        lin.fit(pf.xf,y,Lambda=l)</span><br><span class="line"></span><br><span class="line">        self.lin = lin</span><br><span class="line">        self.poly = pf</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self,x</span>):</span><br><span class="line">        x=self.poly.fit_transform(x)</span><br><span class="line">        prediction=self.lin.predict(x)</span><br><span class="line">        <span class="keyword">return</span> prediction</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">draw</span>(<span class="params">self,X,t</span>):</span><br><span class="line">        plt.style.use(<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line">        plt.figure()</span><br><span class="line">        plt.plot(np.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">50</span>),np.sin(np.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">50</span>)*<span class="number">2</span>*math.pi),c=<span class="string">&#x27;green&#x27;</span>)</span><br><span class="line">        plt.scatter(X,t,marker=<span class="string">&#x27;o&#x27;</span>,edgecolor=<span class="string">&#x27;blue&#x27;</span>,c=<span class="string">&#x27;white&#x27;</span>,linewidths=<span class="number">1.1</span>)</span><br><span class="line">        plt.plot(np.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">50</span>),</span><br><span class="line">                 self.lin.predict(self.poly.fit_transform(np.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">50</span>).reshape(-<span class="number">1</span>,<span class="number">1</span>))),</span><br><span class="line">                 c=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">        s=<span class="string">&#x27;n_features=&#x27;</span>+<span class="built_in">str</span>(self.n_features)</span><br><span class="line">        plt.text(<span class="number">0.7</span>,<span class="number">1</span>,s)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;X&#x27;</span>)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;Y&#x27;</span>)</span><br><span class="line">        s=<span class="string">&#x27;cv\\features=&#x27;</span>+<span class="built_in">str</span>(self.n_features)+<span class="string">&#x27; samples=&#x27;</span>+<span class="built_in">str</span>(<span class="number">1</span>)+<span class="string">&#x27;.png&#x27;</span></span><br><span class="line">        plt.savefig(<span class="string">&#x27;11.png&#x27;</span>)</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">cv_pridict</span>(<span class="params">self, X, y, n_fold</span>):</span><br><span class="line">        cv = Cross_Validation(n_fold)</span><br><span class="line">        X_train, X_test, y_train, y_test = cv.CV(X,y)</span><br><span class="line">        y_allPredict = np.ones((<span class="number">1</span>, self.n_lambda))</span><br><span class="line">        Lambda = np.logspace(-<span class="number">10</span>, -<span class="number">7</span>, self.n_lambda)</span><br><span class="line">        w=[]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_fold):</span><br><span class="line">            y_predict = np.zeros((y_test[i].shape[<span class="number">0</span>], self.n_lambda))</span><br><span class="line">            k=<span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> np.nditer(Lambda) :</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;第&#x27;</span>,k+<span class="number">1</span>+self.n_lambda*i,<span class="string">&#x27;次:&#x27;</span>,j)</span><br><span class="line">                poly = self.fit(X_train[i], y_train[i], j)</span><br><span class="line">                y_pre = self.predict(X_test[i])</span><br><span class="line">                w.append(self.lin.w)</span><br><span class="line">                y_predict[:, k] = y_pre.ravel()</span><br><span class="line">                k=k+<span class="number">1</span></span><br><span class="line">            y_allPredict = np.vstack((y_allPredict, y_predict))</span><br><span class="line">        y_allPredict = y_allPredict[<span class="number">1</span>:]</span><br><span class="line">        <span class="keyword">return</span> y_allPredict, cv, y_test, y_train, X_test, X_train,w</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">RMSE_CV</span>(<span class="params">self, y_allPredict, y_measure, n</span>):</span><br><span class="line">        press = np.square(np.subtract(y_allPredict, y_measure.reshape(-<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">        press_all = np.<span class="built_in">sum</span>(press, axis=<span class="number">0</span>)</span><br><span class="line">        RMSECV = np.sqrt(press_all / n)</span><br><span class="line">        lambda_best_index= np.argmin(RMSECV)</span><br><span class="line">        lambda_best=np.logspace(-<span class="number">10</span>,-<span class="number">7</span>, self.n_lambda)[lambda_best_index]</span><br><span class="line">        <span class="keyword">return</span> RMSECV, lambda_best</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">bias_cv</span>(<span class="params">self, y_allPredict, y_expect, n</span>):</span><br><span class="line">        press = np.square(np.subtract(y_allPredict, y_expect.reshape(-<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">        press_all = np.<span class="built_in">sum</span>(press, axis=<span class="number">0</span>)</span><br><span class="line">        bias_cv = press_all / n</span><br><span class="line">        <span class="keyword">return</span> bias_cv</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">variance_cv</span>(<span class="params">self,y_allPredict, y_expect</span>):</span><br><span class="line">        press = np.square(np.subtract(y_allPredict, y_expect.reshape(-<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">        variance=np.average(press,axis=<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> variance</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_error_cv</span>(<span class="params">self,y_allPredict,y,Lambda,w</span>):</span><br><span class="line">        press = np.square(np.subtract(y_allPredict, y.reshape(-<span class="number">1</span>, <span class="number">1</span>)))</span><br><span class="line">        error1 = np.<span class="built_in">sum</span>(press, axis=<span class="number">0</span>)/<span class="number">2</span></span><br><span class="line">        error2 = np.linalg.norm(w,axis=<span class="number">1</span>)</span><br><span class="line">        error_temp=[]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">            e=np.average(error2[i*<span class="number">5</span>:(i+<span class="number">1</span>)*<span class="number">5</span>])</span><br><span class="line">            error_temp.append(e)</span><br><span class="line">        error2=np.array(error_temp)*Lambda/<span class="number">2</span></span><br><span class="line">        error=error1+error2</span><br><span class="line">        <span class="keyword">return</span> error</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">show_Select_lambda</span>(<span class="params">self,RMSECV</span>):</span><br><span class="line">        x=np.logspace(-<span class="number">10</span>,-<span class="number">7</span>,self.n_lambda)</span><br><span class="line">        plt.plot(x,</span><br><span class="line">                 RMSECV,marker=<span class="string">&#x27;^&#x27;</span>,</span><br><span class="line">                 markersize=<span class="number">10</span>,</span><br><span class="line">                 markerfacecolor=<span class="string">&#x27;orange&#x27;</span>,</span><br><span class="line">                 color=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;lambda&#x27;</span>)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;RMSECV&#x27;</span>)</span><br><span class="line">        ax = plt.gca()</span><br><span class="line">        ax.set_xscale(<span class="string">&quot;log&quot;</span>)</span><br><span class="line">        ax.set_xlim(ax.get_xlim()[::-<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">RSME</span>(<span class="params">self,X,t</span>):</span><br><span class="line">        T_predict = self.lin.predict(self.poly.fit_transform(X))</span><br><span class="line">        SSE = np.<span class="built_in">sum</span>(np.square(t - T_predict))</span><br><span class="line">        MSE = SSE / <span class="built_in">len</span>(T_predict)</span><br><span class="line">        rsme = np.sqrt(MSE)</span><br><span class="line">        <span class="keyword">return</span> rsme</span><br></pre></td></tr></table></figure><h2 id="调整beta和lambda观察rmse变化">调整<spanclass="math inline">\(\beta\)</span>和<spanclass="math inline">\(\lambda\)</span>观察RMSE变化</h2><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__name__&#x27;</span>:</span><br><span class="line">   beta=np.linspace(<span class="number">0</span>,<span class="number">0.5</span>,<span class="number">1000</span>)</span><br><span class="line">   Lambda=np.logspace(-<span class="number">10</span>,<span class="number">0</span>,<span class="number">1000</span>)</span><br><span class="line">   RMSE_SUM=[]</span><br><span class="line">   <span class="comment"># beta和lambda对拟合效果影响</span></span><br><span class="line">   <span class="keyword">for</span> j <span class="keyword">in</span> beta:</span><br><span class="line">        poly = polyRegression(<span class="number">8</span>, <span class="number">1000</span>)</span><br><span class="line">        data=create_data(<span class="number">10</span>,j)</span><br><span class="line">        X=data[:,<span class="number">0</span>]</span><br><span class="line">        t=data[:,<span class="number">1</span>]</span><br><span class="line">        y_allPredict, cv, y_test, y_train, X_test, X_train = poly.cv_pridict(X, t, <span class="number">5</span>)</span><br><span class="line">        RMSECV, best_lambda = poly.RMSE_CV(y_allPredict, t, X.shape[<span class="number">0</span>])</span><br><span class="line">        RMSE_SUM.append(RMSECV)</span><br><span class="line">    RMSE=np.array(RMSE_SUM)</span><br><span class="line">    X, Y = np.meshgrid(Lambda, beta)</span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">15</span>,<span class="number">15</span>))</span><br><span class="line">    ax = plt.axes(projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line">    ax.set_xlabel(<span class="string">&#x27;beta&#x27;</span>)</span><br><span class="line">    ax.set_ylabel(<span class="string">&#x27;lambda&#x27;</span>)</span><br><span class="line">    ax.set_zlabel(<span class="string">&#x27;RSME&#x27;</span>)</span><br><span class="line">    ax.plot_surface(np.log(Y), np.log(X), RMSE, rstride=<span class="number">1</span>, cstride=<span class="number">1</span>, cmap=plt.get_cmap(<span class="string">&#x27;rainbow&#x27;</span>))</span><br><span class="line">    ax.set_title(<span class="string">&#x27;Surface plot&#x27;</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><center left><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230323215538367.png" alt="image-20230323215538367" style="zoom:50%;"  width="800"/><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230323220045143.png" alt="image-20230323220045143" style="zoom: 33%;" width="1250" /></center><p>右图<span class="math inline">\(-\ln \beta\)</span>值作为x轴，<spanclass="math inline">\(\ln \lambda\)</span>作为y轴，左图反之。</p><p>为了方便观察，对局部作图：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/img.png" alt="img" style="zoom: 67%;" /></p><p>首先，从<span class="math inline">\(\ln\lambda\)</span>方向观察，可以看出<spanclass="math inline">\(\lambda\)</span>对RMSE的影响呈波浪状，存在多个极小值，当<spanclass="math inline">\(\lambda\)</span>取很小的值时，在<spanclass="math inline">\(-ln\beta\)</span>较大的时候出现了比较严重的过拟合。</p><p>然后从<span class="math inline">\(-\ln\beta\)</span>方向观察，可以看出<spanclass="math inline">\(\beta\)</span>对RMSE的影响实际上并不大，呈小而密的波浪趋势。</p><h2 id="正则化前后回归系数">正则化前后回归系数</h2><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 选择参数lambda，给出拟合表达</span></span><br><span class="line">    df=pd.read_csv(<span class="string">&#x27;./data/sample=10.csv&#x27;</span>)</span><br><span class="line">    X=df.values[:,<span class="number">1</span>]</span><br><span class="line">    t=df.values[:,<span class="number">2</span>]</span><br><span class="line">    x_train, x_test, T_train, T_test=splitData(X,t)</span><br><span class="line">    <span class="comment"># 正则化</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        poly = polyRegression(i, <span class="number">50</span>)</span><br><span class="line">        y_allPredict, cv, y_test, y_train, X_test, X_train = poly.cv_pridict(X, t, <span class="number">5</span>)</span><br><span class="line">        RMSECV, best_lambda = poly.RMSE_CV(y_allPredict, t, X.shape[<span class="number">0</span>])</span><br><span class="line">        poly_best=polyRegression(i,<span class="number">5</span>)</span><br><span class="line">        poly_best.fit(x_train,T_train,best_lambda)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;次数为&#x27;</span>,i,<span class="string">&#x27;时的权重集合：&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(poly_best.lin.w)</span><br><span class="line">    <span class="comment"># 无正则化</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;无正则化\n&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        poly = polyRegression(i, <span class="number">50</span>)</span><br><span class="line">        poly.fit(x_train, T_train, <span class="number">0</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;次数为&#x27;</span>, i, <span class="string">&#x27;时的权重集合：&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(poly.lin.w)</span><br><span class="line">    rmse_train=[]</span><br><span class="line">    rmse_test=[]</span><br></pre></td></tr></table></figure><p>无正则化：</p><table><colgroup><col style="width: 6%" /><col style="width: 17%" /><col style="width: 17%" /><col style="width: 17%" /><col style="width: 18%" /><col style="width: 6%" /><col style="width: 17%" /></colgroup><thead><tr class="header"><th><span class="math inline">\(w\)</span></th><th>0</th><th>1</th><th>2</th><th>3</th><th>……</th><th>9</th></tr></thead><tbody><tr class="odd"><td></td><td>-0.08673405</td><td>0.43162238</td><td>0.5695881</td><td>-0.05816218</td><td></td><td>-0.07491257</td></tr><tr class="even"><td></td><td></td><td>-1.05343403</td><td>-2.17473669</td><td>11.14510403</td><td></td><td>10.41748047</td></tr><tr class="odd"><td></td><td></td><td></td><td>1.16724815</td><td>-33.31060868</td><td></td><td>-34.4765625</td></tr><tr class="even"><td></td><td></td><td></td><td></td><td>22.29544252</td><td></td><td>56.09375</td></tr><tr class="odd"><td></td><td></td><td></td><td></td><td></td><td></td><td>-60.</td></tr><tr class="even"><td></td><td></td><td></td><td></td><td></td><td></td><td>-14.375</td></tr><tr class="odd"><td></td><td></td><td></td><td></td><td></td><td></td><td>34.796875</td></tr><tr class="even"><td></td><td></td><td></td><td></td><td></td><td></td><td>44.5625</td></tr><tr class="odd"><td></td><td></td><td></td><td></td><td></td><td></td><td>-2.0625</td></tr><tr class="even"><td></td><td></td><td></td><td></td><td></td><td></td><td>-35.390625</td></tr></tbody></table><p>正则化后：</p><table><colgroup><col style="width: 6%" /><col style="width: 17%" /><col style="width: 17%" /><col style="width: 17%" /><col style="width: 17%" /><col style="width: 6%" /><col style="width: 17%" /></colgroup><thead><tr class="header"><th><span class="math inline">\(w\)</span></th><th>0</th><th>1</th><th>2</th><th>3</th><th>……</th><th>9</th></tr></thead><tbody><tr class="odd"><td></td><td>-0.07776724</td><td>0.15514244</td><td>0.17544013</td><td>0.33805469</td><td></td><td>0.21515437</td></tr><tr class="even"><td></td><td></td><td>-0.52292037</td><td>-0.38363097</td><td>-0.80726911</td><td></td><td>-0.44372143</td></tr><tr class="odd"><td></td><td></td><td></td><td>-0.25709792</td><td>-0.42717323</td><td></td><td>-0.42050595</td></tr><tr class="even"><td></td><td></td><td></td><td></td><td>0.41092392</td><td></td><td>-0.25649878</td></tr><tr class="odd"><td></td><td></td><td></td><td></td><td></td><td></td><td>-0.10138744</td></tr><tr class="even"><td></td><td></td><td></td><td></td><td></td><td></td><td>0.02127489</td></tr><tr class="odd"><td></td><td></td><td></td><td></td><td></td><td></td><td>0.1134249</td></tr><tr class="even"><td></td><td></td><td></td><td></td><td></td><td></td><td>0.1815334</td></tr><tr class="odd"><td></td><td></td><td></td><td></td><td></td><td></td><td>0.23170656</td></tr><tr class="even"><td></td><td></td><td></td><td></td><td></td><td></td><td>0.26874031</td></tr></tbody></table><h2 id="bias-variance结构">bias-variance结构</h2><p>程序如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 期望计算</span></span><br><span class="line">    predictAll=[]</span><br><span class="line">    T11=[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">        data1 = create_data(<span class="number">25</span>, np.random.uniform(<span class="number">0</span>,<span class="number">0.5</span>))</span><br><span class="line">        X1 = data1[:,<span class="number">0</span>]</span><br><span class="line">        t1 = data1[:,<span class="number">1</span>]</span><br><span class="line">        x1_train, x1_test, T1_train, T1_test = splitData(X1, t1)</span><br><span class="line">        poly_evey=polyRegression(<span class="number">25</span>,<span class="number">100</span>)</span><br><span class="line">        y_allPredict, cv, y_test, y_train, X_test, X_train,w = poly_evey.cv_pridict(X1, t1, <span class="number">5</span>)</span><br><span class="line">        predictAll.append(y_allPredict)</span><br><span class="line">        RMSECV, best_lambda = poly_evey.RMSE_CV(y_allPredict, t1, X1.shape[<span class="number">0</span>])</span><br><span class="line">        poly_evey.fit(x1_train,T1_train,best_lambda)</span><br><span class="line">        t_predict=poly_evey.predict(X1)</span><br><span class="line">        T11.append(t_predict)</span><br><span class="line"></span><br><span class="line">    T1=np.array(T11)</span><br><span class="line">    f_hat=np.average(T1,axis=<span class="number">0</span>)</span><br><span class="line">    poly11=polyRegression(<span class="number">25</span>,<span class="number">100</span>)</span><br><span class="line">    variances=[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> predictAll:</span><br><span class="line">        variance=poly11.variance_cv(i,f_hat)</span><br><span class="line">        variances.append(variance)</span><br><span class="line">    variance=np.average(variances,axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 生成一个新数据集</span></span><br><span class="line">    data2 = create_data(<span class="number">25</span>, np.random.uniform(<span class="number">0</span>, <span class="number">0.5</span>))</span><br><span class="line">    X2 = data2[:, <span class="number">0</span>]</span><br><span class="line">    t2 = data2[:, <span class="number">1</span>]</span><br><span class="line">    x2_train, x2_test, T2_train, T2_test = splitData(X2, t2)</span><br><span class="line">    poly2=polyRegression(<span class="number">25</span>,<span class="number">100</span>)</span><br><span class="line">    y_allPredict, cv, y_test, y_train, X_test, X_train, w = poly2.cv_pridict(X2, t2, <span class="number">5</span>)</span><br><span class="line">    RMSECV, best_lambda = poly2.RMSE_CV(y_allPredict, t2, X2.shape[<span class="number">0</span>])</span><br><span class="line">    poly2.show_Select_lambda(RMSECV)</span><br><span class="line">    bias_2=poly2.bias_cv(y_allPredict,f_hat,X2.shape[<span class="number">0</span>])</span><br><span class="line">    w=np.array(w)</span><br><span class="line">    error=poly2.test_error_cv(y_allPredict,t2,np.logspace(-<span class="number">10</span>,-<span class="number">7</span>,<span class="number">100</span>),w)</span><br><span class="line">    <span class="built_in">print</span>(bias_2)</span><br><span class="line"></span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.plot(np.logspace(-<span class="number">10</span>,-<span class="number">7</span>, <span class="number">100</span>),bias_2,label=<span class="string">&#x27;bias^2&#x27;</span>,color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">    plt.plot(np.logspace(-<span class="number">10</span>,-<span class="number">7</span>, <span class="number">100</span>),variance, label=<span class="string">&#x27;variance&#x27;</span>, color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">    plt.plot(np.logspace(-<span class="number">10</span>,-<span class="number">7</span>, <span class="number">100</span>),bias_2+variance, label=<span class="string">&#x27;bias^2+variance&#x27;</span>, color=<span class="string">&#x27;pink&#x27;</span>)</span><br><span class="line">    plt.plot(np.logspace(-<span class="number">10</span>,-<span class="number">7</span>, <span class="number">100</span>),error,label=<span class="string">&#x27;test error&#x27;</span>, color=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">    ax = plt.gca()</span><br><span class="line">    ax.set_xscale(<span class="string">&quot;log&quot;</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230326185731318.png" alt="image-20230326185731318" style="zoom:80%;" /></p><h2 id="degreelambda寻优过程"><spanclass="math inline">\(degree\)</span>、<spanclass="math inline">\(lambda\)</span>寻优过程</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">rmse_train=[]</span><br><span class="line">rmse_test=[]</span><br><span class="line"><span class="comment"># 寻找最优次数</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    poly = polyRegression(i, <span class="number">50</span>)</span><br><span class="line">    poly.fit(x_train,T_train,<span class="number">0</span>)</span><br><span class="line">    rmse_train.append(poly.RSME(x_train,T_train))</span><br><span class="line">    rmse_test.append(poly.RSME(x_test,T_test))</span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(np.linspace(<span class="number">0</span>,<span class="number">10</span>,<span class="number">10</span>),</span><br><span class="line">         rmse_test,</span><br><span class="line">         label=<span class="string">&#x27;test&#x27;</span>,</span><br><span class="line">         marker=<span class="string">&#x27;o&#x27;</span>,</span><br><span class="line">         markerfacecolor=<span class="string">&#x27;white&#x27;</span></span><br><span class="line">         , markeredgecolor=<span class="string">&#x27;b&#x27;</span>,</span><br><span class="line">         color=<span class="string">&#x27;b&#x27;</span>,</span><br><span class="line">         markeredgewidth=<span class="number">1.5</span>)</span><br><span class="line">plt.plot(np.linspace(<span class="number">0</span>,<span class="number">10</span>,<span class="number">10</span>),rmse_train,</span><br><span class="line">         label=<span class="string">&#x27;train&#x27;</span>,</span><br><span class="line">         marker=<span class="string">&#x27;o&#x27;</span>,</span><br><span class="line">         markerfacecolor=<span class="string">&#x27;white&#x27;</span>,</span><br><span class="line">         markeredgecolor=<span class="string">&#x27;r&#x27;</span>,</span><br><span class="line">         color=<span class="string">&#x27;r&#x27;</span>,</span><br><span class="line">         markeredgewidth=<span class="number">1.5</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;RMSE&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;degree&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line">best_degree=np.argmin(np.array(rmse_test))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;best degree is&#x27;</span>,best_degree)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;min RMSE in test sets:&#x27;</span>,np.<span class="built_in">min</span>(rmse_test))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对最优次数寻找合适的lambda</span></span><br><span class="line">poly = polyRegression(best_degree, <span class="number">50</span>)</span><br><span class="line">poly.fit(x_train, T_train, <span class="number">0</span>)</span><br><span class="line">poly.draw(X,t)</span><br><span class="line">y_allPredict, cv, y_test, y_train, X_test, X_train,w = poly.cv_pridict(X, t, <span class="number">5</span>)</span><br><span class="line">RMSECV, best_lambda = poly.RMSE_CV(y_allPredict, t, X.shape[<span class="number">0</span>])</span><br><span class="line">poly.show_Select_lambda(RMSECV)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;best lambda is&#x27;</span>,best_lambda)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;min RMSE with regularization:&#x27;</span>,np.<span class="built_in">min</span>(RMSECV))</span><br><span class="line">poly_best = polyRegression(best_degree, <span class="number">50</span>)</span><br><span class="line">poly_best.fit(x_train, T_train, best_lambda)</span><br><span class="line">poly_best.draw(X, t)</span><br></pre></td></tr></table></figure><p>degree寻优：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230326191813731.png" alt="image-20230326191813731" style="zoom:50%;" /></p><p><span class="math inline">\(lambda\)</span>寻优：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230326191840244.png" alt="image-20230326191840244" style="zoom: 67%;" /></p>正则化前后图像对比：<center><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230326191928367.png" alt="image-20230326191928367" style="zoom:50%;" /><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230326191912106.png" alt="image-20230326191912106" style="zoom:50%;" /></center><p>左图为未正则化，右图为正则化后。输出结果为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">best degree is 5</span><br><span class="line">min RMSE in test sets: 0.11753272730633338</span><br><span class="line">best lambda is 1.8420699693267162e-08</span><br><span class="line">min RMSE with regularization: 0.0998645060490816</span><br></pre></td></tr></table></figure><h2 id="样本数目影响">样本数目影响</h2><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">RMSEs=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>,<span class="number">50</span>):</span><br><span class="line">    data=create_data(i,<span class="number">0.25</span>)</span><br><span class="line">    X=data[:,<span class="number">0</span>]</span><br><span class="line">    t=data[:,<span class="number">1</span>]</span><br><span class="line">    X_train, X_test, T_train, T_test=splitData(X,t)</span><br><span class="line">    poly=polyRegression(<span class="number">8</span>,<span class="number">50</span>)</span><br><span class="line">    poly.fit(X_train,T_train,<span class="number">0</span>)</span><br><span class="line">    rmse=poly.RSME(X,t)</span><br><span class="line">    RMSEs.append(rmse)</span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(np.linspace(<span class="number">10</span>,<span class="number">50</span>,<span class="number">40</span>),RMSEs)</span><br><span class="line">plt.ylabel(<span class="string">&quot;RMSE&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;samples&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230326193335597.png" alt="image-20230326193335597" style="zoom:50%;" /></p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230326193511771.png" alt="image-20230326193511771" style="zoom:50%;" /></p><p>上图是样本数量在（10,200）的RMSE图，下图是样本数量在（10,20）的RMSE图，可以明显看出随着样布数目增长RMSE逐渐趋于稳定，仅有很小的波动。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python基础语法总结</title>
      <link href="/2022/09/14/pythonSummry/"/>
      <url>/2022/09/14/pythonSummry/</url>
      
        <content type="html"><![CDATA[<h1 id="Python基础语法学习总结"><a href="#Python基础语法学习总结" class="headerlink" title="Python基础语法学习总结"></a>Python基础语法学习总结</h1><h2 id="实验目的"><a href="#实验目的" class="headerlink" title="实验目的"></a>实验目的</h2><p>学习Python基本语法</p><h2 id="实验场地与设备"><a href="#实验场地与设备" class="headerlink" title="实验场地与设备"></a>实验场地与设备</h2><p>线上</p><h2 id="实验方式"><a href="#实验方式" class="headerlink" title="实验方式"></a>实验方式</h2><p>阅读教程与程序设计</p><h2 id="实验设计"><a href="#实验设计" class="headerlink" title="实验设计"></a>实验设计</h2><p> <img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/Python%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80.png" alt="Python语言基础"></p><p>图1.1 Python基础语法学习实验设计</p><h2 id="实验内容"><a href="#实验内容" class="headerlink" title="实验内容"></a>实验内容</h2><h3 id="Python语法总结"><a href="#Python语法总结" class="headerlink" title="Python语法总结"></a>Python语法总结</h3><h4 id="Python基本语法"><a href="#Python基本语法" class="headerlink" title="Python基本语法"></a>Python基本语法</h4><h4 id="基本语句"><a href="#基本语句" class="headerlink" title="基本语句"></a>基本语句</h4><p>①  首先是输入输出语句，输入语句比较简单为<code>name=input()</code>，基本输出语句为<code>print()</code>,拼接输出使用逗号。</p><p>②  注释采用<code>#</code> 进行书写</p><p>③   代码风格：Python采用的是缩进式代码风格，所以对于复制粘贴比较不友好</p><p>④   条件判断语句：<code>if 条件1 :...elif 条件2 : ... else : ...</code></p><p>⑤循环语句：</p><p>第一种是<code>for</code>循环：<code>for x in []:</code> <code>for x in ...:</code> 循环就是把每个元素代入变量x，然后执行缩进块的语句</p><p>第二种是<code>while</code>循环：<code>while 条件判断语句 :</code>    <code>break</code>、<code>continue</code>和java中用法相同</p><h4 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h4><p><strong>①整数：</strong>对于很大的数，很难数清楚0的个数。Python允许在数字中间以_分隔。</p><p><strong>②浮点数：</strong>允许使用科学计数法定义</p><p><strong>③字符串：</strong>在Python没有严格要求<code>&#39;&#39; </code>和<code>&quot;&quot;</code>的区别在，也就是说没有区分字符和字符串使用二者没有任何区别。</p><ul><li>转义符和Java中保持一致</li><li>Python允许用<code>r&#39;&#39;</code>表示<code>&#39;&#39;</code>内部的字符串默认不转义</li></ul><p><strong>④    布尔值：</strong></p><p>在Python中要注意：<code>True</code>、<code>False</code>要注意开头首字母大写。<br>可以进行与、或、非的运算，运算符分别为：<code>and</code>，<code>or</code>，<code>not</code>  </p><p><strong>⑤空值：</strong>空值用<code>None</code>表示，意义与Java中的<code>null</code>相同。</p><p><strong>⑥list：</strong></p><p>list是Python内置的一种数据类型，list是一种有序的集合，可以随时添加和删除其中的元素。此数据类型在Java的实用类中有封装。list和数组很像，声明方式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">classname = [<span class="string">&#x27;老六&#x27;</span>,<span class="string">&#x27;老八&#x27;</span>,<span class="string">&#x27;老九&#x27;</span>]</span><br></pre></td></tr></table></figure><p>想要调取其中的某个元素也和数组一致，赋值修改等也相同<br>下面列举一下list的ADT</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">list:</span><br><span class="line">append(&#x27;Elem&#x27;)  # 在末尾添加新的元素</span><br><span class="line">insert(i,&#x27;Elem&#x27;) # 将元素插入指定位置</span><br><span class="line">pop() # 删除末尾元素</span><br><span class="line">pop(i) # 删除i处的元素</span><br><span class="line">len(list) # list列表的长度</span><br></pre></td></tr></table></figure><p>list允许混合类型，也允许list嵌套，从而出现多维数组。</p><p><strong>⑦ tuple</strong></p><p>tuple被称为元组，其最大的特点就是不可修改，声明方式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">classname = (<span class="string">&#x27;老六&#x27;</span>,<span class="string">&#x27;老八&#x27;</span>,<span class="string">&#x27;老九&#x27;</span>)</span><br></pre></td></tr></table></figure><p>tuple在定义时要确定元素个数，这里有一个问题，在定义只有一个元素的tuple时，Python语法会认为这是一个小括号，因此在定义一个元组的tuple时，要加一个<code>,</code>避免歧义。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t=(<span class="number">1</span>,)</span><br></pre></td></tr></table></figure><p><strong>⑧字典（dict）</strong></p><p>字典全称为dictionary，在Java实用类中叫hash map。其由键值对（key-value）组成，查找速度快。 下面是一种初始化方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d = &#123;<span class="string">&#x27;Michael&#x27;</span>: <span class="number">95</span>, <span class="string">&#x27;Bob&#x27;</span>: <span class="number">75</span>, <span class="string">&#x27;Tracy&#x27;</span>: <span class="number">85</span>&#125;</span><br></pre></td></tr></table></figure><p>也可以放入指定的key中：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d[<span class="string">&#x27;Adam&#x27;</span>] = <span class="number">67</span></span><br></pre></td></tr></table></figure><p>查找value:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d[<span class="string">&#x27;Adam&#x27;</span>]</span><br></pre></td></tr></table></figure><p>key与value是多对一的关系，key需要是一个不可变对象保证key做hash运算后的唯一性。如果多次对某个key赋值，后边的value会覆盖前面的value 提供了几个函数：</p><ol><li>通过<code>in</code>来判断key是否在dict中，返回值为布尔值，格式为：<code>key in dict</code></li><li>get()方法，<code>dict.get(&#39;key&#39;,空返回值)</code>key不存在时返回空返回值，空返回值可自定义，如果没有定义的话返回None</li><li>pop()方法，删除key，如果有value也一并删除，格式为<code>pop(&#39;key&#39;)</code></li></ol><p><strong>⑨集合（set）</strong></p><p>set是一组key的集合,集合特点；无序性、确定性、互异性<br>要创建一个set，需要提供一个list作为输入集合：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="built_in">set</span>([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure><ul><li>方法：<br><code>add(key)</code>添加一个新的元素<br><code>remove(key)</code>删除一个元素</li><li>两个set可以做交运算和并运算：<br>交运算：<code>s1&amp;s2</code><br>并运算：<code>s1|s2</code></li></ul><h4 id="理解变量"><a href="#理解变量" class="headerlink" title="理解变量"></a>理解变量</h4><p>在Python中变量仅仅是一个一个字母，变量与所对应的值之间的关系靠指针联系起来的。所以很重要的一点就是：<strong>当我们使用变量时，更多的要关注变量指向的东西，他可能是值，也可能是一个函数，也可能是一个变量</strong></p><h4 id="模块"><a href="#模块" class="headerlink" title="模块"></a>模块</h4><h4 id="模块导入"><a href="#模块导入" class="headerlink" title="模块导入"></a>模块导入</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><h4 id="模块下载"><a href="#模块下载" class="headerlink" title="模块下载"></a>模块下载</h4><p>模块下载有比较复杂的方法，也有比较傻瓜式的。先说复杂的，使用Python中自带的pip包管理工具，用命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install numpy</span><br></pre></td></tr></table></figure><p>但是使用pip需要事先了解要导的包的名字，而且不能批量导入，而且在Python编程里也有编程一分钟，导包一小时的说法。pip下载第三方库的源可能会很慢或者失效，需要会自己添加国内的高速镜像。</p><p>傻瓜式的导包，例如在pycharm中可以直接在代码中写出自己需要的包，然后交给pycharm自己去下载，或者用Anaconda提前构建好的Python的库环境。</p><h4 id="函数式编程"><a href="#函数式编程" class="headerlink" title="函数式编程"></a>函数式编程</h4><h4 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h4><p><strong>①函数定义</strong></p><p>在Python中定义函数为，<code>def 函数名(参数):</code>然后，在缩进块中编写函数体，函数的返回值用<code>return</code>语句返回。<br>如果没有return语句，函数执行完毕后也会返回结果，只是结果为None。return None可以简写为return。</p><p>1）空函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">nop</span>():</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>在这里<code>pass</code>作为占位符，表示跳过，也可以用在<code>if</code>的缩进块。</p><p>2）参数限制：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(x, (<span class="built_in">int</span>, <span class="built_in">float</span>)):</span><br><span class="line">      <span class="keyword">raise</span> TypeError(<span class="string">&#x27;bad operand type&#x27;</span>)</span><br></pre></td></tr></table></figure><p>实际上参数限制就是定义一个报错，<code>isinstance()</code>判断数据类型，如果不是就提出一个错误。  <strong>作为一个弱类型语言，定义这一步是很有必要的，有助于读懂代码。</strong></p><p>3）返回值：</p><p>Python允许返回多个值，其返回的实际上是一个tuple元组，但是也可以用两个变量接收。</p><p><strong>②参数定义</strong>  </p><p>在Python中函数参数的定义也比较灵活，提供位置参数、默认参数、可变参数、关键字（key）参数等</p><p>1）位置参数：位置参数指的是参数在传入时，实参和形参有着严格的位置对应关系，为常用参数形式。</p><p>2）默认参数：默认参数是指在位置参数的基础上为其添加默认值，有默认值的参数为默认参数，没有默认值的参数为必选参数<br>基本定义形式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">my_def</span>(<span class="params">a,b=<span class="number">1</span></span>):</span><br><span class="line">    a=b+<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> </span><br></pre></td></tr></table></figure><p>需要注意的是：</p><ul><li>默认参数必须在必选参数后边，否则会无法辨认是否输入必选参数，从而报错。</li><li>默认参数的默认值一定是<strong>不变对象</strong>，由于Python中的变量定义为指针指向，会导致可变对象值发生变化</li></ul><p>3）不可变对象有：数值类型、字符串、tuple元组、None等</p><p>4）可变参数：可变参数指的是参数的数目不固定，定义形式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">my_function</span>(<span class="params">*v</span>):</span><br><span class="line">    <span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> vi <span class="keyword">in</span> v:</span><br><span class="line">        <span class="built_in">sum</span>+=vi</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span></span><br></pre></td></tr></table></figure><p>在可变参数中传入的所有参数将作为一个tuple被接收，该tuple的变量名为函数在定义时的形参名，定义时的需要在参数名前加一个<code>*</code>。</p><p>5）关键字（key）参数</p><p>此处的关键字和c语言中的关键字并不是一个意义，而是在dict中的key的意义。即在传递参数时，同时传递键（key）和值(value),Python会自动封装为一个dict。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">my_function</span>(<span class="params">**v</span>):</span><br><span class="line">    <span class="built_in">print</span>(v)</span><br><span class="line">    <span class="keyword">return</span> </span><br></pre></td></tr></table></figure><p>6）命名关键字参数</p><p>在关键字参数上，进一步限制传入的key的命名，就有了命名关键词参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">person</span>(<span class="params">name, age, *, city, job</span>):</span><br><span class="line">    <span class="built_in">print</span>(name, age, city, job)</span><br></pre></td></tr></table></figure><p>这里需要一个<code>*</code>区分位置参数与命名关键字参数，如果在这之前有可变参数，那么就不需要加<code>*</code>。<br>命名关键字参数必须传入参数名，这和位置参数不同。如果没有传入参数名，调用将报错：</p><p>7）参数组合</p><p>在一个函数中使用多个参数要保证其中的顺序，依次为：必选参数、默认参数、可变参数、命名关键字参数和关键字参数。  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">onefunction</span>(<span class="params">a,b,c=<span class="number">0</span>,*args,job,city,**kw</span>):</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>tips：  </p><ul><li>使用<code>*args</code>和<code>**kw</code>是Python的习惯写法。</li><li>可变参数和关键字参数有一点层级的感觉，中间包裹的是命名关键字参数这个比较尴尬的参数。</li></ul><p><strong>③递归函数</strong></p><p>写法与Java相同。</p><h4 id="实用方法"><a href="#实用方法" class="headerlink" title="实用方法"></a>实用方法</h4><p><strong>①切片</strong></p><p>切片是一个针对tuple和list方便地取元素的方法，语法规则：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">L[起始坐标:终止坐标:步长]</span><br></pre></td></tr></table></figure><p>当起始坐标为0时可以省略；步长为1时可以省略。</p><p><strong>②迭代</strong></p><p>迭代是循环的增强，但是想要弄清迭代，需要知道两件事：一个是能不能迭代，一个是迭代出的数据是什么</p><p>想要知道一个数据能否迭代可以通过一个函数来完成：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections.abc <span class="keyword">import</span> Iterable</span><br><span class="line">L=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line"><span class="built_in">isinstance</span>(L,Iterable)</span><br></pre></td></tr></table></figure><p>迭代出的是什么，和要迭代的对象的储存方式，要特殊记忆一下dic。</p><p><strong>③ 列表生成器</strong></p><p>一种快捷生成list的方式，一个例子如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[x * x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>)]</span><br></pre></td></tr></table></figure><p>如果想要筛选生成的值，可以在<code>for</code>后加上<code>if</code>作为<strong>筛选条件</strong>，注意这里是筛选条件， 因此这里和平时的<code>if else</code>并不是一个东西。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[x * x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>) <span class="keyword">if</span> x % <span class="number">2</span> == <span class="number">0</span>]</span><br></pre></td></tr></table></figure><p><strong>④ 生成器</strong></p><p>生成器是一种惰性的计算方式。包含<code>yield</code>关键字，当一个函数包含<code>yield</code>关键字时，他就成了一个generator函数。<code>yield</code>在generator函数中起到了一个return的作用，即到<code>yield</code>便返回。 在调用时，使用一个变量接受一个generator对象。使用<code>next()</code>函数依次获得下一个返回值。</p><p><strong>⑤迭代器</strong></p><p>区分<code>Iterable</code>和<code>Iterator</code></p><p><code>Iterable</code>是可迭代的，是直接可用于<code>for</code>循环的。包括dict、list、tuple、set、str、grenerator。<br><code>Iterator</code>是迭代器，是直接可用于<code>next()</code>函数的，生成器都是<code>Iterator</code>对象，集合数据类型可以通过<code>iter()</code>获取<code>Interator</code>对象。</p><h4 id="函数式编程-1"><a href="#函数式编程-1" class="headerlink" title="函数式编程"></a>函数式编程</h4><p>函数式编程是一种面向过程的编程思想，实际上是将复杂问题转化为一个个函数。</p><p>在Java的函数定义中，除去<code>void</code>类型不返回值，其余的都需要返回值。因此也就经常存在，使用一个变量接受函数值：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">function</span><span class="params">(x,y)</span>&#123;</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> a=function(x,y);</span><br></pre></td></tr></table></figure><p>那么是不是存在一种可能，我们可以将函数嵌套，让函数调用函数，让函数返回函数，彻底抛弃变量？</p><p>抛弃变量、只有函数就是彻底的函数式编程</p><p><strong>①理解高阶函数</strong></p><p>之前有过变量名和值的理解，在Python中变量名和值是一个指针指向的关系。同理，函数名和函数也是这样的，函数名也是一个变量。也就是说，我们可以通过函数名，拿到函数体。也就是说函数名是什么并不重要，我们看中的是函数体。</p><p>![绘图1](<a href="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/">https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/</a> typora&#x2F;%E7%BB%98%E5%9B%BE1.png)</p><p>那么设想一种情况，现在我们定义了函数f2，那么我可以随便写一个函数，然后返回一个变量f2，那么实际上我就拿到了函数体。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">f2</span>(<span class="params">a,b</span>):</span><br><span class="line">    <span class="keyword">return</span> a+b</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">f3</span>():</span><br><span class="line">    <span class="keyword">return</span> f2</span><br><span class="line"><span class="built_in">print</span>(f3()(<span class="number">1</span>,<span class="number">2</span>))</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20220909173741530.png" alt="image-20220909173741530"></p><p>然后我们在设想另一种情况，现在我们定义了另一种情况，我们在一个函数中写了一个f1作为局部变量，那么我就可以传入变量f2，然后就相当于传入了函数体。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">f2</span>(<span class="params">a,b</span>):</span><br><span class="line">    <span class="keyword">return</span> a+b</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">f1</span>(<span class="params">a,b,f</span>):</span><br><span class="line">    <span class="keyword">return</span> f(a,b)</span><br><span class="line"><span class="built_in">print</span>(f1(<span class="number">1</span>,<span class="number">2</span>,f2))</span><br></pre></td></tr></table></figure><p>现在就可以进行一个区分：</p><ul><li><code>f</code>代表函数名，是变量</li><li><code>f()</code>代表数值，是函数的返回值，返回值是一个量</li></ul><p>高阶函数，就是让函数的参数能够接收别的函数。</p><p>实用的几个函数，有必要查表即可</p><p><strong>②返回函数</strong></p><p>同上文理解，只不过是将一个函数嵌套入了另一个函数</p><p><strong>③ lambda表达式</strong></p><p>与Java中语法相同，目的是为了简化返回函数嵌套</p><h4 id="面向对象编程"><a href="#面向对象编程" class="headerlink" title="面向对象编程"></a>面向对象编程</h4><h4 id="类和对象"><a href="#类和对象" class="headerlink" title="类和对象"></a>类和对象</h4><p>创建类：语法如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">类名</span>(<span class="title class_ inherited__">继承的类</span>):</span><br></pre></td></tr></table></figure><p>python的类非常随意，几乎可以不定义就能用。在类中自带有一个构造函数<code>__init__()</code>,此函数可以重新定义</p><p>生成对象：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a=A()</span><br></pre></td></tr></table></figure><h4 id="访问权限"><a href="#访问权限" class="headerlink" title="访问权限"></a>访问权限</h4><p>如果要让内部属性不被外部访问，可以把属性的名称前加上两个下划线<code>__</code>，在Python中，实例的变量名如果以<code>__</code>开头，就变成了一个私有变量（private），只有内部可以访问，外部不能访问。</p><p>此外，<code>__ __</code>这种变量都是特殊变量，在不清楚的时候不要随便乱改</p><h4 id="继承和多态"><a href="#继承和多态" class="headerlink" title="继承和多态"></a>继承和多态</h4><p>和Java中的思想完全相同</p><h4 id="常用变量和方法"><a href="#常用变量和方法" class="headerlink" title="常用变量和方法"></a>常用变量和方法</h4><p>①<code>__slots__</code></p><p>用这个变量可以起到参数列表的功能，可以在一定程度上限制参数的变量名，用turple进行限定</p><p>②<code>@property</code></p><p>注解编程，可以起到一个简化定义setter和getter函数的作用。@property注解在getter方法上，然后会自动生成 @函数名.setter 的注解，但是要注意的一点是，在getter中就不能使用函数名作为自身的调用值，否则会出现无限的调用，产生爆栈。</p><p>③多继承</p><p>与Java相同</p><p>⑤<code>__str__</code>:和Java中的toString方法相同</p><h4 id="错误调试"><a href="#错误调试" class="headerlink" title="错误调试"></a>错误调试</h4><h4 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a>错误处理</h4><p>参照Java中，对比来学习即可：</p><p>两种方法，一是尝试，二是抛出，尝试采用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line"><span class="keyword">pass</span></span><br><span class="line"><span class="keyword">except</span> baseexception  :</span><br><span class="line"><span class="keyword">pass</span></span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line"><span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>抛出采用<code>raise</code>关键字</p><h4 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h4><p>①断言：<code>assert</code>的意思是，表达式<code>n != 0</code>应该是<code>True</code>，否则，根据程序运行的逻辑，后面的代码肯定会出错。</p><p>如果断言失败，<code>assert</code>语句本身就会抛出<code>AssertionError</code></p><p>②断点：在强大IDE的辅助下，使用断点调试应该是最简单的。</p><h3 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h3><h4 id="石头剪子布"><a href="#石头剪子布" class="headerlink" title="石头剪子布"></a>石头剪子布</h4><p>使用random包中的random函数和条件控制语句，模拟两个电脑互相猜拳：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">win</span>(<span class="params">pc,cc</span>):</span><br><span class="line">    <span class="keyword">if</span> (cc==<span class="number">1</span> <span class="keyword">and</span> pc==<span class="number">2</span>) <span class="keyword">or</span> (cc==<span class="number">2</span> <span class="keyword">and</span> pc==<span class="number">3</span>)<span class="keyword">or</span>(cc==<span class="number">3</span> <span class="keyword">and</span> pc==<span class="number">1</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;电脑一输&quot;</span>)</span><br><span class="line">    <span class="keyword">elif</span> pc==cc:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;平&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;电脑二输&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">computer_choice</span>():</span><br><span class="line">    cc=random.randint(<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">return</span> cc</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show</span>(<span class="params">pc,cc</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;电脑一的出招为&quot;</span>,pc)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;电脑二的出招为&quot;</span>,cc)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">        pc=computer_choice()</span><br><span class="line">        cc=computer_choice()</span><br><span class="line">        show(pc,cc)</span><br><span class="line">        win(pc,cc)</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20220914212607801.png" alt="image-20220914212607801"></p><p>改进提升一下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">win</span>(<span class="params">pc,cc</span>):</span><br><span class="line">    <span class="keyword">if</span> (cc==<span class="number">1</span> <span class="keyword">and</span> pc==<span class="number">2</span>) <span class="keyword">or</span> (cc==<span class="number">2</span> <span class="keyword">and</span> pc==<span class="number">3</span>)<span class="keyword">or</span>(cc==<span class="number">3</span> <span class="keyword">and</span> pc==<span class="number">1</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;玩家输&quot;</span>)</span><br><span class="line">    <span class="keyword">elif</span> pc==cc:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;平&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;玩家赢&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">computer_choice</span>():</span><br><span class="line">    cc=random.randint(<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">return</span> cc</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">str</span>(<span class="params">cc</span>):</span><br><span class="line">    <span class="keyword">if</span> cc==<span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;石头&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> cc==<span class="number">2</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;剪刀&#x27;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;布&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show</span>(<span class="params">f,pc,cc</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;电脑一的出招为&quot;</span>,f(pc))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;电脑二的出招为&quot;</span>,f(cc))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">        cc=computer_choice()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;请输入：1.石头 2.剪刀 3.布&quot;</span>)</span><br><span class="line">        pc=<span class="built_in">input</span>()</span><br><span class="line">        show(<span class="built_in">str</span>,pc,cc)</span><br><span class="line">        win(pc,cc)</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20220914213324805.png" alt="image-20220914213324805"></p><h4 id="ATM模拟"><a href="#ATM模拟" class="headerlink" title="ATM模拟"></a>ATM模拟</h4><p>通过类和对象简单的设计了一个ATM取钱模拟器</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> Account</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ATM</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,money,accounts</span>):</span><br><span class="line">        self.money=money</span><br><span class="line">        self.accounts=accounts</span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">money</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self._money;</span><br><span class="line"><span class="meta">    @money.setter</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">money</span>(<span class="params">self,value</span>):</span><br><span class="line">        self._money=value</span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">accounts</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self._accounts</span><br><span class="line"><span class="meta">    @accounts.setter</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">accounts</span>(<span class="params">self,value</span>):</span><br><span class="line">        self._accounts=value</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">searchId</span>(<span class="params">self,<span class="built_in">id</span></span>):</span><br><span class="line">        <span class="keyword">for</span> account <span class="keyword">in</span> self.accounts:</span><br><span class="line">            <span class="keyword">if</span> account.<span class="built_in">id</span>==<span class="built_in">id</span>:</span><br><span class="line">                <span class="keyword">return</span> account</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">lode</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;请输入账号id&#x27;</span>)</span><br><span class="line">        <span class="built_in">id</span> = <span class="built_in">input</span>()</span><br><span class="line">        account1 = self.searchId(<span class="built_in">id</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;请输入密码&#x27;</span>)</span><br><span class="line">        password = <span class="built_in">input</span>()</span><br><span class="line">        <span class="keyword">if</span> password == account1.password:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;欢迎&quot;</span>, account1.name)</span><br><span class="line">        <span class="keyword">return</span> account1</span><br><span class="line">    <span class="comment"># 存钱</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">save_money</span>(<span class="params">self</span>):</span><br><span class="line">        account=self.lode();</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;请输入要存入的数目&quot;</span>)</span><br><span class="line">        saveMneyValue=<span class="built_in">input</span>()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;存款成功&#x27;</span>)</span><br><span class="line">        account.remain=<span class="built_in">int</span>(account.remain)+<span class="built_in">int</span>(saveMneyValue)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;您的账户余额为&#x27;</span>,account.remain)</span><br><span class="line">        self.money=self.money+<span class="built_in">int</span>(saveMneyValue)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 取钱</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">withdraw_money</span>(<span class="params">self</span>):</span><br><span class="line">        account=self.lode()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;请输入要取出的数目&#x27;</span>)</span><br><span class="line">        withdrawMoneyValue=<span class="built_in">input</span>()</span><br><span class="line">        <span class="keyword">if</span> account.remain &gt; withdrawMoneyValue:</span><br><span class="line">            account.remain=<span class="built_in">int</span>(account.remain)-<span class="built_in">int</span>(withdrawMoneyValue)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;取款成功，您的账户余额为&#x27;</span>,account.remain)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;您的账户余额不足&#x27;</span>)</span><br><span class="line">        self.money=<span class="built_in">int</span>(self.money)-<span class="built_in">int</span>(withdrawMoneyValue)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__str__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;当前ATM中有金额&quot;</span>,self.money,<span class="string">&quot;元&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># atm1=ATM(1000)</span></span><br><span class="line">    <span class="comment"># atm1.__str__()</span></span><br><span class="line">    <span class="comment"># atm1.ave_money(200)</span></span><br><span class="line">    <span class="comment"># atm1.__str__()</span></span><br><span class="line">    <span class="comment"># atm1.withdraw_money(200)</span></span><br><span class="line">    <span class="comment"># atm1.__str__()</span></span><br><span class="line">    accounts=[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        name=<span class="built_in">input</span>()</span><br><span class="line">        <span class="built_in">id</span> = <span class="built_in">input</span>()</span><br><span class="line">        password=<span class="built_in">input</span>()</span><br><span class="line">        remain=<span class="built_in">input</span>()</span><br><span class="line">        accounts.append(Account.account(name, <span class="built_in">id</span>, password, remain))</span><br><span class="line">    atm2=ATM(<span class="number">10000</span>,accounts)</span><br><span class="line">    atm2.save_money()</span><br><span class="line">    atm2.withdraw_money()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">account</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,name,<span class="built_in">id</span>,password,remain</span>):</span><br><span class="line">        self.name=name</span><br><span class="line">        self.remain=remain</span><br><span class="line">        self.password=password</span><br><span class="line">        self.<span class="built_in">id</span>=<span class="built_in">id</span></span><br><span class="line"></span><br><span class="line">    __slots__ = (<span class="string">&#x27;name&#x27;</span>,<span class="string">&#x27;remain&#x27;</span>,<span class="string">&#x27;password&#x27;</span>,<span class="string">&#x27;id&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20220914214759256.png" alt="image-20220914214759256"></p><h4 id="圣诞树画图"><a href="#圣诞树画图" class="headerlink" title="圣诞树画图"></a>圣诞树画图</h4><p>使用Python自带的turtle包，进行圣诞树绘制：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> turtle</span><br><span class="line"></span><br><span class="line">screen = turtle.Screen()</span><br><span class="line">screen.setup(<span class="number">375</span>, <span class="number">700</span>)</span><br><span class="line"></span><br><span class="line">circle = turtle.Turtle()</span><br><span class="line">circle.shape(<span class="string">&#x27;circle&#x27;</span>)</span><br><span class="line">circle.color(<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">circle.speed(<span class="string">&#x27;fastest&#x27;</span>)</span><br><span class="line">circle.up()</span><br><span class="line"></span><br><span class="line">square = turtle.Turtle()</span><br><span class="line">square.shape(<span class="string">&#x27;square&#x27;</span>)</span><br><span class="line">square.color(<span class="string">&#x27;green&#x27;</span>)</span><br><span class="line">square.speed(<span class="string">&#x27;fastest&#x27;</span>)</span><br><span class="line">square.up()</span><br><span class="line"></span><br><span class="line">circle.goto(<span class="number">0</span>, <span class="number">280</span>)</span><br><span class="line">circle.stamp()</span><br><span class="line"></span><br><span class="line">k = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">13</span>):</span><br><span class="line">    y = <span class="number">30</span> * i</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i - k):</span><br><span class="line">        x = <span class="number">30</span> * j</span><br><span class="line">        square.goto(x, -y + <span class="number">280</span>)</span><br><span class="line">        square.stamp()</span><br><span class="line">        square.goto(-x, -y + <span class="number">280</span>)</span><br><span class="line">        square.stamp()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">4</span> == <span class="number">0</span>:</span><br><span class="line">        x = <span class="number">30</span> * (j + <span class="number">1</span>)</span><br><span class="line">        circle.color(<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">        circle.goto(-x, -y + <span class="number">280</span>)</span><br><span class="line">        circle.stamp()</span><br><span class="line">        circle.goto(x, -y + <span class="number">280</span>)</span><br><span class="line">        circle.stamp()</span><br><span class="line">        k += <span class="number">3</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">4</span> == <span class="number">3</span>:</span><br><span class="line">        x = <span class="number">30</span> * (j + <span class="number">1</span>)</span><br><span class="line">        circle.color(<span class="string">&#x27;yellow&#x27;</span>)</span><br><span class="line">        circle.goto(-x, -y + <span class="number">280</span>)</span><br><span class="line">        circle.stamp()</span><br><span class="line">        circle.goto(x, -y + <span class="number">280</span>)</span><br><span class="line">        circle.stamp()</span><br><span class="line"></span><br><span class="line">square.color(<span class="string">&#x27;brown&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">13</span>, <span class="number">17</span>):</span><br><span class="line">    y = <span class="number">30</span> * i</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">        x = <span class="number">30</span> * j</span><br><span class="line">        square.goto(x, -y + <span class="number">280</span>)</span><br><span class="line">        square.stamp()</span><br><span class="line">        square.goto(-x, -y + <span class="number">280</span>)</span><br><span class="line">        square.stamp()</span><br><span class="line">turtle.mainloop()</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20220914215352995.png" alt="image-20220914215352995"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Python作为一个弱类型语言，是有他的弊端的，在一些需要数据类型转换和严格控制数据类型的情况下，会非常难受。而Python最大的优势在于有大量的库，这些库在特定的编程领域会非常便利。Python本身的语言具有极强的灵活性，而灵活性的言外之意就是规范性很难确定。因此，Python的重点是将第三方包为我所用，在数值计算中发挥他最大的作用。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>暑期Python学习（四）</title>
      <link href="/2022/07/18/day-4/"/>
      <url>/2022/07/18/day-4/</url>
      
        <content type="html"><![CDATA[<h1 id="函数高级特性"><a href="#函数高级特性" class="headerlink" title="函数高级特性"></a>函数高级特性</h1><h2 id="切片（Slice）"><a href="#切片（Slice）" class="headerlink" title="切片（Slice）"></a>切片（Slice）</h2><p>切片是一个针对tuple和list方便地取元素的方法，下面举例说明：</p><ol><li>取出list L中的0到3个元素</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">L[<span class="number">0</span>:<span class="number">3</span>]</span><br></pre></td></tr></table></figure><p>当取出元素从第0个开始时，第一个数字可以缺省</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">L[:<span class="number">3</span>]</span><br></pre></td></tr></table></figure><ol><li>取出倒数后三个元素<br>在Python中允许使用<code>L[-1]</code>来取出倒数第一个数，因此可以这样倒着取：</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">L[-<span class="number">3</span>:]</span><br></pre></td></tr></table></figure><ol><li>每两个数取一个数<br>切片的最后一个数字表示步长，步长为多少就隔几个数字。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">L[:<span class="number">10</span>:<span class="number">2</span>]</span><br></pre></td></tr></table></figure><p>字符串和tuple同样可以这样使用，只不过返回值为对应类型。</p><h2 id="迭代（Iteration）"><a href="#迭代（Iteration）" class="headerlink" title="迭代（Iteration）"></a>迭代（Iteration）</h2><p>Python的迭代相比c或者Java来说，功能更强大，除了可以迭代list，还可以迭代dict这种无下标的数据类型。<br>想要知道一个数据能否迭代可以通过一个函数来完成：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections.abc <span class="keyword">import</span> Iterable</span><br><span class="line">L=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line"><span class="built_in">isinstance</span>(L,Iterable)</span><br></pre></td></tr></table></figure><p>下面说明dict如何迭代：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">d=&#123;<span class="string">&#x27;a&#x27;</span>:<span class="number">1</span>,<span class="string">&#x27;b&#x27;</span>:<span class="number">2</span>,<span class="string">&#x27;c&#x27;</span>:<span class="number">3</span>&#125;</span><br><span class="line"><span class="comment"># 迭代key</span></span><br><span class="line"><span class="keyword">for</span> key <span class="keyword">in</span> d:</span><br><span class="line">    <span class="built_in">print</span>(key)</span><br><span class="line"><span class="comment"># 迭代value</span></span><br><span class="line"><span class="keyword">for</span> value <span class="keyword">in</span> d.values():</span><br><span class="line">    <span class="built_in">print</span>(value)</span><br><span class="line"><span class="comment"># 迭代key和value</span></span><br><span class="line"><span class="keyword">for</span> k,v <span class="keyword">in</span> d.items:</span><br><span class="line">    <span class="built_in">print</span>(k)</span><br><span class="line">    <span class="built_in">print</span>(v)</span><br></pre></td></tr></table></figure><p>需要理解的是，这里的key，value，k，v都是for循环中的形参，没有实际意义。也就是说当<code>in d</code>的时候默认就是取<code>key</code> 。当要迭代其他的时候只需要更改<code>in</code>的后面。我猜测这可能与dict的存储方式有关。</p><p>多个元素同时迭代在其他list中也是可以实现的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">l=&#123;(<span class="number">1</span>,<span class="number">2</span>),(<span class="number">3</span>,<span class="number">4</span>),(<span class="number">5</span>,<span class="number">6</span>)&#125;</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> l:</span><br><span class="line">    <span class="built_in">print</span>(x)</span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> l:</span><br><span class="line">    <span class="built_in">print</span>(x,y)</span><br></pre></td></tr></table></figure><h2 id="列表生成式"><a href="#列表生成式" class="headerlink" title="列表生成式"></a>列表生成式</h2><p>一种快捷生成list的方式，一个例子如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[x * x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>)]</span><br></pre></td></tr></table></figure><p>如果想要筛选生成的值，可以在<code>for</code>后加上<code>if</code>作为<strong>筛选条件</strong>，注意这里是筛选条件， 因此这里和平时的<code>if else</code>并不是一个东西。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[x * x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>) <span class="keyword">if</span> x % <span class="number">2</span> == <span class="number">0</span>]</span><br></pre></td></tr></table></figure><h2 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h2><p>如果列表元素可以按照某种算法推算出来，那我们是否可以在循环的过程中不断推算出后续的元素呢？这样就不必创建完整的list，从而节省大量的空间。在Python中，这种一边循环一边计算的机制，称为生成器：generator。</p><h3 id="创建generator"><a href="#创建generator" class="headerlink" title="创建generator"></a>创建generator</h3><ol><li>把一个列表生成式的<code>[]</code>改成<code>(）</code></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">g = (x * x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>))</span><br></pre></td></tr></table></figure><ol><li>包含<code>yield</code>关键字<br>当一个函数包含<code>yield</code>关键字时，他就成了一个generator函数。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">fib</span>(<span class="params"><span class="built_in">max</span></span>):</span><br><span class="line">    n, a, b = <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> n &lt; <span class="built_in">max</span>:</span><br><span class="line">        <span class="keyword">yield</span> b</span><br><span class="line">        a, b = b, a + b</span><br><span class="line">        n = n + <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;done&#x27;</span></span><br></pre></td></tr></table></figure><p><code>yield</code>在generator函数中起到了一个return的作用，即到<code>yield</code>便返回。 在调用时，使用一个变量接受一个generator对象。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">f = fib(<span class="number">6</span>)</span><br></pre></td></tr></table></figure><h3 id="调用generator获得值"><a href="#调用generator获得值" class="headerlink" title="调用generator获得值"></a>调用generator获得值</h3><ol><li>使用<code>next()</code>函数依次获得下一个返回值</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">next</span>(f)</span><br></pre></td></tr></table></figure><ol><li>使用<code>for</code>循环</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">g = (x * x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>))</span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> g:</span><br><span class="line">    <span class="built_in">print</span>(n)</span><br></pre></td></tr></table></figure><h2 id="迭代器"><a href="#迭代器" class="headerlink" title="迭代器"></a>迭代器</h2><h3 id="区分Iterable和Iterator"><a href="#区分Iterable和Iterator" class="headerlink" title="区分Iterable和Iterator"></a>区分<code>Iterable</code>和<code>Iterator</code></h3><p><code>Iterable</code>是可迭代的，是直接可用于<code>for</code>循环的。包括dict、list、tuple、set、str、grenerator。<br><code>Iterator</code>是迭代器，是直接可用于<code>next()</code>函数的，生成器都是<code>Iterator</code>对象，集合数据类型可以通过<code>iter()</code>获取<code>Interator</code>对象。</p><h3 id="for循环的本质"><a href="#for循环的本质" class="headerlink" title="for循环的本质"></a><code>for</code>循环的本质</h3><p>在Python中<code>for</code>循环本质上就是一个不断调用<code>next()</code>的过程。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">it=<span class="built_in">iter</span>([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        x=<span class="built_in">next</span>(it)</span><br><span class="line">    <span class="keyword">except</span> StopIteration:</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Python学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>暑期Python学习（三）</title>
      <link href="/2022/07/16/day3/"/>
      <url>/2022/07/16/day3/</url>
      
        <content type="html"><![CDATA[<h1 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h1><h2 id="函数定义"><a href="#函数定义" class="headerlink" title="函数定义"></a>函数定义</h2><p>在Python中定义函数为，<code>def 函数名(参数):</code>然后，在缩进块中编写函数体，函数的返回值用<code>return</code>语句返回。<br>如果没有return语句，函数执行完毕后也会返回结果，只是结果为None。return None可以简写为return。</p><h3 id="空函数"><a href="#空函数" class="headerlink" title="空函数"></a>空函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">nop</span>():</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>在这里<code>pass</code>作为占位符，表示跳过，也可以用在<code>if</code>的缩进块。</p><h3 id="参数限制"><a href="#参数限制" class="headerlink" title="参数限制"></a>参数限制</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(x, (<span class="built_in">int</span>, <span class="built_in">float</span>)):</span><br><span class="line">      <span class="keyword">raise</span> TypeError(<span class="string">&#x27;bad operand type&#x27;</span>)</span><br></pre></td></tr></table></figure><p>实际上参数限制就是定义一个报错，<code>isinstance()</code>判断数据类型，如果不是就提出一个错误。<br><strong><strong>作为一个弱类型语言，定义这一步是很有必要的，有助于读懂代码。</strong></strong></p><h3 id="返回值"><a href="#返回值" class="headerlink" title="返回值"></a>返回值</h3><p>Python允许返回多个值，其返回的实际上是一个tuple元组，但是也可以用两个变量接收。</p><h3 id="参数定义"><a href="#参数定义" class="headerlink" title="参数定义"></a>参数定义</h3><p>在Python中函数参数的定义也比较灵活，提供位置参数、默认参数、可变参数、关键字（key）参数等</p><h4 id="位置参数"><a href="#位置参数" class="headerlink" title="位置参数"></a>位置参数</h4><p>位置参数指的是参数在传入时，实参和形参有着严格的位置对应关系，为常用参数形式。</p><h4 id="默认参数"><a href="#默认参数" class="headerlink" title="默认参数"></a>默认参数</h4><p>默认参数是指在位置参数的基础上为其添加默认值，有默认值的参数为默认参数，没有默认值的参数为必选参数<br>基本定义形式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">my_def</span>(<span class="params">a,b=<span class="number">1</span></span>):</span><br><span class="line">    a=b+<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> </span><br></pre></td></tr></table></figure><p>需要注意的是：</p><ul><li>默认参数必须在必选参数后边，否则会无法辨认是否输入必选参数，从而报错。</li><li>默认参数的默认值一定是<strong>不变对象</strong>，由于Python中的变量定义为指针指向，会导致可变对象值发生变化</li></ul><p>不可变对象有：数值类型、字符串、tuple元组、None等</p><h4 id="可变参数"><a href="#可变参数" class="headerlink" title="可变参数"></a>可变参数</h4><p>可变参数指的是参数的数目不固定，定义形式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">my_function</span>(<span class="params">*v</span>):</span><br><span class="line">    <span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> vi <span class="keyword">in</span> v:</span><br><span class="line">        <span class="built_in">sum</span>+=vi</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span></span><br></pre></td></tr></table></figure><p>在可变参数中传入的所有参数将作为一个tuple被接收，该tuple的变量名为函数在定义时的形参名，<br>定义时的需要在参数名前加一个<code>*</code>。</p><h4 id="关键字（key）参数"><a href="#关键字（key）参数" class="headerlink" title="关键字（key）参数"></a>关键字（key）参数</h4><p>此处的关键字和c语言中的关键字并不是一个意义，而是在dict中的key的意义。即在传递参数时<br>，同时传递键（key）和值(value),Python会自动封装为一个dict。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">my_function</span>(<span class="params">**v</span>):</span><br><span class="line">    <span class="built_in">print</span>(v)</span><br><span class="line">    <span class="keyword">return</span> </span><br></pre></td></tr></table></figure><h4 id="命名关键字参数"><a href="#命名关键字参数" class="headerlink" title="命名关键字参数"></a>命名关键字参数</h4><p>在关键字参数上，进一步限制传入的key的命名，就有了命名关键词参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">person</span>(<span class="params">name, age, *, city, job</span>):</span><br><span class="line">    <span class="built_in">print</span>(name, age, city, job)</span><br></pre></td></tr></table></figure><p>这里需要一个<code>*</code>区分位置参数与命名关键字参数，如果在这之前有可变参数，那么就不需要加<code>*</code>。<br>命名关键字参数必须传入参数名，这和位置参数不同。如果没有传入参数名，调用将报错：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>person(<span class="string">&#x27;Jack&#x27;</span>, <span class="number">24</span>, <span class="string">&#x27;Beijing&#x27;</span>, <span class="string">&#x27;Engineer&#x27;</span>)</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">TypeError: person() missing <span class="number">2</span> required keyword-only arguments: <span class="string">&#x27;city&#x27;</span> <span class="keyword">and</span> <span class="string">&#x27;job&#x27;</span></span><br></pre></td></tr></table></figure><h4 id="参数组合"><a href="#参数组合" class="headerlink" title="参数组合"></a>参数组合</h4><p>在一个函数中使用多个参数要保证其中的顺序，依次为：必选参数、默认参数、可变参数、命名关键字参数和关键字参数。  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">onefunction</span>(<span class="params">a,b,c=<span class="number">0</span>,*args,job,city,**kw</span>):</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>tips：  </p><ul><li>使用<code>*args</code>和<code>**kw</code>是Python的习惯写法。</li><li>可变参数和关键字参数有一点层级的感觉，中间包裹的是命名关键字参数这个比较尴尬的参数。</li></ul><h2 id="递归函数"><a href="#递归函数" class="headerlink" title="递归函数"></a>递归函数</h2><p>写法与Java相同。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Python学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>暑期Python学习（二）</title>
      <link href="/2022/07/10/day2/"/>
      <url>/2022/07/10/day2/</url>
      
        <content type="html"><![CDATA[<h1 id="python基本语法">Python基本语法</h1><h2 id="数据类型">数据类型</h2><p>首先必须说明一点，Python和JavaScript一样是一个弱类型语言，和Java、C++有所不同，Python在定义变量时，无需进行类型声明。</p><h3 id="整数">整数</h3><p>对于很大的数，很难数清楚0的个数。Python允许在数字中间以_分隔。</p><h3 id="浮点数">浮点数</h3><p>允许使用科学计数法定义</p><h3 id="字符串">字符串</h3><p>在Python没有严格要求<code>''</code>和<code>""</code>的区别在，也就是说没有区分字符和字符串使用二者没有任何区别。</p><ul><li>转义符和Java中保持一致</li><li>Python允许用<code>r''</code>表示<code>''</code>内部的字符串默认不转义</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">r&#x27;\t\\&#x27;</span>)</span><br></pre></td></tr></table></figure><p>输出结果为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\t\\</span><br></pre></td></tr></table></figure><ul><li>Python允许用<code>'''...'''</code>的格式表示多行内容，输出结果按行。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#x27;&#x27;这是一个</span></span><br><span class="line"><span class="string">很长很长</span></span><br><span class="line"><span class="string">的句子&#x27;&#x27;&#x27;</span>)</span><br></pre></td></tr></table></figure><h3 id="布尔值">布尔值</h3><p>在Python中要注意：<code>True</code>、<code>False</code>要注意开头首字母大写。<br />可以进行与、或、非的运算，运算符分别为：<code>and</code>，<code>or</code>，<code>not</code></p><h3 id="空值">空值</h3><p>空值用<code>None</code>表示，意义与Java中的<code>null</code>相同。</p><h2 id="变量与常量">变量与常量</h2><h3 id="变量">变量</h3><p>变量名必须是大小写英文、数字和<code>_</code>的组合，且不能用数字开头</p><ul><li>在变量创立时，Python是这样的：<br />① 找一块内存，存储一个数值<br />② 找一块内存，建立一个变量，将这个变量指向数值</li><li>这里注意Python的变量建立和指针相关。</li></ul><h3 id="常量">常量</h3><p>在Python中，通常用全部大写的变量名表示常量，但是并不能保证常量不变</p><h2 id="list和tuple">list和tuple</h2><h3 id="list">list</h3><p>list是Python内置的一种数据类型，list是一种有序的集合，可以随时添加和删除其中的元素。<br />此数据类型在Java的实用类中有封装。<br />list和数组很像，声明方式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">classname = [<span class="string">&#x27;老六&#x27;</span>,<span class="string">&#x27;老八&#x27;</span>,<span class="string">&#x27;老壁灯&#x27;</span>]</span><br></pre></td></tr></table></figure><p>想要调取其中的某个元素也和数组一致，赋值修改等也相同<br />下面列举一下list的ADT</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">list:</span><br><span class="line">append(&#x27;Elem&#x27;)  # 在末尾添加新的元素</span><br><span class="line">insert(i,&#x27;Elem&#x27;) # 将元素插入指定位置</span><br><span class="line">pop() # 删除末尾元素</span><br><span class="line">pop(i) # 删除i处的元素</span><br><span class="line">len(list) # list列表的长度</span><br></pre></td></tr></table></figure><p>list允许混合类型，也允许list嵌套，从而出现多维数组。</p><h3 id="tuple">tuple</h3><p>tuple被称为元组，其最大的特点就是不可修改，声明方式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">classname = (<span class="string">&#x27;老六&#x27;</span>,<span class="string">&#x27;老八&#x27;</span>,<span class="string">&#x27;老壁灯&#x27;</span>)</span><br></pre></td></tr></table></figure><p>tuple在定义时要确定元素个数，这里有一个问题，在定义只有一个元素的tuple时，Python语法会认为这是一个小括号，因此在定义一个元组的tuple时，要加一个<code>,</code>避免歧义。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t=(<span class="number">1</span>,)</span><br></pre></td></tr></table></figure><h2 id="流程控制语句">流程控制语句</h2><h3 id="条件判断">条件判断</h3><p>if语句，需要注意的是Python中的流程控制语句结尾都是冒号</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a=<span class="built_in">input</span>()</span><br><span class="line">a=<span class="built_in">int</span>(a)</span><br><span class="line"><span class="keyword">if</span> a&lt;<span class="number">1</span>:</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line"><span class="keyword">elif</span> a&gt;<span class="number">2</span>:</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>()</span><br></pre></td></tr></table></figure><p>因为是弱类型语言，在比较、计算时要给数据指定一个类型。</p><h3 id="循环">循环</h3><ul><li><code>for x in []:</code><code>for x in ...:</code>循环就是把每个元素代入变量x，然后执行缩进块的语句tips：</li></ul><ol type="1"><li>xxxxxxxxxx it=iter([1,2,3,4,5])while True:    try:        x=next(it)   except StopIteration:        breakpython</li><li>Python提供了range(x)函数，生成[0,x-1]的整数</li></ol><ul><li><p><code>while</code> <code>while 条件判断语句 :</code></p></li><li><p><code>break</code>、<code>continue</code>和java中用法相同</p></li></ul><h2 id="字典dict与集合set">字典（dict）与集合（set）</h2><h3 id="字典dict">字典（dict）</h3><p>字典全称为dictionary，在Java实用类中叫hashmap。其由键值对（key-value）组成，查找速度快。下面是一种初始化方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d = &#123;<span class="string">&#x27;Michael&#x27;</span>: <span class="number">95</span>, <span class="string">&#x27;Bob&#x27;</span>: <span class="number">75</span>, <span class="string">&#x27;Tracy&#x27;</span>: <span class="number">85</span>&#125;</span><br></pre></td></tr></table></figure><p>也可以放入指定的key中：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d[<span class="string">&#x27;Adam&#x27;</span>] = <span class="number">67</span></span><br></pre></td></tr></table></figure><p>查找value:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d[<span class="string">&#x27;Adam&#x27;</span>]</span><br></pre></td></tr></table></figure><p>key与value是多对一的关系，key需要是一个不可变对象保证key做hash运算后的唯一性。如果多次对某个key赋值，后边的value会覆盖前面的value提供了几个函数：</p><ol type="1"><li>通过<code>in</code>来判断key是否在dict中，返回值为布尔值，格式为：<code>key in dict</code></li><li>get()方法，<code>dict.get('key',空返回值)</code>key不存在时返回空返回值，空返回值可自定义，如果没有定义的话返回None</li><li>pop()方法，删除key，如果有value也一并删除，格式为<code>pop('key')</code></li></ol><h3 id="集合set">集合（set）</h3><p>set是一组key的集合,集合特点；无序性、确定性、互异性要创建一个set，需要提供一个list作为输入集合：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="built_in">set</span>([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure><ul><li>方法： <code>add(key)</code>添加一个新的元素<code>remove(key)</code>删除一个元素</li><li>两个set可以做交运算和并运算： 交运算：<code>s1&amp;s2</code>并运算：<code>s1|s2</code></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Python学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>暑期Python学习（一）</title>
      <link href="/2022/07/10/day_1/"/>
      <url>/2022/07/10/day_1/</url>
      
        <content type="html"><![CDATA[<h1 id="Python入门"><a href="#Python入门" class="headerlink" title="Python入门"></a>Python入门</h1><p> 个人笔记，在有C++和Java基础下的学习。</p><h2 id="命令控制行和python交互页面的区别："><a href="#命令控制行和python交互页面的区别：" class="headerlink" title="命令控制行和python交互页面的区别："></a>命令控制行和python交互页面的区别：</h2><ul><li>命令控制行：输入命令Python进入交互界面，然后可以写Python命令，<br>可以通过<code>python 文件名.py</code>运行整个Python文件。使用<code>exit（） </code>命令退出。<br><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/day_1_2.png" alt="day_1_2"></li><li>Python交互界面：直接输入Python语句，不能运行整个Python文件。<br><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/day_1_1.png" alt="day_1_1"><br>Python交互模式主要是为了调试Python代码用的，也便于初学者学习，它不是正式运行Python代码的环境！<br>tip：SyntaxError指的是代码语法有错误。</li></ul><h2 id="第一个程序"><a href="#第一个程序" class="headerlink" title="第一个程序"></a>第一个程序</h2><p>写一个hello world，用记事本或者IDE都可以。通过命令控制行运行</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;hello world&quot;</span>)</span><br></pre></td></tr></table></figure><ul><li>在py文件所在目录下，打开命令控制行，使用命令运行：<br><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/day_1_3.png" alt="day_1_3"></li></ul><h2 id="输入输出"><a href="#输入输出" class="headerlink" title="输入输出"></a>输入输出</h2><p>输入：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">name = <span class="built_in">input</span>(<span class="string">&#x27;这里可以加一个提示，不必用print&#x27;</span>)     <span class="comment"># name是接收变量</span></span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#x27;</span>,<span class="string">&#x27;&#x27;</span>)  <span class="comment"># 用于连续输出，中间有空格</span></span><br></pre></td></tr></table></figure><h2 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用#表示注释</span></span><br></pre></td></tr></table></figure><h2 id="代码风格"><a href="#代码风格" class="headerlink" title="代码风格"></a>代码风格</h2><p>Python中代码采用缩进，可以不写分号。<code>:</code>结尾时，后续视为代码块自动缩进（采用IDE时），缩进距离无限制<br>一般为四个空格。显然Python对cv工程师很不友好，要检查缩进是否正确。<br>Python是大小写敏感型。 </p>]]></content>
      
      
      
        <tags>
            
            <tag> Python学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2022/07/01/hello-world/"/>
      <url>/2022/07/01/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p><p><a href="https://zh.usa1lib.org/booklist/155353/c2a989">书集 (usa1lib.org)</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
