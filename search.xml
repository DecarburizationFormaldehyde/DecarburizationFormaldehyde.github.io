<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>搓OS-day5</title>
      <link href="/2024/01/14/%E6%90%93OS-day5/"/>
      <url>/2024/01/14/%E6%90%93OS-day5/</url>
      
        <content type="html"><![CDATA[<h2 id="手搓os-day5">手搓OS-day5</h2><p>咕咕，做一个老鸽子真的是太舒服了（雾）。这里我先提出一个操作系统公共厕所说（）。众所周知，厕所是一种紧俏资源（CPU计算资源），只能独占，这里我们做一个抽（恶）象（心）的假设，人们是可以容忍临时换人的（状态机），有了这个现（逆）实（天）模型，后面就容易理解了。</p><h3 id="复习">复习</h3><h4 id="并发">并发</h4><p>并发，指的是一个时间段内两个进程同时运行（往往是交替的），而不是完全的同时，以人类视角来看并发是相当恶心的，带入一下上边的模型就能体会到。</p><p>而与并发常混淆的是<code>并行</code>，并行是我们可以理解的，也就是两个不同的进程（不只是进程）在同时刻处于运行态，但是放在上面的模型中，如果只有一个坑位，显然并行也是不行的，这也就是一般操作系统课程中常常考虑的单处理机。</p><p>这里画一个图就懂了：</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240114221544023.png"alt="并发与并行" /><figcaption aria-hidden="true">并发与并行</figcaption></figure><p>可能有些基础薄弱的同学要问了，处理机和CPU有什么区别吗？</p><p>这个还是有一点区别的，处理机，顾名思义，是个处理什么玩意的机器，所以他是处理什么的呢，处理的是数据和程序，实际上，处理机是一个除去外设的一个计算机，而处理器就是CPU，处理机包含处理器：</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240114222149946.png"alt="image-20240114222149946" /><figcaption aria-hidden="true">image-20240114222149946</figcaption></figure><p>这个说法在课本上多次提到，我个人认为是很大程度上为我们理解增加了障碍，在操作系统中我们其实就可以狭隘的理解成分配了计算资源（CPU）就好。</p><h4 id="并发带来的问题">并发带来的问题</h4><p>在上一篇的实验中其实已经能够看出来，由于并发的程序相当随机，所以会出现输出并不符合预期的情况，一般有两种情况：运行顺序不好，访问共同资源，分别对应两种问题：同步与互斥。</p><p>今天先来解决互斥问题。</p><h3 id="peterson算法">Peterson算法</h3><h4 id="理论">理论</h4><p>这个算法相当奇怪，但是是一个礼貌的算法，我们回到上面的厕所模型。厕所里关了（<del>被阿姨锁门且关灯</del>）甲乙两人，甲乙两人都可能想进入厕所（想进厕所是随机的），那怎么才能保证厕所仅仅被一人使用呢？</p><p><code>甲：我想去厕所，但是我得看看乙在不在里边</code></p><p>于是，甲大声且自信的说出，我要去厕所啦，你在用吗，然后乙回复：我正在用，并且听到乙在一直说：我要上厕所，于是甲决定等一会儿，只听见乙还在叫嚷（</p><p>没错这个算法就是这么诡异的状况，但是很礼貌，现在我们把这个过程对应到变量上：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = <span class="number">1</span>; # 甲表示我要上厕所</span><br><span class="line">turn = B; # 我先问问乙在不在</span><br><span class="line"><span class="keyword">while</span>(y &amp;&amp; turn==B); # 那甲先等会儿</span><br><span class="line"># 否则</span><br><span class="line">x = <span class="number">0</span>; # 甲愉快的进入厕所，并结束</span><br></pre></td></tr></table></figure><p>这就是Peterson算法的基本流程，如果将其写的更加全面一点：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">TA</span><span class="params">()</span> &#123; <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line"><span class="comment">/* ❶ */</span>  x = <span class="number">1</span>;</span><br><span class="line"><span class="comment">/* ❷ */</span>  turn = B;</span><br><span class="line"><span class="comment">/* ❸ */</span>  <span class="keyword">while</span> (y &amp;&amp; turn == B) ;</span><br><span class="line"><span class="comment">/* ❹ */</span>  x = <span class="number">0</span>; &#125; &#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">TB</span><span class="params">()</span> &#123; <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line"><span class="comment">/* ① */</span>  y = <span class="number">1</span>;</span><br><span class="line"><span class="comment">/* ② */</span>  turn = A;</span><br><span class="line"><span class="comment">/* ③ */</span>  <span class="keyword">while</span> (x &amp;&amp; turn == A) ;</span><br><span class="line"><span class="comment">/* ④ */</span>  y = <span class="number">0</span>; &#125; &#125;</span><br></pre></td></tr></table></figure><h4 id="volatile和编译器屏障顺序性">volatile和编译器屏障（顺序性）</h4><h5 id="编译器指令重排">编译器指令重排</h5><p>根据上一篇的认识，我们已经知道在现代计算机上，程序的执行并不具有原子性，机器语言的顺序与我们写出的高级语言的顺序也会不一致。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> a,b;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">foo</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    a=b+<span class="number">1</span>;</span><br><span class="line">    b=<span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过我们之前的编译操作和反编译操作：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">gcc -c -o compile1.o  compile_demo.c</span> </span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">0000000000000000 &lt;foo&gt;:</span><br><span class="line">   0:   f3 0f 1e fa             endbr64 </span><br><span class="line">   4:   55                      push   %rbp</span><br><span class="line">   5:   48 89 e5                mov    %rsp,%rbp</span><br><span class="line">   8:   8b 05 00 00 00 00       mov    0x0(%rip),%eax        # e &lt;foo+0xe&gt;</span><br><span class="line">   e:   83 c0 01                add    $0x1,%eax</span><br><span class="line">  11:   89 05 00 00 00 00       mov    %eax,0x0(%rip)        # 17 &lt;foo+0x17&gt;</span><br><span class="line">  17:   c7 05 00 00 00 00 00    movl   $0x0,0x0(%rip)        # 21 &lt;foo+0x21&gt; b=0</span><br><span class="line">  1e:   00 00 00 </span><br><span class="line">  21:   90                      nop</span><br><span class="line">  22:   5d                      pop    %rbp</span><br><span class="line">  23:   c3                      ret    </span><br></pre></td></tr></table></figure><p>如果我们采用O2级别的编译优化：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">gcc -c -O2  -o compile2.o compile_demo.c</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">0000000000000000 &lt;foo&gt;:</span><br><span class="line">   0:   f3 0f 1e fa             endbr64 </span><br><span class="line">   4:   8b 05 00 00 00 00       mov    0x0(%rip),%eax        # a &lt;foo+0xa&gt;</span><br><span class="line">   a:   c7 05 00 00 00 00 00    movl   $0x0,0x0(%rip)        # 14 &lt;foo+0x14&gt; b=0</span><br><span class="line">  11:   00 00 00 </span><br><span class="line">  14:   83 c0 01                add    $0x1,%eax</span><br><span class="line">  17:   89 05 00 00 00 00       mov    %eax,0x0(%rip)        # 1d &lt;foo+0x1d&gt;</span><br><span class="line">  1d:   c3                      ret    </span><br></pre></td></tr></table></figure><p>可以摁着头皮尝试阅读一下，其实也不难看懂（我写了一句注释<code>b=0</code>），可以看出，<code>b=0与a=b+1</code>两句话在不同的编译优化上，表现出的位置实际上是不同的，这是因为在单线程下，a与b的赋值顺序在编译器看来其实无关痛痒，但在多线程并发下很可能会出问题，就比如上面的Peterson算法，如果编译器调换了循环等待与其他语句的顺序，那么Peterson算法将不再成立。</p><p>对于这个问题也存在对应的解决方案：</p><h5 id="显式编译屏障">显式编译屏障</h5><p>编译器提供了编译器屏障（compiler barriers），用来告知不可重排</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> barrier() asm volatile(<span class="string">&quot;&quot;</span>:::<span class="string">&quot;memory&quot;</span>)</span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> a,b;</span><br><span class="line"><span class="type">void</span>()</span><br><span class="line">&#123;</span><br><span class="line">    a=b+<span class="number">1</span>;</span><br><span class="line">    barrier()</span><br><span class="line">    b=<span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>显然这个宏定义也超出我的知识范围了，问问chatgpt吧：</p><p><code>具体而言，这个宏的定义中包含了一个内联汇编语句,这个汇编语句的作用是告诉编译器在这里插入一个内存屏障，确保前面的内存操作（读或写）和后面的内存操作在执行时的顺序不能被重排。 memory是一个内存屏障的类型，表示在这个位置之前和之后的所有内存访问不能被重排。</code></p><p>再次编译，反编译：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">0000000000000000 &lt;foo&gt;:</span><br><span class="line">   0:   f3 0f 1e fa             endbr64 </span><br><span class="line">   4:   8b 05 00 00 00 00       mov    0x0(%rip),%eax        # a &lt;foo+0xa&gt;</span><br><span class="line">   a:   83 c0 01                add    $0x1,%eax</span><br><span class="line">   d:   89 05 00 00 00 00       mov    %eax,0x0(%rip)        # 13 &lt;foo+0x13&gt;</span><br><span class="line">  13:   c7 05 00 00 00 00 00    movl   $0x0,0x0(%rip)        # 1d &lt;foo+0x1d&gt;  b=0</span><br><span class="line">  1a:   00 00 00 </span><br><span class="line">  1d:   c3                      ret    </span><br></pre></td></tr></table></figure><h5 id="隐式编译屏障">隐式编译屏障</h5><p>当某个函数包含屏障时，调用该函数也有屏障的作用</p><h4 id="实现">实现</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;thread.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> A 1</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> B 2</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> BARRIER __sync_synchronize() <span class="comment">// GCC 内建的同步内存屏障函数</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">atomic_int</span> nested; <span class="comment">// atomic_int 是 C 标准中 &lt;stdatomic.h&gt; 头文件中定义的原子类型</span></span><br><span class="line"><span class="type">atomic_long</span> count;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">critical_section</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">long</span> cnt = atomic_fetch_add(&amp;count, <span class="number">1</span>); <span class="comment">// 原子加法</span></span><br><span class="line">    <span class="type">int</span> i = atomic_fetch_add(&amp;nested, <span class="number">1</span>) + <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">if</span> (i != <span class="number">1</span>) <span class="comment">// 进入临界区的线程不能多于两个</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d thread in the critical section @ count=%ld\n&quot;</span>, i, cnt);</span><br><span class="line">        assert(<span class="number">0</span>); <span class="comment">// 断言，上一次学过了，因此只要这个程序不停止，证明就正常跑起来了</span></span><br><span class="line">    &#125;</span><br><span class="line">    atomic_fetch_add(&amp;nested, <span class="number">-1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="keyword">volatile</span> x = <span class="number">0</span>, y = <span class="number">0</span>, turn; </span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">chatGPT:</span></span><br><span class="line"><span class="comment">volatile 是一个关键字，用于告诉编译器不要对这些变量进行优化，以确保每次访问都从内存中读取或写入变量的值，而不使用缓存。</span></span><br><span class="line"><span class="comment">在多线程编程中，volatile 通常用于标记多个线程之间共享的变量，以确保对这些变量的访问是可见的。</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">TA</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        x=<span class="number">1</span>;</span><br><span class="line">        BARRIER;</span><br><span class="line">        turn=B;</span><br><span class="line">        BARRIER;</span><br><span class="line">        <span class="keyword">while</span> (<span class="number">1</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (!y) <span class="keyword">break</span>;</span><br><span class="line">            BARRIER;</span><br><span class="line">            <span class="keyword">if</span> (turn!=B) <span class="keyword">break</span>;</span><br><span class="line">            BARRIER;</span><br><span class="line">        &#125;</span><br><span class="line">        critical_section();</span><br><span class="line">        x=<span class="number">0</span>;</span><br><span class="line">        BARRIER;</span><br><span class="line">    &#125;    </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">TB</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        y=<span class="number">1</span>;</span><br><span class="line">        BARRIER;</span><br><span class="line">        turn=A;</span><br><span class="line">        BARRIER;</span><br><span class="line">        <span class="keyword">while</span> (<span class="number">1</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (!x) <span class="keyword">break</span>;</span><br><span class="line">            BARRIER;</span><br><span class="line">            <span class="keyword">if</span> (turn!=A) <span class="keyword">break</span>;</span><br><span class="line">            BARRIER;</span><br><span class="line">        &#125;</span><br><span class="line">        critical_section();</span><br><span class="line">        y=<span class="number">0</span>;</span><br><span class="line">        BARRIER;</span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    create(TA);</span><br><span class="line">    create(TB);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="实现多线程求和原子性">实现多线程求和（原子性）</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;thread.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> N 100000000</span></span><br><span class="line"></span><br><span class="line"><span class="type">long</span> sum =<span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">atomic_inc</span><span class="params">(<span class="type">long</span> *ptr)</span>&#123;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">    内联汇编，俺不会，功能是原子自增</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="keyword">asm</span> <span class="title function_">volatile</span><span class="params">(</span></span><br><span class="line"><span class="params">        <span class="string">&quot;lock incq %0&quot;</span>  <span class="comment">// Atomic + memory fence</span></span></span><br><span class="line"><span class="params">        :<span class="string">&quot;+m&quot;</span>(*ptr)</span></span><br><span class="line"><span class="params">        :</span></span><br><span class="line"><span class="params">        :<span class="string">&quot;memory&quot;</span> <span class="comment">// 内存屏障</span></span></span><br><span class="line"><span class="params">    )</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">Tsum</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">atomic_inc</span>(&amp;sum);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    create(Tsum);</span><br><span class="line">    create(Tsum);</span><br><span class="line">    join();  <span class="comment">// 结束进程</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;sum=%ld\n&quot;</span>,sum);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="总结">总结</h3><p>并发提供了新的功能，但确确实实带来了极大的实现挑战，注意理解顺序性，原子性在实现中的必要性，要明白我们写的高级代码，在运行时会出很多幺蛾子,从而更好地理解并发的进程同步。</p><h3 id="参考链接">参考链接</h3><p><ahref="https://blog.csdn.net/wll1228/article/details/121875525">volatile和编译器屏障_asmvolatile("yield" ::: "memory");-CSDN博客</a></p><p><a href="https://jyywiki.cn/OS/2023/build/lect6.ipynb.html">6.并发控制基础 (jyywiki.cn)</a></p><p><ahref="https://pages.cs.wisc.edu/~remzi/OSTEP/threads-api.pdf">single.dvi(wisc.edu)课本阅读材料</a></p><p><a href="https://godbolt.org/">Compiler Explorer (godbolt.org)很好玩的编译网站</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 搓OS.log </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>不得不知道的实用数据结构算法（一）</title>
      <link href="/2024/01/13/%E4%B8%8D%E5%BE%97%E4%B8%8D%E7%9F%A5%E9%81%93%E7%9A%84%E5%AE%9E%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AE%97%E6%B3%95%EF%BC%88%E4%B8%80%EF%BC%89/"/>
      <url>/2024/01/13/%E4%B8%8D%E5%BE%97%E4%B8%8D%E7%9F%A5%E9%81%93%E7%9A%84%E5%AE%9E%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AE%97%E6%B3%95%EF%BC%88%E4%B8%80%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h2id="不得不知道的实用数据结构算法一">不得不知道的实用数据结构算法（一）</h2><p>新坑说开就开，就是这么随（不）心（知）所（死）欲（活），这个系列实际上是针对数据结构中的一些低时间复杂度的常用模板or思考方式的总结，ok，今天先进行的是线性表。</p><h3 id="线性表">线性表</h3><p>定义：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># <span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="keyword">typedef</span> ElemType <span class="type">int</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">typedef</span> <span class="title">SeqList</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    ElemType  *data;  <span class="comment">// 按道理这里应该有很多实现方法，比如直接上一个数组，通过宏定义最大数组长度</span></span><br><span class="line">    <span class="type">int</span> size;</span><br><span class="line">    <span class="type">int</span> capacity;</span><br><span class="line">&#125;SeqList;</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># <span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta"># <span class="keyword">define</span> MAXSIZE 100</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> ElemType <span class="type">int</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">typedef</span> <span class="title">SeqList</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    ElemType  data[MAXSIZE];</span><br><span class="line">    <span class="type">int</span> length;</span><br><span class="line">&#125;SeqList;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">init</span><span class="params">(SeqList *l)</span></span><br><span class="line">&#123;</span><br><span class="line">    l-&gt;length=<span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>秉承着不给自己找麻烦，后边就不用动态分配空间的代码了，虽然在我初学的时候觉得动态分配真的很优雅（起码不怕爆了）</p><p>OK，然后迅速的过一下基本操作以及其操作的流程以及弊端（懒得写了）：</p><p><code>删除</code>：删除一个元素，要将后边的元素都移过来，实际上也就是说复杂度是O(n)</p><p><code>遍历</code>：这不必多说，自然O(n)</p><p><code>随机存取</code>：这是顺序表的强项</p><p><code>插入</code>：和插入其实一致，但是要求后移后面的元素</p><p>然而很多算法题会颠覆你对基本操作的认识，也就是会让你优化一种插入操作or删除操作，使一个本来暴力解时间复杂度为O(n<sup>2</sup>)的算法优化为时间复杂度为O(n)的算法</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/e61190ef76c6a7ef54f88818eeaa655af2de6689.jpeg@f_auto"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>我们先举个例子：</p><p><code>现在有一个顺序表，其中有元素n个，现在我希望删除其中的所有偶数元素</code></p><p>我们从直觉上很容易写出这样一个代码：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">dele_even</span><span class="params">(SeqList *l)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> (l==<span class="literal">NULL</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;顺序表未初始化&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> ;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; l-&gt;length; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (l-&gt;data[i]%<span class="number">2</span>==<span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            delete(l,i); #时间复杂度是O(n)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>简单瞅一眼，很明显可以看出这是个O(n<sup>2</sup>)的时间复杂度的算法，但是有没有一种可能，这个算法可以被优化到O(n)，这就是技巧一：有效的循环合并</p><h3 id="技巧一有效的循环合并">技巧一：有效的循环合并</h3><p>我们可以分析一下刚才删除的过程，其实有一些动作是多余的，我们其实没有必要去移动一个可能会被删除的元素：当我们找到一个偶数时，实际上后边的元素中依旧可能存在偶数，那么我们将这些偶数移动到前面就是一个多余的动作，因为以后依旧要被删除，其后边的元素仍旧面临的再一次循环的境地，因此我们是不是可以通过某种手段避免无效的遍历移动呢？</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">dele_even_good</span><span class="params">(SeqList *l)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> (l==<span class="literal">NULL</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;顺序表未初始化&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> ;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> m=<span class="number">0</span>; <span class="comment">//用于存储找到了多少偶数</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; l-&gt;length; i++)</span><br><span class="line">    &#123;</span><br><span class="line">         <span class="keyword">if</span> (m!=<span class="number">0</span> &amp;&amp; i-m&gt;<span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            l-&gt;data[i-m]=l-&gt;data[i];</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (l-&gt;data[i]%<span class="number">2</span>==<span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            m++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    l-&gt;length=l-&gt;length-m;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里采用了一边删除一边寻找的方式，将两个循环合并到了一起，从而有效的降低了时间复杂度。这种思想很适合于使用在处理一些你想无脑调API的时候的优化。</p><h3id="技巧二为什么不试试多次就地逆置呢">技巧二：为什么不试试多次就地逆置呢</h3><p>众所周知，就地逆置是处理一些奇奇怪怪需要一大堆循环的题目的利器，比如互换两块顺序表的位置：</p><p>有一个数组A[m+n]，要求将这前m个元素和后n个元素前后互换那么就地逆置就很有用了，我们只需要整体一次，再局部两次：</p><p><code>（1,2,3,……,m,m+1,……,m+n）</code></p><p>第一次就地逆置：<code>（m+n,……,m+1,m,……,3,2,1）</code></p><p>第二次局部逆置：<code>（m+1,……,m+n,m,……,3,2,1）</code></p><p>第三次局部逆置：<code>（m+1,……,m+n,1,2,3,……,m）</code></p><p>漂亮！</p><h3id="技巧三空间换时间随机存取之光">技巧三：空间换时间，随机存取之光</h3><p>随机存取就是一个很爽的性质，这意味着只要我们找到了元素的index就可以迅速的锁定元素，比如现在需要给一个顺序剔除重复元素，那么我怎么知道元素重复了呢？我们可以再来一个顺序表通过哈希的方式得到，举个例子：</p><p>假如我们扫描到了一个元素3，那么我们就将hash[3]=1（即新创建的顺序表）的位置，以此类推，那么当我们每扫描到一个元素的时候，只需要其比较hash[data]是否值为1，如果为1那么就重复了，再去执行我们前面做好的删除算法即可。</p><h3 id="总结">总结</h3><p>还有一些顺序表的算法题目，就比较没规律了，需要通过画图，手动运算一下，来找一下其中的规律，嗯，这些应付普通考试已经够了，剩下等我刷刷Leecode再行总结。</p>]]></content>
      
      
      
        <tags>
            
            <tag> C语言 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>搓OS-day4</title>
      <link href="/2024/01/12/%E6%90%93OS-day4/"/>
      <url>/2024/01/12/%E6%90%93OS-day4/</url>
      
        <content type="html"><![CDATA[<h2 id="手搓os-day4">手搓OS-day4</h2><p>今天才是真真的操作系统的部分，并发控制，今天要学习的是多线程编程库（没怎么看，少更）。</p><h3 id="复习进程与线程">复习：进程与线程</h3><p><code>进程</code>：运行的一个程序以及其已经在计算机中的所拥有的资源的和（理解型说法，并不准确），进程是<code>资源分配</code>的基本单位。PCB用于标志进程的存在。此外关于进程还存在<code>进程间通信问题</code>,<code>进程特性</code>，<code>进程切换</code>等问题。</p><p>就我个人理解为何要引入进程概念，是为了管理资源分配的问题，不只是空间资源还有计算资源，因为计算机的资源是紧俏的（当然也有机制限制），并不能满足所有的所有的程序<code>同时</code>运行（当然这里限制在单核处理器）。但是由于应用有要求，需要发展出能在人难以感知的情况下”同时“运行（并发），而进程恰好通过把资源与程序进行耦合（不知道用词好不好，类似一个搭积木的感觉）既保护了程序状态，又实现了程序运行的切换。</p><p>当人们线程用出来了甜头，想要进一步榨干计算机资源（bushi），然后就有了线程，线程就是榨干计算资源的（），但是线程并不是资源分配的单位。</p><h3 id="多线程编程">多线程编程</h3><p>貌似并不难</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;thread.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">Thello</span><span class="params">(<span class="type">int</span> id)</span> &#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%c&quot;</span>, <span class="string">&quot;_ABCDEFGHIJKLMNOPQRSTUVWXYZ&quot;</span>[id]);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">    create(Thello);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>很好玩，使命令行爆炸。</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240112211838011.png"alt="image-20240112211838011" /><figcaption aria-hidden="true">image-20240112211838011</figcaption></figure><p>这下很有并发的魅力（不是），但是联系底层让人后背发凉，细一想貌似也没什么大不了的</p><p><code>“处理器一次执行一条指令” 的基本假设在今天的计算机系统上不再成立</code>，虽然但是这是不难理解的，两条程序由于并发or并行很可能会出现共享区的变量出现问题</p><p>后面的故事，还是读参考链接吧，如果有操作系统基础的同学一定明白，进程同步互斥的问题都是从这里衍生出来的。</p><h3 id="参考链接">参考链接</h3><p><a href="https://jyywiki.cn/OS/2023/build/lect5.ipynb.html">5.多处理器编程：从入门到放弃 (jyywiki.cn)</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 搓OS.log </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>搓OS-day3</title>
      <link href="/2024/01/10/%E6%90%93OS-day3/"/>
      <url>/2024/01/10/%E6%90%93OS-day3/</url>
      
        <content type="html"><![CDATA[<h2 id="手搓os-day3">手搓OS-day3</h2><p>挺过了昨天的抽（硬）象（件）玩意，今天终于要迎来美丽的实战了（<del>很能绷的住</del>），下面我们要迎接大量的操作系统概念，虽然俺可能描述不清楚，但是我相信代码的力量，从现在要挑战编程能力惹。我尽可能拆开代码记录我的编程心路（<u><strong>阿门</strong></u>worship）</p><h3 id="架构">架构</h3><p>这里老师采用了一个分层的方式设计的架构，在硬件上通过一个AbstractMachine抽象出了部分API，这好处是显而易见的，就类似一个虚拟平台，对跨硬件是很有帮助的，显然Abstract的很多汇编我是不会写的，但是老师帮忙搭建好了（感恩）</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240111095855963.png"alt="简单架构" /><figcaption aria-hidden="true">简单架构</figcaption></figure><p>搓不动了，先放一放，研究一下设备无关编程（菜，哭）</p><h3 id="断言的重要性">断言的重要性</h3><p>这个和我们在JAVA中接触过的单元测试有些相似，说他重要体现在快速定位错误（不是运行错误）的重要性上</p><p>断言基本用法：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;assert.h&gt;</span></span></span><br><span class="line"></span><br><span class="line">assert(<span class="type">bool</span> exppression) <span class="comment">//显然这里传入一个bool量，但想起int中0和非0分别代表false和true</span></span><br></pre></td></tr></table></figure><p>使用场景：</p><ol type="1"><li><p>在函数入口做合法性检查</p></li><li><p>将<code>assert(0)</code>放在绝对不会出现的地方</p></li><li><p>放在需要一些条件必须满足的地方</p></li></ol><p>使用原则：</p><ol type="1"><li>一个断言检查一个条件</li><li>断言不能代替<code>if else</code></li><li>可以用开关条件编译打开或关闭断言，一般debug模式打开而在release模式下关闭。</li></ol><h3 id="linux中proc文件中的进程">Linux中proc文件中的进程</h3><h4 id="c语言文件操作">C语言文件操作</h4><p>用一个<code>FILE*</code>的一个指针来指定一个<code>FILE</code>格式的结构体。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FILE *fp;</span><br></pre></td></tr></table></figure><h5 id="打开和关闭">打开和关闭</h5><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">FILE *<span class="title function_">fopen</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *filename,<span class="type">const</span> <span class="type">char</span> *model)</span>;</span><br><span class="line"><span class="comment">// 文件名和打开参数</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">fclose</span><span class="params">(FILE *stream)</span>;</span><br><span class="line"><span class="comment">// 传入指针</span></span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line"><span class="comment">//打开名为test.txt的文件，打开方式w为只读</span></span><br><span class="line">FILE* pf = fopen(<span class="string">&quot;test.txt&quot;</span>, <span class="string">&quot;w&quot;</span>);  <span class="comment">//接收返回的文件信息区指针 (如果文件不存在，会自动创建)</span></span><br><span class="line"><span class="comment">//如果文件打开失败（例如文件不存在），会返回NULL</span></span><br><span class="line"><span class="keyword">if</span> (pf == <span class="literal">NULL</span>) &#123;</span><br><span class="line">perror(<span class="string">&quot;fopen\n&quot;</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//关闭文件</span></span><br><span class="line">fclose(pf);</span><br><span class="line"><span class="comment">//还需要将指针置空</span></span><br><span class="line">pf = <span class="literal">NULL</span>;</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="文件顺序读写">文件顺序读写</h5><p>字符输入</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">fgetc(<span class="string">&#x27;A&#x27;</span>,pf);</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i=<span class="number">0</span>; i&lt;<span class="number">26</span>;i++)&#123;</span><br><span class="line">    fputc(<span class="string">&#x27;a&#x27;</span>+i,pf);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>字符输出：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ch=fgetc(pf);</span><br></pre></td></tr></table></figure><p>按行写入：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">fputs</span>(<span class="string">&quot;hello\n&quot;</span>,pf)</span><br></pre></td></tr></table></figure><p>按行读取：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">char</span> *arr;</span><br><span class="line">fgets(arr,<span class="number">5</span>,pf);</span><br></pre></td></tr></table></figure><p>格式化输入：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">fprintf</span>(pf,<span class="string">&quot;%s %d %f&quot;</span>,s.name,s.age,s.height)；</span><br></pre></td></tr></table></figure><p>格式化读入：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">fscanf</span>(pf,<span class="string">&quot;%s %d %f&quot;</span>,s.name,&amp;(s.age),&amp;(s.height));</span><br></pre></td></tr></table></figure><h4 id="linux-proc进程文件含义">Linux Proc进程文件含义</h4><ul><li>comm：进程名</li><li>cwd：当前工作目录，是个软链接，指向实际的路径</li><li>environ：环境变量</li><li>exe：进程启动的二进制，也是个软链接，指向实际的文件路径</li><li>fd：进程打开的文件描述符，每个描述符也是个软链接，指向打开的文件，如果涉及到socket，则会显示socket的inode号fdinfo/：进程打开文件时的一些属性</li><li>root：根路径</li><li>stat：进程的状态信息，包括ppid、进程名、进程启动时间等（这个是有用的）</li><li>status：进程的一些参数信息，包括uid、gid、虚拟内存、capability等</li><li>task/：进程的子线程，每个子目录就是一个线程的信息</li></ul><p>其余见下链接</p><h3 id="总结">总结</h3><p>嗯，今天编程的难度有点大，导致总结难产，主要看的内容也在参考链接里贴出来了，C语言好难（我好菜），<del>明天预告maybe更难产</del></p><h3 id="参考链接">参考链接</h3><p><ahref="https://zhuanlan.zhihu.com/p/619966043?utm_id=0">Linux内核：进程管理——进程文件系统/proc详解 - 知乎 (zhihu.com)</a></p><p><a href="https://jyywiki.cn/OS/2023/labs/M1.html">M1: 打印进程树(pstree) (jyywiki.cn)</a></p><p><ahref="https://blog.csdn.net/RongLin02/article/details/116244719">Linux学习之打印进程树_利用/proc进行进程树的打印-CSDN博客</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 搓OS.log </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>搓OS-day2</title>
      <link href="/2024/01/10/%E6%90%93OS-day2/"/>
      <url>/2024/01/10/%E6%90%93OS-day2/</url>
      
        <content type="html"><![CDATA[<h2 id="手搓os-day2">手搓OS-day2</h2><p>今天看的东西全都围绕这两个C语言代码展开</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// say.c</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">putch</span><span class="params">(<span class="type">char</span> ch)</span>;</span><br><span class="line"><span class="type">int</span> <span class="title function_">putchar</span><span class="params">(<span class="type">int</span> ch)</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">say</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *s)</span> &#123;</span><br><span class="line">  <span class="keyword">for</span> (; *s; s++) &#123;</span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> __ARCH__</span></span><br><span class="line">    putch(*s); <span class="comment">// AbstractMachine，没有 libc，调用 TRM API 打印字符</span></span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">    <span class="built_in">putchar</span>(*s); <span class="comment">// 操作系统，调用 libc 打印字符</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// main.c</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">say</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *s)</span>;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">  say(<span class="string">&quot;hello\n&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="操作系统上的c程序">操作系统上的C程序</h3><h4 id="编译过程的一些参数含义">编译过程的一些参数含义</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">gcc -c -O2 -o main.o main.c</span><br><span class="line">gcc -c -O2 -o say.o say.c</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-c 表示生成目标文件而不进行链接</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-O2 表示使用优化级别为O2</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-o main.o 表示生成的指定文件的名称为main.o</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">file say.o main.o</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">用于查看目标文件类型</span></span><br></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">say.o:  ELF 64-bit LSB relocatable, x86-64, version 1 (SYSV), not stripped</span><br><span class="line">main.o: ELF 64-bit LSB relocatable, x86-64, version 1 (SYSV), not stripped</span><br></pre></td></tr></table></figure><p>表明两个文件都是64位的ELF格式可重定位文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">objdump -d main.o</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">objdump GNU工具，用于显示二进制文件信息</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-d 表示显示目标文件的汇编代码（反编译）</span></span><br></pre></td></tr></table></figure><p>汇编代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">0000000000000000 &lt;main&gt;:</span><br><span class="line">   0:   f3 0f 1e fa             endbr64 </span><br><span class="line">   4:   48 83 ec 08             sub    $0x8,%rsp</span><br><span class="line">   8:   48 8d 3d 00 00 00 00    lea    0x0(%rip),%rdi        # f &lt;main+0xf&gt;</span><br><span class="line">   f:   e8 00 00 00 00          call   14 &lt;main+0x14&gt;</span><br><span class="line">  14:   31 c0                   xor    %eax,%eax</span><br><span class="line">  16:   48 83 c4 08             add    $0x8,%rsp</span><br><span class="line">  1a:   c3                      ret    </span><br></pre></td></tr></table></figure><p>发现地址是从0开始的（<del>死去的组成原理开始袭击我</del>），可以看出这是一个CISC指令集，采用小端存储，系统地址按字节编址，<code>call</code>指令对应机器码为：<code>0xe8H</code>，可以看见偏移量现在是0，因为并不知道从哪儿调用</p><p><code>lea</code>是获取调用say参数的指令</p><h4 id="链接">链接</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">gcc main.o say.o</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">./a.out</span> </span><br><span class="line">hello</span><br></pre></td></tr></table></figure><p>这里不能直接用<code>ld</code>进行链接，这其实可以理解的，因为我们并没有对<code>putchar</code>做任何定义。而真正的链接流程与下面的加载流程的2中的细节其实是完全对应的（这也不难理解，链接好后加载到内存是很合理的吧）</p><p>同理这里也可用使用<code>objdump</code>来查看文件内容</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">objdump -d a.out</span></span><br></pre></td></tr></table></figure><h4 id="加载">加载</h4><p>流程：</p><ol type="1"><li>Shell接受命令后使用<code>fork()</code>创建一个新进程</li><li>在子进程中使用<code>execve()</code>加载<code>a.out</code>，在这里做出必要的内存映射：</li></ol><p>​ ① 执行动态链接库</p><p>​ ②跳转到<code>a.out</code>的<code>_start</code>运行，初始化C语言运行环境</p><p>​ ③ 执行<code>main</code></p><ol start="3" type="1"><li>如需要输入输出会使用特殊指令进行系统调用</li></ol><p><u><strong>补漏</strong></u>：</p><p>gdb指令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb) starti #运行到第一条指令便停止</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb) bt f  # backtrace full 打印堆栈信息</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb)info inferiors # 打印线程/进程信息</span><br></pre></td></tr></table></figure><p>Linux指令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!cat /proc/&#123;PID&#125;/maps #打印进程内存信息</span><br></pre></td></tr></table></figure><p>具体流程我也没看懂，后边看懂了再补</p><h3 id="bare-metal上的c程序">Bare-Metal上的C程序</h3><p>Bare-Metal就是一块纯铁（bushi），就是类似一个没有</p><p>操作系统的情况下（我先这么理解），续：通常用来描述在没有操作系统或软件层的支持的情况下运行的计算机系统（chatGPT如是说）。</p><p><del>唉，还是要写Makefile</del></p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">NAME := hello</span><br><span class="line">SRCS := main.c say.c</span><br><span class="line"><span class="keyword">include</span> <span class="variable">$(AM_HOME)</span>/Makefile.app</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make -nB ARCH=x86_64-qemu</span><br></pre></td></tr></table></figure><h4 id="编译">编译</h4><p>在之前C语言的部分上研究过，编译就是对.c文件翻译为可重定位的（relocatabel）的二进制目标文件（.o）。没有操作系统意味着所有的系统调用都是不成立的，所以没啥太大区别（）。需要加一个参数。</p><h4 id="链接-1">链接</h4><p>链接命令（<del>看着吓人</del>）：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ld -melf_x86_64 -N -Ttext-segment=0x00100000 -o build/hello-x86_64-qemu.o \</span><br><span class="line">  main.o say.o am-x86_64-qemu.a klib-x86_64-qemu.a</span><br></pre></td></tr></table></figure><p><code>-melf_x86_64</code>：指定链接为<code>x86_64 ELF</code>格式</p><p><code>-N</code>：没看懂（）</p><p><code>-Ttext-segment=0x00100000</code>：设置加载地址</p><p>后边给出了要链接的文件，分别是<code>main.o</code>,<code>say.o</code>和必要的库函数（AbstractMachine和klib）</p><p>总结一下，这个链接后的文件并不能直接在操作系统上正常运行（不能不能跑，而是会报错），原因在于会非法访问，需要在bare-mental上运行，要创建一个镜像文件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">( cat abstract-machine/am/src/x86/qemu/boot/mbr \</span><br><span class="line">  head -c 1024 /dev/zero \</span><br><span class="line">  cat build/hello-x86_64-qemu.o ) \</span><br><span class="line"><span class="meta prompt_">  &gt; </span><span class="language-bash">/tmp/hello/build/hello-x86_64-qemu</span></span><br></pre></td></tr></table></figure><p>镜像由一个512字节的MBR（主引导记录），1024字节的空文件和hello-x86_64-qemu.o组成</p><p>这里提一下qemu的含义：QUEM（QuickEmulator）是一款开源的模拟器和虚拟机监视器，支持模拟多种体系结构（包括x86、ARM、MIPS 等）以及在不同操作系统上运行。</p><p>启动qemu的方式：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">qemu-system-x86_64 -hda your_disk_image.img </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">后面某个磁盘映像</span></span><br></pre></td></tr></table></figure><h4 id="加载-1">加载</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">qemu-system-x86_64 -S -s -serial none -nographic hello-x86_64-qemu</span></span><br></pre></td></tr></table></figure><p>这也是在启动镜像文件，其中加了不少参数，具体含义：</p><p><code>-S</code>：在模拟器初始化完成（CPU Reset）后暂停</p><p><code>-s</code>：启动gdb调试服务</p><p><code>-serial none</code>：忽略串口输入输出</p><p><code>-nographic</code>：不启动图形化界面</p><h5 id="cpu-reset">CPU Reset</h5><p>运行完成后采用<code>info registers</code>查看寄存器状态。这里关心两个状态：</p><ul><li><p><code>CR0=60000010</code>：先解释CR0是个什么玩意（<del>毕竟我也不知道</del>），CR0是x86架构中的控制寄存器，是控制处理器行为的一个寄存器，关键位有：</p><table><colgroup><col style="width: 37%" /><col style="width: 11%" /><col style="width: 50%" /></colgroup><thead><tr class="header"><th>关键位</th><th>位置</th><th>作用</th></tr></thead><tbody><tr class="odd"><td>PE（Protection Enable）</td><td>最低位</td><td>PE=1时为保护模式 PE=0时为实模式</td></tr><tr class="even"><td>MP（Monitor Coprocessor）</td><td>通常不用</td><td>控制是否启用监视协处理器监视</td></tr><tr class="odd"><td>EM（Emulation）</td><td></td><td>控制x87浮点指令</td></tr><tr class="even"><td>TS（Task Switched）</td><td></td><td>任务切换位</td></tr><tr class="odd"><td>ET（Extension Type）</td><td></td><td>用于标识处理器支持的浮点单元类型</td></tr><tr class="even"><td>NE（Number Error）</td><td></td><td>浮点异常</td></tr></tbody></table></li><li><p><code>%cs = 0xf000</code>,<code>%ip = 0xfff0</code>,相当于PC指针位于<code>0xfff0</code></p><p>这里还是得解释：</p><p><code>CS</code>寄存器标识的是代码段寄存器，根据内存分段式存储的原理，这里存储的代码的起始地址，那么我们猜一猜也能猜出这个<code>IP</code>(instructionpoint)实际上代表的就是偏移量，因此能够算出实际的<code>PC=CS+IP</code>（此处需要做一个逻辑扩展，当然算数扩展也无所谓），<del>死去的组成原理和操作系统疯狂攻击</del></p></li></ul><h5 id="firmware加载master-boot-record">Firmware：加载Master BootRecord</h5><p>下面会相对亲切一点，这就是操作系统启动的过程</p><ol type="1"><li>CPU从一个特定主存地址（BIOS中断向量，这个东西就是我们上面刚才算出的PC）开始，取指令，执行ROM中的引导程序，这里会进行硬件自检</li><li>读入主引导记录（Master BootRecord），执行磁盘引导程序，扫描分区表</li><li>从主分区（活动分区）读入分区引导记录，执行程序</li><li>从根目录下找到操作系统初始化程序并执行</li></ol><h5 id="boot-loader解析并加载-elf-文件">Boot Loader：解析并加载 ELF文件</h5><p>这块属实看太不懂，总结一手就是我们通过某种程序将我们要运行的ELF文件加载到了MBR，并通过启动操作系统的类似的方法，成功将程序放入了内存</p><h3 id="总结">总结</h3><p>这下是确实深入了解操作系统了，我们通过阅读这个在裸机上的如何实现一个C语言程序的运行，比较透彻的理解了C语言的编译链接，以及具体在启动过程中的一些细节，最重要的是，理解操作系统实际上建立在一个AbstractMachine上的一个程序，在链接程序时表现的尤其明显。（这里有大量细节推荐去看老师的课程主页，链接贴在下面了，点查看原文可看）</p><h3 id="参考链接">参考链接</h3><p><a href="https://jyywiki.cn/AbstractMachine/AM_Programs.html">为Bare-Metal 编程：编译、链接与加载 (jyywiki.cn)</a></p><p>感谢chatGPT的友情回答（<del>麻木.jpg</del>）</p>]]></content>
      
      
      
        <tags>
            
            <tag> 搓OS.log </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>搓OS-day1</title>
      <link href="/2024/01/09/%E6%90%93OS-day1/"/>
      <url>/2024/01/09/%E6%90%93OS-day1/</url>
      
        <content type="html"><![CDATA[<h2 id="手搓os-day1">手搓OS-day1</h2><p>今天进入正式开搓的阶段（<del>霉比</del>maybe），今天比较大的阻碍还是代码障碍比较大，需要回顾和总结大量的基础，所以会显得人比较菜（其实就是菜），还有一个比较好的调试方式。然后就是对老师口中的玩具的分析（==<del>好难玩的玩具</del>==），从中结合我们学过的基本的操作系统的知识进行结合，体会其中状态机和程序的概念。</p><h3 id="python部分">Python部分</h3><h4 id="generator函数生成器">Generator（函数生成器）</h4><p>其中的重要关键字<code>yield</code>（生产，生成的意思<del>考研词汇</del>），代码运行到<code>yield</code>关键字后会自动保存</p><p>一个弯弯绕的小栗子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">number_generator</span>():</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        a=i+<span class="number">10</span></span><br><span class="line">        <span class="keyword">yield</span> a</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_generator</span>():</span><br><span class="line">    f=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        a=i+<span class="number">10</span>+f</span><br><span class="line">        <span class="built_in">print</span>(a)</span><br><span class="line">        f=<span class="keyword">yield</span> a</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    generator_1=number_generator() <span class="comment"># 接收生成器对象</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        <span class="built_in">print</span>(generator_1.__next__())</span><br><span class="line">    </span><br><span class="line">    generator_2=add_generator()</span><br><span class="line">    <span class="comment"># 直接调用next</span></span><br><span class="line">    <span class="built_in">next</span>(generator_2)</span><br><span class="line">    <span class="comment"># 采用send方式</span></span><br><span class="line">    generator_2.send(<span class="number">10</span>)  <span class="comment">#  按道理这里应该是11，但通过send函数改变f的值后变为21</span></span><br></pre></td></tr></table></figure><p>另外第一次启动生成器是不能使用send方法，会报错：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TypeError: can&#x27;t send non-None value to a just-started generator</span><br></pre></td></tr></table></figure><p>对此有两种解决方案： ① 第一次启动是使用<code>next()</code>函数</p><p>② 第一次传入<code>send()</code>的值为<code>None</code></p><h4 id="match函数">match函数</h4><p>match语句是 Python 3.10中引入的一种结构模式匹配的特性，允许在数据结构中匹配复杂的模式。基本形式如下（==这个真挺好用的==）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">match a,args:</span><br><span class="line">case <span class="string">&quot;haha&quot;</span>,xs:</span><br><span class="line">        <span class="built_in">print</span>(xs)</span><br><span class="line">    case <span class="string">&quot;lala&quot;</span>,(f,args):</span><br><span class="line">        .....</span><br></pre></td></tr></table></figure><p>有一些接受函数返回参数的技巧：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">syscall,args,*_=self._func.send(self.retval)</span><br></pre></td></tr></table></figure><p><code>*_</code>和<code>_</code>可以有效的扔掉不想要的变量，保留有效变量</p><h4 id="运算符">:= 运算符</h4><p><code>:=</code>运算符是Python3.10中的新特性，提供在赋值的同时并运算：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">t:=<span class="number">1</span>+<span class="number">2</span></span><br><span class="line"><span class="comment"># 等价于</span></span><br><span class="line">t=<span class="number">1</span></span><br><span class="line">t+<span class="number">2</span></span><br></pre></td></tr></table></figure><h4 id="exec-函数">exec 函数</h4><p>exec函数是Python标准库中的函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">exec</span>(<span class="built_in">str</span>,variables)</span><br></pre></td></tr></table></figure><p><code>str</code>是一段代码，<code>exec</code>执行该段代码，将运行后的函数接口传递到variable字典</p><p>一个小栗子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">code = <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">def greet(name):</span></span><br><span class="line"><span class="string">    print(f&quot;Hello, &#123;name&#125;!&quot;)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">greet(&quot;John&quot;)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行字符串中的代码</span></span><br><span class="line"><span class="built_in">exec</span>(code)</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建一个全局字典，以方便调用</span></span><br><span class="line">globals_dict = &#123;&#125;</span><br><span class="line"><span class="built_in">exec</span>(code, globals_dict)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从 globals_dict 中获取 greet 函数</span></span><br><span class="line">greet_func = globals_dict[<span class="string">&#x27;greet&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用 greet 函数</span></span><br><span class="line">greet_func(<span class="string">&quot;111&quot;</span>)</span><br></pre></td></tr></table></figure><h4 id="sys包">SYS包</h4><p>sys，就是system的简写，秉承着用多少学多少的理念我们先补一点，以后遇到了再补（<del>懒狗</del>）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sys.avg <span class="comment">#读取命令行中参数</span></span><br><span class="line"><span class="comment">#此外还有常用的path，先摆了</span></span><br></pre></td></tr></table></figure><h3 id="gdb">GDB</h3><p>还是秉承用多少学多少，gdb是一种命令行调试工具，那就意味着没有IDE要用命令行打断点。</p><p>可以类比使用IDE的debug，程序在debug的模式下运行，同理在用gdb调试时也就要在gdb模式下调试，步骤如下：</p><ol type="1"><li>编译要调试的代码：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -g -o tst tst.c</span><br></pre></td></tr></table></figure><p>这里要提的是，<code>-g</code>使得能够在栈帧中查看代码和对应行号，具体对于栈帧的描述可以去查一下内存的虚拟映射，</p><ol start="2" type="1"><li>在gdb下运行：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gdb ./tst</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240109185527196.png" alt="运行结果" style="zoom:67%;" /></p><ol start="3" type="1"><li>然后就可以用gdb指令进行调试了，下面罗列指令并且给出执行效果</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看代码</span></span><br><span class="line">list</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">或者</span></span><br><span class="line">l</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240109185757649.png" alt="ls查看代码" style="zoom:67%;" /></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">运行</span></span><br><span class="line">run </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">或者</span></span><br><span class="line">r</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240109185933173.png"alt="运行" /><figcaption aria-hidden="true">运行</figcaption></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">打断点</span></span><br><span class="line">break n # n为行号 或者用</span><br><span class="line">b n</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看断点</span></span><br><span class="line">info b</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">禁用断点</span></span><br><span class="line">disable b</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">重新启用</span></span><br><span class="line">enable b</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">执行下一条指令，但不进入函数体</span></span><br><span class="line">next # 或者</span><br><span class="line">n</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">进入函数体</span></span><br><span class="line">step</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">监视变量值</span></span><br><span class="line">print # 或者</span><br><span class="line">p</span><br></pre></td></tr></table></figure><p>剩下的功能用到再学（<del>咕咕</del>）</p><h3 id="vscode的一种调试方式">VScode的一种调试方式</h3><p>因为要运行一个类似这样的指令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python os-model.py hello.py</span><br></pre></td></tr></table></figure><p>才能运行整个程序，所以这给调试带来了困扰，因为我并不知道如何在debug的同时输入命令行，这里我想到了两个解决方案：</p><p>①通过再写一个Python文件，通过os包执行指令就可以打上断点（<del>天才</del>），结果就是路径始终对不上</p><p>② 如下：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240109191717359.png" alt="添加配置" style="zoom:67%;" /></p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240109191821830.png" alt="添加参数args" style="zoom:67%;" /></p><p>这个args就代表的是命令中的参数</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python xx.py paramter</span><br></pre></td></tr></table></figure><p>于是就可以顺利调试了。</p><h3 id="os玩具模型">OS玩具模型</h3><p>这里还是简单画个图：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240109193054392.png" alt="OS模型" style="zoom:67%;" /></p><p>简单解释一下，step提供了一个获取运行线程的下一步指令的功能，而run函数提供了一个将下一步指令转化为机器指令（可执行）的功能，而run中也就提供了各种系统调用的接口：比如随机切换线程，线程休眠，读写调用等等。</p><p>在实现中采用了一个很精妙的方法，通过对待运行文件的内容读取，并修改其中的系统调用为一个生成器函数，转入OS系统的栈中存储函数入口，然后通过OS运行就得到了运行结果（妙啊~），这里建议大家去看看代码。</p><p>Makefile先不写了，用到再写（<del>咕咕</del>）</p><h3 id="参考链接">参考链接</h3><hr /><p>今日无</p>]]></content>
      
      
      
        <tags>
            
            <tag> 搓OS.log </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>搓OS-day0</title>
      <link href="/2024/01/08/%E6%90%93OS-day0/"/>
      <url>/2024/01/08/%E6%90%93OS-day0/</url>
      
        <content type="html"><![CDATA[<h2 id="手搓os-day0">手搓OS-day0</h2><p>今天，俺开了一个新的巨坑，我要手搓一个操作系统的模拟，主要参考的是南京大学的蒋老师的课程，最后附课程链接（需要的同学点查看原文即可看到链接），目前已经上手两天，嗯，怎么评价呢，很难，这个新坑也主要是记录我的心路历程和中间遇到的一些问题，因为涉及的技术奇多无比，其中有许多我不掌握的语法，因此可能会显得比较啰嗦。</p><p><strong>day0</strong>主要做的都是准备工作，但是准备工作也相当难做，下面简单记录一下：</p><h3 id="配置一台linux机器">配置一台Linux机器</h3><p>已经头大了开始，这次配置因为服务器到期了，于是选择了一个很新的配置方式：WSL</p><p>WSL全名是Windows Subsystem ForLinux（大概是，意思应该是对的），也就是Windows自带的一个子系统，同时兼容了Windows与Linux，好处就是切换自由，占用资源少，缺点就是稍微慢一点（但是也无所谓其实，毕竟我们不需要超级高的响应速度，能动就行）。</p><p>大概的配置流程不是很复杂（真的吗？）：</p><ol type="1"><li>启用Windows中的WSL服务（在管理员模式下的powershell中运行）</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart</span><br></pre></td></tr></table></figure><ol start="2" type="1"><li>启动虚拟化</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart</span><br></pre></td></tr></table></figure><ol start="3" type="1"><li>下载WSL2并安装【<ahref="https://wslstorestorage.blob.core.windows.net/wslblob/wsl_update_x64.msi">链接</a>（点了就会自动下载哦，阅读原文可以点链接）】</li><li>设置默认版本为WSL2</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wsl --set-default-version 2</span><br></pre></td></tr></table></figure><ol start="5" type="1"><li>从应用商店下载Ubantu，如下：</li></ol><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240108232817639.png" alt="应用商店" style="zoom:50%;" /></p><ol start="6" type="1"><li>安装后直接运行，根据提示设置账号密码</li><li>设置root密码：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo passwd</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240108233254220.png" alt="终端界面" style="zoom:67%;" /></p><ol start="8" type="1"><li>如果不考虑图形化界面的话（<del>图形化界面崩溃了</del>），到这里基本就Ok了，然后就是连接Vscode，基本不需要怎么配置直接在终端运行即可：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">code.</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20240108233413032.png" alt="接入VScode" style="zoom:67%;" /></p><h3 id="配置anaconda">配置Anaconda</h3><p>习惯上为了有一个舒适的Python的环境体验，还是配置了一个Anaconda，这里要记录一下拉取方式的Anaconda下载方式：</p><ol type="1"><li>拉取下载</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-5.3.1-Linux-x86_64.sh</span><br></pre></td></tr></table></figure><p>或者采用下面的源</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-2023.07-2-Linux-x86_64.sh</span><br></pre></td></tr></table></figure><ol start="2" type="1"><li>运行安装</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash Anaconda3-5.3.1-Linux-x86_64.s</span><br></pre></td></tr></table></figure><p>无脑同意，小心不要跳过太多。</p><ol start="3" type="1"><li>配置路径（这步貌似不做也没啥问题）</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">打开配置文件</span></span><br><span class="line">sudo gedit ~/.bashrc</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">最后一行添加路径</span></span><br><span class="line">export PATH=&quot;/home/用户名/anaconda3/bin:$PATH&quot;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">保存后更新</span></span><br><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure><h3 id="c与c-简单配置">C与C<sup>++</sup> 简单配置</h3><p>为了能跑C和C<sup>++</sup> 的代码，要简单配置一下二者的编译环境</p><p>C语言（配置好后也就是gcc编译，之前的文章有提过）：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install build-essential</span><br></pre></td></tr></table></figure><p>C<sup>++</sup> 环境：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install g++</span><br></pre></td></tr></table></figure><p>实际上g++貌似并不怎么用，在VScode里有gcc就够了，后边还有调试断点用的GDB，有点复杂（<del>还没看完</del>明天再写）,虽然但是这些东西都是一月七号做的（），明天再写今天的工作。</p><h3 id="参考链接">参考链接：</h3><p>[1] <ahref="https://blog.csdn.net/dally2/article/details/108206234">【Linux系统下载Anaconda3】_anacondalinux下载-CSDN博客</a></p><p>[2] <ahref="https://www.cnblogs.com/dwingzone/p/12619781.html">实验四Linux系统搭建C语言编程环境 - Dwingzone - 博客园 (cnblogs.com)</a></p><p>[3] <ahref="https://zhuanlan.zhihu.com/p/386590591">史上最全的WSL安装教程 -知乎 (zhihu.com)</a></p><p>[4] <ahref="https://jyywiki.cn/OS/2023/index.html">操作系统：设计与实现 (2023春季学期) (jyywiki.cn)</a></p><p>[5] <ahref="https://zhuanlan.zhihu.com/p/409547049">WSL+VSCode食用指南 - 知乎(zhihu.com)</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 搓OS.log </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux常用命令</title>
      <link href="/2024/01/06/linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
      <url>/2024/01/06/linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<h2id="linux常用命令以及备忘自用略乱">linux常用命令以及备忘（自用略乱）</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">命令格式：命令[-选项][参数]</span><br></pre></td></tr></table></figure><p>选项：操作、参数：对象</p><h3 id="文件相关">文件相关</h3><h4 id="vim">vim</h4><p>ESC：退出编辑模式</p><p>i：进入编辑</p><p>:q 退出vim</p><p>:w 写回</p><p>:wq 写回并退出vim</p><p>vim filename.type 创建文件</p><h4 id="mkdir">mkdir</h4><p>创建文件夹</p><h4 id="cd">cd</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd .. #回到上一层</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /目录 #打开某文件夹</span><br></pre></td></tr></table></figure><h4 id="ls">ls</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls #显示当前目录下的所有文件名</span><br></pre></td></tr></table></figure><h4 id="mv">mv</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv oldname.txt newname.txt #改名</span><br></pre></td></tr></table></figure><p>但也具有功能移动</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv hello.txt hello # 文件 + 目录</span><br></pre></td></tr></table></figure><h4 id="cp">cp</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp -rp[原文件或目录][目标目录]  # -r 复制目录 -p 保留文件属性</span><br></pre></td></tr></table></figure><h4 id="cat">cat</h4><h3 id="gcc命令">gcc命令</h3><h3 id="g命令">g++命令</h3>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>图神经网络——gnn</title>
      <link href="/2023/09/03/gnn/"/>
      <url>/2023/09/03/gnn/</url>
      
        <content type="html"><![CDATA[<h1 id="图神经网络gnn初步">图神经网络——GNN初步</h1><h2id="最简单的图神经网络着眼于节点">最简单的图神经网络——着眼于节点</h2><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/%E9%A1%B5-1(2).png"alt="页-1(2)" /><figcaption aria-hidden="true">页-1(2)</figcaption></figure><p>这张图就挺清楚了，但是我们还有一些问题没有说清楚，数据是什么，数据在哪儿，数据怎么运算，目的是什么</p><p>从派别上，更像是频率派，实际上是在分析各个节点之间的一个关系。</p><h3 id="target节点嵌入隐状态h_v">target：节点嵌入(隐)状态（<spanclass="math inline">\(h_v\)</span>）</h3><h3 id="数学表达">数学表达：</h3><p>节点邻居：</p><ul><li>点集：<span class="math inline">\(co[v]\)</span></li><li>边集：<span class="math inline">\(ne[v]\)</span></li></ul><p>节点嵌入：<span class="math inline">\(x_v\)</span></p><p>输出嵌入：<span class="math inline">\(o_v\)</span></p><p>局部转移函数： <span class="math display">\[h_v=f(x_v,x_{co[v]},h_{ne[v]},x_{ne[v]})\]</span> 局部输出函数： <span class="math display">\[o_v=g(h_v,x_v)\]</span> 学习方法：梯度下降 <span class="math display">\[loss=\sum_{i=1}^{p}{(t_i-o_i)}\]</span> p是所有的目标节点的数目</p><h3 id="缺点">缺点</h3><p>缺点实际上是相当显然的</p><ol type="1"><li>缺乏对边的学习</li><li>传递效率低</li><li>梯度消失</li><li>多次迭代后点的值是固定的、平滑的，fixednode，导致整个图的区分意义不大</li></ol><h2 id="gcn着眼全图">GCN——着眼全图</h2><h3 id="傅里叶变换">傅里叶变换</h3><p>通俗来讲，我们平时见到的连续可导函数，都是建立在时域，傅里叶变换就要要将他变换到频域</p><p>那么频域又是什么东西？</p><p>频域首先要有频率，那么是什么出现的频率，比如是周期函数才有频率，最经典的周期函数正是三角函数，傅里叶很开创的搞出来了所有的函数都可以用三角函数来分解的一个变换，就是傅里叶变换。</p><p>空间域：空域，又称图像空间，说白了就是像素级处理。</p><h3 id="图谱理论">图谱理论</h3><h4 id="拉普拉斯算子">拉普拉斯算子</h4><p>一个多元函数的所有二阶偏导数 <span class="math display">\[\Delta f=\sum^{n}_{i}{\frac{\part^2 f }{\part x_i^2}}\]</span> 考虑一个二元函数<spanclass="math inline">\(f(x,y)\)</span>，则拉普拉斯算子可以表示为： <spanclass="math display">\[\Delta f=\frac{\part^2f}{\part x^2}+\frac{\part^2f}{\part y^2}\]</span> 可以从单侧差分公式中有： <span class="math display">\[\Delta f \approx \frac{f(x+\Delta x,y)+f(x-\Delta x,y)-2f(x,y)}{(\Deltax)^2}+\frac{f(x,y+\Delta y)+f(x,y-\Delta y)-2f(x,y)}{(\Delta y)^2}\]</span> 对二元函数离散化采样： <span class="math display">\[\begin{bmatrix}  f(x_1,y_1)&amp;f(x_2,y_1)  &amp;\cdot\cdot\cdot  &amp; f(x_n,y_1)\\   f(x_1,y_2)&amp; f(x_2,y_2)  &amp;\cdot\cdot\cdot  &amp;f(x_n,y_2) \\\cdot\cdot\cdot&amp;\cdot\cdot\cdot  &amp;\cdot\cdot\cdot  &amp;\cdot\cdot\cdot \\  f(x_1,y_n)&amp; f(x_2,y_n)  &amp;\cdot\cdot\cdot  &amp;f(x_n,y_n)\end{bmatrix}\]</span> 令<span class="math inline">\(\Delta x=x_{i+1}-x_i=1,\Deltay=y_{i+1}-y_i=1\)</span></p><p>则点<spanclass="math inline">\((x_i,y_i)\)</span>的laplace算子可以如下公式近似计算：<span class="math display">\[\frac{f(x_i+\Delta x,y_i)+f(x_i-\Delta x,y_j)-2f(x_i,y_j)}{(\Deltax)^2}+\frac{f(x_i,y_j+\Delta y)+f(x_i,y_j-\Delta y)-2f(x_i,y_j)}{(\Deltay)^2}\]</span></p><p><span class="math display">\[=\frac{f(x_{i+1},y_j)+f(x_{i-1},y_j)-2f(x_i,y_j)}{1^2}+\frac{f(x_i,y_{j+1})+f(x_i,y_{j-1})-2f(x_i,y_j)}{1^2}\]</span></p><p><span class="math display">\[=f(x_{i+1},y_j)+f(x_{i-1},y_j)+f(x_i,y_{j+1})+f(x_i,y_{j-1})-4f(x_i,y_j)\]</span></p><p>于是他就变成了一个离散的一个中心和四个相邻节点的图的结构，将laplace算子离散化表示：<span class="math display">\[\Delta f=\sum_{(k,l)\in N(i,j)}^{}{(f(x_k,y_l)-f(x_i,y_j))}\]</span> 很惊喜的发现，卷积出现了！</p><p><ahref="https://zhuanlan.zhihu.com/p/81502804">谱聚类方法推导和对拉普拉斯矩阵的理解- 知乎 (zhihu.com)</a></p><h4 id="laplace-矩阵">laplace 矩阵</h4><p>有无向图<span class="math inline">\(G=（E,V）\)</span>,<spanclass="math inline">\(V\)</span>有n个节点，邻接矩阵为W，加权度矩阵D，将lapace算子扩展到图上：<span class="math display">\[\Delta f_i=\sum_{j \in N_i}{w_{ij}(f_i-f_j)}\]</span> 那么我们可以改写成矩阵形式： <span class="math display">\[\Delta f=\begin{bmatrix}\Delta f_1 \\\cdot \cdot \cdot \\\Delta f_n \\\end{bmatrix}=\begin{bmatrix}d_1f_1-w_1f \\\cdot \cdot \cdot \\d_nf_n-w_nf\\\end{bmatrix}=\begin{bmatrix}d_1 &amp;&amp; &amp;&amp; \\&amp;&amp; \cdot \cdot \cdot&amp;&amp;\\&amp;&amp; &amp;&amp;d_n\\\end{bmatrix}\begin{bmatrix}f1 \\\cdot \cdot \cdot \\f2\\\end{bmatrix}-\begin{bmatrix}w_1\\\cdot \cdot \cdot \\w_2\\\end{bmatrix}\begin{bmatrix}f_1\\\cdot \cdot \cdot \\f_2\\\end{bmatrix}\]</span></p><p><span class="math display">\[=\mathbf{(D-W)f}\]</span></p><p>那么就有laplace矩阵 <span class="math display">\[\mathbf{L}=\mathbf{D-W}\]</span> 性质：</p><ol type="1"><li>对任意向量<span class="math inline">\(f \in\mathbb{R^n}\)</span>，有<span class="math inline">\(\mathbf{f^TLf}=\frac{1}{2}\sum_{i=1}^{n}{\sum_{j=1}^{n}{w_{ij}(f_i-f_j)^2}}\)</span></li><li>laplace矩阵时半正定矩阵</li><li>laplace矩阵的最小特征值为0，其对应的特征向量常向量1，级所有分量为1</li><li>laplace矩阵有n个非负实数特征值。</li></ol><h4 id="归一化laplace矩阵">归一化laplace矩阵</h4><p>对称归一化： <span class="math display">\[L=D^{-1/2}LD^{-1/2}=I-D^{-1/2}WD^{-1/2}\]</span> 随机漫步归一化： <span class="math display">\[L_{rw}=D^{-1}L=I-D^{-1}W\]</span></p><h3 id="谱网络到gcn">谱网络到GCN</h3><p>谱网络通过对归一化laplace进行特征分解在频域上建立了卷积核： <spanclass="math display">\[g_{\theta} *x=Ug_{\theta}(\Lambda) U^Tx\]</span> 其中<spanclass="math inline">\(U\)</span>是对称归一化的laplace矩阵进行特征值分解后的特征向量，<spanclass="math inline">\(\Lambda\)</span>是相对应的特征值</p><p>很显然此运算极其复杂，包括一个很大的矩阵函数，而且卷积核规模受限，因此引入了多项式进行逼近截断：<span class="math display">\[g_{\theta}(\Lambda)\approx \sum_{k=0}^{K}{\theta_k \Lambda^k}\]</span> ChebNet引入了切比雪夫多项式 <spanclass="math inline">\(T_k\)</span>对 <spanclass="math inline">\(g_\theta\)</span>进行拟合。切比雪夫多项式有个重要性质: <span class="math display">\[T_n(cos(\theta))=cos(n\theta)\]</span> <imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230905113021320.png"alt="image-20230905113021320" /></p><p><spanclass="math inline">\(\tilde{\Lambda}=2\frac{\Lambda}{\lambda_{max}}-I\)</span>，那么卷积核就转化为：<span class="math display">\[g_{\theta} *x=\sum_{k=0}^{K}{\theta_K^`UT_{k}(\tilde \Lambda) U^Tx}\]</span> 令K=1，则 <span class="math display">\[g_{\theta} *x=\sum_{k=0}^{1}{\theta_K^`UT_{k}(\tilde \Lambda)U^Tx}=\theta_0x+\theta_1(\frac{2}{\lambda_{max}}L-I_N)x\]</span> 由于正则化后的拉普拉斯矩阵特征值最大不超过2，令<spanclass="math inline">\(\lambda_{max}=2\)</span> <spanclass="math display">\[g_{\theta} *x=\theta_0x+\theta_1(\frac{2}{\lambda_{max}}L-I_N)x=\theta_0x+\theta_1(L-I_N)x\]</span> 又因为： <span class="math display">\[L=D^{-1/2}LD^{-1/2}=I-D^{-1/2}WD^{-1/2}\]</span> 因此： <span class="math display">\[g_{\theta} *x=\theta_0x-\theta_1D^{-1/2}WD^{-1/2}x\]</span> 令<spanclass="math inline">\(\theta=\theta_0=-\theta_1\)</span>，共享参数得：<span class="math display">\[g_{\theta} *x\approx\theta(I_N-D^{-1/2}WD^{-1/2})x=\theta(D^{-1/2}\tildeWD^{-1/2})x\]</span> 堆叠卷积层，并进行重整化（或者叫重正则化）： <spanclass="math display">\[H^{(l+1)}=\sigma(\mathbf{\tilde {D}^{-1/2}\tilde {A}\tilde{D}^{-1/2}H^{(l)}W^{(l)} })\]</span></p><p>over</p><h3 id="空间方法">空间方法</h3><h4 id="neural-fps">neural FPS</h4><p><span class="math display">\[x=h_v^{t-1}+\sum_{i=1}^{|N_v|}{h_i^{t-1}} \\h_v^t=\sigma(xW_t^{|N_v|})\]</span></p><p>还是简单介绍一下，h是节点嵌入或者叫隐层状态，w是某个节点有多少个邻居的权重</p><h4 id="patchy-san">PATCHY-SAN</h4><ol type="1"><li>节点序列选择</li><li>选择邻居节点作为感受野，共选择k个</li><li>图标准化，为感受野节点排序，映射到向量空间</li><li>采用CNN架构进行卷积运算</li></ol><h4 id="dcnn">DCNN</h4><p>扩散卷积神经网络，用于节点分类： <span class="math display">\[\mathbf{H}=\sigma(\mathbf{W^c} \odot P*X)\]</span></p><h4 id="dgcn">DGCN</h4><p>dual graph convolutional network（DGCN），</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230905123536601.png"alt="image-20230905123536601" /><figcaption aria-hidden="true">image-20230905123536601</figcaption></figure><p>网络架构如上，上面一层采用了最基本的GCN来做运算，在下一层用PPMI矩阵P代替正则化邻接矩阵。其目的是为了统合局部一致性和全局一致性。</p><p>PMI是一种来衡量两种事物之间相似性的指标： <spanclass="math display">\[PMI(x,y)=ln\frac{p(xy)}{p(x)p(y)}\]</span> 令不相关和负相关的PMI值都为0，即得矩阵<spanclass="math inline">\(P\)</span></p><p>这是一个很巧妙的构思，实际上将其转变成了一个很经典的loss函数，可以应用各种正则化技巧。</p><h4 id="lgcn">LGCN</h4><p>learnable graph convolution networks</p><p>这个网络是基于可学习网络卷积层和子图训练策略</p><p>可学习网络卷积层，利用CNN作为聚合器，通过邻接矩阵获得前k个特征元素，然后利用一维CNN计算隐层：<span class="math display">\[\hat{H}_t=g(H_t,A,k)\\H_{t+1}=c(\hat{H}_t)\]</span> 其中<spanclass="math inline">\(g(\cdot)\)</span>函数为获取特征元素</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230905151902605.png"alt="image-20230905151902605" /><figcaption aria-hidden="true">image-20230905151902605</figcaption></figure><h2 id="挑战">挑战：</h2><p>如果从股票价格入手，难以构造一个图，其次如何构造一个动态的图，如何有GNN来学习这个动态的图，都很具有挑战性</p>]]></content>
      
      
      
        <tags>
            
            <tag> 图神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>信管专业指南</title>
      <link href="/2023/08/11/xgGuide/"/>
      <url>/2023/08/11/xgGuide/</url>
      
        <content type="html"><![CDATA[<h1 id="信管专业指南">信管专业指南</h1><blockquote><p>更新记录：</p><p>8.14 补充学姐的说法，更新课程介绍</p><p>8.16 修正部分更换信息，完成课程介绍</p><p>8.22 科创嗯写</p></blockquote><blockquote><p>千万别外传，学长还想要毕业证（</p></blockquote><p>信息管理与信息系统是管理科学与工程的二级学科，授予管理学学术学位。</p><blockquote><p><strong><em>最重要的事情</em></strong></p></blockquote><p>一定要找清楚自己的路，明白自己的道，说白了就是要明白自己想干什么，这是很难的，要对自己的未来做好规划。</p><h2 id="专业学习">专业学习</h2><p>专业学习部分我们要先整体后局部的认识，现有一个大概的认识，我们再细说。</p><p>这里我们只讲专业课或者叫专业基础课，什么思政课我们就不细说了，一会儿会在老师介绍（学生视角）里提一下。</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/%E9%A1%B5-1(1).png"alt="页-1(1)" /><figcaption aria-hidden="true">页-1(1)</figcaption></figure><h3id="专业方向并不固定可以自己开发">专业方向（并不固定，可以自己开发）</h3><p>肉眼可见的几个方向啊：</p><ol type="1"><li><p>信息系统开发，这里有几个层次：</p><p>① 一般管理信息系统，基本已经被淘汰了</p><p>② 决策支持系统，定义极其宽泛，因此没法说他被淘汰了</p><p>③ AI or 大数据系统，比较火的东西</p></li><li><p>金融工程师，正在摸索的一个就业方向，难度较高，管培生和金融方向门槛高，必须得整个好学校的研究生（量化岗和头部券商基本上咱学校基本上是卷不上，可以不在这个路线上花费太多精力<img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/18B4C9C0.png" alt="18B4C9C0" style="zoom:33%;" />)</p></li><li><p>管理方向，包括但不限于产品经理、产品运营、人力资源、市场营销等等</p></li><li><p>自己找方向，包括但不限于硬件开发、算法、科研等等</p></li></ol><h3 id="课程联系">课程联系</h3><p>简单介绍一下课程之间的联系，数学相关的课程是三门AI课程相关的重要基础，基本开发上JAVA和数据库是大部分开发的基础。后面都是对开发的一些延拓。</p><p>这里特别提一下系统工程，系统工程是很管理的一门课，但是准确来说是管理科学工程的一个入门，这是一门学术引路的课程，他会引导你进入管理科学的学术世界。</p><h3 id="专业利弊">专业利弊</h3><p>虽然说既来之则安之，但是我们要知己知彼，才能百战百胜。</p><p>优势：相比于计算机科学我们更像是国外的软件工程。，我们在软件业的晋升是非常顺畅的，但是国内的软件业貌似对于晋升并不是很感冒；老师对热点把握会很准，考研可选择性很大。</p><p>缺点：大部分老师都不大行，不专精，要自己选择专精哪个方向，人话，要自学。</p><h3 id="教师介绍说真话">教师介绍（说真话）</h3><p>丁斌：你们最先接触到的专业老师，负责的课为面向对象开发、数据结构、Javaweb；最大特征就是：<strong>摆</strong>，如果你听不懂他讲课那就对了，他确实讲不明白，因此这三门课要努力自学，自己开悟；因为这三门课都是比较重要的，好在db（简称）的期末命题思路非常简单，就是你平时做的题，<strong><em>基本上所有的期末考试题目都来源于作业题库和实验题库</em></strong>，所以只要你肯卷卷，拿个高分还是不难的。</p><p>赵萌：非常好的一个老师，很专业，目前学校里做学术做的比较好的老师，<strong>组里会收本科生</strong>，主要研究方向是一些先进数学方法、计算机算法在管理科学上的应用，<strong>如果你有保研或者学术想法可以大二就去赵老师的组里去跟着老师读论文</strong>。教授的课程为系统工程，我认为这是一个学术启蒙的课程，老师会告诉你最简单的学术究竟是什么，老师很严格，上课很有激情（嗓门很大）。</p><p>蒋学英：老师人也还可以，负责的课程是计算机操作系统、认识实习、信息系统开发与管理，<strong>上课事情比较多</strong>，会有很频繁的签到、作业，而且作业的要求也很多，<strong>作业想拿高分有时候还要别出心裁</strong>（一会儿在课程介绍里细说）。</p><p>王军：<strong>脾气比较怪的老师，如果你和打好关系他会分数给的不错</strong>，至少不难看（，负责的课程：运筹学、金融学、数学建模、R语言与量化金融，我个人认为他运筹学和金融学教的还凑合，其他真不行，网课的效果要比线下好，线下讲课他会吐字不清，（R语言与量化金融很多年没开出来了，所以也不知道他教的怎么样），数学建模教的是真的不行，完全不懂数学（）。</p><p>计网老师换了，我不知道咋样（</p><p>赵煜辉：我比较喜欢的一个老师，非常严格，会在大三开一个组（专门给本科生），主要研究量化金融或者nlp工作，<strong>平时的研究生组里也是收本科生的</strong>。负责的课为三门AI以及数据分析相关的课程，课程难度较大，涉及程序设计和数学算法推导，如果能跟下来会有很大的进步。</p><p>程雪：老师人还行，也是主打摆烂的老师。负责的课程内容为：决策支持系统，我不好评价，我感觉这个课确实没啥大用，是一个介绍性课程，学不到太多新东西。</p><p>王素欣：大好人，负责供应链管理课程，主打一个摆大烂，考试极其简单，是教机械和供应链方面的，供应链管理这门课讲的内容不太硬核，但是考试真的不好拿高分呀，大家小心</p><p>孙建勇：孙建勇老师，教的很好很实用，是工业工程方向的，教的课叫做erp</p><p>黄亮：专业主任，负责课程：数据库系统概论、大数据开发技术、专业实习，大好人，除了数据库会挂人，其他的都基本不会，是实实在在的大好人，考试会精准的给你画重点，就是可能你把握不住（哭）。</p><h3 id="课程介绍">课程介绍</h3><blockquote><p><strong>大二上学期</strong></p></blockquote><p>概率论与数理统计：重在理解，未来在机器学习与统计学习中概率论将发挥他强大的力量。多做做往年题，要比高数线代简单的多。</p><p>大学物理：是两门课，分别是力学和电磁学，难度不大，用途没有（是真的完全没用），是由资材学院的老师负责教，<strong>考试小题选择比较简单，大题基本为课本上的课后题原题，</strong>可以带计算器，比较容易拿高分。</p><p>面向对象程序设计：俗称JAVA，分为实验和考试两部分，随着近两年db的持续摆烂，面向对象设计考试也逐渐简单了，也主要以他在清览云平台和头歌平台（都是他留作业做实验用的平台）上的题库为主。<strong>但是这门课非常重要，要从中明白面向对象编程的基本思想，目前速度要求不高的开发依旧是以JAVA全栈为主，如果未来有开发的想法，要在JAVA上不断拓展。</strong></p><p>离散数学：是和数学学院一起上的课，由数统的老师教授，一般是郭静梅老师，教的不错，老师人也不错，但是离散数学本身很难，主要是研究代数理论、集合论、逻辑推理、图论、简单数论等（都可以被代数统一），理解比较困难，<strong>想要考一个高分重在理解</strong>，而且离散数学是你未来研究代数、计算机数学的一个重要基础。</p><p>统计学：没学明白（，老师讲课讲的不太好，是可以带计算器的考试，具体怎么复习这个不太会，考试难度我感觉不大，但是不好考高分，建议多做做课后题。</p><p>创业基础：五级分制，小组展示结课，想要拿95，要看老师评判方式，有些老师是按投票来的，那时候就找一些人缘好的人结组，可以提高拿95的概率。</p><blockquote><p><strong>大二下学期</strong></p></blockquote><p>毛概：好好背背，看看能不能找到一个叫孙戬的老师教的学生，如果你是他教的请务必好好做课上展示，这个老师会给你画考点的。</p><p>习概：没学过，基本同理</p><p>运筹学：王军教的课，他可能会给你整点有的没的，可能你觉得没什么用的玩意或者和这课没什么关系的东西，这些东西就自己课下找时间去了解一下，你让他讲他也说不明白，我们那年没有考试，是论文结课，不知道现在如何，他考试出的会比较难（一些学长学姐说的），好好复习。</p><p>数据结构：如果你想跨考计算机，数据结构是必考的，虽然db教的很不行（<img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/18C9DA25.png" alt="18C9DA25" style="zoom:33%;" />)，但是务必把实验都好好做了，虽然一般计算机考研要求用c语言或c++但是基本的逻辑都是相同的，只是表述方式变了一点，实验做好了以后改换一个语言是很容易的一个事情。考试的话选择都是题库原题，大题是新题，但是考的不难，手写代码一般是从后两章查找排序出，就算不是也会很简单，在十行之内而且如果不会写代码可以直接写文字流程。</p><p>数据库系统概论：黄亮老师负责，课讲得可能会让你觉得比较无聊，但是他上课讲得每一句话基本都有用，黄老师的特点就是比较接地气，他比较喜欢用简单的技术做一些皮实好用的东西。数据库会有几次试验，印象中难度不大，数据库的查询sql是一个重难点，一定要好好学，<strong>而且数据库是唯一一个会挂人的专业课</strong>。临考前他会画题型、考点，最后考试就是按题型考。</p><p>系统工程导论：赵萌老师负责，平时分有上课回答问题和作业，还有一个课堂测验。结课是一个小组论文，有答辩；因此小组论文一定要做的稍微复杂一点，尽可能要有创新点，<strong>这门课是一个非常好的课</strong>，一定要好好学一下，这门课基本上就把管理科学的框架说明白了。</p><p>数据通信与网络：计网，408科目之一，计算机网络的知识点比较庞杂，但是是很成系统的，学计网的时候一定要学完一章就往回复习一章进行总结，因为我们学的是自下向上的，每学下一章都是对上一章的屏蔽，当你学完一章回顾的时候你就能很好的理解上一层的作用和层与层的关系。学完你会发现这个通信结构是很巧妙的。</p><p>计算机操作系统：由蒋学英老师教授，开卷考试，4次作业，平时分很复杂，4次作业他会给你挑很多奇怪的错误，就务必顺着他的意思写，第一次作业务必把论文排版好看一点，他很看重这个，<strong>操作系统在刚开始学的时候可能会会学不明白，建议快速补一下计算机基础，因为你可能刚开始甚至分不清主存和辅存……</strong>考试的话，题量很大，但题目不难，需要理解后才能做完。</p><p>认识实习：还是蒋学英老师负责，这个一般令大家比较难绷，因为找不到合适的实习，这里浇个冷水，以大二的水平是找不到开发实习岗位的。这个课的重点是了解你工作单位的管理信息系统，所以其实是个单位就可以，然后要让老师有一种耳目一新的感觉，给他一种你非常用心的感觉，论文排版一定要有图有文字，图下边要有文字解释，格式一定要都写对。五级分制，如果要想拿95分是需要答辩的。</p><blockquote><p>大三第一学期</p></blockquote><p>从这学期开始就要上自己选修的课程了，课程也开始比较重量级。</p><p>Web开发技术：db的课程，看了上边那两个你也知道他的风格了，有实验，考试结课，考试很简单，也是抽题库，不是抽题库的大题就稍微写写，都比较简单。</p><p>信息系统开发与管理：蒋学英的课程，类似软件工程，有实验课，实验课极其逆天，以半天为单位上课，下课前要交实验报告，实验内容全是画图设计，上课一定好好听，不会画一定去问他，要不然根本画不对。考试闭卷，有重点，但是给分很迷，没什么技巧，就是猛背。</p><p>信息法基础：选修，没啥用，不推荐（虽然他给了我目前的最高分），喜欢法律的可以学下，分为课上展示和结课论文，难度不大。</p><p>大数据开发技术：黄亮老师负责，开卷，可以带PPT，考试内容全在PPT上，PPT上会有小问题，上课他会给你说答案，说答案的时候务必记一下，因为简答题就是那些小问题（！），有平时作业，但是好像权重不大。</p><p>项目管理：选修，<del>是一个工商管理的老师负责，王林老师，他的组也收本科生，你们想去也可联系一下，目前学术做的也是风头正盛，但是但是老师很严格，有一个课上展示很不好做，考试也比较难，如果你实在不想学代码了可以尝试。</del>现在已经加入赵煜辉宇宙，第一年不知道怎么样，待更新</p><p>会计学：选修，贾正武负责，会计的一个老师，好像是我们学院的党委书记，这个我就不好评价了，你都来学信管了，为甚么要选修会计学呢，不过你要是想纯管理，那就选吧，要不然学分凑不够（</p><p>数据挖掘与数据仓库：选修，<strong>赵煜辉老师的课是有相互关系的，千万不要跳着选，否则会比较难受</strong>，数据挖掘与数据仓库是一个介绍性的课程，课本叫introductionto date mining，是这套分析的起步课程，他主要介绍了一套从数据到数据分析的流程，以及流程的部分细节，<strong>论文结课</strong>，中间会有很多小作业，但是不会很及时的收，如果你想好好学的话的一定要记住每次的小作业，<strong>他留完作业就在记事本上写一下以防忘记</strong>，有实验课，实验课有一定难度，另外，<strong>数据挖掘里虽然没有Python字样，但是同样需要学习Python</strong>，而且Python课上是不教的，你要在暑假自学。</p><p>Python高维数据分析：选修，赵煜辉老师负责，<strong>相当于数据挖掘的进阶课程</strong>，其主要是研究基本的矩阵变换优化以及多元统计的应用，主要抓住高维数据这一特殊数据进行分析，因此不再是全流程的介绍，是主要对（数据挖掘）算法的研究，并用Python进行编程，<strong>是很硬核的一门课</strong>，理解上是有门槛的，教材纯英文，<strong>论文结课</strong>，和数据挖掘一样也是有很多小作业，相比数据挖掘实验会更多。</p><blockquote><p>大三第二学期</p></blockquote><p>就业指导：辅导员教，没啥可说的，结课一般为简历+面试</p><p>金融学：选修，实际上是金融工程，主要内容是了解货币的衍生物（我听说金融工程是最简单的金融），王军的课，这<strong>是他讲的唯一还行的课，讲的比较通俗易懂</strong>，如果他还是论文结课是可以选的，如果他改成了开卷考试，嗯，王军的考试听说不是很行。</p><p>信息资源组织与管理：选修，还是王军的课，没上过具体讲啥也不清楚，去年是论文结课，不过他的课结课有商量的余地。</p><p>信息安全技术：选修，是由计算机学院的老师于七龙负责，是一个介绍性质的课程，开卷考试，考的比较简单，老师人很好。</p><p>ERP系统及其应用：选修，介绍直接复制孙建勇老师的介绍了，孙建勇老师，教的很好很实用，是工业工程方向的，教的课叫做erp，比较好玩儿听说。</p><p>决策支持系统：选修，程雪老师负责，决策支持系统是一个非常笼统的介绍性课程，只负责介绍什么是，用什么知识构造，不包含任何实操，而且相对介绍的不够先进，所以课是没啥用的，实验也比较无聊，结课论文的推荐也令人比较麻，嗯，不是非常推荐。</p><p>数学建模：选修，王军教的，上课体验极差，上课会讲R语言（但是他完全不懂数学建模，R语言讲的也非常一般！）如果，他有一丝想要考试结课的念头，<strong>你们一定要逼他改成论文结课！</strong>因为数学建模是一个非常面向应用的课程，是对各种现实问题的数学建模，考试完全没办法考出来，<strong>但是你要忽悠好了，拿个高分很容易</strong>。</p><p>供应链管理：选修，王素欣老师负责，大好人，负责供应链管理课程，主打一个摆大烂，考试极其简单，是教机械和供应链方面的，<strong>供应链管理这门课讲的内容不太硬核，但是考试真的不好拿高分呀</strong>，大家小心。</p><p>统计学习与机器学习：选修，赵煜辉宇宙第三部，这一部摆脱了之前体系，从贝叶斯统计的角度进行建模，概率角度的建模很大程度弥补了样本对不足的缺点，是对之前课程的升华，一般到这里，绝大部分同学已经放弃了，我上这课的时候交作业的只有七八个人，因此难度其实非常大了，<strong>结课还是论文结课</strong>。</p><p>R语言与量化金融：选修，王军负责，两年没开出来了，不知道怎么样。</p><p>专业实习：最后一门保研要用的课了，黄亮老师负责，要求应用新技术，做一些<strong>有用的东西</strong>，一定得有用，没啥用的东西黄老师一般不咋认可，这门课可以参考科创比赛的一些产品。</p><h3 id="上课不教的小工具">上课不教的小工具</h3><p>都是成熟的带学生了，有些东西老师上课是不教的，但是你是必须会的，包括一些查资料、找资源、看论文的东西，还有一些实用工具。</p><p><strong>科学上网：</strong>不能细说，会就是会不会就是不会，作为一名学信管的人，你不会不知道一些国外的博客比国内写的好太多吧（）</p><p><strong>学校VPN：</strong><ahref="http://vpn.neuq.edu.cn/login">校外远程资源访问系统（WebVPN）(neuq.edu.cn)</a>可以通过这个玩意访问校内网（等价于连接校园网），可以访问知网、websci等论文网站，并且免费下载。缺点是不太稳定，</p><p><strong>总校VPN：</strong><ahref="https://pass.neu.edu.cn/tpass/login?service=https%3A%2F%2Fwebvpn.neu.edu.cn%2Flogin%3Fcas_login%3Dtrue">智慧东大--统一身份认证(neu.edu.cn)</a>功能上是差不多的，论文可能买的相对全一点，更加稳定。</p><p><strong>总校邮箱：</strong>分校的邮箱申请是很麻烦的，但是当你搞完总校VPN的时候你就搞到了一个总校的邮箱，而大部分专业软件都是可以凭借学生邮箱免费使用的哦。</p><p><strong>JetBrains：</strong>一个公司的名字，主要是各种IDE，其IDE（继承开发环境）都非常好用，专业版收费，但是可以通过总校邮箱白嫖。</p><p><strong>easyScholar：</strong>一个浏览器插件，可以显示各种文章的评级以及影响因子。</p><p><strong>知云文献翻译：</strong>免费的论文翻译软件，非常好用，看文献利器。</p><p><strong>SciHubCRX：</strong>浏览器插件，提供直接在scihub上搜索文献，scihub是一个著名的免费文献分享的网站。</p><p><strong>iTranlator：</strong>浏览器插件，可以快速翻译浏览器页面的英文。</p><p><strong>z-library：</strong><ahref="https://singlelogin.re/">Z-Library Project(singlelogin.re)</a>，需要翻，影子图书馆，书非常全。</p><p><strong>安娜的档案：</strong><ahref="https://zh.annas-archive.org/">安娜的档案(annas-archive.org)</a>，可平替zlibrary，影子图书馆，你想找的大部分国外的书还有比较有名的中文教材都可以找到，运气好可以直接进。</p><p><strong>哔哩哔哩大学：</strong>懂都懂，黑马程序员入门</p><p><strong>斯坦福CS系列公开课：</strong>我们需要听得不多，但是如果你想扩展视野，这套课非常好，不过是英文哦（b站可能有熟肉）<ahref="https://www.baidu.com/link?url=qXa8r3Jy8wlfz9e8X3AMR74zbbvFAYLfNFvuOse8Es-kUU_feT-bdNS6_gTKMwJ5MSTm-Y9xql6cVWZU_BqFlq&amp;wd=&amp;eqid=a936701500013dec0000000264df181c">CS101</a></p><p><strong>Leecode：</strong>著名刷题平台，可能收费，不过有学校oj平替<ahref="http://newoj.acmclub.cn/">（学校OJ）</a></p><h3 id="如何学好">如何学好</h3><blockquote><p>虽然我学的也不是很行，但是经验还是差不多的</p></blockquote><p><strong><em>多上手！！！！</em></strong></p><p>代码类的课程一般都需要你多动手，多写，多练，这个一定不能摆烂，如果你不写，那你必然是学不会（有点绝对）。</p><p><strong><em>多类比！！！</em></strong></p><p><strong>理解很重要</strong>，大部分课程的原理其实很简单，大部分都能从生活中类比，而且很多都包含一些管理思想。比如操作系统里存在共享内存的线程互斥访问，其实我们做一个比较下流的类比（），其实就是一个公共厕所（共享内存），不同人（线程，这些人恐怕还有点尿频）要去这个厕所，那么这些调度算法就很容易理解了。</p><p><strong><em>学好数学！！</em></strong></p><p>多去了解基本的计算机数学，这会为你后面的学习打下良好的基础。至于计算机数学是什么，要学会自己用工具去查。</p><p><strong><em>多上网查！</em></strong></p><p>老师不会的，互联网会教你，不要仅仅百度也要学会google，怎么google就得自己学习了。google和百度的内容含金量，你只要自己查过就知道。尤其是程序问题，只要你敢搜，就一定会有同样的错误在网上被问了千八百遍。</p><blockquote><p>下面的东西有一定的共同性，大家都可以看看</p></blockquote><h2 id="生活">生活</h2><blockquote><p>拒绝信息差，给自己提前布局</p></blockquote><p>这里给大家一点在学校里能摸到的各种没啥用的奖项列举一下，以及对你的学校生活有什么帮助。</p><p><strong>想要入党：</strong>需要奖学金、校级奖励（去年开始校级奖励开始严格了，只包括一些荣誉称号）、校级荣誉、高思评、说的过去的成绩、班内主要任职。</p><p>这些要求其实是比较严苛的，所以导致基本上只有班内主要的班委能够入党，而基本上也只有主要班委和部分负责人才有校级奖励，所以开学换班委大家还是要争取一下的，<strong>比如有些人有助导身份在选班委的时候是很有说服力的，不用长篇累牍的介绍，就仅仅扔出你是助导表现出诚意就能被选上。</strong></p><p><strong>支教保研：</strong>这个主要需要你去卷学生工作，实际上名额就在团委老师手里，需要大三在团委有主要任职，还要相应的有一些在校期间的比赛奖励之类的。</p><p>剩下的信息差，基本上也不多了，大一你们该接触的也都接触到了，<strong>要处理好人情世故</strong>，这个事情，在大一跌倒过就应该能理解，不要用要求自己的标准要求别人，尽可能顺着别人的意愿，除非极其违背原则，否则规则都是可以适当浮动的，这样能比较好的处理好人际关系，当然这是维护一些比较简单的联系比较弱的关系，你们的好闺蜜、死哥们，那还用得着这种技巧。</p><p>嗯，你们的大学时间还很长，多多培养自己的兴趣爱好，多探索一下自己的边界。为自己的未来消弭信息差。<em>香农（信息论）说过，信息是消除事务不确定性的东西，越早获取信息，越早能找准目标，越早发力。</em></p><h2 id="科创">科创</h2><blockquote><p>大二是一个很好的进组时间</p></blockquote><p>科创可以简单分为三类：进组科研，进组打比赛，自己摸索</p><h3 id="进组科研">进组科研</h3><p>进组科研我知道的几个：</p><p><strong>赵萌老师</strong>：想进组大二开学就可以找赵萌老师去聊一下了，给你们贴一下他的官网链接：<ahref="http://glxy.neuq.edu.cn/info/1332/4948.htm">赵萌-管理学院(neuq.edu.cn)</a>，是目前学校科研做的最好的一批老师，方向在官网里都有。</p><p><strong>赵煜辉老师：</strong>他应该是很乐意收的，但是应该比较放养，这个没什么前车之鉴，他确实收，但是会要求你有比较高的水平，他现在的研究比较偏向金融数据分析和AI一类的。</p><p><strong>王林老师：</strong>不太技术的同学们可以考虑一下，他是工管的老师，是有本科生组的，也是目前学术做的比较好的老师。<ahref="http://glxy.neuq.edu.cn/info/1333/6630.htm">王林-管理学院(neuq.edu.cn)</a>，会计、工管的同学都可以考虑一下。</p><p><strong>电商</strong>那边的老师，目前也有手里有研究计划的老师，比如刘冰玉老师等等，你们如果有心参与也可以私下找老师聊一下。</p><p>行管我是真的不太清楚。</p><p><strong><em>还有另一个思路：进其他学院的实验室</em></strong>，但是这就要求你要有充足的信息来源，知道其他学院有什么实验室，实验室有什么待遇。</p><p><strong>进组科研能给你带来什么：</strong></p><p>① 做的好的话，你的手里能够拿到一篇小论文</p><p>② 有些组会把科研拿去打创赛</p><p>③ 做的不好能够很大程度提升你的专业知识、动手能力、前沿视野</p><h3 id="进组打比赛">进组打比赛</h3><p>学校有很多做的比较好的创业项目组，他们会在开学时进行一波猛招新，如果你们看到有合适的就可以简单问问，看看自己合不合适，能不能学，这块的选择余地非常大，而且需要投入也非常大。</p><p>进组打比赛的话推荐大家平时就加一下挑战杯之类的群，一般有招新需求的话他们会在群里发，这里还可以继续细分：</p><p><strong>偏硬件的有：</strong>robotmaster（类似机器人）、智能车、分出来的智漠、龙芯等等，这些都会找人，但是需要你有基本的c语言基础，只要你有意向基本上他会教你，这种都属于是大组，资金充足，组里大佬也多，他们一般打的是固定的比赛，但是由于大佬多可以带着你打其他的比赛。</p><p><strong>偏算法一些的：</strong>计工那边有ACM俱乐部，网络安全协会等等，这种比较硬核，但也不是没有机会，ACM，网安进去的门槛都不高，但是拿奖是相当费时间的。</p><p><strong>偏向创意创业的</strong>：这种组一般都不大，但是他们会拿出一些很好的创意点，一般这种组招人的话需要你知道有这么个组，需要你发动自己的人脉去打听，比如你认识大创的主席、部长之类的，或者打比赛比较多的人，问他们会有比较大的收获。</p><ol type="1"><li>这种组一般就是会去打，挑战杯、互联网+、三创赛，也就是比较常见的商赛</li><li>一般需要的人都是特殊开发（比如cv、nlp、ai等）、web开发（一般只需要套壳）、美工（稀缺人才）、答辩、策划、文案、运营(可有可无)</li><li>需要你混到核心，拿奖才比较有效。</li></ol><h3 id="自己摸索">自己摸索</h3><p>不太推荐，没人带你，打比赛很大程度都是竹篮打水一场空，很多项目都是已经琢磨了三四年的东西，你把一个今年搞了半年的东西扔上去实在是差太多，而且资源也远远跟不上。</p><p>但是有些比赛是可以自己摸索的：</p><ol type="1"><li>数学建模：数学建模基本就是自己摸索，当然你也可以找几个大三什么的带带你，但是终归是一个纯粹靠自己的比赛。</li><li>什么电赛、蓝桥杯、程序设计之类的比赛，有的含金量不高，有的是有报名限制，具体想了解的自己看看那个比赛等级的说明。</li></ol><h2 id="毕业">毕业</h2><p>为什么叫毕业呢这里，你毕业无非是考研和就业，而就业几乎是终极目标，<strong>所以一定要提前至少一年或两年想好是考研还是就业</strong>，因为你要提前做好准备。</p><h3 id="读研"><strong>读研</strong></h3><h4 id="保研">保研</h4><p>没经历过真不熟</p><h4 id="考研">考研</h4><p>正在考，考上了再写</p><h4 id="出国">出国</h4><p>学姐懂，等着她搞完了让她写，大二下也来的及准备（</p><h3 id="就业">就业</h3><h4 id="考公">考公</h4><p>毕业的尽头是就业，就业的尽头是考公，但是务必了解到考公也有无数种，考公也有对专业的限制，所以要提前了解，我没仔细了解过，所以大家得去自己查一部分。</p><p>考公有：选调、国考、省考、事业编、军队文职、三支一扶、人才引进各种各样，具体了解请百度，或者问问考上的。</p><p><ahref="https://zhuanlan.zhihu.com/p/557271130">考公最全攻略丨小白考编看这一篇就够了- 知乎 (zhihu.com)</a></p><p>其实考个老师也不是不行（）</p><h4 id="进厂">进厂</h4><p>目前进厂形式不太好，所以具体现在就业是个什么逻辑，俺也不是很懂，就简单摆一下形势和可能去向。</p><p>就业相对好一点的去了银行，进大厂的很少，比亚迪比较多，岗位都不知道，因为不给公开看。</p><p>—————待续—————</p>]]></content>
      
      
      
        <tags>
            
            <tag> 杂记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C语言文件框架与运行</title>
      <link href="/2023/08/05/cFrame/"/>
      <url>/2023/08/05/cFrame/</url>
      
        <content type="html"><![CDATA[<h1 id="c语言文件框架与运行">C语言文件框架与运行</h1><p>不知道大家有没有一种感觉，当你初学c语言运用（仅仅是运用）到熟练的时候，会明显感受到一些疑惑：这个头文件我好像从来没写过、这个多文件我好像也从来没用过、这个多文件的C语言程序又是怎么跑起来的</p><h2 id="c语言的文件框架">C语言的文件框架</h2><h3 id="没有框架">没有框架</h3><p>最简单的结构是什么？就是没有结构，一个单一的<code>XX.c</code>文件配合gcc工具编译就可以运行。</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230807120653069.png" alt="无框架示例" style="zoom:50%;" /></p><p>这里简单介绍一下gcc，gcc是GUN中的一个编译工具，在C语言中的指令（该顺序也就是c语言运行的顺序）主要有：</p><ol type="1"><li>预处理，进行宏展开等,生成代码文件为<code>helloworld.i</code></li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -E helloworld.c</span><br></pre></td></tr></table></figure><ol start="2" type="1"><li>编译，生成汇编代码，生成代码文件为<code>helloworld.s</code></li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -S helloworld.c</span><br></pre></td></tr></table></figure><ol start="3" type="1"><li>汇编，生成机器码，生成代码文件为<code>helloworld.o</code></li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -c helloworld.c</span><br></pre></td></tr></table></figure><ol start="4" type="1"><li>链接，实际上直接链接能够运行以上所有的步骤，生成的是一个名为helloworld的可执行文件</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -o helloworld helloworld.c</span><br></pre></td></tr></table></figure><p>在命令行中运行c语言程序的方式：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.\helloworld</span><br></pre></td></tr></table></figure><p>实际上就是运行我们刚刚链接出来的可执行文件，中间的部分是我们的命名，命名为<code>helloworld</code></p><h3 id="头文件源文件结构">头文件+源文件结构</h3><p>我作为一个半路出家的C语言使用者（以前是使用JAVA和Python），简单使用是并不难的，但是当我想做多文件结构的时候我发现我并不会，C语言并没有像JAVA和Python一样的导入方法，但是其实是有的，就是我们在单文件编程时不怎么搭理的头文件。</p><h4 id="头文件">头文件</h4><p>首先说说头文件，头文件是什么，我们先从名字上来说：头文件，头是什么？头在哪儿？头位于人的最顶端，是人脑所在的地方负责思考获取知识。C语言中的头文件也是，头文件就是C语言main程序中的最顶端，负责获取知识（程序接口）。</p><p>那么头文件又该如何定义，细节又是如何？</p><p>我们先举个例子直观理解：</p><p>众所周知，C语言是面向过程的语言，其中函数是面向过程语言的精髓，下面我们首先定义一个函数：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">helloworld</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;hello,World!\n&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>众所周知，当程序员定义完用户程序后，main函数想要调用需要事先声明：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">helloworld</span><span class="params">()</span>; <span class="comment">// 声明函数</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    helloworld();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">helloworld</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;hello,World!\n&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>现在请大家想象一个情况，如果现在我们有1万个函数要声明，那是不很麻烦，而且会有极高的耦合度，且不方便阅读。而头文件就代替了声明加函数定义的部分。</p><p>于是我们可以拆一下，分为这样的结构：</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230807140743646.png"alt="文件结构" /><figcaption aria-hidden="true">文件结构</figcaption></figure><p>其中<code>helloworld.c</code>中为</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">helloworld</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;hello,World!\n&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>helloworld.h</code>中为：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> EXAMPLE_HELLOWORLD_H</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> EXAMPLE_HELLOWORLD_H</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">helloworld</span><span class="params">()</span>;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span> <span class="comment">//EXAMPLE_HELLOWORLD_H</span></span></span><br></pre></td></tr></table></figure><p><code>main.c</code>中为：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;helloworld.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    helloworld();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样就将整个文件模块化了，但是其中依旧存在一些问题没有讲清楚，比如这个头文件到底怎么写，里边的内容都有什么含义？下面我们先解释一些前置的知识，慢慢道来。</p><h4 id="include命令"><code>#include</code>命令</h4><p><code>#include</code>命令实际上很简单，可以等同为<code>import</code>语句，其叫做文件包含命令，用来引入对应的头文件，其工作原理就是将头文件的内容插入到当前命令所在的位置上，连接成一整个源文件。</p><p><code>#include</code>命令分为两种：</p><ol type="1"><li><p>一种是<code>#include&lt;&gt;</code>，引用的是编译器的类库路径里面的头文件，其用于导入官方标准头文件</p></li><li><p>另一种是<code>#include""</code>，引用的是你程序目录的相对路径中的头文件，如果在程序目录没有找到引用的头文件则到编译器的类库路径的目录下找该头文件，其用于导入自定义的头文件</p></li></ol><p>也就是说引用系统标准库都可以，但第一种更快；引用自己定义的头文件只能用第二种。</p><h4 id="宏定义">宏定义</h4><p>#define叫做宏定义命令它也是C语言预处理命令的一种，所谓宏定义，就是用一个标识符来表示一个字符串。</p><p>宏定义的形式为：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> 宏名 字符串</span></span><br></pre></td></tr></table></figure><p>宏名就是一种标识符，而字符串可以是数字、表达式、if语句、函数等。</p><p>tips：</p><ul><li><p>宏定义仅仅是替换，并不计算</p></li><li><p>宏定义的处理步骤是上面的预处理阶段，因此是否正确要等到编译阶段</p></li><li><p>宏定义可以拥有定义域</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> PI 3.1415</span></span><br><span class="line">———————作用域——————</span><br><span class="line"><span class="meta">#<span class="keyword">undef</span> PI</span></span><br></pre></td></tr></table></figure></li><li><p>习惯上，宏定义用大写</p></li></ul><p>常见的预处理命令有：</p><table><thead><tr class="header"><th style="text-align: center;">命令</th><th style="text-align: center;">说明</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">#</td><td style="text-align: center;">空指令</td></tr><tr class="even"><td style="text-align: center;">#include</td><td style="text-align: center;">引入头文件</td></tr><tr class="odd"><td style="text-align: center;">#define</td><td style="text-align: center;">定义宏</td></tr><tr class="even"><td style="text-align: center;">#undef</td><td style="text-align: center;">取消宏</td></tr><tr class="odd"><td style="text-align: center;">#if</td><td style="text-align: center;">如果条件为真，则编译if内的代码</td></tr><tr class="even"><td style="text-align: center;">#ifdef</td><td style="text-align: center;">如果宏已经定义，则编译if内的代码</td></tr><tr class="odd"><td style="text-align: center;">#ifundef</td><td style="text-align: center;">如果宏未定义，则编译if内的代码</td></tr><tr class="even"><td style="text-align: center;">#elif</td><tdstyle="text-align: center;">如果前面的#if条件为假，当前条件为真，则编译</td></tr><tr class="odd"><td style="text-align: center;">#endif</td><td style="text-align: center;">结束一个#if</td></tr></tbody></table><h4 id="头文件编写">头文件编写</h4><p>现在前置知识都已经补足了，我们来说一声头文件编写的规范：</p><ul><li>建议把所有的常量、宏、系统全局变量和函数原型写在头文件中，在需要的时候随时引用这些头文件</li><li>源文件的名字可以不和头文件一样，但是为了好管理，一般头文件名和源文件名一样</li><li>不管是标准头文件，还是自定义头文件，都只能包含变量和函数的声明，不能包含定义，<strong>否则在多次引入时会引起重复定义错误</strong>（重定义）</li></ul><p>这里也就可以解释为什么头文件要有这个程序段了：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> EXAMPLE_HELLOWORLD_H</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> EXAMPLE_HELLOWORLD_H</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">helloworld</span><span class="params">()</span>;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span> <span class="comment">//EXAMPLE_HELLOWORLD_H</span></span></span><br></pre></td></tr></table></figure><p>一旦该头文件被重复引用，那么就会检测到有这个宏定义了已经，那么就不会再次编译这个头文件，从而避免了重定义错误。</p><h2 id="关于gccmake与cmake">关于gcc、make与CMake</h2><p>建议参考：<ahref="https://blog.csdn.net/wuzheyan2008/article/details/119026007">关于gcc、make和CMake的区别_cmake和gcc的区别_ericwzy945的博客-CSDN博客</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> C语言 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python之IDE</title>
      <link href="/2023/07/23/IDE/"/>
      <url>/2023/07/23/IDE/</url>
      
        <content type="html"><![CDATA[<h2 id="python入门之ide">Python入门之IDE</h2><p>想必大家都在什么某抖、某b或者某些不太懂的电视剧里看到过黑客大佬（可能是）一块命令行敲代码敲一天，对此我的评价是：要么是纯粹演的，要么是真大佬。</p><p>命令行是可以解决所有编程问题，例如Python也自带有IDLE，或者Python的交互式页面，其都是在命令行窗口进行编程的，但是显而易见，这种方式我写个十八行代码，两三个变量还是可行的，一旦代码变复杂，记住变量都成为了一个困难的工作。因此IDE最基本要解决的问题就出现了。</p><p>这里简单介绍两个Python常用的IDE，以及下载安装。</p><h2 id="pycharm">Pycharm</h2><p>Pycharm是由JetBrains开发的一个专门的Python集成开发环境，由于其极其亲民，简单上手闻名。当然目前业界的许多IDE都是由JetBrains开发的，并且安卓开发的著名名言kotlin也是由JetBrains主导研发的。</p><h3 id="下载">下载</h3><p>这里是Pycharm下载的官方网站（<ahref="https://www.jetbrains.com/pycharm/">官网</a>），如下图，在红色框框中就可以下载了</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230724000324453.png"alt="image-20230724000324453" /><figcaption aria-hidden="true">image-20230724000324453</figcaption></figure><p>Pycharm分为Free Community（免费社区版）和Professional（专业版）</p><p>在点击下载后，显示在最上边的是专业版，是需要付费的</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230724000717317.png"alt="专业版" /><figcaption aria-hidden="true">专业版</figcaption></figure><p>向下滚动，看到社区版本，如果囊中羞涩（但是确实贵），社区版也是足够我们学习使用的。</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230724001208274.png"alt="这还是刚才的网页只是下拉了" /><figcaption aria-hidden="true">这还是刚才的网页只是下拉了</figcaption></figure><p><strong>但是</strong>，我们是学生，我们可以<strong>白嫖</strong></p><h3id="专业版白嫖需要学校邮箱或者学信网">专业版白嫖（需要学校邮箱或者学信网）</h3><p>还是在这个网页，在右上角有一个小人头，点进去</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230724002352976.png"alt="image-20230724002352976" /><figcaption aria-hidden="true">image-20230724002352976</figcaption></figure><p>这时候会蹦出来一个让你登陆的界面，如果你有账号那就登陆就好了，如果没有请注册一个，<strong>并且务必记住账号密码</strong>。</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230724002741727.png"alt="image-20230724002741727" /><figcaption aria-hidden="true">image-20230724002741727</figcaption></figure><p>我已经有账号就直接登陆了，但为了更好的演示我注册一个新的账号，注册很简单，登陆后页面是这样的：</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230724003726451.png"alt="image-20230724003726451" /><figcaption aria-hidden="true">image-20230724003726451</figcaption></figure><p>这个页面的意思是说你目前没有任何许可证，他告诉你你可以如何获得许可证：买一个，找公司要一个，学生或老师免费</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230724003835700.png"alt="image-20230724003835700" /><figcaption aria-hidden="true">image-20230724003835700</figcaption></figure><p>好了，第三个就是我们想要的，那么我们点进去，一直往下划</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230724004035867.png"alt="image-20230724004035867" /><figcaption aria-hidden="true">image-20230724004035867</figcaption></figure><p>点击红框里的Applynow，进去后我们会看到一个页面，这时我们可以选择切换为中文，当然不换也行。</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230724004131577.png"alt="image-20230724004131577" /><figcaption aria-hidden="true">image-20230724004131577</figcaption></figure><p>简单说明一下各个需要填什么：</p><ul><li>我是学生</li><li>就读</li><li>是否就读计算机科学，随便选无所谓</li><li>邮箱地址：<strong>务必填写正确的学校邮箱地址</strong>，以我的为例<code>202011@stu.neu.edu.cn</code>,这非常重要，因为学校邮箱是证明学生在读的重要东西。</li><li>姓名正常填写</li><li>后边除了接受协议必须勾选，其余都如实填写就行</li></ul><p>然后点击提交，会跳转出如下的界面：</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230724004923274.png"alt="image-20230724004923274" /><figcaption aria-hidden="true">image-20230724004923274</figcaption></figure><p>这个界面的意思是说，去你的学校邮箱等待JetBrains发的邮件，这时候打开学校邮箱等待就行了</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230724005119114.png"alt="image-20230724005119114" /><figcaption aria-hidden="true">image-20230724005119114</figcaption></figure><p>接到邮件后，点击他发给你的链接，阅读后续协议并同意，然后你就能够获得：</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230724005400501.png"alt="image-20230724005400501" /><figcaption aria-hidden="true">image-20230724005400501</figcaption></figure><p>JetBrains几乎所有产品的专业版许可证！</p><h3 id="安装">安装</h3><p>安装没有什么难度，列举几个重要的点：</p><ul><li>要记得加入path路径勾选</li><li>要记得切换安装路径，尽量不装C盘</li></ul><p>安装结束后，打开Pycharm界面：</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230724005711445.png"alt="image-20230724005711445" /><figcaption aria-hidden="true">image-20230724005711445</figcaption></figure><p>正常登陆就可以美美的使用Pycharm了</p><h2 id="vscode">Vscode</h2><p>Vscode作为一个轻量级的IDE，其最大的优点就是快，相比Pycharm要开个几分钟，Vscode几乎是瞬间打开，但是Vscode的各项设置并不是很傻瓜，需要自己配置或者安装插件，有些功能的集成也不如Pycharm。</p><p>Vscode的安装就不再详细的描述了，这里简单描述一下安装Python插件</p><ul><li>进入插件市场，点击左边的红框：</li></ul><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230724010109565.png"alt="image-20230724010109565" /><figcaption aria-hidden="true">image-20230724010109565</figcaption></figure><ul><li>在最上角搜索Python</li></ul><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230724010237254.png"alt="image-20230724010237254" /><figcaption aria-hidden="true">image-20230724010237254</figcaption></figure><ul><li>直接下载这个就可以用了</li></ul><h2 id="总结">总结</h2><p>完成乱七八糟的下载后就可以开始体验一下鸟枪换炮的快感了，用完应该只有一句话“这是飞一样的感觉~”。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Anaconda从入门到入土</title>
      <link href="/2023/07/22/Anaconda/"/>
      <url>/2023/07/22/Anaconda/</url>
      
        <content type="html"><![CDATA[<h1 id="anaconda从入门到入土">Anaconda——从入门到入土</h1><h2 id="引入">引入</h2><p>刚刚入门Python的同学可能对环境配置并没有什么感觉，毕竟就是一个pip的事，这时候我们设想一下，现在你在Github上下载了一个Python项目，然而这个项目需要你的numpy版本为1.12，而你的numpy版本是1.11，那么你是不是就要删除再安装？这仅仅是一个项目，而在日常编程中经常面对这种问题，而Anaconda就解决了这个问题。</p><h3 id="python环境">Python环境</h3><p>这里我随便打开了一个我电脑上的Python的源文件：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230722214308903.png" alt="朴素的Python目录" style="zoom: 67%;" /></p><p>在这里Lib中存放了Python的官方包和第三方包，所有的第三方包都在site-packages中，这其中就有我们常用的matplotlib。</p><center class="half"><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230722214809310.png" alt="image-20230722214809310" width="400"/><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230722215158542.png" alt="image-20230722215158542" width="400"/></center><h2 id="anaconda">Anaconda</h2><p>Anaconda(<ahref="https://www.anaconda.com/download/#macos">官网</a>）就是可以便捷获取包且对包能够进行管理，同时对环境可以统一管理的发行版本。Anaconda包含了conda、Python在内的超过180个科学包及其依赖项。</p><h3 id="下载">下载</h3><p>下载一般是没有什么难度的一步一步的走下去就行，这里简单提一下，Anaconda有标准版和mini版，如果你的电脑内存吃紧，那可以考虑安装mini-conda，功能上只是没有图形化界面，但是真的小很多。</p><h3 id="配置环境变量">配置环境变量</h3><p>在<code>控制面板\系统和安全\系统\高级系统设置\环境变量\用户变量\PATH</code>中添加 anaconda的安装目录的Scripts文件夹,比如我的路径是<code>F:\miniconda3\Scripts</code>,看个人安装路径不同需要自己调整。</p><p>这个学习过Java的同学应该对这套工作已经很熟悉了。配置完成后，就可以在你的shell界面(win+R输入<code>cmd</code>，也就是命令行界面)输入命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda --version</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230722222040833.png"alt="image-20230722222040833" /><figcaption aria-hidden="true">image-20230722222040833</figcaption></figure><p>显示出你的Anaconda版本即表示配置成功。</p><p>Anaconda本身是自带一个<code>Anaconda Powershell Prompt</code>的命令行工具，</p><p>为了避免可能发生的错误,我们先把所有工具包进行升级，在命令行输入：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda upgrade --all</span><br></pre></td></tr></table></figure><h3 id="anaconda与虚拟环境">Anaconda与虚拟环境</h3><p>首先回顾一个操作系统中的概念：虚拟。</p><p>操作系统中的虚拟性是指通过软件技术将一个物理资源分割为多个逻辑资源，是的多个应用程序可以同时使用这些逻辑资源，从而提高系统的利用率和效率。</p><p>这里我们用人话描述一下就是把一整块资源转化成好多个逻辑资源，但实际上还是这些资源，虚拟环境也是这样的思路。具体的原理大家可以参见<ahref="https://whiteboxml.com/blog/the-definitive-guide-to-python-virtual-environments-with-conda">[Theguide to Python virtual environments withconda]</a>这篇博客，写的非常详细。</p><h3 id="anaconda常用命令">Anaconda常用命令</h3><h4 id="进入环境-activate">进入环境 activate</h4><p>activate （意为：激活，学过神经网络的懂都懂），在shell中输入：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda activate</span><br></pre></td></tr></table></figure><p>就可以直接进入Anaconda自带的base环境中，如果这时候输入Python那么就进入的当下base环境中的Python，而不是原来电脑中的Python。</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230722230729568.png"alt="image-20230722230729568" /><figcaption aria-hidden="true">image-20230722230729568</figcaption></figure><h4 id="创建环境-create">创建环境 create</h4><p>创建虚拟环境的命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n ml python=3.7</span><br></pre></td></tr></table></figure><p>上面的命令的含义简单介绍一下，-n表示要写入他的名字也就是name，Python=3.7指下载3.7版本的Python</p><h4 id="切换环境-activate">切换环境 activate</h4><p>其实还是进入，只不过从真实到虚拟和虚拟到虚拟，所以我一直将这个命令叫做激活。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda activate ml</span><br></pre></td></tr></table></figure><p>这样就切换到了ml的虚拟环境中，这里特别强调一点，如果环境名记不住的话，写错了是切换不进去的，所以我们还有下面这条命令。</p><h4 id="查看环境-env-list">查看环境 env list</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda env list </span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230722231424466.png"alt="image-20230722231424466" /><figcaption aria-hidden="true">image-20230722231424466</figcaption></figure><h4 id="安装第三方包-install">安装第三方包 install</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install requests</span><br></pre></td></tr></table></figure><p>conda命令的安装好处就在于会直接帮你安装好依赖，但是坏处是慢，不稳定，而且有时候会不如pip下载灵活。因此，只要能切换到虚拟环境中去，那么依然可以使用pip命令进行安装。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install request</span><br></pre></td></tr></table></figure><h4 id="卸载第三方包-remove">卸载第三方包 remove</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda remove requests</span><br></pre></td></tr></table></figure><p>或者</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip uninstall requests</span><br></pre></td></tr></table></figure><h4 id="导入导出环境">导入导出环境</h4><p>导出当前环境的包信息可以用命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda env export &gt; name.yaml</span><br></pre></td></tr></table></figure><p>将包信息存入yaml文件中，当需要重新创建一个相同的虚拟环境时可以用：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda env create -f name.yaml</span><br></pre></td></tr></table></figure><h2 id="连接到pycharm">连接到Pycharm</h2><p>Pycharm相对更为方便，在<code>Setting =&gt; Project =&gt; Project Interpreter</code>里面修改 Project Interpreter。可能是一个小齿轮，也可能是Addinterpreter。</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230723001703414.png" alt="image-20230723001703414" style="zoom: 50%;" /></p><p>然后在里边设置你的conda本地路径，就可以使用了。</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230723001842057.png" alt="image-20230723001842057" style="zoom:67%;" /></p><h2 id="连接到vscode">连接到Vscode</h2><ol type="1"><li>安装Python插件</li></ol><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230723000208886.png"alt="image-20230723000208886" /><figcaption aria-hidden="true">image-20230723000208886</figcaption></figure><ol start="2" type="1"><li><p>配置Python解释器</p><ul><li>按Ctrl+Shift+P，输入python，选择解释器</li><li>添加解释器路径</li></ul></li></ol><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230723000957655.png"alt="添加成功后的情况" /><figcaption aria-hidden="true">添加成功后的情况</figcaption></figure><h2 id="最后">最后</h2><p>Anaconda 是一个非常好用的包管理软件，比如在Anaconda上使用jupyternotebook等，快速切换包，以及他的一些数据分析包。</p><h2 id="推荐阅读">推荐阅读</h2><p><ahref="https://research.computing.yale.edu/sites/default/files/files/anaconda.pdf">Introductionto Anaconda (yale.edu)</a> 耶鲁大学的一个PPT</p>]]></content>
      
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>yolov5</title>
      <link href="/2023/07/05/yolov5/"/>
      <url>/2023/07/05/yolov5/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>yolo系列基础学习</title>
      <link href="/2023/07/04/yoloV3/"/>
      <url>/2023/07/04/yoloV3/</url>
      
        <content type="html"><![CDATA[<h1 id="yolov1">Yolov1</h1><h2 id="核心内容">核心内容</h2><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230704171038267.png"alt="分而治之" /><figcaption aria-hidden="true">分而治之</figcaption></figure><p>①分而治之，其类似卷积神经网络，目的是通过分块找到物体中心，其核心思路就是一个莽，全都用CNN莽出来</p><p>②leaky ReLu <span class="math display">\[y=\begin{array}{l}  \left\{\begin{matrix}  x,x&gt;0 \\0.1x,otherwise\end{matrix}\right.    \end{array}\]</span> ③ 端到端训练</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/20180910130225149"alt="端到端训练" /><figcaption aria-hidden="true">端到端训练</figcaption></figure><h1 id="yolov2">Yolov2</h1><h2 id="同比v1的改进">同比v1的改进</h2><p><strong>tradeoff：折中</strong></p><p>batch normalization：某种正则化手段，BN</p><p>high resolution classifier：微调与训练模型</p><p>Convolutional With Anchor Boxes：anchor机制</p><ul><li><p>Dimension Clusters：选择anchorprior需要手动设置，采用k-means聚类找到一个合适的大小</p></li><li><p>Direct location prediction: 解决不稳定，相对位置预测</p></li></ul><p>Fine-Grained Features: 调整后的yolo将在13*13的特征上做检测任务</p><p>multi-scale training：多标准化输入训练</p><p>Darknet-19：backbone网络</p><h1 id="yolov3">Yolov3</h1><h2 id="基本流程">基本流程</h2><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/24215864-83d220ef29016abf"alt="基本组件" /><figcaption aria-hidden="true">基本组件</figcaption></figure><h2 id="保留部分">保留部分</h2><ul><li>分割检测</li><li>leaky ReLu</li><li>端到端训练，loss function 不变</li><li>BN正则化不变，放在leaky ReLu和每一层卷积后</li><li>mult scale training</li></ul><h2 id="基本组件">基本组件</h2><p>CBL：Yolov3网络结构的最小组件，由Conv+Bn+Leaky_relu组成</p><p>Res unit：借鉴Resnet网络中的残差结构，让网络可以构建的更深。</p><p>ResX：由一个CBL和X个残差组件构成</p><h2 id="基础操作">基础操作</h2><p>Concat：拼接</p><p>Add：张量相加，与shortcut功能一致</p><h2 id="backbone">backbone</h2><p>v3中没有池化层和全连接层，尺寸变换通过改变卷积和步长</p><p>backbone会将输入图片的尺寸缩短到原来的<spanclass="math inline">\(\frac{1}{32}\)</span>,所以要求输入图片得是32的倍数</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/24215864-e67c9e615638e745"alt="尺寸变换比较" /><figcaption aria-hidden="true">尺寸变换比较</figcaption></figure><p>这里要注意Darknet-19是要比Darknet-53快的，因此v3还提供了tinynet</p><h2 id="perdictions-across-scales">Perdictions across scales</h2><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230705105112921.png"alt="image-20230705105112921" /><figcaption aria-hidden="true">image-20230705105112921</figcaption></figure><p>这个借鉴了FPN(feature pyramidnetworks)，采用多尺度来对不同size的目标进行检测，越精细的gridcell就可以检测出越精细的物体。规律为1:2:4</p>]]></content>
      
      
      
        <tags>
            
            <tag> 视觉 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python高维数据分析实验报告</title>
      <link href="/2023/04/23/pythonHighDeminsion/"/>
      <url>/2023/04/23/pythonHighDeminsion/</url>
      
        <content type="html"><![CDATA[<h1 id="实验一-python基础语法学习总结">实验一Python基础语法学习总结</h1><h2 id="实验目的">实验目的</h2><p>学习Python基本语法</p><h2 id="实验场地与设备">实验场地与设备</h2><p>线上</p><h2 id="实验方式">实验方式</h2><p>阅读教程与程序设计</p><h2 id="实验设计">实验设计</h2><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/Python%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80.png"alt="Python语言基础" /><figcaption aria-hidden="true">Python语言基础</figcaption></figure><p><span class="math display">\[图1.1 Python基础语法学习实验设计\]</span></p><h2 id="实验内容">实验内容</h2><h3 id="python语法总结">1. Python语法总结</h3><h4 id="python基本语法">1.1 Python基本语法</h4><h4 id="基本语句">（1） 基本语句</h4><p>①首先是输入输出语句，输入语句比较简单为<code>name=input()</code>，基本输出语句为<code>print()</code>,拼接输出使用逗号。</p><p>② 注释采用<code>#</code> 进行书写</p><p>③代码风格：Python采用的是缩进式代码风格，所以对于复制粘贴比较不友好</p><p>④条件判断语句：<code>if 条件1 :...elif 条件2 : ... else : ...</code></p><p>⑤ 循环语句：</p><p>第一种是<code>for</code>循环：<code>for x in []:</code><code>for x in ...:</code>循环就是把每个元素代入变量x，然后执行缩进块的语句</p><p>第二种是<code>while</code>循环：<code>while 条件判断语句 :</code><code>break</code>、<code>continue</code>和java中用法相同</p><h4 id="数据类型">（2） 数据类型</h4><p><strong>①整数：</strong>对于很大的数，很难数清楚0的个数。Python允许在数字中间以_分隔。</p><p><strong>② 浮点数：</strong>允许使用科学计数法定义</p><p><strong>③字符串：</strong>在Python没有严格要求<code>''</code>和<code>""</code>的区别在，也就是说没有区分字符和字符串使用二者没有任何区别。</p><ul><li>转义符和Java中保持一致</li><li>Python允许用<code>r''</code>表示<code>''</code>内部的字符串默认不转义</li></ul><p><strong>④ 布尔值：</strong></p><p>在Python中要注意：<code>True</code>、<code>False</code>要注意开头首字母大写。可以进行与、或、非的运算，运算符分别为：<code>and</code>，<code>or</code>，<code>not</code></p><p><strong>⑤空值：</strong>空值用<code>None</code>表示，意义与Java中的<code>null</code>相同。</p><p><strong>⑥ list：</strong></p><p>list是Python内置的一种数据类型，list是一种有序的集合，可以随时添加和删除其中的元素。此数据类型在Java的实用类中有封装。list和数组很像，声明方式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">classname = [<span class="string">&#x27;老六&#x27;</span>,<span class="string">&#x27;老八&#x27;</span>,<span class="string">&#x27;老九&#x27;</span>]</span><br></pre></td></tr></table></figure><p>想要调取其中的某个元素也和数组一致，赋值修改等也相同<br />下面列举一下list的ADT</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">list:</span><br><span class="line">append(&#x27;Elem&#x27;)  # 在末尾添加新的元素</span><br><span class="line">insert(i,&#x27;Elem&#x27;) # 将元素插入指定位置</span><br><span class="line">pop() # 删除末尾元素</span><br><span class="line">pop(i) # 删除i处的元素</span><br><span class="line">len(list) # list列表的长度</span><br></pre></td></tr></table></figure><p>list允许混合类型，也允许list嵌套，从而出现多维数组。</p><p><strong>⑦ tuple</strong></p><p>tuple被称为元组，其最大的特点就是不可修改，声明方式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">classname = (<span class="string">&#x27;老六&#x27;</span>,<span class="string">&#x27;老八&#x27;</span>,<span class="string">&#x27;老九&#x27;</span>)</span><br></pre></td></tr></table></figure><p>tuple在定义时要确定元素个数，这里有一个问题，在定义只有一个元素的tuple时，Python语法会认为这是一个小括号，因此在定义一个元组的tuple时，要加一个<code>,</code>避免歧义。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t=(<span class="number">1</span>,)</span><br></pre></td></tr></table></figure><p><strong>⑧ 字典（dict）</strong></p><p>字典全称为dictionary，在Java实用类中叫hashmap。其由键值对（key-value）组成，查找速度快。下面是一种初始化方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d = &#123;<span class="string">&#x27;Michael&#x27;</span>: <span class="number">95</span>, <span class="string">&#x27;Bob&#x27;</span>: <span class="number">75</span>, <span class="string">&#x27;Tracy&#x27;</span>: <span class="number">85</span>&#125;</span><br></pre></td></tr></table></figure><p>也可以放入指定的key中：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d[<span class="string">&#x27;Adam&#x27;</span>] = <span class="number">67</span></span><br></pre></td></tr></table></figure><p>查找value:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d[<span class="string">&#x27;Adam&#x27;</span>]</span><br></pre></td></tr></table></figure><p>key与value是多对一的关系，key需要是一个不可变对象保证key做hash运算后的唯一性。如果多次对某个key赋值，后边的value会覆盖前面的value提供了几个函数：</p><ol type="1"><li>通过<code>in</code>来判断key是否在dict中，返回值为布尔值，格式为：<code>key in dict</code></li><li>get()方法，<code>dict.get('key',空返回值)</code>key不存在时返回空返回值，空返回值可自定义，如果没有定义的话返回None</li><li>pop()方法，删除key，如果有value也一并删除，格式为<code>pop('key')</code></li></ol><p><strong>⑨ 集合（set）</strong></p><p>set是一组key的集合,集合特点；无序性、确定性、互异性要创建一个set，需要提供一个list作为输入集合：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="built_in">set</span>([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure><ul><li>方法： <code>add(key)</code>添加一个新的元素<code>remove(key)</code>删除一个元素</li><li>两个set可以做交运算和并运算： 交运算：<code>s1&amp;s2</code>并运算：<code>s1|s2</code></li></ul><h4 id="理解变量">（3） 理解变量</h4><p>在Python中变量仅仅是一个一个字母，变量与所对应的值之间的关系靠指针联系起来的。所以很重要的一点就是：<strong>当我们使用变量时，更多的要关注变量指向的东西，他可能是值，也可能是一个函数，也可能是一个变量</strong></p><h4 id="模块">1.2 模块</h4><h4 id="模块导入">（1） 模块导入</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><h4 id="模块下载">（2） 模块下载</h4><p>模块下载有比较复杂的方法，也有比较傻瓜式的。先说复杂的，使用Python中自带的pip包管理工具，用命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install numpy</span><br></pre></td></tr></table></figure><p>但是使用pip需要事先了解要导的包的名字，而且不能批量导入，而且在Python编程里也有编程一分钟，导包一小时的说法。pip下载第三方库的源可能会很慢或者失效，需要会自己添加国内的高速镜像。</p><p>傻瓜式的导包，例如在pycharm中可以直接在代码中写出自己需要的包，然后交给pycharm自己去下载，或者用Anaconda提前构建好的Python的库环境。</p><h4 id="函数式编程">1.3 函数式编程</h4><h4 id="函数">（1） 函数</h4><p><strong>① 函数定义</strong></p><p>在Python中定义函数为，<code>def 函数名(参数):</code>然后，在缩进块中编写函数体，函数的返回值用<code>return</code>语句返回。<br />如果没有return语句，函数执行完毕后也会返回结果，只是结果为None。returnNone可以简写为return。</p><p>1）空函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">nop</span>():</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>在这里<code>pass</code>作为占位符，表示跳过，也可以用在<code>if</code>的缩进块。</p><p>2）参数限制：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(x, (<span class="built_in">int</span>, <span class="built_in">float</span>)):</span><br><span class="line">      <span class="keyword">raise</span> TypeError(<span class="string">&#x27;bad operand type&#x27;</span>)</span><br></pre></td></tr></table></figure><p>实际上参数限制就是定义一个报错，<code>isinstance()</code>判断数据类型，如果不是就提出一个错误。<strong>作为一个弱类型语言，定义这一步是很有必要的，有助于读懂代码。</strong></p><p>3）返回值：</p><p>Python允许返回多个值，其返回的实际上是一个tuple元组，但是也可以用两个变量接收。</p><p><strong>② 参数定义</strong></p><p>在Python中函数参数的定义也比较灵活，提供位置参数、默认参数、可变参数、关键字（key）参数等</p><p>1）位置参数：位置参数指的是参数在传入时，实参和形参有着严格的位置对应关系，为常用参数形式。</p><p>2）默认参数：默认参数是指在位置参数的基础上为其添加默认值，有默认值的参数为默认参数，没有默认值的参数为必选参数基本定义形式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">my_def</span>(<span class="params">a,b=<span class="number">1</span></span>):</span><br><span class="line">    a=b+<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> </span><br></pre></td></tr></table></figure><p>需要注意的是：</p><ul><li>默认参数必须在必选参数后边，否则会无法辨认是否输入必选参数，从而报错。</li><li>默认参数的默认值一定是<strong>不变对象</strong>，由于Python中的变量定义为指针指向，会导致可变对象值发生变化</li></ul><p>3）不可变对象有：数值类型、字符串、tuple元组、None等</p><p>4）可变参数：可变参数指的是参数的数目不固定，定义形式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">my_function</span>(<span class="params">*v</span>):</span><br><span class="line">    <span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> vi <span class="keyword">in</span> v:</span><br><span class="line">        <span class="built_in">sum</span>+=vi</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span></span><br></pre></td></tr></table></figure><p>在可变参数中传入的所有参数将作为一个tuple被接收，该tuple的变量名为函数在定义时的形参名，定义时的需要在参数名前加一个<code>*</code>。</p><p>5）关键字（key）参数</p><p>此处的关键字和c语言中的关键字并不是一个意义，而是在dict中的key的意义。即在传递参数时，同时传递键（key）和值(value),Python会自动封装为一个dict。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">my_function</span>(<span class="params">**v</span>):</span><br><span class="line">    <span class="built_in">print</span>(v)</span><br><span class="line">    <span class="keyword">return</span> </span><br></pre></td></tr></table></figure><p>6）命名关键字参数</p><p>在关键字参数上，进一步限制传入的key的命名，就有了命名关键词参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">person</span>(<span class="params">name, age, *, city, job</span>):</span><br><span class="line">    <span class="built_in">print</span>(name, age, city, job)</span><br></pre></td></tr></table></figure><p>这里需要一个<code>*</code>区分位置参数与命名关键字参数，如果在这之前有可变参数，那么就不需要加<code>*</code>。<br />命名关键字参数必须传入参数名，这和位置参数不同。如果没有传入参数名，调用将报错：</p><p>7）参数组合</p><p>在一个函数中使用多个参数要保证其中的顺序，依次为：必选参数、默认参数、可变参数、命名关键字参数和关键字参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">onefunction</span>(<span class="params">a,b,c=<span class="number">0</span>,*args,job,city,**kw</span>):</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>tips：</p><ul><li>使用<code>*args</code>和<code>**kw</code>是Python的习惯写法。</li><li>可变参数和关键字参数有一点层级的感觉，中间包裹的是命名关键字参数这个比较尴尬的参数。</li></ul><p><strong>③ 递归函数</strong></p><p>写法与Java相同。</p><h4 id="实用方法">（2） 实用方法</h4><p><strong>① 切片</strong></p><p>切片是一个针对tuple和list方便地取元素的方法，语法规则：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">L[起始坐标:终止坐标:步长]</span><br></pre></td></tr></table></figure><p>当起始坐标为0时可以省略；步长为1时可以省略。</p><p><strong>② 迭代</strong></p><p>迭代是循环的增强，但是想要弄清迭代，需要知道两件事：一个是能不能迭代，一个是迭代出的数据是什么</p><p>想要知道一个数据能否迭代可以通过一个函数来完成：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections.abc <span class="keyword">import</span> Iterable</span><br><span class="line">L=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line"><span class="built_in">isinstance</span>(L,Iterable)</span><br></pre></td></tr></table></figure><p>迭代出的是什么，和要迭代的对象的储存方式，要特殊记忆一下dic。</p><p><strong>③ 列表生成器</strong></p><p>一种快捷生成list的方式，一个例子如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[x * x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>)]</span><br></pre></td></tr></table></figure><p>如果想要筛选生成的值，可以在<code>for</code>后加上<code>if</code>作为<strong>筛选条件</strong>，注意这里是筛选条件，因此这里和平时的<code>if else</code>并不是一个东西。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[x * x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>) <span class="keyword">if</span> x % <span class="number">2</span> == <span class="number">0</span>]</span><br></pre></td></tr></table></figure><p><strong>④ 生成器</strong></p><p>生成器是一种惰性的计算方式。包含<code>yield</code>关键字，当一个函数包含<code>yield</code>关键字时，他就成了一个generator函数。<code>yield</code>在generator函数中起到了一个return的作用，即到<code>yield</code>便返回。在调用时，使用一个变量接受一个generator对象。使用<code>next()</code>函数依次获得下一个返回值。</p><p><strong>⑤ 迭代器</strong></p><p>区分<code>Iterable</code>和<code>Iterator</code></p><p><code>Iterable</code>是可迭代的，是直接可用于<code>for</code>循环的。包括dict、list、tuple、set、str、grenerator。<code>Iterator</code>是迭代器，是直接可用于<code>next()</code>函数的，生成器都是<code>Iterator</code>对象，集合数据类型可以通过<code>iter()</code>获取<code>Interator</code>对象。</p><h4 id="函数式编程-1">（3） 函数式编程</h4><p>函数式编程是一种面向过程的编程思想，实际上是将复杂问题转化为一个个函数。</p><p>在Java的函数定义中，除去<code>void</code>类型不返回值，其余的都需要返回值。因此也就经常存在，使用一个变量接受函数值：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">function</span><span class="params">(x,y)</span>&#123;</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> a=function(x,y);</span><br></pre></td></tr></table></figure><p>那么是不是存在一种可能，我们可以将函数嵌套，让函数调用函数，让函数返回函数，彻底抛弃变量？</p><p>抛弃变量、只有函数就是彻底的函数式编程</p><p><strong>① 理解高阶函数</strong></p><p>之前有过变量名和值的理解，在Python中变量名和值是一个指针指向的关系。同理，函数名和函数也是这样的，函数名也是一个变量。也就是说，我们可以通过函数名，拿到函数体。也就是说函数名是什么并不重要，我们看中的是函数体。</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/%E7%BB%98%E5%9B%BE1.png"alt="绘图1" /><figcaption aria-hidden="true">绘图1</figcaption></figure><p>那么设想一种情况，现在我们定义了函数f2，那么我可以随便写一个函数，然后返回一个变量f2，那么实际上我就拿到了函数体。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">f2</span>(<span class="params">a,b</span>):</span><br><span class="line">    <span class="keyword">return</span> a+b</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">f3</span>():</span><br><span class="line">    <span class="keyword">return</span> f2</span><br><span class="line"><span class="built_in">print</span>(f3()(<span class="number">1</span>,<span class="number">2</span>))</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20220909173741530.png"alt="image-20220909173741530" /><figcaption aria-hidden="true">image-20220909173741530</figcaption></figure><p>然后我们在设想另一种情况，现在我们定义了另一种情况，我们在一个函数中写了一个f1作为局部变量，那么我就可以传入变量f2，然后就相当于传入了函数体。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">f2</span>(<span class="params">a,b</span>):</span><br><span class="line">    <span class="keyword">return</span> a+b</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">f1</span>(<span class="params">a,b,f</span>):</span><br><span class="line">    <span class="keyword">return</span> f(a,b)</span><br><span class="line"><span class="built_in">print</span>(f1(<span class="number">1</span>,<span class="number">2</span>,f2))</span><br></pre></td></tr></table></figure><p>现在就可以进行一个区分：</p><ul><li><code>f</code>代表函数名，是变量</li><li><code>f()</code>代表数值，是函数的返回值，返回值是一个量</li></ul><p>高阶函数，就是让函数的参数能够接收别的函数。</p><p>实用的几个函数，有必要查表即可</p><p><strong>② 返回函数</strong></p><p>同上文理解，只不过是将一个函数嵌套入了另一个函数</p><p><strong>③ lambda表达式</strong></p><p>与Java中语法相同，目的是为了简化返回函数嵌套</p><h4 id="面向对象编程">1.4 面向对象编程</h4><h4 id="类和对象">（1）类和对象</h4><p>创建类：语法如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">类名</span>(<span class="title class_ inherited__">继承的类</span>):</span><br></pre></td></tr></table></figure><p>python的类非常随意，几乎可以不定义就能用。在类中自带有一个构造函数<code>__init__()</code>,此函数可以重新定义</p><p>生成对象：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a=A()</span><br></pre></td></tr></table></figure><h4 id="访问权限">（2）访问权限</h4><p>如果要让内部属性不被外部访问，可以把属性的名称前加上两个下划线<code>__</code>，在Python中，实例的变量名如果以<code>__</code>开头，就变成了一个私有变量（private），只有内部可以访问，外部不能访问。</p><p>此外，<code>__ __</code>这种变量都是特殊变量，在不清楚的时候不要随便乱改</p><h4 id="继承和多态">（3）继承和多态</h4><p>和Java中的思想完全相同</p><h4 id="常用变量和方法">（4）常用变量和方法</h4><p>① <code>__slots__</code></p><p>用这个变量可以起到参数列表的功能，可以在一定程度上限制参数的变量名，用turple进行限定</p><p>② <code>@property</code></p><p>注解编程，可以起到一个简化定义setter和getter函数的作用。<spanclass="citation"data-cites="property注解在getter方法上">@property注解在getter方法上</span>，然后会自动生成<span class="citation" data-cites="函数名.setter">@函数名.setter</span>的注解，但是要注意的一点是，在getter中就不能使用函数名作为自身的调用值，否则会出现无限的调用，产生爆栈。</p><p>③ 多继承</p><p>与Java相同</p><p>⑤ <code>__str__</code>:和Java中的toString方法相同</p><h4 id="错误调试">1.5 错误调试</h4><h4 id="错误处理">（1）错误处理</h4><p>参照Java中，对比来学习即可：</p><p>两种方法，一是尝试，二是抛出，尝试采用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line"><span class="keyword">pass</span></span><br><span class="line"><span class="keyword">except</span> baseexception  :</span><br><span class="line"><span class="keyword">pass</span></span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line"><span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>抛出采用<code>raise</code>关键字</p><h4 id="测试">（2）测试</h4><p>①断言：<code>assert</code>的意思是，表达式<code>n != 0</code>应该是<code>True</code>，否则，根据程序运行的逻辑，后面的代码肯定会出错。</p><p>如果断言失败，<code>assert</code>语句本身就会抛出<code>AssertionError</code></p><p>② 断点：在强大IDE的辅助下，使用断点调试应该是最简单的。</p><h3 id="实践">2.实践</h3><h4 id="石头剪子布">2.1 石头剪子布</h4><p>使用random包中的random函数和条件控制语句，模拟两个电脑互相猜拳：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">win</span>(<span class="params">pc,cc</span>):</span><br><span class="line">    <span class="keyword">if</span> (cc==<span class="number">1</span> <span class="keyword">and</span> pc==<span class="number">2</span>) <span class="keyword">or</span> (cc==<span class="number">2</span> <span class="keyword">and</span> pc==<span class="number">3</span>)<span class="keyword">or</span>(cc==<span class="number">3</span> <span class="keyword">and</span> pc==<span class="number">1</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;电脑一输&quot;</span>)</span><br><span class="line">    <span class="keyword">elif</span> pc==cc:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;平&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;电脑二输&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">computer_choice</span>():</span><br><span class="line">    cc=random.randint(<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">return</span> cc</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show</span>(<span class="params">pc,cc</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;电脑一的出招为&quot;</span>,pc)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;电脑二的出招为&quot;</span>,cc)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">        pc=computer_choice()</span><br><span class="line">        cc=computer_choice()</span><br><span class="line">        show(pc,cc)</span><br><span class="line">        win(pc,cc)</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20220914212607801.png"alt="image-20220914212607801" /><figcaption aria-hidden="true">image-20220914212607801</figcaption></figure><p>改进提升一下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">win</span>(<span class="params">pc,cc</span>):</span><br><span class="line">    <span class="keyword">if</span> (cc==<span class="number">1</span> <span class="keyword">and</span> pc==<span class="number">2</span>) <span class="keyword">or</span> (cc==<span class="number">2</span> <span class="keyword">and</span> pc==<span class="number">3</span>)<span class="keyword">or</span>(cc==<span class="number">3</span> <span class="keyword">and</span> pc==<span class="number">1</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;玩家输&quot;</span>)</span><br><span class="line">    <span class="keyword">elif</span> pc==cc:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;平&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;玩家赢&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">computer_choice</span>():</span><br><span class="line">    cc=random.randint(<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">return</span> cc</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">str</span>(<span class="params">cc</span>):</span><br><span class="line">    <span class="keyword">if</span> cc==<span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;石头&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> cc==<span class="number">2</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;剪刀&#x27;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;布&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show</span>(<span class="params">f,pc,cc</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;电脑一的出招为&quot;</span>,f(pc))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;电脑二的出招为&quot;</span>,f(cc))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">        cc=computer_choice()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;请输入：1.石头 2.剪刀 3.布&quot;</span>)</span><br><span class="line">        pc=<span class="built_in">input</span>()</span><br><span class="line">        show(<span class="built_in">str</span>,pc,cc)</span><br><span class="line">        win(pc,cc)</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20220914213324805.png"alt="image-20220914213324805" /><figcaption aria-hidden="true">image-20220914213324805</figcaption></figure><h4 id="atm模拟">2.2 ATM模拟</h4><p>通过类和对象简单的设计了一个ATM取钱模拟器</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> Account</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ATM</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,money,accounts</span>):</span><br><span class="line">        self.money=money</span><br><span class="line">        self.accounts=accounts</span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">money</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self._money;</span><br><span class="line"><span class="meta">    @money.setter</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">money</span>(<span class="params">self,value</span>):</span><br><span class="line">        self._money=value</span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">accounts</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self._accounts</span><br><span class="line"><span class="meta">    @accounts.setter</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">accounts</span>(<span class="params">self,value</span>):</span><br><span class="line">        self._accounts=value</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">searchId</span>(<span class="params">self,<span class="built_in">id</span></span>):</span><br><span class="line">        <span class="keyword">for</span> account <span class="keyword">in</span> self.accounts:</span><br><span class="line">            <span class="keyword">if</span> account.<span class="built_in">id</span>==<span class="built_in">id</span>:</span><br><span class="line">                <span class="keyword">return</span> account</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">lode</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;请输入账号id&#x27;</span>)</span><br><span class="line">        <span class="built_in">id</span> = <span class="built_in">input</span>()</span><br><span class="line">        account1 = self.searchId(<span class="built_in">id</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;请输入密码&#x27;</span>)</span><br><span class="line">        password = <span class="built_in">input</span>()</span><br><span class="line">        <span class="keyword">if</span> password == account1.password:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;欢迎&quot;</span>, account1.name)</span><br><span class="line">        <span class="keyword">return</span> account1</span><br><span class="line">    <span class="comment"># 存钱</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">save_money</span>(<span class="params">self</span>):</span><br><span class="line">        account=self.lode();</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;请输入要存入的数目&quot;</span>)</span><br><span class="line">        saveMneyValue=<span class="built_in">input</span>()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;存款成功&#x27;</span>)</span><br><span class="line">        account.remain=<span class="built_in">int</span>(account.remain)+<span class="built_in">int</span>(saveMneyValue)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;您的账户余额为&#x27;</span>,account.remain)</span><br><span class="line">        self.money=self.money+<span class="built_in">int</span>(saveMneyValue)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 取钱</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">withdraw_money</span>(<span class="params">self</span>):</span><br><span class="line">        account=self.lode()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;请输入要取出的数目&#x27;</span>)</span><br><span class="line">        withdrawMoneyValue=<span class="built_in">input</span>()</span><br><span class="line">        <span class="keyword">if</span> account.remain &gt; withdrawMoneyValue:</span><br><span class="line">            account.remain=<span class="built_in">int</span>(account.remain)-<span class="built_in">int</span>(withdrawMoneyValue)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;取款成功，您的账户余额为&#x27;</span>,account.remain)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;您的账户余额不足&#x27;</span>)</span><br><span class="line">        self.money=<span class="built_in">int</span>(self.money)-<span class="built_in">int</span>(withdrawMoneyValue)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__str__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;当前ATM中有金额&quot;</span>,self.money,<span class="string">&quot;元&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># atm1=ATM(1000)</span></span><br><span class="line">    <span class="comment"># atm1.__str__()</span></span><br><span class="line">    <span class="comment"># atm1.ave_money(200)</span></span><br><span class="line">    <span class="comment"># atm1.__str__()</span></span><br><span class="line">    <span class="comment"># atm1.withdraw_money(200)</span></span><br><span class="line">    <span class="comment"># atm1.__str__()</span></span><br><span class="line">    accounts=[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        name=<span class="built_in">input</span>()</span><br><span class="line">        <span class="built_in">id</span> = <span class="built_in">input</span>()</span><br><span class="line">        password=<span class="built_in">input</span>()</span><br><span class="line">        remain=<span class="built_in">input</span>()</span><br><span class="line">        accounts.append(Account.account(name, <span class="built_in">id</span>, password, remain))</span><br><span class="line">    atm2=ATM(<span class="number">10000</span>,accounts)</span><br><span class="line">    atm2.save_money()</span><br><span class="line">    atm2.withdraw_money()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">account</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,name,<span class="built_in">id</span>,password,remain</span>):</span><br><span class="line">        self.name=name</span><br><span class="line">        self.remain=remain</span><br><span class="line">        self.password=password</span><br><span class="line">        self.<span class="built_in">id</span>=<span class="built_in">id</span></span><br><span class="line"></span><br><span class="line">    __slots__ = (<span class="string">&#x27;name&#x27;</span>,<span class="string">&#x27;remain&#x27;</span>,<span class="string">&#x27;password&#x27;</span>,<span class="string">&#x27;id&#x27;</span>)</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20220914214759256.png"alt="image-20220914214759256" /><figcaption aria-hidden="true">image-20220914214759256</figcaption></figure><h4 id="圣诞树画图">2.3 圣诞树画图</h4><p>使用Python自带的turtle包，进行圣诞树绘制：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> turtle</span><br><span class="line"></span><br><span class="line">screen = turtle.Screen()</span><br><span class="line">screen.setup(<span class="number">375</span>, <span class="number">700</span>)</span><br><span class="line"></span><br><span class="line">circle = turtle.Turtle()</span><br><span class="line">circle.shape(<span class="string">&#x27;circle&#x27;</span>)</span><br><span class="line">circle.color(<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">circle.speed(<span class="string">&#x27;fastest&#x27;</span>)</span><br><span class="line">circle.up()</span><br><span class="line"></span><br><span class="line">square = turtle.Turtle()</span><br><span class="line">square.shape(<span class="string">&#x27;square&#x27;</span>)</span><br><span class="line">square.color(<span class="string">&#x27;green&#x27;</span>)</span><br><span class="line">square.speed(<span class="string">&#x27;fastest&#x27;</span>)</span><br><span class="line">square.up()</span><br><span class="line"></span><br><span class="line">circle.goto(<span class="number">0</span>, <span class="number">280</span>)</span><br><span class="line">circle.stamp()</span><br><span class="line"></span><br><span class="line">k = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">13</span>):</span><br><span class="line">    y = <span class="number">30</span> * i</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i - k):</span><br><span class="line">        x = <span class="number">30</span> * j</span><br><span class="line">        square.goto(x, -y + <span class="number">280</span>)</span><br><span class="line">        square.stamp()</span><br><span class="line">        square.goto(-x, -y + <span class="number">280</span>)</span><br><span class="line">        square.stamp()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">4</span> == <span class="number">0</span>:</span><br><span class="line">        x = <span class="number">30</span> * (j + <span class="number">1</span>)</span><br><span class="line">        circle.color(<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">        circle.goto(-x, -y + <span class="number">280</span>)</span><br><span class="line">        circle.stamp()</span><br><span class="line">        circle.goto(x, -y + <span class="number">280</span>)</span><br><span class="line">        circle.stamp()</span><br><span class="line">        k += <span class="number">3</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">4</span> == <span class="number">3</span>:</span><br><span class="line">        x = <span class="number">30</span> * (j + <span class="number">1</span>)</span><br><span class="line">        circle.color(<span class="string">&#x27;yellow&#x27;</span>)</span><br><span class="line">        circle.goto(-x, -y + <span class="number">280</span>)</span><br><span class="line">        circle.stamp()</span><br><span class="line">        circle.goto(x, -y + <span class="number">280</span>)</span><br><span class="line">        circle.stamp()</span><br><span class="line"></span><br><span class="line">square.color(<span class="string">&#x27;brown&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">13</span>, <span class="number">17</span>):</span><br><span class="line">    y = <span class="number">30</span> * i</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">        x = <span class="number">30</span> * j</span><br><span class="line">        square.goto(x, -y + <span class="number">280</span>)</span><br><span class="line">        square.stamp()</span><br><span class="line">        square.goto(-x, -y + <span class="number">280</span>)</span><br><span class="line">        square.stamp()</span><br><span class="line">turtle.mainloop()</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20220914215352995.png"alt="image-20220914215352995" /><figcaption aria-hidden="true">image-20220914215352995</figcaption></figure><h2 id="总结">3.总结</h2><p>Python作为一个弱类型语言，是有他的弊端的，在一些需要数据类型转换和严格控制数据类型的情况下，会非常难受。而Python最大的优势在于有大量的库，这些库在特定的编程领域会非常便利。Python本身的语言具有极强的灵活性，而灵活性的言外之意就是规范性很难确定。因此，Python的重点是将第三方包为我所用，在数值计算中发挥他最大的作用。</p><h1 id="实验二-python科学计算库和高维数据导入方法">实验二PYTHON科学计算库和高维数据导入方法</h1><h2 id="实验目的-1">实验目的</h2><ol type="1"><li>掌握基本的numpy对象及其对应方法</li><li>掌握常用的numpy数学函数，学习查找numpy帮助文档</li><li>重点学习numpy线性代数方法</li><li>掌握matplotlib的绘图对象关系</li><li>掌握基本的绘制图形的方法，包括绘制、属性设置、子图</li><li>能够通过查阅文档、示例，画出复杂图像</li><li>导入mat数据集</li></ol><h2 id="实验场地与设备-1">实验场地与设备</h2><p>实验室4074</p><h2 id="实验方式-1">实验方式</h2><p>阅读教程与程序设计</p><h2 id="实验设计-1">实验设计</h2><p>使用corn数据集进行学习</p><h2 id="实验内容-1">实验内容</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">data=sio.loadmat(<span class="string">&quot;NIRcorn.mat&quot;</span>)</span><br><span class="line"><span class="comment"># 首先输出data观察一下data的组成</span></span><br><span class="line"><span class="comment"># print(data)</span></span><br><span class="line"><span class="comment"># 观察到下面的数据实际上是一个dict,那么就可以通过k-v进行取值。</span></span><br><span class="line"><span class="comment"># print(data.keys())</span></span><br><span class="line"><span class="comment"># 输出结果如下</span></span><br><span class="line"><span class="comment"># &#x27;__header__&#x27;, &#x27;__version__&#x27;, &#x27;__globals__&#x27;, &#x27;m5spec&#x27;, &#x27;cornspect&#x27;,</span></span><br><span class="line"><span class="comment"># &#x27;cornwavelength&#x27;, &#x27;propvals&#x27;, &#x27;cornprop&#x27;, &#x27;NIRcoin&#x27;, &#x27;information&#x27;,</span></span><br><span class="line"><span class="comment"># &#x27;mp5spec&#x27;, &#x27;mp6spec&#x27;, &#x27;m5nbs&#x27;, &#x27;mp5nbs&#x27;, &#x27;mp6nbs&#x27;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">首先debug，观察变量信息，发现header、version、global都没有什么实际用处，应该是数据集作者做的标注</span></span><br><span class="line"><span class="string">通过查找原数据集页面，得知：</span></span><br><span class="line"><span class="string">information:Information about the data,数据说明</span></span><br><span class="line"><span class="string">以下都是根据NBS的玻璃标准划分的仪器信息</span></span><br><span class="line"><span class="string">    m5nbs:NBS glass stds on m5 </span></span><br><span class="line"><span class="string">    mp5nbs:NBS glass stds on mp5 </span></span><br><span class="line"><span class="string">    mp6nbs:NBS glass stds on mp6</span></span><br><span class="line"><span class="string">这些和玉米都没有关系</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">查阅翻译：</span></span><br><span class="line"><span class="string">cornspect：吸光率数值</span></span><br><span class="line"><span class="string">cornwavelength：玉米波长</span></span><br><span class="line"><span class="string">cornprop：玉米的一些属性</span></span><br><span class="line"><span class="string">propvals:Property values for samples，这个里边有 &#x27;Moisture&#x27;,&#x27;Oil&#x27;,&#x27;Protein &#x27;,&#x27;Starch&#x27;  </span></span><br><span class="line"><span class="string">下面这些是从三台不同的仪器上获得的光谱：</span></span><br><span class="line"><span class="string">    m5spec:Spectra on instrument m5 </span></span><br><span class="line"><span class="string">    mp5spec:Spectra on instrument mp5</span></span><br><span class="line"><span class="string">    mp6spec:Spectra on instrument mp6 </span></span><br><span class="line"><span class="string">观察provals和cornprop的值，我们可以发现，这二者数据一模一样，所以只需要使用conprop即可。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">a=data[&#x27;m5spec&#x27;]</span></span><br><span class="line"><span class="string">print(type(a))</span></span><br><span class="line"><span class="string">print(a)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># print(a)</span></span><br><span class="line"><span class="comment"># 经过测试是可行的，但是里边还有一些其他的组成</span></span><br><span class="line"><span class="comment"># debug观察，发现a中只有一个元素就是我们所输出的</span></span><br><span class="line"><span class="comment"># 并且该数据的数据类型为&lt;class &#x27;numpy.ndarray&#x27;&gt;</span></span><br><span class="line"><span class="comment"># 又观察到内部实际上存在几个“表头”，所以他实际上是一个结构数组，</span></span><br><span class="line"><span class="comment"># 转到MATLAB观察原数据，发现确实是一个结构体，在读取时自动转化为了结构数组</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># m5spec=data[&#x27;m5spec&#x27;]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面开始正式分析画图：</span></span><br><span class="line">cornwavelength=data[<span class="string">&quot;cornwavelength&quot;</span>]</span><br><span class="line">x=[]</span><br><span class="line"><span class="comment"># 输出观察发现，是一个ndarray组成的list所以只取第一个元素</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(cornwavelength)):</span><br><span class="line">    x.append(cornwavelength[i][<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 获取吸光率</span></span><br><span class="line">cornspect = data[<span class="string">&#x27;cornspect&#x27;</span>]</span><br><span class="line"><span class="comment"># 随机取出五组透光率</span></span><br><span class="line"><span class="comment"># 先随机生成五组数据</span></span><br><span class="line">rd=np.random.randint(<span class="number">0</span>,<span class="number">80</span>,<span class="number">5</span>)</span><br><span class="line"><span class="comment"># 存储透光率数据</span></span><br><span class="line">y1 = []</span><br><span class="line">y2 = []</span><br><span class="line">y3 = []</span><br><span class="line">y4 = []</span><br><span class="line">y5 = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">700</span>):</span><br><span class="line">    y1.append(cornspect[rd[<span class="number">0</span>], i])</span><br><span class="line">    y2.append(cornspect[rd[<span class="number">1</span>], i])</span><br><span class="line">    y3.append(cornspect[rd[<span class="number">2</span>], i])</span><br><span class="line">    y4.append(cornspect[rd[<span class="number">3</span>], i])</span><br><span class="line">    y5.append(cornspect[rd[<span class="number">4</span>], i])</span><br><span class="line"><span class="comment"># 导入字体</span></span><br><span class="line">matplotlib.rc(<span class="string">&quot;font&quot;</span>,family=<span class="string">&#x27;DengXian&#x27;</span>)</span><br><span class="line"><span class="comment"># 绘制图像</span></span><br><span class="line">fig=plt.figure(<span class="number">1</span>)</span><br><span class="line">plt.plot(x,y1,label=<span class="built_in">str</span>(rd[<span class="number">0</span>])+<span class="string">&#x27;号样本&#x27;</span>)</span><br><span class="line">plt.plot(x,y2,label=<span class="built_in">str</span>(rd[<span class="number">1</span>])+<span class="string">&#x27;号样本&#x27;</span>)</span><br><span class="line">plt.plot(x,y3,label=<span class="built_in">str</span>(rd[<span class="number">2</span>])+<span class="string">&#x27;号样本&#x27;</span>)</span><br><span class="line">plt.plot(x,y4,label=<span class="built_in">str</span>(rd[<span class="number">3</span>])+<span class="string">&#x27;号样本&#x27;</span>)</span><br><span class="line">plt.plot(x,y5,label=<span class="built_in">str</span>(rd[<span class="number">4</span>])+<span class="string">&#x27;号样本&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加图例</span></span><br><span class="line">plt.legend()</span><br><span class="line"><span class="comment"># 添加网格</span></span><br><span class="line">plt.grid(linestyle=<span class="string">&#x27;-.&#x27;</span>)</span><br><span class="line"><span class="comment"># 添加坐标轴名称</span></span><br><span class="line">plt.xlabel(<span class="string">&quot;波长/nm&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;吸光率&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># 绘制蛋白质等</span></span><br><span class="line">plt.clf()</span><br><span class="line"><span class="comment"># 导入玉米特征矩阵</span></span><br><span class="line">cornprop=data[<span class="string">&#x27;cornprop&#x27;</span>]</span><br><span class="line"><span class="comment"># 水分</span></span><br><span class="line">Moisture=cornprop[:,<span class="number">0</span>]</span><br><span class="line"><span class="comment"># 油脂</span></span><br><span class="line">Oil=cornprop[:,<span class="number">1</span>]</span><br><span class="line"><span class="comment"># 蛋白质</span></span><br><span class="line">Protein=cornprop[:,<span class="number">2</span>]</span><br><span class="line"><span class="comment"># 淀粉</span></span><br><span class="line">Starch=cornprop[:,<span class="number">3</span>]</span><br><span class="line"><span class="comment"># 随机抽取绘制饼图</span></span><br><span class="line">plt.pie(cornprop[rd[<span class="number">4</span>],:],labels=[<span class="string">&#x27;Moisture&#x27;</span>,<span class="string">&#x27;Oil&#x27;</span>,<span class="string">&#x27;Protein &#x27;</span>,<span class="string">&#x27;Starch&#x27;</span>],explode=(<span class="number">0</span>, <span class="number">0.2</span>, <span class="number">0</span>, <span class="number">0</span>),autopct=<span class="string">&#x27;%.2f%%&#x27;</span>)</span><br><span class="line">plt.title(<span class="built_in">str</span>(rd[<span class="number">4</span>])+<span class="string">&#x27;号样本的化学成分饼图&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.clf()</span><br><span class="line"><span class="comment"># 生成一个序号</span></span><br><span class="line">x=np.linspace(<span class="number">1</span>,<span class="number">80</span>,<span class="number">80</span>)</span><br><span class="line"><span class="comment"># 绘制不同化学成分的比较</span></span><br><span class="line">plt.plot(x,Moisture,label=<span class="string">&#x27;水分&#x27;</span>)</span><br><span class="line">plt.plot(x,Oil,label=<span class="string">&#x27;油脂&#x27;</span>)</span><br><span class="line">plt.plot(x,Protein,label=<span class="string">&#x27;蛋白质&#x27;</span>)</span><br><span class="line">plt.plot(x,Starch,label=<span class="string">&#x27;淀粉&#x27;</span>)</span><br><span class="line"><span class="comment"># 添加标题</span></span><br><span class="line">plt.title(<span class="string">&#x27;化学成分对比图&#x27;</span>)</span><br><span class="line"><span class="comment"># 添加坐标轴</span></span><br><span class="line">plt.xlabel(<span class="string">&#x27;X&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Y&#x27;</span>)</span><br><span class="line"><span class="comment"># 添加图例</span></span><br><span class="line">plt.legend(loc=<span class="string">&#x27;right&#x27;</span>)</span><br><span class="line"><span class="comment"># 添加网格</span></span><br><span class="line">plt.grid(linestyle=<span class="string">&#x27;-.&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">plt.clf()</span><br><span class="line"><span class="comment"># 求各个属性均值</span></span><br><span class="line">Moisture_ave=np.mean(Moisture)</span><br><span class="line">Oil_ave=np.mean(Oil)</span><br><span class="line">Protein_ave=np.mean(Protein)</span><br><span class="line">Starch_ave=np.mean(Starch)</span><br><span class="line"><span class="comment"># 设置权重</span></span><br><span class="line">weight=[Moisture_ave,Oil_ave,Protein_ave,Starch_ave]</span><br><span class="line"><span class="comment"># 设置序列点</span></span><br><span class="line">x=np.linspace(<span class="number">0</span>,<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line"><span class="comment"># 绘制柱状图</span></span><br><span class="line">plt.barh(x,weight,tick_label=[<span class="string">&#x27;Moisture&#x27;</span>,<span class="string">&#x27;Oil&#x27;</span>,<span class="string">&#x27;Protein &#x27;</span>,<span class="string">&#x27;Starch&#x27;</span>])</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Attribute&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Attribute_mean&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;各属性均值图&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>根据样本，可大概观察出1400波长以上透光率相对变化比较明显</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221002234045488.png" alt="image-20221002234045488"  /><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221002234758742.png" alt="image-20221002234758742"  /></p><p>各属性对比饼图，属性均值图：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221002234112149.png" alt="image-20221002234112149"  /></p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221002234218414.png" alt="image-20221002234218414"  /></p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221003002332397.png"alt="image-20221003002332397" /><figcaption aria-hidden="true">image-20221003002332397</figcaption></figure><h2 id="总结-1">总结</h2><p>mat数据集中可能存在结构体，通过scipy导入后，会自动将结构体转换为ndarray的结构数组；会将所有属性统一封装成dict，通过k-v取出。</p><h1 id="实验三-python矩阵运算">实验三 Python矩阵运算</h1><h2 id="实验目的-2">实验目的</h2><ol type="1"><li>掌握Python中的矩阵运算</li><li>尝试使用特征值分解协方差矩阵的方式进行降维</li></ol><h2 id="实验场地与设备-2">实验场地与设备</h2><p>实验室4074</p><h2 id="实验方式-2">实验方式</h2><p>程序设计</p><h2 id="实验设计-2">实验设计</h2><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/%E5%AE%9E%E9%AA%8C%E4%B8%89.png"alt="实验三" /><figcaption aria-hidden="true">实验三</figcaption></figure><h2 id="实验内容-2">实验内容</h2><h3 id="矩阵乘积">矩阵乘积</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">基本矩阵运算练习</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 矩阵乘法</span></span><br><span class="line">x=np.linspace(<span class="number">0</span>,<span class="number">8</span>,<span class="number">9</span>).reshape(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">y=np.linspace(<span class="number">1</span>,<span class="number">9</span>,<span class="number">9</span>).reshape(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"><span class="comment"># 内积</span></span><br><span class="line">innerZ=np.inner(x,y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;矩阵内积：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(innerZ)</span><br><span class="line"><span class="comment"># 张量积</span></span><br><span class="line">outerZ=np.outer(x,y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;矩阵张量积：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(outerZ)</span><br><span class="line"><span class="comment"># 线性代数矩阵乘法</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;线性代数矩阵乘法&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(np.dot(x,y))</span><br></pre></td></tr></table></figure><p>运行结果：<img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221016202747098.png" alt="image-20221016202747098" style="zoom: 67%;" /></p><h3 id="范数">范数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 范数</span></span><br><span class="line"><span class="comment"># 初始化一个向量</span></span><br><span class="line">a=np.linspace(<span class="number">0</span>,<span class="number">9</span>,<span class="number">10</span>)</span><br><span class="line"><span class="comment"># 向量二范数</span></span><br><span class="line">a_norm = np.linalg.norm(a,<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;向量a的二范数为&quot;</span>,a_norm)</span><br><span class="line"><span class="comment"># 矩阵二范数</span></span><br><span class="line">x_norm =np.linalg.norm(x,<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;矩阵x的二范数为&quot;</span>,x_norm)</span><br><span class="line"><span class="comment"># 向量p范数</span></span><br><span class="line">a_norm = np.linalg.norm(a,np.inf) <span class="comment">#调用np中的变量inf表示无穷</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;向量a的p范数为&quot;</span>,a_norm)</span><br><span class="line"><span class="comment"># 矩阵p范数</span></span><br><span class="line">x_norm =np.linalg.norm(x,np.inf)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;矩阵x的二范数为&quot;</span>,x_norm)</span><br></pre></td></tr></table></figure><p>运行结果为：<imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221016202949373.png"alt="image-20221016202949373" /></p><h3 id="迹">迹</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 矩阵的迹</span></span><br><span class="line">x_trace = np.trace(x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;矩阵x的迹:&quot;</span>,x_trace)</span><br></pre></td></tr></table></figure><p>运行结果为：<imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221016203045259.png"alt="image-20221016203045259" /></p><h3 id="奇异值分解">奇异值分解</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入数据集</span></span><br><span class="line">data=sio.loadmat(<span class="string">&quot;NIRcorn.mat&quot;</span>)</span><br><span class="line"><span class="comment"># 获取玉米化学成分含量数据</span></span><br><span class="line">cornprop=data[<span class="string">&#x27;cornprop&#x27;</span>]</span><br><span class="line">cornprop=np.array(cornprop)</span><br><span class="line"><span class="comment"># 数据标准化</span></span><br><span class="line">scaler = StandardScaler(copy=<span class="literal">True</span>)</span><br><span class="line">cornprop=scaler.fit_transform(cornprop)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机抽样</span></span><br><span class="line"><span class="comment"># 随机抽取6个样本</span></span><br><span class="line">ran=np.random.randint(<span class="number">0</span>,<span class="number">80</span>,<span class="number">6</span>)</span><br><span class="line">cornpropSample1=cornprop[ran][:]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;随机抽取6个样本结果&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(cornpropSample1)</span><br><span class="line"><span class="comment"># 奇异值分解</span></span><br><span class="line">u1,e1,v1=np.linalg.svd(cornpropSample1)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;左矩阵U：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(u1)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;奇异值为：&quot;</span>,e1)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;右矩阵V^T：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(np.transpose(v1))</span><br></pre></td></tr></table></figure><p>运行结果为：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221016203239743.png" alt="image-20221016203239743" style="zoom:67%;" /></p><h3 id="特征值和奇异值比较">特征值和奇异值比较</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">随机抽取四个样本，对奇异值和特征值进行对比</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 随机抽取4个</span></span><br><span class="line">ran1=np.random.randint(<span class="number">0</span>,<span class="number">80</span>,<span class="number">4</span>)</span><br><span class="line">cornpropSample2=cornprop[ran1][:]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;随机抽取4个样本结果&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(cornpropSample2)</span><br><span class="line"><span class="comment"># 奇异值分解</span></span><br><span class="line">u2,e2,v2=np.linalg.svd(cornpropSample2)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;奇异值：&quot;</span>,e2)</span><br><span class="line"><span class="comment"># 判断是否能做特征分解</span></span><br><span class="line"><span class="comment"># 验证rank是否为4</span></span><br><span class="line"><span class="keyword">if</span> np.linalg.matrix_rank(cornpropSample2)==<span class="number">4</span>:</span><br><span class="line">    evalue=np.linalg.eigvals(cornpropSample2)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;特征值：&quot;</span>,evalue)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;秩为：&quot;</span>,np.linalg.matrix_rank(cornpropSample2))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;为不满秩矩阵，无法进行特征分解&quot;</span>)</span><br></pre></td></tr></table></figure><p>运行结果为：<img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221016203500623.png" alt="image-20221016203500623" style="zoom:80%;" /><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221016203531499.png" alt="image-20221016203531499" style="zoom:80%;" /></p><p>结果表明，不是任何一个方阵都能使得奇异值和特征值，奇异值代表的是最大范围的线性变换程度，特征值代表的线性变换时的方向不变量。</p><h3 id="相关性分析">相关性分析</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">进行各个化学成分间的相关性分析</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 求协方差矩阵</span></span><br><span class="line">cov=np.cov(cornprop.transpose())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;协方差矩阵&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(cov)</span><br><span class="line"><span class="comment"># 可视化</span></span><br><span class="line">plt.figure(dpi=<span class="number">120</span>)</span><br><span class="line">sns.heatmap(data=cov,</span><br><span class="line">            cmap=plt.get_cmap(<span class="string">&#x27;Greens_r&#x27;</span>),</span><br><span class="line">            xticklabels=[<span class="string">&#x27;Moisture&#x27;</span>,<span class="string">&#x27;Oil&#x27;</span>,<span class="string">&#x27;Protein &#x27;</span>,<span class="string">&#x27;Starch&#x27;</span>],</span><br><span class="line">            yticklabels=[<span class="string">&#x27;Moisture&#x27;</span>,<span class="string">&#x27;Oil&#x27;</span>,<span class="string">&#x27;Protein &#x27;</span>,<span class="string">&#x27;Starch&#x27;</span>]</span><br><span class="line">           )</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>输出结果为：</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221016204408714.png"alt="image-20221016204408714" /><figcaption aria-hidden="true">image-20221016204408714</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221016204333850.png"alt="image-20221016204333850" /><figcaption aria-hidden="true">image-20221016204333850</figcaption></figure><p>简单观察，可以看出淀粉和蛋白质的呈现负相关且比较强烈，蛋白质和油脂之间的关系呈现正相关。</p><h3 id="pca的初步尝试">PCA的初步尝试</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">协方差可进一步深度挖掘，结合各种矩阵运算进行PCA</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 对协方差矩阵进行特征值分解</span></span><br><span class="line">cov_evalue,cov_vectors = np.linalg.eig(cov)</span><br><span class="line"><span class="comment"># 然后选取前几个维度进行降维即可</span></span><br><span class="line"><span class="comment"># 构造特征矩阵</span></span><br><span class="line">smat = np.zeros((<span class="number">4</span>, <span class="number">4</span>))</span><br><span class="line">smat = np.diag(cov_evalue)</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">p=np.dot(cov_vectors[:<span class="number">2</span>,:],cornpropSample2)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;降维后结果：&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(p)</span><br></pre></td></tr></table></figure><p>输出结果：</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20221016204707495.png"alt="image-20221016204707495" /><figcaption aria-hidden="true">image-20221016204707495</figcaption></figure><h2 id="总结-2">总结</h2><p>本次实验为下一节的PCA进行铺垫，也是绝大部分算法的基础。在学习奇异值分解和特征分解的时候，我通过查阅资料终于找到了解决从特征值到特征矩阵构建的方法，非常有成就感。</p><h1 id="实验三-最小二乘法">实验三 最小二乘法</h1><h2 id="实验目的-3">实验目的</h2><ol type="1"><li>生成正定矩阵联系线性回归</li><li>选取部分属性进行最小二乘算法</li><li>掌握最小二乘法</li></ol><h2 id="实验场地与设备-3">实验场地与设备</h2><p>实验室4074</p><h2 id="实验方式-3">实验方式</h2><p>程序设计</p><h2 id="实验设计-3">实验设计</h2><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204184750871.png" alt="image-20230204184750871" style="zoom: 50%;" /></p><h2 id="实验内容-3">实验内容</h2><h3 id="生成正定矩阵使用最小二乘">生成正定矩阵使用最小二乘</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">1.尝试网站代码应用</span></span><br><span class="line"><span class="string">2.理解源代码</span></span><br><span class="line"><span class="string">3.回归源码转化伪代码、流程图</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 导入必要库</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets, linear_model</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error, r2_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入数据集</span></span><br><span class="line">diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 简单分析数据集</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x&quot;</span>,diabetes_X) <span class="comment"># 442*10</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y&quot;</span>,diabetes_y) <span class="comment"># 1*442</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用一个x的特征</span></span><br><span class="line">diabetes_X = diabetes_X[:, np.newaxis, <span class="number">2</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分训练集和测试集</span></span><br><span class="line"><span class="comment"># x</span></span><br><span class="line">diabetes_X_train = diabetes_X[:-<span class="number">20</span>]</span><br><span class="line">diabetes_X_test = diabetes_X[-<span class="number">20</span>:]</span><br><span class="line"><span class="comment"># y</span></span><br><span class="line">diabetes_y_train = diabetes_y[:-<span class="number">20</span>]</span><br><span class="line">diabetes_y_test = diabetes_y[-<span class="number">20</span>:]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建线性回归对象</span></span><br><span class="line">regr = linear_model.LinearRegression()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练线性回归模型</span></span><br><span class="line">regr.fit(diabetes_X_train, diabetes_y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试集预测</span></span><br><span class="line">diabetes_y_pred = regr.predict(diabetes_X_test)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">应该是某种误差，具体得看源码</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># The coefficients</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Coefficients: \n&quot;</span>, regr.coef_)</span><br><span class="line"><span class="comment"># The mean squared error</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Mean squared error: %.2f&quot;</span> % mean_squared_error(diabetes_y_test, diabetes_y_pred))</span><br><span class="line"><span class="comment"># The coefficient of determination: 1 is perfect prediction</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Coefficient of determination: %.2f&quot;</span> % r2_score(diabetes_y_test, diabetes_y_pred))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.scatter(diabetes_X_test, diabetes_y_test, color=<span class="string">&quot;black&quot;</span>)</span><br><span class="line">plt.plot(diabetes_X_test, diabetes_y_pred, color=<span class="string">&quot;blue&quot;</span>, linewidth=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">plt.xticks(())</span><br><span class="line">plt.yticks(())</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204182023479.png"alt="image-20230204182023479" /><figcaption aria-hidden="true">image-20230204182023479</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204182051171.png"alt="image-20230204182051171" /><figcaption aria-hidden="true">image-20230204182051171</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204184117890.png"alt="image-20230204184117890" /><figcaption aria-hidden="true">image-20230204184117890</figcaption></figure><h3 id="选取部分属性进行最小二乘算法">选取部分属性进行最小二乘算法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error, r2_score</span><br><span class="line"></span><br><span class="line">data=sio.loadmat(<span class="string">&quot;../NIRcorn.mat&quot;</span>)</span><br><span class="line"></span><br><span class="line">cornprop = data[<span class="string">&quot;cornprop&quot;</span>][:,<span class="number">0</span>].reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">m5spec=data[<span class="string">&#x27;m5spec&#x27;</span>][<span class="string">&#x27;data&#x27;</span>][<span class="number">0</span>][<span class="number">0</span>][:,<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建线性回归对象</span></span><br><span class="line">regr = linear_model.LinearRegression()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练线性回归模型</span></span><br><span class="line">regr.fit(cornprop,m5spec)</span><br><span class="line">y_pred = regr.predict(cornprop)</span><br><span class="line">plt.scatter(cornprop, m5spec, color=<span class="string">&quot;black&quot;</span>)</span><br><span class="line">plt.plot(cornprop, y_pred, color=<span class="string">&quot;blue&quot;</span>, linewidth=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">plt.xticks(())</span><br><span class="line">plt.yticks(())</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204184257098.png"alt="image-20230204184257098" /><figcaption aria-hidden="true">image-20230204184257098</figcaption></figure><h2 id="总结-3">总结</h2><p>最小二乘法作为线性回归的基础，其数学推导十分重要，深刻理解了最小二乘才能初步理解高维空间中的空间变换以及相关的几何意义。</p><h1 id="实验四-主成分分析">实验四 主成分分析</h1><h2 id="实验目的-4">实验目的</h2><ol type="1"><li>掌握PCA算法原理</li><li>用python实现PCA降维</li><li>体会python面向对象的灵活</li></ol><h2 id="实验场地与设备-4">实验场地与设备</h2><p>实验室4074</p><h2 id="实验方式-4">实验方式</h2><p>程序设计</p><h2 id="实验设计-4">实验设计</h2><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204185133692.png"alt="image-20230204185133692" /><figcaption aria-hidden="true">image-20230204185133692</figcaption></figure><h2 id="实验内容-4">实验内容</h2><h3 id="伪代码">伪代码</h3><figure class="highlight pascal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">input：data,n_components</span><br><span class="line">output：U，S</span><br><span class="line">-----------------------------------------</span><br><span class="line">Data_mean=np.mean(data)</span><br><span class="line">Data=np.substract(data,Data_mean)</span><br><span class="line">cov_X=np.cov(np.transpose(Data))</span><br><span class="line">U,S,V=np.linalg.svd(cov_X)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="python实现">python实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br><span class="line"><span class="keyword">from</span> sklearn.utils.extmath <span class="keyword">import</span> svd_flip</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PCA</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="comment"># 初始化</span></span><br><span class="line">    np.set_printoptions(suppress=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,components</span>):</span><br><span class="line">        self.components=components</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self,X</span>):</span><br><span class="line">        X_mean=np.mean(X)</span><br><span class="line">        X=np.subtract(X,X_mean)</span><br><span class="line">        cov_X=np.cov(np.transpose(X))</span><br><span class="line">        <span class="keyword">if</span> np.linalg.matrix_rank(cov_X)&lt;np.shape(cov_X)[<span class="number">0</span>]:</span><br><span class="line">            U,S,V=np.linalg.svd(cov_X)</span><br><span class="line">            U, V = svd_flip(U, V)</span><br><span class="line">            U=np.array(U[:self.components]).T</span><br><span class="line">            U *= S[:self.components]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            explained_variance_ = (S * S.T) / (np.shape(X)[<span class="number">0</span>] - <span class="number">1</span>)</span><br><span class="line">            total_var = explained_variance_.<span class="built_in">sum</span>()</span><br><span class="line">            explained_variance_ratio_ = explained_variance_ / total_var</span><br><span class="line">            self.explained_variance_ratio_ = explained_variance_ratio_[:self.components]</span><br><span class="line">            <span class="keyword">return</span> U,S</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            eigValue,eigVector=np.linalg.eig(cov_X)</span><br><span class="line">            index = np.argsort(-eigValue)</span><br><span class="line">            <span class="keyword">if</span> self.components &gt; np.shape(X)[<span class="number">1</span>]:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;features is lower than commponents&#x27;</span>)</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                T = np.array(eigVector[index[:self.components]]).T</span><br><span class="line">                P = np.dot(X,T)</span><br><span class="line">                <span class="comment"># 求解解释变量</span></span><br><span class="line">                <span class="comment"># 要不要根据对抽样统计做方差的无偏估计</span></span><br><span class="line">                <span class="comment"># 使用特征值分解一旦不满秩，就会出现复数解</span></span><br><span class="line">                explained_variance_ = (eigValue * eigValue.T)/(np.shape(X)[<span class="number">0</span>]-<span class="number">1</span>)</span><br><span class="line">                total_var = explained_variance_.<span class="built_in">sum</span>()</span><br><span class="line">                explained_variance_ratio_ = explained_variance_ / total_var</span><br><span class="line">                self.explained_variance_ratio_=explained_variance_ratio_[:self.components]</span><br><span class="line">                <span class="keyword">return</span> P,T</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    data = sio.loadmat(<span class="string">&quot;../NIRcorn.mat&quot;</span>)</span><br><span class="line"></span><br><span class="line">    cornprop = data[<span class="string">&quot;cornprop&quot;</span>]</span><br><span class="line">    m5spec = data[<span class="string">&#x27;m5spec&#x27;</span>][<span class="string">&#x27;data&#x27;</span>][<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">    y = data[<span class="string">&#x27;cornprop&#x27;</span>][:, [<span class="number">0</span>]]</span><br><span class="line">    x = m5spec</span><br><span class="line"></span><br><span class="line">    pca=PCA(<span class="number">2</span>)</span><br><span class="line">    U,S=pca.fit(x)</span><br><span class="line">    <span class="built_in">print</span>(</span><br><span class="line">        <span class="string">&quot;explained variance ratio (first two components): %s&quot;</span></span><br><span class="line">        % <span class="built_in">str</span>(pca.explained_variance_ratio_)</span><br><span class="line">    )</span><br></pre></td></tr></table></figure><p>explained variance ratio (first two components): [0.999940010.00005929]</p><h3 id="调用pca降维鸢尾花">调用PCA降维鸢尾花</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line"></span><br><span class="line">X = iris.data</span><br><span class="line">y = iris.target</span><br><span class="line">target_names = iris.target_names</span><br><span class="line"></span><br><span class="line">pca = PCA(n_components=<span class="number">2</span>)</span><br><span class="line">X_r = pca.fit(X).transform(X)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Percentage of variance explained for each components</span></span><br><span class="line"><span class="built_in">print</span>(</span><br><span class="line">    <span class="string">&quot;explained variance ratio (first two components): %s&quot;</span></span><br><span class="line">    % <span class="built_in">str</span>(pca.explained_variance_ratio_)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">colors = [<span class="string">&quot;navy&quot;</span>, <span class="string">&quot;turquoise&quot;</span>, <span class="string">&quot;darkorange&quot;</span>]</span><br><span class="line">lw = <span class="number">2</span></span><br><span class="line"><span class="keyword">for</span> color, i, target_name <span class="keyword">in</span> <span class="built_in">zip</span>(colors, [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], target_names):</span><br><span class="line">    plt.scatter(</span><br><span class="line">        <span class="comment"># y==i是一个推导式，本质上是返回一个布尔数组，从而达成筛选的目的</span></span><br><span class="line">        X_r[y == i, <span class="number">0</span>], X_r[y == i, <span class="number">1</span>], color=color, alpha=<span class="number">0.8</span>, lw=lw, label=target_name</span><br><span class="line">    )</span><br><span class="line">plt.legend(loc=<span class="string">&quot;best&quot;</span>, shadow=<span class="literal">False</span>, scatterpoints=<span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">&quot;PCA of IRIS dataset&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204185710362.png"alt="image-20230204185710362" /><figcaption aria-hidden="true">image-20230204185710362</figcaption></figure><h3 id="调用pca降维nircorn">调用pca降维NIRcorn</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"></span><br><span class="line">data=sio.loadmat(<span class="string">&quot;../NIRcorn.mat&quot;</span>)</span><br><span class="line"></span><br><span class="line">cornprop = data[<span class="string">&quot;cornprop&quot;</span>]</span><br><span class="line">m5spec=data[<span class="string">&#x27;m5spec&#x27;</span>][<span class="string">&#x27;data&#x27;</span>][<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># x_mean=np.mean(m5spec)</span></span><br><span class="line"><span class="comment"># x_center=np.subtract(m5spec,x_mean)</span></span><br><span class="line"></span><br><span class="line">pca = PCA(n_components=<span class="number">2</span>)</span><br><span class="line">x = pca.fit(m5spec).transform(m5spec)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(</span><br><span class="line">    <span class="string">&quot;explained variance ratio (first two components): %s&quot;</span></span><br><span class="line">    % <span class="built_in">str</span>(pca.explained_variance_ratio_)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">plt.scatter(x[:,<span class="number">0</span>],x[:,<span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204185800726.png" /></p><h2 id="总结-4">总结</h2><p>主成分分析是基于投影的方法，而衡量投影距离的就是协方差矩阵。而对于协方差矩阵的分解方式就显得尤为重要，我自己实现的PCA与sklearn种出现显著差异的原因就是在奇异值分解的方式。sklearn采用的是随机奇异值分解。</p><h1 id="实验五-主成分回归">实验五 主成分回归</h1><h2 id="实验目的-5">实验目的</h2><ol type="1"><li>掌握PCR算法原理</li><li>掌握交叉验证算法应用；</li><li>体会python面向对象的灵活</li></ol><h2 id="实验场地与设备-5">实验场地与设备</h2><p>实验室4074</p><h2 id="实验方式-5">实验方式</h2><p>程序设计</p><h2 id="实验设计-5">实验设计</h2><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204194417158.png" alt="image-20230204194417158" style="zoom:50%;" /></p><h2 id="实验内容-5">实验内容</h2><h3 id="伪代码-1">伪代码</h3><figure class="highlight pascal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">PCR.fit</span><br><span class="line">-----------------------------</span><br><span class="line">input:X,y,n_components</span><br><span class="line">output:P,b</span><br><span class="line">------------------------------</span><br><span class="line">P = PCA(X,n_components)</span><br><span class="line">T = X*P</span><br><span class="line">b = LS.fit(T,y)</span><br></pre></td></tr></table></figure><figure class="highlight pascal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">PCR.predict</span><br><span class="line">-----------------------------</span><br><span class="line">input:X,P,b</span><br><span class="line">output:y_predict</span><br><span class="line">-----------------------------</span><br><span class="line">T = X*P</span><br><span class="line">y_predict = T*b</span><br></pre></td></tr></table></figure><figure class="highlight pascal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">PCR.cv</span><br><span class="line">-----------------------------</span><br><span class="line">input:X,y,max_pcs,k</span><br><span class="line">output:best_pcs</span><br><span class="line">-----------------------------X_train,X_val,y_train,y_val = cross validation.split(X,y,k)</span><br><span class="line">  <span class="keyword">for</span> n_pcs <span class="keyword">in</span> range(<span class="number">2</span>,max_pcs+<span class="number">1</span>):</span><br><span class="line">   y_predict = [ ]</span><br><span class="line">   <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,k):</span><br><span class="line">   P,b = PCR.fit(X_train=X_k≠i,y_train=y_k≠i,n_pcs)</span><br><span class="line">   ypre = PCR.predict(X_val=X_k=i,P,b)</span><br><span class="line">   y_predict.append(ypre)</span><br><span class="line">   RMSE(y,y_predict,len(y))</span><br><span class="line">  best_pcs = RMSE.<span class="keyword">index</span>(min(RMSE))</span><br><span class="line"> return best_pcs</span><br></pre></td></tr></table></figure><h3 id="python实现-1"><strong>Python实现</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> cross_validation</span><br><span class="line"><span class="comment"># from sklearn.decomposition import PCA</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Cross_Validation</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, x, y, n_folds, max_components</span>):</span><br><span class="line">        self.x = x</span><br><span class="line">        self.y = y</span><br><span class="line">        self.n_folds = n_folds</span><br><span class="line">        self.max_components = max_components</span><br><span class="line">        self.n = x.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">CV</span>(<span class="params">self</span>):</span><br><span class="line">        kf = cross_validation.KFold(self.n, self.n_folds)</span><br><span class="line">        x_train=[]</span><br><span class="line">        x_test=[]</span><br><span class="line">        y_train=[]</span><br><span class="line">        y_test=[]</span><br><span class="line">        <span class="keyword">for</span> train_index,test_index <span class="keyword">in</span> kf:</span><br><span class="line">            xtr, xte = self.x[train_index], self.x[test_index]</span><br><span class="line">            ytr, yte = self.y[train_index], self.y[test_index]</span><br><span class="line">            x_train.append(xtr)</span><br><span class="line">            x_test.append(xte)</span><br><span class="line">            y_train.append(ytr)</span><br><span class="line">            y_test.append(yte)</span><br><span class="line">        <span class="keyword">return</span> x_train, x_test, y_train, y_test</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br><span class="line"><span class="keyword">from</span> Cross_Validation <span class="keyword">import</span> Cross_Validation</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PCR</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, max_components</span>):</span><br><span class="line">        self.max_components=max_components</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self,X,y,best_components</span>):</span><br><span class="line">        self.x_mean = np.mean(X, axis=<span class="number">0</span>)</span><br><span class="line">        self.y_mean = np.mean(y, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># sklearn中的pca自带中心化处理</span></span><br><span class="line">        pca=PCA(n_components=best_components)</span><br><span class="line">        pca=pca.fit(X)</span><br><span class="line">        X_r=pca.transform(X)</span><br><span class="line">        b=np.linalg.lstsq(X_r,np.subtract(y,self.y_mean))[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">return</span> b,pca</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">pridict</span>(<span class="params">self,b,X,pca</span>):</span><br><span class="line">        T=pca.transform(X)</span><br><span class="line">        y_pre = np.dot(T, b)</span><br><span class="line">        y_predict = np.add(y_pre, self.y_mean)</span><br><span class="line">        <span class="keyword">return</span> y_predict</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">cv_pridict</span>(<span class="params">self,X,y,n_fold,</span>):</span><br><span class="line">        cv = Cross_Validation(X,y,n_fold,self.max_components)</span><br><span class="line">        X_train, X_test, y_train, y_test = cv.CV()</span><br><span class="line">        y_allPredict=np.ones((<span class="number">1</span>,self.max_components))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_fold):</span><br><span class="line">            y_predict=np.zeros((y_test[i].shape[<span class="number">0</span>],self.max_components))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(self.max_components):</span><br><span class="line">                b,pca=self.fit(X_train[i],y_train[i],j+<span class="number">1</span>)</span><br><span class="line">                y_pre=self.pridict(b,X_test[i],pca)</span><br><span class="line">                y_predict[:,j]=y_pre.ravel()</span><br><span class="line"></span><br><span class="line">            y_allPredict=np.vstack((y_allPredict,y_predict))</span><br><span class="line">        y_allPredict=y_allPredict[<span class="number">1</span>:]</span><br><span class="line">        <span class="keyword">return</span> y_allPredict,cv</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">RMSE_CV</span>(<span class="params">self,y_allPredict, y_measure,cv</span>):</span><br><span class="line">        press = np.square(np.subtract(y_allPredict, y_measure))</span><br><span class="line">        press_all = np.<span class="built_in">sum</span>(press, axis=<span class="number">0</span>)</span><br><span class="line">        RMSECV = np.sqrt(press_all / cv.n)</span><br><span class="line">        min_RMSECV = <span class="built_in">min</span>(RMSECV)</span><br><span class="line">        comp_array = RMSECV.argsort()</span><br><span class="line">        comp_best = comp_array[<span class="number">0</span>] + <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> RMSECV, min_RMSECV, comp_best</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">show_Select_comp</span>(<span class="params">self,RMSECV</span>):</span><br><span class="line">        x=np.linspace(<span class="number">1</span>,<span class="number">20</span>,<span class="number">20</span>)</span><br><span class="line">        plt.figure()</span><br><span class="line">        plt.plot(x,RMSECV)</span><br><span class="line">        plt.ylabel(RMSECV)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;n_comp&#x27;</span>)</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    data = sio.loadmat(<span class="string">&quot;../NIRcorn.mat&quot;</span>)</span><br><span class="line"></span><br><span class="line">    cornprop = data[<span class="string">&quot;cornprop&quot;</span>]</span><br><span class="line">    m5spec = data[<span class="string">&#x27;m5spec&#x27;</span>][<span class="string">&#x27;data&#x27;</span>][<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">    y = data[<span class="string">&#x27;cornprop&#x27;</span>][:, [<span class="number">0</span>]]</span><br><span class="line">    x=m5spec</span><br><span class="line">    y_mean=np.mean(y,axis=<span class="number">0</span>)</span><br><span class="line">    pcr=PCR(<span class="number">20</span>)</span><br><span class="line">    b,pca=pcr.fit(x,y,<span class="number">14</span>)</span><br><span class="line">    y_pre=pcr.pridict(b,x,pca)</span><br><span class="line">    <span class="built_in">print</span>(y)</span><br><span class="line">    <span class="built_in">print</span>(y_pre)</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    # 预测图显示</span></span><br><span class="line"><span class="string">    plt.figure()</span></span><br><span class="line"><span class="string">    plt.scatter(np.linspace(1,80,80),y_pre)</span></span><br><span class="line"><span class="string">    plt.scatter(np.linspace(1, 80, 80),y)</span></span><br><span class="line"><span class="string">    plt.show()</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    y_pre,cv=pcr.cv_pridict(x,y,<span class="number">10</span>)</span><br><span class="line">    <span class="built_in">print</span>(y_pre)</span><br><span class="line">    RMSEcv,min_RMSEcv,best_comp=pcr.RMSE_CV(y_pre,cv.y,cv)</span><br><span class="line">    <span class="built_in">print</span>(RMSEcv)</span><br><span class="line">    pcr.show_Select_comp(RMSEcv)</span><br><span class="line"><span class="comment"># &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>参数选择：<imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204192233033.png"alt="image-20230204192233033" /></p><p>预测结果：</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204192338375.png"alt="image-20230204192338375" /><figcaption aria-hidden="true">image-20230204192338375</figcaption></figure><h2 id="总结-5">总结</h2><p>主成分回归分析(PCR)，以主成分为自变量进行的回归分析。是分析多元共线性问题的一种方法，当自变量存在复共线性刚，用于改进最小二乘回归的统计分析方法。霍特林1933年首先用主成分分析相关结构，1965年马西提出主成分回归。</p><p>基本步骤：</p><p>（1）将自变量转换为标准分；</p><p>（2）求出这此标准分的主成分，去掉特征根很小的主成分；</p><p>（3）用最小二乘法作因变量对保留的主成分的回归；</p><p>（4）将回归方程中的主成分换成标准分的线性组合，得到由标准分给出的回归方程</p><p>在实现过程中，注意到一点，self在python面向对象的活用，可以大幅度减少变量定义，而且可以作为全局变量跳出循环中，非常好用。</p><h1 id="实验六-偏最小二乘算法">实验六 偏最小二乘算法</h1><h2 id="实验目的-6">实验目的</h2><ol type="1"><li>实现NIPALS算法并对nircorn数据集进行预测</li><li>掌握交叉验证算法应用；</li><li>实现PLS算法</li></ol><h2 id="实验场地与设备-6">实验场地与设备</h2><p>实验室4074</p><h2 id="实验方式-6">实验方式</h2><p>程序设计</p><h2 id="实验设计-6">实验设计</h2><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204194521892.png" alt="image-20230204194521892" style="zoom:50%;" /></p><h2 id="实验内容-6">实验内容</h2><h3 id="nipls伪代码">NIPLS伪代码</h3><figure class="highlight pascal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">NIPALS.py</span><br><span class="line">--------------------------------------------</span><br><span class="line">input: X,Y,n_comp</span><br><span class="line">output:P,Q,T,U,W,C</span><br><span class="line">--------------------------------------------</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(n_comp):</span><br><span class="line">    u_new=Y[i+<span class="number">1</span>]</span><br><span class="line">    u_old=np.ones((Y.shape[i+<span class="number">1</span>],<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> || u_new-u_old ||&gt;=<span class="number">0.0001</span>(极小值):</span><br><span class="line">        u_old=u_new</span><br><span class="line">        w = X^T * u_new / ( u_old^T * u_old )</span><br><span class="line">        w = w / sqrt(w^T * w)</span><br><span class="line">        t = X * w</span><br><span class="line">        c = Y * t /( t^T * t )</span><br><span class="line">        c = c / sqrt(c^T * c)</span><br><span class="line">        u_new = Y * c</span><br><span class="line"></span><br><span class="line">    p = X * t / ( t^T * t )</span><br><span class="line">    q = Y * c / ( c^T * c )</span><br><span class="line">    X1 = X - t * p^T</span><br><span class="line">    b1 = u_new^T * t / ( t^T * t )</span><br><span class="line">    Y1 = Y - b * t * q^T</span><br><span class="line"></span><br><span class="line">    B[n_comp,:]=b</span><br><span class="line">    P[:,n_comp]=p</span><br><span class="line">    Q[:,n_comp]=q</span><br><span class="line">    T[:,n_comp]=t</span><br><span class="line">    U[:,n_comp]=u_new</span><br><span class="line">    W[:,n_comp]=w</span><br><span class="line">    C[:,n_comp]=c</span><br><span class="line">--------------------------------------------</span><br></pre></td></tr></table></figure><h3 id="nipls实现">NIPLS实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> linalg</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NIPALS</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, max_pcs, sigma=<span class="number">0.0001</span></span>):</span><br><span class="line"></span><br><span class="line">        self.max_pcs = max_pcs</span><br><span class="line">        self.sigma = sigma</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, X, Y</span>):</span><br><span class="line">        E, F = X, Y</span><br><span class="line">        P = np.mat(np.ones((X.shape[<span class="number">1</span>], self.max_pcs)))  <span class="comment"># X载荷矩阵——P</span></span><br><span class="line">        T = np.mat(np.ones((X.shape[<span class="number">0</span>], self.max_pcs)))  <span class="comment"># X得分矩阵——T</span></span><br><span class="line">        W = np.mat(np.ones((X.shape[<span class="number">1</span>], self.max_pcs)))  <span class="comment"># X权重矩阵——W</span></span><br><span class="line">        Q = np.mat(np.ones((Y.shape[<span class="number">1</span>], self.max_pcs)))  <span class="comment"># Y载荷矩阵——Q</span></span><br><span class="line">        U = np.mat(np.ones((X.shape[<span class="number">0</span>], self.max_pcs)))  <span class="comment"># Y得分矩阵——U</span></span><br><span class="line">        C = np.mat(np.ones((Y.shape[<span class="number">1</span>], self.max_pcs)))  <span class="comment"># Y权重矩阵C</span></span><br><span class="line">        B = np.ones((self.max_pcs, X.shape[<span class="number">1</span>], Y.shape[<span class="number">1</span>]))</span><br><span class="line">        <span class="keyword">for</span> pcs <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, self.max_pcs):</span><br><span class="line"></span><br><span class="line">            t_old, t_new = np.zeros((X.shape[<span class="number">0</span>], <span class="number">1</span>)), np.ones((X.shape[<span class="number">0</span>], <span class="number">1</span>))  <span class="comment"># (64,1)</span></span><br><span class="line">            p_old, p_new = np.ones((X.shape[<span class="number">1</span>], <span class="number">1</span>)), np.ones((X.shape[<span class="number">1</span>], <span class="number">1</span>))  <span class="comment"># (700,1)</span></span><br><span class="line">            w_old, w_new = np.ones((X.shape[<span class="number">1</span>], <span class="number">1</span>)), np.ones((X.shape[<span class="number">1</span>], <span class="number">1</span>))  <span class="comment"># (700,1)</span></span><br><span class="line">            q_old, q_new = np.ones((Y.shape[<span class="number">1</span>], <span class="number">1</span>)), np.ones((Y.shape[<span class="number">1</span>], <span class="number">1</span>))  <span class="comment"># (4,1)</span></span><br><span class="line">            u_old, u_new = np.mat(Y[:, <span class="number">0</span>]).T, np.ones((X.shape[<span class="number">0</span>], <span class="number">1</span>))  <span class="comment"># (64,1)</span></span><br><span class="line">            <span class="keyword">while</span> (np.sqrt(np.<span class="built_in">sum</span>(np.square(np.subtract(t_new, t_old)) / t_new.shape[<span class="number">0</span>])) &gt; self.sigma):</span><br><span class="line">                t_old = t_new</span><br><span class="line">                w_old = (np.dot(u_old.T, X) / np.dot(u_old.T, u_old)).T</span><br><span class="line">                w_new = (w_old.T / np.sqrt(np.dot(w_old.T, w_old))).T</span><br><span class="line">                t_new = np.dot(X, w_new) / np.dot(w_new.T, w_new)</span><br><span class="line">                q_old = (np.dot(t_new.T, Y) / np.dot(t_new.T, t_new)).T</span><br><span class="line">                q_new = (q_old.T / np.linalg.norm(q_old.T)).T</span><br><span class="line">                u_new = np.dot(Y, q_new) / np.dot(q_new.T, q_new)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (Y.shape[<span class="number">1</span>] == <span class="number">1</span>):  <span class="comment"># 判断Y是否是一维</span></span><br><span class="line">                p_old = (np.dot(t_new.T, X) / np.dot(t_new.T, t_new)).T</span><br><span class="line">                p_new = (p_old.T / np.linalg.norm(p_old.T)).T</span><br><span class="line">                t_new = t_old * np.linalg.norm(p_old.T)</span><br><span class="line">                w_new = (w_old.T * np.linalg.norm(p_old.T)).T</span><br><span class="line"></span><br><span class="line">            b = np.dot(np.dot(w_new, linalg.inv(np.dot(p_new.T, w_new))), q_new.T)</span><br><span class="line"></span><br><span class="line">            P[:, pcs] = p_new  <span class="comment"># 保存p</span></span><br><span class="line">            T[:, pcs] = t_new  <span class="comment"># 保存t</span></span><br><span class="line">            W[:, pcs] = w_new  <span class="comment"># 保存w</span></span><br><span class="line">            B[pcs, ::] = b  <span class="comment"># 保存b</span></span><br><span class="line">            Q[:, pcs] = q_new  <span class="comment"># 保存q</span></span><br><span class="line">            U[:, pcs] = u_new  <span class="comment"># 保存u</span></span><br><span class="line">            E = E - np.dot(t_new, p_new.T)</span><br><span class="line">            F = F - np.dot(t_new, q_new.T)</span><br><span class="line">            self.X = E</span><br><span class="line">            self.Y = F</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> P, T, W, Q, U, B</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, X, B, best_pcs</span>):</span><br><span class="line">        B_new = np.zeros((B[<span class="number">0</span>].shape[<span class="number">0</span>], B[<span class="number">0</span>].shape[<span class="number">1</span>]))</span><br><span class="line">        B_new[:] = B[best_pcs - <span class="number">1</span>]</span><br><span class="line">        Y_predict = np.dot(X, B_new)</span><br><span class="line">        <span class="keyword">return</span> Y_predict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">RMSE</span>(<span class="params">y, y_predict, k</span>):</span><br><span class="line">    press = np.square(np.subtract(y, y_predict))</span><br><span class="line">    press_all = np.<span class="built_in">sum</span>(press, axis=<span class="number">0</span>)</span><br><span class="line">    RMSE = np.sqrt(press_all / k)</span><br><span class="line">    <span class="keyword">return</span> RMSE</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 导入数据</span></span><br><span class="line">    data = sio.loadmat(<span class="string">&quot;../NIRcorn.mat&quot;</span>)</span><br><span class="line">    cornprop = data[<span class="string">&quot;cornprop&quot;</span>]</span><br><span class="line">    Y = cornprop</span><br><span class="line">    <span class="built_in">print</span>(np.shape(Y))</span><br><span class="line">    A = data[<span class="string">&quot;m5spec&quot;</span>]</span><br><span class="line">    m5spec = A[<span class="string">&quot;data&quot;</span>][<span class="number">0</span>][<span class="number">0</span>]  <span class="comment"># 80*700矩阵</span></span><br><span class="line">    <span class="comment"># 划分数据集</span></span><br><span class="line">    X_train, X_test, y_train, y_test = train_test_split(m5spec, Y, test_size=<span class="number">0.2</span>, random_state=<span class="number">0</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;X_train:&quot;</span>, X_train.shape)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;X_test:&quot;</span>, X_test.shape)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;y_train:&quot;</span>, y_train.shape)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;y_test:&quot;</span>, y_test.shape)</span><br><span class="line">    <span class="comment"># 将训练集中心化</span></span><br><span class="line">    X_mean = np.mean(X_train, axis=<span class="number">0</span>)</span><br><span class="line">    X_center = np.subtract(X_train, X_mean)</span><br><span class="line">    Y_mean = np.mean(y_train, axis=<span class="number">0</span>)</span><br><span class="line">    Y_center = np.subtract(y_train, Y_mean)</span><br><span class="line">    X_test_mean = np.mean(X_test, axis=<span class="number">0</span>)</span><br><span class="line">    X_test_center = np.subtract(X_test, X_test_mean)</span><br><span class="line">    pls = NIPALS(<span class="number">5</span>)</span><br><span class="line">    P, T, W, Q, U, B = pls.fit(X_center, Y_center)</span><br><span class="line">    Y_predict = pls.predict(X_test_center, B, <span class="number">2</span>)</span><br><span class="line">    Ypre = Y_predict + Y_mean</span><br><span class="line">    rmse = RMSE(y_test.ravel(), Ypre.ravel(), Y_center.shape[<span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Y_predict:&quot;</span>, Ypre)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;rmse:&quot;</span>, rmse)</span><br></pre></td></tr></table></figure><p>rmse: 0.5119355259810657</p><h3 id="pls实现">PLS实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cross_decomposition <span class="keyword">import</span> PLSRegression</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> Cross_Validation <span class="keyword">import</span> Cross_Validation</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">pls</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,max_comp</span>):</span><br><span class="line">        self.max_comp=max_comp</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self,X,Y,n_comp</span>):</span><br><span class="line">        pls=PLSRegression(n_components=n_comp)</span><br><span class="line">        pls.fit(X,Y)</span><br><span class="line">        <span class="keyword">return</span> pls</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self,X,pls</span>):</span><br><span class="line">        <span class="keyword">return</span> pls.predict(X)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">cv_predict</span>(<span class="params">self,X,y,n_fold</span>):</span><br><span class="line">        cv = Cross_Validation(X, y, n_fold, self.max_comp)</span><br><span class="line">        X_train, X_test, y_train, y_test = cv.CV()</span><br><span class="line">        y_allPredict = np.ones((<span class="number">1</span>, self.max_comp))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_fold):</span><br><span class="line">            y_predict = np.zeros((y_test[i].shape[<span class="number">0</span>], self.max_comp))</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(self.max_comp):</span><br><span class="line">                pls=self.fit(X_train[i],y_train[i],j+<span class="number">1</span>)</span><br><span class="line">                y_pre=self.predict(X_test[i],pls)</span><br><span class="line">                y_predict[:,j]=y_pre.ravel()</span><br><span class="line">            y_allPredict = np.vstack((y_allPredict, y_predict))</span><br><span class="line">        y_allPredict = y_allPredict[<span class="number">1</span>:]</span><br><span class="line">        <span class="keyword">return</span> y_allPredict, cv,y_test,y_train,X_test,X_train</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">RMSE_CV</span>(<span class="params">self, y_allPredict, y_measure, cv</span>):</span><br><span class="line">        press = np.square(np.subtract(y_allPredict, y_measure))</span><br><span class="line">        press_all = np.<span class="built_in">sum</span>(press, axis=<span class="number">0</span>)</span><br><span class="line">        RMSECV = np.sqrt(press_all / cv.n)</span><br><span class="line">        min_RMSECV = <span class="built_in">min</span>(RMSECV)</span><br><span class="line">        comp_array = RMSECV.argsort()</span><br><span class="line">        comp_best = comp_array[<span class="number">0</span>] + <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> RMSECV, min_RMSECV, comp_best</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">show_Select_comp</span>(<span class="params">self,RMSECV</span>):</span><br><span class="line">        x=np.linspace(<span class="number">1</span>,<span class="number">20</span>,<span class="number">20</span>)</span><br><span class="line">        plt.figure()</span><br><span class="line">        plt.plot(x,RMSECV,marker=<span class="string">&#x27;^&#x27;</span>,markersize=<span class="number">10</span>,markerfacecolor=<span class="string">&#x27;orange&#x27;</span>,color=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;num_components&#x27;</span>)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;RMSECV&#x27;</span>)</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">show_predict</span>(<span class="params">self,y</span>):</span><br><span class="line">        plt.figure()</span><br><span class="line">        plt.plot([<span class="built_in">min</span>(y), <span class="built_in">max</span>(y)], [<span class="built_in">min</span>(y), <span class="built_in">max</span>(y)], label=<span class="string">&#x27;y=x&#x27;</span>, color=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">        plt.scatter(y, y_pre, color=<span class="string">&#x27;red&#x27;</span>, label=<span class="string">&#x27;y_all&#x27;</span>)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;measure value&#x27;</span>)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;predict value&#x27;</span>)</span><br><span class="line">        plt.legend()</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">show_predict</span>(<span class="params">self,y,y_pre</span>):</span><br><span class="line">        plt.figure()</span><br><span class="line">        plt.plot([<span class="built_in">min</span>(y), <span class="built_in">max</span>(y)], [<span class="built_in">min</span>(y), <span class="built_in">max</span>(y)], label=<span class="string">&#x27;y=x&#x27;</span>, color=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">        plt.scatter(y, y_pre, color=<span class="string">&#x27;red&#x27;</span>, label=<span class="string">&#x27;y_all&#x27;</span>)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;measure value&#x27;</span>)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;predict value&#x27;</span>)</span><br><span class="line">        plt.legend()</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">show_cv_predict</span>(<span class="params">self,y,x_test,y_test,y_train,x_train,pls</span>):</span><br><span class="line">        plt.figure()</span><br><span class="line">        plt.plot([<span class="built_in">min</span>(y), <span class="built_in">max</span>(y)], [<span class="built_in">min</span>(y), <span class="built_in">max</span>(y)], label=<span class="string">&#x27;y=x&#x27;</span>, color=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">        plt.scatter(y_test[<span class="number">0</span>],self.predict(x_test[<span class="number">0</span>],pls), color=<span class="string">&#x27;red&#x27;</span>, label=<span class="string">&#x27;test set&#x27;</span>)</span><br><span class="line">        plt.scatter(y_train[<span class="number">0</span>],self.predict(x_train[<span class="number">0</span>],pls), color=<span class="string">&#x27;blue&#x27;</span>, label=<span class="string">&#x27;train set&#x27;</span>)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;measure value&#x27;</span>)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;predict value&#x27;</span>)</span><br><span class="line">        plt.legend()</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    data = sio.loadmat(<span class="string">&quot;../NIRcorn.mat&quot;</span>)</span><br><span class="line"></span><br><span class="line">    cornprop = data[<span class="string">&quot;cornprop&quot;</span>]</span><br><span class="line">    m5spec = data[<span class="string">&#x27;m5spec&#x27;</span>][<span class="string">&#x27;data&#x27;</span>][<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">    y = data[<span class="string">&#x27;cornprop&#x27;</span>][:, [<span class="number">0</span>]]</span><br><span class="line">    x=m5spec</span><br><span class="line"></span><br><span class="line">    pls=pls(<span class="number">20</span>)</span><br><span class="line">    pls1=pls.fit(x,y,<span class="number">14</span>)</span><br><span class="line">    y_pre=pls.predict(x,pls1)</span><br><span class="line">    <span class="built_in">print</span>(y)</span><br><span class="line">    <span class="built_in">print</span>(y_pre)</span><br><span class="line"></span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.plot([<span class="built_in">min</span>(y), <span class="built_in">max</span>(y)],[<span class="built_in">min</span>(y), <span class="built_in">max</span>(y)],label=<span class="string">&#x27;y=x&#x27;</span>,color=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">    plt.scatter(y, y_pre,color=<span class="string">&#x27;red&#x27;</span>,label=<span class="string">&#x27;y_all&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;measure value&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;predict value&#x27;</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">    y_pre, cv,y_test,y_train,x_test,x_train = pls.cv_predict(x, y, <span class="number">10</span>)</span><br><span class="line">    <span class="built_in">print</span>(y_pre)</span><br><span class="line">    RMSEcv, min_RMSEcv, best_comp = pls.RMSE_CV(y_pre, cv.y, cv)</span><br><span class="line">    <span class="built_in">print</span>(RMSEcv)</span><br><span class="line">    pls.show_Select_comp(RMSEcv)</span><br><span class="line"></span><br><span class="line">    pls.show_cv_predict(y,x_test,y_test,y_train,x_train,pls1)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> cross_validation</span><br><span class="line"><span class="comment"># from sklearn.decomposition import PCA</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Cross_Validation</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, x, y, n_folds, max_components</span>):</span><br><span class="line">        self.x = x</span><br><span class="line">        self.y = y</span><br><span class="line">        self.n_folds = n_folds</span><br><span class="line">        self.max_components = max_components</span><br><span class="line">        self.n = x.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">CV</span>(<span class="params">self</span>):</span><br><span class="line">        kf = cross_validation.KFold(self.n, self.n_folds)</span><br><span class="line">        x_train=[]</span><br><span class="line">        x_test=[]</span><br><span class="line">        y_train=[]</span><br><span class="line">        y_test=[]</span><br><span class="line">        <span class="keyword">for</span> train_index,test_index <span class="keyword">in</span> kf:</span><br><span class="line">            xtr, xte = self.x[train_index], self.x[test_index]</span><br><span class="line">            ytr, yte = self.y[train_index], self.y[test_index]</span><br><span class="line">            x_train.append(xtr)</span><br><span class="line">            x_test.append(xte)</span><br><span class="line">            y_train.append(ytr)</span><br><span class="line">            y_test.append(yte)</span><br><span class="line">        <span class="keyword">return</span> x_train, x_test, y_train, y_test</span><br></pre></td></tr></table></figure><p>预测结果：</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204193337549.png"alt="image-20230204193337549" /><figcaption aria-hidden="true">image-20230204193337549</figcaption></figure><p>参数选择：<imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204193345363.png"alt="image-20230204193345363" /></p><p>拟合效果：</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204193435252.png"alt="image-20230204193435252" /><figcaption aria-hidden="true">image-20230204193435252</figcaption></figure><h2 id="总结-6">总结</h2><p>PLS的代码实现总体上和PCR类似，其核心区别就在于PLS的fit和predict函数发生了改变，</p><h1 id="实验七-岭回归">实验七 岭回归</h1><h2 id="实验目的-7">实验目的</h2><ol type="1"><li>实现RR算法</li><li>掌握交叉验证算法应用；</li><li>观察岭脊</li></ol><h2 id="实验场地与设备-7">实验场地与设备</h2><p>实验室4074</p><h2 id="实验方式-7">实验方式</h2><p>程序设计</p><h2 id="实验设计-7">实验设计</h2><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204194615350.png" alt="image-20230204194615350" style="zoom:50%;" /></p><h2 id="实验内容-7">实验内容</h2><h3 id="岭迹">岭迹</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"></span><br><span class="line"><span class="comment"># X is the 10x10 Hilbert matrix</span></span><br><span class="line">X = <span class="number">1.0</span> / (np.arange(<span class="number">1</span>, <span class="number">11</span>) + np.arange(<span class="number">0</span>, <span class="number">10</span>)[:, np.newaxis])</span><br><span class="line">y = np.ones(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">n_alphas = <span class="number">200</span></span><br><span class="line">alphas = np.logspace(-<span class="number">10</span>, -<span class="number">2</span>, n_alphas)</span><br><span class="line"></span><br><span class="line">coefs = []</span><br><span class="line"><span class="keyword">for</span> a <span class="keyword">in</span> alphas:</span><br><span class="line">    ridge = linear_model.Ridge(alpha=a, fit_intercept=<span class="literal">False</span>)</span><br><span class="line">    ridge.fit(X, y)</span><br><span class="line">    coefs.append(ridge.coef_)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(alphas)</span><br><span class="line">ax = plt.gca()</span><br><span class="line"></span><br><span class="line">ax.plot(alphas, coefs)</span><br><span class="line"><span class="comment"># ax.set_xscale(&quot;log&quot;)</span></span><br><span class="line"><span class="comment"># ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis</span></span><br><span class="line">plt.xlabel(<span class="string">&quot;alpha&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;weights&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Ridge coefficients as a function of the regularization&quot;</span>)</span><br><span class="line">plt.axis(<span class="string">&quot;tight&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>算术坐标尺度<imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204193803654.png"alt="image-20230204193803654" /></p><p>对数坐标尺度<imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204193817727.png"alt="image-20230204193817727" /></p><h3 id="rr实现">RR实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge</span><br><span class="line"><span class="keyword">from</span> Cross_Validation <span class="keyword">import</span> Cross_Validation</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RidgeRegression</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,n_lambda</span>):</span><br><span class="line">        self.n_lambda=n_lambda</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self,X,y,best_lambda</span>):</span><br><span class="line">        c=np.dot(X.T,X)</span><br><span class="line">        I=np.eye(np.shape(c)[<span class="number">0</span>])</span><br><span class="line">        d=np.dot(best_lambda,I)</span><br><span class="line">        e=(c+d)</span><br><span class="line">        e=np.linalg.inv(e)</span><br><span class="line">        b = np.dot(X.T, y)</span><br><span class="line">        b=np.dot(e,b)</span><br><span class="line">        self.b=b</span><br><span class="line">        <span class="keyword">return</span> b</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">pridict</span>(<span class="params">self,x</span>):</span><br><span class="line">        y_pri=np.dot(x,self.b)</span><br><span class="line">        <span class="keyword">return</span> y_pri</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">cv_pridict</span>(<span class="params">self,X,y,n_fold</span>):</span><br><span class="line">        cv = Cross_Validation(X, y, n_fold, self.n_lambda)</span><br><span class="line">        X_train, X_test, y_train, y_test = cv.CV()</span><br><span class="line">        y_allPredict = np.ones((<span class="number">1</span>, self.n_lambda))</span><br><span class="line">        lambda1=np.logspace(-<span class="number">10</span>,-<span class="number">2</span>,self.n_lambda)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_fold):</span><br><span class="line">            y_predict = np.zeros((y_test[i].shape[<span class="number">0</span>], self.n_lambda))</span><br><span class="line">            k=<span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> j  <span class="keyword">in</span> np.nditer(lambda1) :</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;第&#x27;</span>,k+<span class="number">1</span>+self.n_lambda*i,<span class="string">&#x27;次:&#x27;</span>,j)</span><br><span class="line">                pls = self.fit(X_train[i], y_train[i], j)</span><br><span class="line">                y_pre = self.pridict(X_test[i])</span><br><span class="line">                y_predict[:, k] = y_pre.ravel()</span><br><span class="line">                k=k+<span class="number">1</span></span><br><span class="line">            y_allPredict = np.vstack((y_allPredict, y_predict))</span><br><span class="line">        y_allPredict = y_allPredict[<span class="number">1</span>:]</span><br><span class="line">        <span class="keyword">return</span> y_allPredict, cv, y_test, y_train, X_test, X_train</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">RMSE_CV</span>(<span class="params">self, y_allPredict, y_measure, cv</span>):</span><br><span class="line">        press = np.square(np.subtract(y_allPredict, y_measure))</span><br><span class="line">        press_all = np.<span class="built_in">sum</span>(press, axis=<span class="number">0</span>)</span><br><span class="line">        RMSECV = np.sqrt(press_all / cv.n)</span><br><span class="line">        lambda_best= <span class="built_in">min</span>(RMSECV)</span><br><span class="line">        <span class="keyword">return</span> RMSECV, lambda_best</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">show_Select_lambda</span>(<span class="params">self,RMSECV</span>):</span><br><span class="line">        x=np.logspace(-<span class="number">10</span>,-<span class="number">2</span>,self.n_lambda)</span><br><span class="line">        plt.figure()</span><br><span class="line">        plt.plot(x,RMSECV,marker=<span class="string">&#x27;^&#x27;</span>,markersize=<span class="number">10</span>,markerfacecolor=<span class="string">&#x27;orange&#x27;</span>,color=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;lambda&#x27;</span>)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;RMSECV&#x27;</span>)</span><br><span class="line">        ax = plt.gca()</span><br><span class="line">        ax.set_xscale(<span class="string">&quot;log&quot;</span>)</span><br><span class="line">        ax.set_xlim(ax.get_xlim()[::-<span class="number">1</span>])</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">show_cv_predict</span>(<span class="params">self, y, x_test, y_test, y_train, x_train</span>):</span><br><span class="line">        plt.figure()</span><br><span class="line">        plt.plot([<span class="built_in">min</span>(y), <span class="built_in">max</span>(y)], [<span class="built_in">min</span>(y), <span class="built_in">max</span>(y)], label=<span class="string">&#x27;y=x&#x27;</span>, color=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">        plt.scatter(y_test[<span class="number">0</span>], self.pridict(x_test[<span class="number">0</span>]), color=<span class="string">&#x27;red&#x27;</span>, label=<span class="string">&#x27;test set&#x27;</span>)</span><br><span class="line">        plt.scatter(y_train[<span class="number">0</span>], self.pridict(x_train[<span class="number">0</span>]), color=<span class="string">&#x27;blue&#x27;</span>, label=<span class="string">&#x27;train set&#x27;</span>)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;measure value&#x27;</span>)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;predict value&#x27;</span>)</span><br><span class="line">        plt.legend()</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ ==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    data = sio.loadmat(<span class="string">&quot;../NIRcorn.mat&quot;</span>)</span><br><span class="line"></span><br><span class="line">    cornprop = data[<span class="string">&quot;cornprop&quot;</span>]</span><br><span class="line">    m5spec = data[<span class="string">&#x27;m5spec&#x27;</span>][<span class="string">&#x27;data&#x27;</span>][<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">    y = data[<span class="string">&#x27;cornprop&#x27;</span>][:, [<span class="number">0</span>]]</span><br><span class="line">    x = m5spec</span><br><span class="line"></span><br><span class="line">    rr=RidgeRegression(<span class="number">50</span>)</span><br><span class="line">    rr.fit(x,y,<span class="number">0.335641904424</span>)</span><br><span class="line">    y_pri=rr.pridict(x)</span><br><span class="line"></span><br><span class="line">    y_allPredict, cv, y_test, y_train, X_test, X_train=rr.cv_pridict(x,y,<span class="number">20</span>)</span><br><span class="line">    RMSECV, best_lambda =rr.RMSE_CV(y_allPredict,cv.y,cv)</span><br><span class="line">    rr.show_Select_lambda(RMSECV)</span><br><span class="line">    <span class="built_in">print</span>(best_lambda)</span><br><span class="line"></span><br><span class="line">    rr.show_cv_predict(y, X_test, y_test, y_train, X_train)</span><br><span class="line">    <span class="built_in">print</span>(y_train[<span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(rr.pridict(X_train[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> cross_validation</span><br><span class="line"><span class="comment"># from sklearn.decomposition import PCA</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Cross_Validation</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, x, y, n_folds, max_lambda</span>):</span><br><span class="line">        self.x = x</span><br><span class="line">        self.y = y</span><br><span class="line">        self.n_folds = n_folds</span><br><span class="line">        self.n = x.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">CV</span>(<span class="params">self</span>):</span><br><span class="line">        kf = cross_validation.KFold(self.n, self.n_folds)</span><br><span class="line">        x_train=[]</span><br><span class="line">        x_test=[]</span><br><span class="line">        y_train=[]</span><br><span class="line">        y_test=[]</span><br><span class="line">        <span class="keyword">for</span> train_index,test_index <span class="keyword">in</span> kf:</span><br><span class="line">            xtr, xte = self.x[train_index], self.x[test_index]</span><br><span class="line">            ytr, yte = self.y[train_index], self.y[test_index]</span><br><span class="line">            x_train.append(xtr)</span><br><span class="line">            x_test.append(xte)</span><br><span class="line">            y_train.append(ytr)</span><br><span class="line">            y_test.append(yte)</span><br><span class="line">        <span class="keyword">return</span> x_train, x_test, y_train, y_test</span><br></pre></td></tr></table></figure><p>正则化参数选择图像<imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204194028992.png"alt="image-20230204194028992" /></p><p>拟合效果图像</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230204194101069.png"alt="image-20230204194101069" /><figcaption aria-hidden="true">image-20230204194101069</figcaption></figure><p>可以发现最后回归系数都分布在10左右，比较平均，有很强的抗扰动。</p><h2 id="总结-7">总结</h2><p>岭回归对于模型的特征控制有着很好的效果，形成的回归系数相对平均有很强的抗干扰左右，而且能解决多重共线性，解决布满秩的情况。有很强的应用价值。</p>]]></content>
      
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习作业</title>
      <link href="/2023/04/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BD%9C%E4%B8%9A/"/>
      <url>/2023/04/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BD%9C%E4%B8%9A/</url>
      
        <content type="html"><![CDATA[<h1 id="作业九-反向传播算法bp">作业九 反向传播算法（BP）</h1><h2 id="算法推导">算法推导</h2><p><img src="G:\专业学习\第六学期\机器学习\神经网络.png" alt="神经网络" style="zoom: 25%;" /></p><p>令input layer 到hidden layer的权重为<spanclass="math inline">\(w_{ih}\)</span>，hidden layer和outputlayer的权重为<span class="math inline">\(w_{ho}\)</span></p><p>前向算法伪代码：</p><table><colgroup><col style="width: 100%" /></colgroup><thead><tr class="header"><th>Algorithm1: forward</th></tr></thead><tbody><tr class="odd"><td>input: X</td></tr><tr class="even"><td>output: <span class="math inline">\(y\)</span></td></tr><tr class="odd"><td>1. hidden_in=<span class="math inline">\(w_{ih}X+b_1\)</span><br/>2. hidden_out=<spanclass="math inline">\(\sigma(hidden\_in)\)</span><br/>3. output_in=<spanclass="math inline">\(w_{ho}X+b_2\)</span><br/>4. output_out=<spanclass="math inline">\(\sigma(output\_out)\)</span>#根据情况可有可无，无的话则output_in即为output_out<br/>5.y=output_out<br />6.<br/>7. return <spanclass="math inline">\(y\)</span></td></tr></tbody></table><p>output的输出结果为：<spanclass="math inline">\(y_j\)</span>，目标结果为<spanclass="math inline">\(t_j\)</span></p><p>令误差函数为<spanclass="math inline">\(E=\frac{1}{2}\sum_{j=0}^{n}{(y_j-t_j)^2}\)</span>，其中<spanclass="math inline">\(i\)</span>为output layer的神经元个数</p><p>下面给出反向传播的伪代码：</p><table><colgroup><col style="width: 100%" /></colgroup><thead><tr class="header"><th>Algorithm1: backprop</th></tr></thead><tbody><tr class="odd"><td>input: X,t,y,learn_rate</td></tr><tr class="even"><td>output: null</td></tr><tr class="odd"><td>1. <spanclass="math inline">\(\delta_1=(y-t)\sigma^{&#39;}(y)\)</span> #outputlayer的梯度<br />2. <spanclass="math inline">\(\delta_2=\sigma^{&#39;}(hidden\_output)\sum_{i=0}^{n}{w_{ho}\delta_1}\)</span>#求解hidden layer的梯度<br />3. <br/>4. <spanclass="math inline">\(w_{ih}-=learn\_rate*\delta_2\)</span><br/>5. <spanclass="math inline">\(w_{ho}-=learn\_rate*\delta_1\)</span><br/>6. <spanclass="math inline">\(b_{2}-=learn\_rate*\delta_2\)</span><br/>7. <spanclass="math inline">\(b_{1}-=learn\_rate*\delta_1\)</span><br/>8.<br/>9. return</td></tr></tbody></table><p>其中梯度求导原因如下： <span class="math display">\[\begin{array}{left}\frac{\partial E}{\partial w_{ij}}=\frac{\partial E}{\partiala{j}}\frac{\partial a_j}{\partial w_{ij}} \\其中：\\E=\frac{1}{2}\sum_{j=0}^{n}{(y_j-t_j)^2}\\a_j=\sum_i{w_{ij}z_i}\\z_j=\sigma(a_j)\\那么：\\\frac{\partial E}{\partial a{j}}=y_j-t_j \\\delta \equiv\frac{\partial E}{\partial a{j}}\\则：\\\frac{\partial E}{\partial w_{ij}}=\delta\frac{\partial a_j}{\partialw_{ij}}=\delta\sigma^{&#39;}(a_j)\end{array}\]</span></p><h2 id="拟合sin曲线">拟合sin曲线</h2><p>在实现中，outputlayer输出时不能采用Sigmoid函数激活，否则无法出现正常结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NN</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_neurons, hidden_neurons, output_neurons, learning_rate, epochs</span>):</span><br><span class="line">        self.input_neurons = input_neurons</span><br><span class="line">        self.hidden_neurons = hidden_neurons</span><br><span class="line">        self.output_neurons = output_neurons</span><br><span class="line">        self.epochs = epochs</span><br><span class="line">        self.lr = learning_rate</span><br><span class="line"></span><br><span class="line">        self.wih = np.random.normal(<span class="number">0</span>, <span class="number">1</span>, (self.hidden_neurons, self.input_neurons))</span><br><span class="line">        self.bih = <span class="number">0</span></span><br><span class="line">        self.who = np.random.normal(<span class="number">0</span>, <span class="number">1</span>, (self.output_neurons, self.hidden_neurons))</span><br><span class="line">        self.bho = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">activation</span>(<span class="params">self, Z</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-Z))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sigmoid_derivative</span>(<span class="params">self, Z</span>):</span><br><span class="line">        <span class="keyword">return</span> self.activation(Z) * (<span class="number">1</span> - self.activation(Z))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 前向传播</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, input_list</span>):</span><br><span class="line">        inputs = np.array(input_list, ndmin=<span class="number">2</span>)</span><br><span class="line">        hidden_inputs = np.dot(self.wih, inputs) + self.bih</span><br><span class="line">        hidden_outputs = self.activation(hidden_inputs)</span><br><span class="line">        final_inputs = np.dot(self.who, hidden_outputs) + self.bho</span><br><span class="line">        final_outputs=final_inputs</span><br><span class="line">        <span class="keyword">return</span> final_outputs</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 反向传播</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">backprop</span>(<span class="params">self, inputs_list, targets_list</span>):</span><br><span class="line">        inputs = np.array(inputs_list, ndmin=<span class="number">2</span>)</span><br><span class="line">        tj = np.array(targets_list, ndmin=<span class="number">2</span>)</span><br><span class="line">        hidden_inputs = np.dot(self.wih, inputs) + self.bih</span><br><span class="line">        hidden_outputs = self.activation(hidden_inputs)</span><br><span class="line">        final_inputs = np.dot(self.who, hidden_outputs) + self.bho</span><br><span class="line">        yj = final_inputs</span><br><span class="line">        output_errors = (yj - tj)</span><br><span class="line">        hidden_errors = np.dot(self.who.T, output_errors)*self.sigmoid_derivative(hidden_outputs)</span><br><span class="line">        self.who -= self.lr * np.dot(output_errors , np.transpose(hidden_outputs))</span><br><span class="line">        self.wih -= self.lr * np.dot(hidden_errors, np.transpose(inputs))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># updating bias</span></span><br><span class="line">        self.bho -= self.lr * output_errors</span><br><span class="line">        self.bih -= self.lr * hidden_errors</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, inputs_list, targets_list</span>):</span><br><span class="line">        loss_list=[]</span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(self.epochs):</span><br><span class="line">            self.backprop(inputs_list, targets_list)</span><br><span class="line">            y_pre=self.predict(inputs_list)</span><br><span class="line">            loss=np.sqrt(np.<span class="built_in">sum</span>(np.square(y_pre-targets_list)))/<span class="number">2</span></span><br><span class="line">            loss_list.append(loss)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Epoch <span class="subst">&#123;epoch&#125;</span>/<span class="subst">&#123;self.epochs&#125;</span> ,loss:<span class="subst">&#123;loss&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> loss_list</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, X</span>):</span><br><span class="line">        outputs = self.forward(X).T</span><br><span class="line">        <span class="keyword">return</span> outputs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line"></span><br><span class="line">    plt.style.use(<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line">    <span class="comment"># 创建数据</span></span><br><span class="line">    x = np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line">    y = np.sin(<span class="number">2</span> * np.pi * x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 添加随机噪声</span></span><br><span class="line">    np.random.seed(<span class="number">20</span>)</span><br><span class="line">    y_noisy = y + <span class="number">0.05</span> * np.random.normal(size=x.shape)</span><br><span class="line">    nn = NN(<span class="number">1</span>, <span class="number">50</span>, <span class="number">1</span>, <span class="number">0.02</span>,<span class="number">200</span>)</span><br><span class="line">    loss=nn.fit(x, y_noisy)</span><br><span class="line"></span><br><span class="line">    x_test = np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line">    y_pred = nn.predict(x_test)</span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.plot(x_test, y_pred, label=<span class="string">&#x27;Regressor&#x27;</span>, color=<span class="string">&#x27;#FFA628&#x27;</span>)</span><br><span class="line">    plt.plot(x, y, label=<span class="string">&#x27;True function&#x27;</span>, color=<span class="string">&#x27;g&#x27;</span>)</span><br><span class="line">    plt.scatter(x, y_noisy, edgecolor=<span class="string">&#x27;b&#x27;</span>, s=<span class="number">20</span>, label=<span class="string">&#x27;Noisy samples&#x27;</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.plot(np.linspace(<span class="number">3</span>,<span class="built_in">len</span>(loss),<span class="built_in">len</span>(loss)-<span class="number">3</span>),loss[<span class="number">3</span>:])</span><br><span class="line">    plt.title(<span class="string">&#x27;loss curve&#x27;</span>)</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p>经过200次迭代后，结果如下：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230507143232977.png" alt="image-20230507143232977" style="zoom:50%;" /></p><p>loss曲线如下：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230507143309196.png" alt="image-20230507143309196" style="zoom:50%;" /></p><p>如果迭代2000次：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/f624b4755450bca033368ecadb12ed7.png" alt="f624b4755450bca033368ecadb12ed7" style="zoom: 67%;" /></p><p>可以看到有明显过拟合。</p><p>如果输出结果，采用Sigmoid函数处理：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230507143624375.png" alt="image-20230507143624375" style="zoom: 50%;" /></p><p>原因很简单，因为Sigmoid函数将数值缩放到了0，导致结果均为0，如果将误差符号反向，那么将得到一条y=1的直线作业八神经网络初步</p><h1 id="作业八-神经网络初步">作业八 神经网络初步</h1><p>sklearn中人工神经网络（ANN）主要提供的是多层感知机（MLP），其中有回归和分类两种，回归感知机还有能够自动实现交叉验证的版本。</p><h2 id="mlpclassifier二分类">MLPClassifier二分类</h2><p>流程如下：</p><ol type="1"><li>导入iris数据，取后两类</li><li>标准化</li><li>PCA得到x_pca，y</li><li>初始化MLP，训练</li><li>绘制分类面</li></ol><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> l1_min_c</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_decision_surface</span>(<span class="params">model, X, y, grid_size=<span class="number">0.02</span></span>):</span><br><span class="line">    <span class="comment"># 获取数据范围</span></span><br><span class="line">    x_min, x_max = X[:, <span class="number">0</span>].<span class="built_in">min</span>() - <span class="number">0.5</span>, X[:, <span class="number">0</span>].<span class="built_in">max</span>() + <span class="number">0.5</span></span><br><span class="line">    y_min, y_max = X[:, <span class="number">1</span>].<span class="built_in">min</span>() - <span class="number">0.5</span>, X[:, <span class="number">1</span>].<span class="built_in">max</span>() + <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 生成网格点</span></span><br><span class="line">    xx, yy = np.meshgrid(np.arange(x_min, x_max, grid_size), np.arange(y_min, y_max, grid_size))</span><br><span class="line">    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])</span><br><span class="line">    Z = Z.reshape(xx.shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 绘制分类面和训练数据</span></span><br><span class="line">    cmap_light = ListedColormap([<span class="string">&#x27;#FFAAAA&#x27;</span>, <span class="string">&#x27;#AAFFAA&#x27;</span>, <span class="string">&#x27;#AAAAFF&#x27;</span>])</span><br><span class="line">    cmap_bold = ListedColormap([<span class="string">&#x27;#FF0000&#x27;</span>, <span class="string">&#x27;#00FF00&#x27;</span>, <span class="string">&#x27;#0000FF&#x27;</span>])</span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)</span><br><span class="line">    plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y, cmap=cmap_bold, edgecolor=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line">    plt.xlim(xx.<span class="built_in">min</span>(), xx.<span class="built_in">max</span>())</span><br><span class="line">    plt.ylim(yy.<span class="built_in">min</span>(), yy.<span class="built_in">max</span>())</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Sepal length&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;Sepal width&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Iris classification using MLP&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">X = iris.data</span><br><span class="line">y = iris.target</span><br><span class="line"></span><br><span class="line">X = X[y != <span class="number">0</span>]</span><br><span class="line">y = y[y != <span class="number">0</span>]</span><br><span class="line"><span class="comment"># 标准化</span></span><br><span class="line">standard=StandardScaler()</span><br><span class="line">X=standard.fit_transform(X)</span><br><span class="line"><span class="comment"># PCA</span></span><br><span class="line">pca=PCA(n_components=<span class="number">2</span>)</span><br><span class="line">x_pca=pca.fit_transform(X)</span><br><span class="line"><span class="comment"># 初始化mlp</span></span><br><span class="line">mlp=MLPClassifier(solver=<span class="string">&#x27;lbfgs&#x27;</span>,hidden_layer_sizes=(<span class="number">5</span>,<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">mlp.fit(x_pca,y)</span><br><span class="line"></span><br><span class="line">plot_decision_surface(mlp, x_pca, y)</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230422220300024.png" alt="image-20230422220300024" style="zoom:50%;" /></p><h2 id="mlpclassifier多分类">MLPClassifier多分类</h2><p>流程如下：</p><ol type="1"><li>导入iris数据</li><li>标准化</li><li>PCA得到x_pca，y</li><li>初始化MLP，训练</li><li>绘制分类面</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> plot_confusion_matrix</span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_decision_surface</span>(<span class="params">model, X, y, grid_size=<span class="number">0.02</span></span>):</span><br><span class="line">    <span class="comment"># 获取数据范围</span></span><br><span class="line">    x_min, x_max = X[:, <span class="number">0</span>].<span class="built_in">min</span>() - <span class="number">0.5</span>, X[:, <span class="number">0</span>].<span class="built_in">max</span>() + <span class="number">0.5</span></span><br><span class="line">    y_min, y_max = X[:, <span class="number">1</span>].<span class="built_in">min</span>() - <span class="number">0.5</span>, X[:, <span class="number">1</span>].<span class="built_in">max</span>() + <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 生成网格点</span></span><br><span class="line">    xx, yy = np.meshgrid(np.arange(x_min, x_max, grid_size), np.arange(y_min, y_max, grid_size))</span><br><span class="line">    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])</span><br><span class="line">    Z = Z.reshape(xx.shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 绘制分类面和训练数据</span></span><br><span class="line">    cmap_light = ListedColormap([<span class="string">&#x27;#FFAAAA&#x27;</span>, <span class="string">&#x27;#AAFFAA&#x27;</span>, <span class="string">&#x27;#AAAAFF&#x27;</span>])</span><br><span class="line">    cmap_bold = ListedColormap([<span class="string">&#x27;#FF0000&#x27;</span>, <span class="string">&#x27;#00FF00&#x27;</span>, <span class="string">&#x27;#0000FF&#x27;</span>])</span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)</span><br><span class="line">    plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y, cmap=cmap_bold, edgecolor=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line">    plt.xlim(xx.<span class="built_in">min</span>(), xx.<span class="built_in">max</span>())</span><br><span class="line">    plt.ylim(yy.<span class="built_in">min</span>(), yy.<span class="built_in">max</span>())</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Sepal length&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;Sepal width&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Iris classification using MLP&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line">iris = load_iris()</span><br><span class="line">X = iris.data[:, :<span class="number">2</span>]  <span class="comment"># 只使用前两个特征</span></span><br><span class="line">y = iris.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分数据集</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建多层感知器模型</span></span><br><span class="line">mlp = MLPClassifier(hidden_layer_sizes=(<span class="number">10</span>,), max_iter=<span class="number">1000</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">mlp.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制分类面</span></span><br><span class="line">plot_decision_surface(mlp, X_train, y_train)</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230422220443459.png" alt="image-20230422220443459" style="zoom:50%;" /></p><h2 id="mlpregressor">MLPRegressor</h2><p>程序流程如下：</p><ol type="1"><li>创建数据X，y</li><li>为y添加随机噪声</li><li>初始化MLP</li><li>训练MLP</li><li>绘制预测效果图</li></ol><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPRegressor</span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line"><span class="comment"># 创建数据</span></span><br><span class="line">x = np.linspace(-<span class="number">5</span>, <span class="number">5</span>, <span class="number">100</span>)</span><br><span class="line">y = np.sin(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加随机噪声</span></span><br><span class="line">np.random.seed(<span class="number">42</span>)</span><br><span class="line">y_noisy = y + <span class="number">0.2</span> * np.random.normal(size=x.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建多层感知器模型</span></span><br><span class="line">mlp = MLPRegressor(hidden_layer_sizes=(<span class="number">50</span>,), max_iter=<span class="number">1000</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">mlp.fit(x.reshape(-<span class="number">1</span>, <span class="number">1</span>), y_noisy)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测并绘制结果</span></span><br><span class="line">x_test = np.linspace(-<span class="number">5.5</span>, <span class="number">5.5</span>, <span class="number">100</span>)</span><br><span class="line">y_pred = mlp.predict(x_test.reshape(-<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">plt.plot(x_test, y_pred, label=<span class="string">&#x27;MLP Regressor&#x27;</span>,color=<span class="string">&#x27;#FFA628&#x27;</span>)</span><br><span class="line">plt.plot(x, y, label=<span class="string">&#x27;True function&#x27;</span>,color=<span class="string">&#x27;g&#x27;</span>)</span><br><span class="line">plt.scatter(x, y_noisy, edgecolor=<span class="string">&#x27;b&#x27;</span>, s=<span class="number">20</span>, label=<span class="string">&#x27;Noisy samples&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.title(<span class="string">&#x27;MLP Regressor&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230422220624823.png" alt="image-20230422220624823" style="zoom:50%;" /></p><h1 id="作业七-逻辑回归分类">作业七 逻辑回归分类</h1><p>由于都是从sklearn中调用，并不涉及什么复杂算法，因此下面采用列表的方式描述程序作用</p><h2 id="二分类逻辑回归">二分类逻辑回归</h2><p>首先说明下面程序的目的：</p><table><thead><tr class="header"><th>1.观察不同惩罚项系数对应参数变化</th></tr></thead><tbody><tr class="odd"><td><strong>2.观察不同惩罚项系数对应错误率</strong></td></tr><tr class="even"><td><strong>3.可视化二分类结果</strong></td></tr></tbody></table><p>流程如下：</p><ol type="1"><li>导入iris数据，取后两类</li><li>标准化</li><li>PCA得到x_pca，y</li><li>初始化逻辑回归</li><li>调整参数c，分别训练逻辑回归得到权重参数和错误率</li><li>绘制错误率和权重参数曲线</li><li>绘制分类面</li></ol><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> l1_min_c</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">X = iris.data</span><br><span class="line">y = iris.target</span><br><span class="line"><span class="comment"># 选出前两类</span></span><br><span class="line">X = X[y != <span class="number">0</span>]</span><br><span class="line">y = y[y != <span class="number">0</span>]</span><br><span class="line"><span class="comment"># 画出图像</span></span><br><span class="line">plt.figure()</span><br><span class="line">plt.scatter(X[y == <span class="number">2</span>, <span class="number">0</span>], X[y == <span class="number">2</span>, <span class="number">1</span>], color=<span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;0&#x27;</span>)</span><br><span class="line">plt.scatter(X[y == <span class="number">1</span>, <span class="number">0</span>], X[y == <span class="number">1</span>, <span class="number">1</span>], color=<span class="string">&#x27;g&#x27;</span>, label=<span class="string">&#x27;1&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># 训练</span></span><br><span class="line">cs = l1_min_c(X, y, loss=<span class="string">&#x27;log&#x27;</span>) * np.logspace(<span class="number">0</span>, <span class="number">7</span>, <span class="number">16</span>)</span><br><span class="line"><span class="comment"># 初始化逻辑回归</span></span><br><span class="line">clf = LogisticRegression(</span><br><span class="line">    penalty=<span class="string">&#x27;l1&#x27;</span>,</span><br><span class="line">    solver=<span class="string">&#x27;liblinear&#x27;</span>,</span><br><span class="line">    tol=<span class="number">1e-6</span>,</span><br><span class="line">    max_iter=<span class="built_in">int</span>(<span class="number">1e6</span>),</span><br><span class="line">    warm_start=<span class="literal">True</span>,</span><br><span class="line">    intercept_scaling=<span class="number">1000.0</span>,</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 错误率</span></span><br><span class="line">errors = []</span><br><span class="line"><span class="comment"># 各个特征对参数</span></span><br><span class="line">coefs_ = []</span><br><span class="line"><span class="comment"># 拟合观察参数</span></span><br><span class="line"><span class="keyword">for</span> c <span class="keyword">in</span> cs:</span><br><span class="line">    clf.set_params(C=c)</span><br><span class="line">    clf.fit(X, y)</span><br><span class="line">    y_pre = clf.predict(X)</span><br><span class="line">    error = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(y)):</span><br><span class="line">        <span class="keyword">if</span> y_pre[i] != y[i]:</span><br><span class="line">            error = error + <span class="number">1</span></span><br><span class="line">    errors.append(error)</span><br><span class="line">    coefs_.append(clf.coef_.ravel().copy())</span><br><span class="line">errors = np.array(errors) / <span class="built_in">len</span>(y)</span><br><span class="line">coefs_ = np.array(coefs_)</span><br><span class="line"><span class="comment"># 绘制参数变化</span></span><br><span class="line">plt.plot(np.log10(cs), coefs_, marker=<span class="string">&quot;o&quot;</span>)</span><br><span class="line">ymin, ymax = plt.ylim()</span><br><span class="line">plt.xlabel(<span class="string">&quot;log(C)&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Coefficients&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Logistic Regression Path&quot;</span>)</span><br><span class="line">plt.axis(<span class="string">&quot;tight&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># 绘制错误率</span></span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(np.log10(cs), errors, marker=<span class="string">&#x27;^&#x27;</span>, color=<span class="string">&#x27;orange&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;error rate&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;log(C)&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># 最优拟合</span></span><br><span class="line">clf.set_params(C=<span class="number">1</span>)</span><br><span class="line">clf.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># PCA可视化</span></span><br><span class="line">pca = PCA(n_components=<span class="number">2</span>)</span><br><span class="line">X1 = pca.fit_transform(X)</span><br><span class="line">clf.set_params(C=<span class="number">1</span>)</span><br><span class="line">clf.fit(X1, y)</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.scatter(X1[y == <span class="number">2</span>, <span class="number">0</span>], X1[y == <span class="number">2</span>, <span class="number">1</span>], color=<span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;2&#x27;</span>)</span><br><span class="line">plt.scatter(X1[y == <span class="number">1</span>, <span class="number">0</span>], X1[y == <span class="number">1</span>, <span class="number">1</span>], color=<span class="string">&#x27;g&#x27;</span>, label=<span class="string">&#x27;1&#x27;</span>)</span><br><span class="line">plt.plot([<span class="built_in">min</span>(X1[:, <span class="number">0</span>]), <span class="built_in">max</span>(X1[:, <span class="number">0</span>])], [-(<span class="built_in">min</span>(X1[:, <span class="number">0</span>]) * clf.coef_[<span class="number">0</span>, <span class="number">0</span>] + clf.intercept_[<span class="number">0</span>]) / clf.coef_[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">                                          -(<span class="built_in">max</span>(X1[:, <span class="number">0</span>]) * clf.coef_[<span class="number">0</span>, <span class="number">0</span>] + clf.intercept_[<span class="number">0</span>]) / clf.coef_[<span class="number">0</span>, <span class="number">1</span>]],</span><br><span class="line">         label=<span class="string">&#x27;classier&#x27;</span>, linewidth=<span class="number">3.0</span>, color=<span class="string">&#x27;black&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.xlabel(<span class="string">&#x27;component 1&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;component 2&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>结果如下：</p><p>不同惩罚项对应的参数变化，可以看出当惩罚项小于1时，对于模型的稀疏化效果较好。</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230422214826267.png" alt="image-20230422214826267" style="zoom:50%;" /></p><p>不同惩罚项系数对应的分类错误率，选择为10时效果较好；</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230422214946938.png" alt="image-20230422214946938" style="zoom:50%;" /></p><p>分类结果效果如图：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230422215101050.png" alt="image-20230422215101050" style="zoom:50%;" /></p><h2 id="多分类逻辑回归">多分类逻辑回归</h2><p>首先说明下面程序的目的：</p><table><thead><tr class="header"><th>1.绘制多分类的分类面</th></tr></thead><tbody></tbody></table><p>流程如下：</p><ol type="1"><li>导入iris数据</li><li>标准化</li><li>PCA得到x_pca，y</li><li>初始化逻辑回归，训练逻辑回归</li><li>绘制分类面</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> l1_min_c</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">X = iris.data</span><br><span class="line">y = iris.target</span><br><span class="line"><span class="comment"># 标准化</span></span><br><span class="line">standard=StandardScaler()</span><br><span class="line">X=standard.fit_transform(X)</span><br><span class="line"><span class="comment"># PCA</span></span><br><span class="line">pca=PCA(n_components=<span class="number">2</span>)</span><br><span class="line">x_pca=pca.fit_transform(X)</span><br><span class="line"><span class="comment"># 初始化逻辑回归</span></span><br><span class="line">clf = LogisticRegression(</span><br><span class="line">    solver=<span class="string">&#x27;liblinear&#x27;</span>,</span><br><span class="line">    max_iter=<span class="built_in">int</span>(<span class="number">1e6</span>),</span><br><span class="line">    warm_start=<span class="literal">True</span>,</span><br><span class="line">    intercept_scaling=<span class="number">1000.0</span></span><br><span class="line">)</span><br><span class="line">clf.fit(x_pca,y)</span><br><span class="line">coef,intercept=np.array(clf.coef_),np.array(clf.intercept_)</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.scatter(x_pca[y == <span class="number">2</span>, <span class="number">0</span>], x_pca[y == <span class="number">2</span>, <span class="number">1</span>], color=<span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;2&#x27;</span>)</span><br><span class="line">plt.scatter(x_pca[y == <span class="number">1</span>, <span class="number">0</span>], x_pca[y == <span class="number">1</span>, <span class="number">1</span>], color=<span class="string">&#x27;g&#x27;</span>, label=<span class="string">&#x27;1&#x27;</span>)</span><br><span class="line">plt.scatter(x_pca[y == <span class="number">0</span>, <span class="number">0</span>], x_pca[y == <span class="number">0</span>, <span class="number">1</span>], color=<span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;0&#x27;</span>)</span><br><span class="line">plt.plot([<span class="built_in">min</span>(x_pca[:, <span class="number">0</span>]), <span class="built_in">max</span>(x_pca[:, <span class="number">0</span>])], [-(<span class="built_in">min</span>(x_pca[:, <span class="number">0</span>]) * coef[<span class="number">0</span>, <span class="number">0</span>] + intercept[<span class="number">0</span>]) / coef[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">                                          -(<span class="built_in">max</span>(x_pca[:, <span class="number">0</span>]) * coef[<span class="number">0</span>, <span class="number">0</span>] + intercept[<span class="number">0</span>]) / coef[<span class="number">0</span>, <span class="number">1</span>]],</span><br><span class="line">         label=<span class="string">&#x27;classier&#x27;</span>, linewidth=<span class="number">3.0</span>, color=<span class="string">&#x27;black&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.plot([<span class="built_in">min</span>(x_pca[:, <span class="number">0</span>]), <span class="built_in">max</span>(x_pca[:, <span class="number">0</span>])], [-(<span class="built_in">min</span>(x_pca[:, <span class="number">0</span>]) * coef[<span class="number">1</span>, <span class="number">0</span>] + intercept[<span class="number">1</span>]) / coef[<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                                          -(<span class="built_in">max</span>(x_pca[:, <span class="number">0</span>]) * coef[<span class="number">1</span>, <span class="number">0</span>] + intercept[<span class="number">1</span>]) / coef[<span class="number">1</span>, <span class="number">1</span>]],</span><br><span class="line">         label=<span class="string">&#x27;classier&#x27;</span>, linewidth=<span class="number">3.0</span>, color=<span class="string">&#x27;black&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">plt.plot([<span class="built_in">min</span>(x_pca[:, <span class="number">0</span>]), <span class="built_in">max</span>(x_pca[:, <span class="number">0</span>])], [-(<span class="built_in">min</span>(x_pca[:, <span class="number">0</span>]) * coef[<span class="number">2</span>, <span class="number">0</span>] + intercept[<span class="number">2</span>]) / coef[<span class="number">2</span>, <span class="number">1</span>],</span><br><span class="line">                                          -(<span class="built_in">max</span>(x_pca[:, <span class="number">0</span>]) * coef[<span class="number">2</span>, <span class="number">0</span>] + intercept[<span class="number">2</span>]) / coef[<span class="number">2</span>, <span class="number">1</span>]],</span><br><span class="line">         label=<span class="string">&#x27;classier&#x27;</span>, linewidth=<span class="number">3.0</span>, color=<span class="string">&#x27;black&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">plt.ylim(-<span class="number">5</span>,<span class="number">5</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.xlabel(<span class="string">&#x27;component 1&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;component 2&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230422215323041.png" alt="image-20230422215323041" style="zoom:50%;" /></p><h1 id="作业六">作业六</h1><h2 id="bayesian-linear-regression">Bayesian Linear Regression</h2><p>所有算法都放在同一个Python文件下，函数算法伪代码如下：</p><table><colgroup><col style="width: 100%" /></colgroup><thead><tr class="header"><th>Algorithm1: fit</th></tr></thead><tbody><tr class="odd"><td>input: X,t,degree, <spanclass="math inline">\(\alpha,\beta,\phi\)</span></td></tr><tr class="even"><td>output: <span class="math inline">\(m_n,S_n\)</span></td></tr><tr class="odd"><td>1. <strong><span class="math inline">\(if\)</span></strong>len(X.shape) == 1: # 预先判断形状<br /> 2. X=X.reshape(-1,1)<br />3.<strong><span class="math inline">\(if\)</span></strong> len(t.shape)==1:<br />4. t=t.reshape(-1,1)<br />5. <spanclass="math inline">\(S_n^{-1}=\alpha I+\beta\phi(X)^T\phi(X)\)</span> #计算协方差的逆<br />6. <spanclass="math inline">\(S_n=\)</span>np.linalg.inv(<spanclass="math inline">\(S_n^{-1}\)</span>)<br />7. <spanclass="math inline">\(m_n=\beta S_n \phi(X)^Tt\)</span> # 计算均值<br />8.<br />9. return <spanclass="math inline">\(m_n,S_n\)</span></td></tr></tbody></table><table><colgroup><col style="width: 100%" /></colgroup><thead><tr class="header"><th>Algorithm2: predict</th></tr></thead><tbody><tr class="odd"><td>input: X, <span class="math inline">\(\phi,m_n,S_n\)</span></td></tr><tr class="even"><td>output: <span class="math inline">\(mean,\sigma^2\)</span></td></tr><tr class="odd"><td>1. <span class="math inline">\(\sigma^2\)</span> = <spanclass="math inline">\(\frac{1}{\beta}+\phi(X)S_n\phi(X)^T\)</span><br />2.mean=<span class="math inline">\(\phi(x)m_n\)</span><br />3.<br/>4.return mean, <span class="math inline">\(\sigma ^2\)</span></td></tr></tbody></table><p>代码实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> multivariate_normal</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> Polyfeature <span class="keyword">import</span> Polyfeature</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BLR</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,n_features,alpha=<span class="number">0</span>,beta=<span class="number">1</span>,phi=<span class="string">&#x27;linear&#x27;</span></span>):</span><br><span class="line">        self.n_features=n_features</span><br><span class="line">        self.alpha=alpha</span><br><span class="line">        self.beta=beta</span><br><span class="line">        self.phi=phi</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    alpha 表示w的先验的精度</span></span><br><span class="line"><span class="string">    beta  表示数据的精度</span></span><br><span class="line"><span class="string">    phi   表示基函数，可选参数为：linear、gaussain、polynomial、sigmoid</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">gaussian</span>(<span class="params">self,x, mu, sigma</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span> / (sigma * np.sqrt(<span class="number">2</span> * np.pi)) * np.exp(-(x - mu) ** <span class="number">2</span> / (<span class="number">2</span> * sigma ** <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self,X,t</span>):</span><br><span class="line">        <span class="comment"># 检查向量是否是二维数组并转化</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(X.shape) == <span class="number">1</span>:</span><br><span class="line">            X=X.reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(t.shape) == <span class="number">1</span>:</span><br><span class="line">            t=t.reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 是否要0均值？</span></span><br><span class="line">        <span class="keyword">global</span> phi_x</span><br><span class="line">        <span class="keyword">global</span> x</span><br><span class="line">        <span class="keyword">if</span> self.phi==<span class="string">&#x27;linear&#x27;</span>:</span><br><span class="line">            phi_x=X</span><br><span class="line">            x=np.dot(phi_x,phi_x.T)</span><br><span class="line">        <span class="keyword">if</span> self.phi==<span class="string">&#x27;polynomial&#x27;</span>:</span><br><span class="line">            polyf=Polyfeature(self.n_features)</span><br><span class="line">            phi_x=polyf.fit_transform(X)</span><br><span class="line">            x=np.dot(phi_x.T,phi_x)</span><br><span class="line">        <span class="comment"># Sn的逆</span></span><br><span class="line">        Sn_inverse=self.alpha*np.eye(x.shape[<span class="number">0</span>])+self.beta*x</span><br><span class="line">        <span class="comment"># 计算期望</span></span><br><span class="line">        mn=self.beta*np.dot(np.dot(np.linalg.inv(Sn_inverse),phi_x.T),t)</span><br><span class="line"></span><br><span class="line">        self.phi_x=phi_x</span><br><span class="line">        self.Sn_inverse=Sn_inverse</span><br><span class="line">        self.mn=mn</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self,X</span>):</span><br><span class="line">        <span class="keyword">if</span> self.phi==<span class="string">&#x27;linear&#x27;</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(X.shape)==<span class="number">1</span>:</span><br><span class="line">                X = X.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">                sigma2=<span class="number">1</span>/self.beta+np.dot(np.dot(self.phi_x.T,np.linalg.inv(self.Sn_inverse)),self.phi_x)</span><br><span class="line">                t_pre=self.gaussian(X,self.mn,np.sqrt(sigma2))</span><br><span class="line">                <span class="keyword">return</span> t_pre</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.phi==<span class="string">&#x27;polynomial&#x27;</span>:</span><br><span class="line">            polyf=Polyfeature(self.n_features)</span><br><span class="line">            X=polyf.fit_transform(X)</span><br><span class="line"></span><br><span class="line">        sigma2 = np.diag(<span class="number">1</span> / self.beta + X @ np.linalg.inv(self.Sn_inverse) @ X.T).reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">        mean=np.dot(X,self.mn)</span><br><span class="line"></span><br><span class="line">        upper = mean + np.sqrt(sigma2)</span><br><span class="line">        lower = mean - np.sqrt(sigma2)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> mean,sigma2,upper,lower</span><br></pre></td></tr></table></figure><p>回归效果：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/90e39f72c8da404c0738ddf8072aae4.png" alt="90e39f72c8da404c0738ddf8072aae4" style="zoom: 67%;" /></p><h2 id="不同样本数量影响拟合效果">不同样本数量影响拟合效果</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">   x_1=np.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">100</span>)</span><br><span class="line">    X_data=[np.array([<span class="number">0.5</span>]),</span><br><span class="line">                     np.array([<span class="number">0.3</span>,<span class="number">0.6</span>]),</span><br><span class="line">                     np.array([<span class="number">0.25</span>,<span class="number">0.5</span>,<span class="number">0.75</span>,<span class="number">0.8</span>]),</span><br><span class="line">                     np.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">60</span>)]</span><br><span class="line">j=<span class="number">1</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">6</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> X_data:</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">2</span>,j)</span><br><span class="line">    t=np.sin(<span class="number">2</span>*np.pi*i)+np.random.normal(loc=<span class="number">0</span>,scale=<span class="number">0.2</span>,size=i.shape)</span><br><span class="line">    <span class="keyword">if</span> j&lt;<span class="number">2</span>:</span><br><span class="line">        blr = BLR(<span class="number">5</span>, phi=<span class="string">&#x27;polynomial&#x27;</span>,alpha=<span class="number">0.2</span>)</span><br><span class="line">        plt.title(<span class="string">&#x27;alpha=0.2&#x27;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        blr = BLR(<span class="number">4</span>, phi=<span class="string">&#x27;polynomial&#x27;</span>)</span><br><span class="line">        plt.title(<span class="string">&#x27;without alpha&#x27;</span>)</span><br><span class="line">    j=j+<span class="number">1</span></span><br><span class="line">    <span class="comment"># 绘制sin原图像</span></span><br><span class="line">    plt.plot(x_1,np.sin(<span class="number">2</span>*np.pi*x_1),label=<span class="string">&#x27;sin(x)&#x27;</span>)</span><br><span class="line">    <span class="comment"># 绘制数据散点</span></span><br><span class="line">    plt.scatter(i, t, color=<span class="string">&#x27;g&#x27;</span>,label=<span class="string">&#x27;samples&#x27;</span>)</span><br><span class="line">    blr.fit(i, t)</span><br><span class="line">    plt.plot(x_1, blr.predict(x_1)[<span class="number">0</span>], color=<span class="string">&#x27;black&#x27;</span>,label=<span class="string">&#x27;prediction&#x27;</span>)</span><br><span class="line">    <span class="comment"># 绘制阴影部分</span></span><br><span class="line">    plt.fill_between(x_1.squeeze(), blr.predict(x_1)[<span class="number">3</span>].squeeze(), blr.predict(x_1)[<span class="number">2</span>].squeeze(), alpha=<span class="number">0.4</span>,label=<span class="string">&#x27;varience&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.xlabel(<span class="string">&#x27;X&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;t&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230408203151173.png"alt="image-20230408203151173" /><figcaption aria-hidden="true">image-20230408203151173</figcaption></figure><p>同时，我调整了样本数量较小时的<spanclass="math inline">\(\alpha\)</span>值，下图是无正则化的情况（样本数量为1时，必须有正则化否则出现奇异矩阵）：</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230408203316307.png"alt="image-20230408203316307" /><figcaption aria-hidden="true">image-20230408203316307</figcaption></figure><h2 id="交叉验证调优">交叉验证调优</h2><p>因为要做调优，所以固定生成数据，设定种子为0。</p><p>在固定<spanclass="math inline">\(\alpha=0,beta=10\)</span>时，首先确定degree：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230408213637573.png" alt="image-20230408213637573" style="zoom:50%;" /></p><p>best degree is 9 min RMSE in test sets: 0.2014522467351943</p><p>接下来在<spanclass="math inline">\(degrer=9\)</span>的情况下，寻找<spanclass="math inline">\(\alpha\)</span>的参数最优情况：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230408221238294.png" alt="image-20230408221238294" style="zoom:50%;" /></p><p>parameter_best is 2.848035868435799e-05</p><p>最后，按以上两种情况搜寻参数<spanclass="math inline">\(\beta\)</span>：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230408221701245.png" alt="image-20230408221701245" style="zoom: 50%;" /></p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230408221719701.png" alt="image-20230408221719701" style="zoom:50%;" /></p><p>beta_best is 14.84968262254465</p><p>最终参数选择结果为：</p><table><thead><tr class="header"><th><span class="math inline">\(\alpha\)</span></th><th>2.848035868435799e-05</th></tr></thead><tbody><tr class="odd"><td><span class="math inline">\(degree\)</span></td><td><strong>9</strong></td></tr><tr class="even"><td><span class="math inline">\(\beta\)</span></td><td><strong>14.84968262254465</strong></td></tr></tbody></table><p>最终拟合结果：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230408222416810.png" alt="image-20230408222416810" style="zoom: 50%;" /></p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230408222947483.png" alt="image-20230408222947483" style="zoom: 50%;" /></p><h2 id="模拟拟合过程似然先验">模拟拟合过程（似然、先验）</h2><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230408233948782.png" alt="image-20230408233948782" style="zoom:67%;" /></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> multivariate_normal, norm</span><br><span class="line"><span class="keyword">from</span> numpy.random <span class="keyword">import</span> seed, uniform, randn</span><br><span class="line"><span class="keyword">from</span> numpy.linalg <span class="keyword">import</span> inv</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">x, a</span>):</span><br><span class="line">    <span class="keyword">return</span> a[<span class="number">0</span>] + a[<span class="number">1</span>] * x</span><br><span class="line"></span><br><span class="line">a = np.array([-<span class="number">0.3</span>, <span class="number">0.5</span>])</span><br><span class="line">N = <span class="number">30</span></span><br><span class="line">sigma = <span class="number">0.2</span></span><br><span class="line">X = uniform(-<span class="number">1</span>, <span class="number">1</span>, (N, <span class="number">1</span>))</span><br><span class="line">T = f(X, a) + randn(N, <span class="number">1</span>) * sigma</span><br><span class="line"></span><br><span class="line">beta = (<span class="number">1</span> / sigma) ** <span class="number">2</span> <span class="comment"># precision</span></span><br><span class="line">alpha = <span class="number">2.0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">posterior_w</span>(<span class="params">phi, t, S0, m0</span>):</span><br><span class="line">    SN = inv(inv(S0) + beta * Phi.T @ Phi)</span><br><span class="line">    mN = SN @ (inv(S0) @ m0 + beta * Phi.T @ t)</span><br><span class="line">    <span class="keyword">return</span> SN, mN</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sample_vals</span>(<span class="params">X, T, ix</span>):</span><br><span class="line">    x_in = X[ix]</span><br><span class="line">    Phi = np.c_[np.ones_like(x_in), x_in]</span><br><span class="line">    t = T[[ix]]</span><br><span class="line">    <span class="keyword">return</span> Phi, t</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_prior</span>(<span class="params">m, S, liminf=-<span class="number">1</span>, limsup=<span class="number">1</span>, step=<span class="number">0.05</span>, ax=plt, **kwargs</span>):</span><br><span class="line">    grid = np.mgrid[liminf:limsup + step:step, liminf:limsup + step:step]</span><br><span class="line">    nx = grid.shape[-<span class="number">1</span>]</span><br><span class="line">    z = multivariate_normal.pdf(grid.T.reshape(-<span class="number">1</span>, <span class="number">2</span>), mean=m.ravel(), cov=S).reshape(nx, nx).T</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ax.contourf(*grid, z, cmap=<span class="string">&#x27;jet&#x27;</span>,interpolation=<span class="string">&#x27;nearest&#x27;</span>,**kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_sample_w</span>(<span class="params">mean, cov, size=<span class="number">10</span>, ax=plt</span>):</span><br><span class="line">    w = np.random.multivariate_normal(mean=mean.ravel(), cov=cov, size=size)</span><br><span class="line">    x = np.linspace(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> wi <span class="keyword">in</span> w:</span><br><span class="line">        ax.plot(x, f(x, wi), c=<span class="string">&quot;tab:blue&quot;</span>, alpha=<span class="number">0.4</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_likelihood_obs</span>(<span class="params">X, T, ix, ax=plt</span>):</span><br><span class="line">    W = np.mgrid[-<span class="number">1</span>:<span class="number">1</span>:<span class="number">0.1</span>, -<span class="number">1</span>:<span class="number">1</span>:<span class="number">0.1</span>]</span><br><span class="line">    x, t = sample_vals(X, T, ix)</span><br><span class="line">    mean = W.T.reshape(-<span class="number">1</span>, <span class="number">2</span>) @ x.T</span><br><span class="line"></span><br><span class="line">    likelihood = norm.pdf(t, loc=mean, scale=np.sqrt(<span class="number">1</span> / beta)).reshape(<span class="number">20</span>, <span class="number">20</span>).T</span><br><span class="line">    ax.contourf(*W, likelihood,cmap=<span class="string">&#x27;jet&#x27;</span>,interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">    ax.scatter(-<span class="number">0.3</span>, <span class="number">0.5</span>, c=<span class="string">&quot;white&quot;</span>, marker=<span class="string">&quot;+&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">SN = np.eye(<span class="number">2</span>) / alpha</span><br><span class="line">mN = np.zeros((<span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">seed(<span class="number">1643</span>)</span><br><span class="line">N = <span class="number">20</span></span><br><span class="line">nobs = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">20</span>]</span><br><span class="line">ix_fig = <span class="number">1</span></span><br><span class="line">fig, ax = plt.subplots(<span class="built_in">len</span>(nobs) + <span class="number">1</span>, <span class="number">3</span>, figsize=(<span class="number">10</span>, <span class="number">12</span>))</span><br><span class="line">plot_prior(mN, SN, ax=ax[<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">1</span>].scatter(-<span class="number">0.3</span>, <span class="number">0.5</span>, c=<span class="string">&quot;white&quot;</span>, marker=<span class="string">&quot;+&quot;</span>)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">0</span>].axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">plot_sample_w(mN, SN, ax=ax[<span class="number">0</span>, <span class="number">2</span>])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, N + <span class="number">1</span>):</span><br><span class="line">    Phi, t = sample_vals(X, T, i)</span><br><span class="line">    SN, mN = posterior_w(Phi, t, SN, mN)</span><br><span class="line">    <span class="keyword">if</span> i + <span class="number">1</span> <span class="keyword">in</span> nobs:</span><br><span class="line">        plot_likelihood_obs(X, T, i, ax=ax[ix_fig, <span class="number">0</span>])</span><br><span class="line">        plot_prior(mN, SN, ax=ax[ix_fig, <span class="number">1</span>])</span><br><span class="line">        ax[ix_fig, <span class="number">1</span>].scatter(-<span class="number">0.3</span>, <span class="number">0.5</span>, c=<span class="string">&quot;white&quot;</span>, marker=<span class="string">&quot;+&quot;</span>)</span><br><span class="line">        ax[ix_fig, <span class="number">2</span>].scatter(X[:i + <span class="number">1</span>], T[:i + <span class="number">1</span>], c=<span class="string">&quot;crimson&quot;</span>)</span><br><span class="line">        ax[ix_fig, <span class="number">2</span>].set_xlim(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        ax[ix_fig, <span class="number">2</span>].set_ylim(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">for</span> l <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">            ax[ix_fig, l].set_xlabel(<span class="string">&quot;$w_0$&quot;</span>)</span><br><span class="line">            ax[ix_fig, l].set_ylabel(<span class="string">&quot;$w_1$&quot;</span>)</span><br><span class="line">        plot_sample_w(mN, SN, ax=ax[ix_fig, <span class="number">2</span>])</span><br><span class="line">        ix_fig += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">titles = [<span class="string">&quot;likelihood&quot;</span>, <span class="string">&quot;prior/posterior&quot;</span>, <span class="string">&quot;data space&quot;</span>]</span><br><span class="line"><span class="keyword">for</span> axi, title <span class="keyword">in</span> <span class="built_in">zip</span>(ax[<span class="number">0</span>], titles):</span><br><span class="line">    axi.set_title(title, size=<span class="number">15</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h1 id="作业五">作业五</h1><h2 id="等价核绘制">等价核绘制</h2><p>首先是高斯核的绘制，下图是一个取值为线性的高斯核函数的图像<img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402182640901.png" alt="image-20230402182640901" style="zoom: 80%;" /></p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402182755965.png" alt="image-20230402182755965" style="zoom:67%;" /></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gaussianLike</span>(<span class="params">mu,sigma,x</span>):</span><br><span class="line">    <span class="keyword">return</span> np.exp((-<span class="number">1</span>/<span class="number">2</span>)*np.matmul(np.matmul((x-mu),np.linalg.inv(sigma)),(x-mu).reshape(<span class="built_in">len</span>(x),<span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gaussianKernel</span>(<span class="params">gaussianLike,x</span>):</span><br><span class="line">    <span class="keyword">return</span> np.dot(gaussianLike(np.zeros(<span class="number">2</span>,),np.eye(<span class="number">2</span>,<span class="number">2</span>),x),gaussianLike(np.zeros(<span class="number">2</span>,),np.eye(<span class="number">2</span>,<span class="number">2</span>),x))</span><br><span class="line"></span><br><span class="line">x=np.linspace(-<span class="number">2</span>,<span class="number">2</span>,<span class="number">100</span>)</span><br><span class="line">y=np.linspace(-<span class="number">2</span>,<span class="number">2</span>,<span class="number">100</span>)</span><br><span class="line">X, Y = np.meshgrid(x, y)</span><br><span class="line">Z=[]</span><br><span class="line">z1=np.ones((<span class="number">100</span>,<span class="number">100</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> x:</span><br><span class="line">    n=<span class="number">0</span></span><br><span class="line">    z=[]</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> y:</span><br><span class="line">        m=<span class="number">0</span></span><br><span class="line">        z.append(gaussianKernel(gaussianLike,[i,j]))</span><br><span class="line">        z1[n,m]=gaussianKernel(gaussianLike,[i,j])</span><br><span class="line">        m+=<span class="number">1</span></span><br><span class="line">    n+=<span class="number">1</span></span><br><span class="line">    Z.append(z)</span><br><span class="line">Z=np.array(Z)</span><br><span class="line"></span><br><span class="line">plt.imshow(Z,cmap=<span class="string">&#x27;hot&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">ax = plt.axes(projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line">ax.plot_surface(X,Y,Z,cmap=<span class="string">&#x27;rainbow&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>下面复现课本的等价核：</p><p><strong>高斯核</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gaussian_kernel</span>(<span class="params">x, y, sigma</span>):</span><br><span class="line">    <span class="keyword">return</span> np.exp(-np.linalg.norm(x - y)**<span class="number">2</span> / (<span class="number">2</span> * (sigma ** <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_kernel_matrix</span>(<span class="params">X, sigma</span>):</span><br><span class="line">    n = X.shape[<span class="number">0</span>]</span><br><span class="line">    K = np.zeros((n, n))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i, n):</span><br><span class="line">            K[i, j] = gaussian_kernel(X[i], X[j], sigma)</span><br><span class="line">            K[j, i] = K[i, j]</span><br><span class="line">    <span class="keyword">return</span> K</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成示例数据集</span></span><br><span class="line">X = np.linspace(-<span class="number">5</span>, <span class="number">5</span>, <span class="number">100</span>).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">y = np.sin(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算不同带宽参数下的高斯等价核矩阵</span></span><br><span class="line">sigmas = [<span class="number">0.1</span>, <span class="number">1</span>, <span class="number">10</span>]</span><br><span class="line"><span class="keyword">for</span> sigma <span class="keyword">in</span> sigmas:</span><br><span class="line">    K = compute_kernel_matrix(X, sigma)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 绘制高斯核形状图像</span></span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.imshow(K, cmap=<span class="string">&#x27;jet&#x27;</span>, interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">r&#x27;Gaussian Kernel with $\sigma=$&#x27;</span> + <span class="built_in">str</span>(sigma))</span><br><span class="line">    plt.colorbar()</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402183003203.png"alt="image-20230402183003203" /><figcaption aria-hidden="true">image-20230402183003203</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402183010833.png"alt="image-20230402183010833" /><figcaption aria-hidden="true">image-20230402183010833</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402183017836.png"alt="image-20230402183017836" /><figcaption aria-hidden="true">image-20230402183017836</figcaption></figure><p><strong>多项式核</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">polynomial_kernel</span>(<span class="params">x, y, degree, coef0=<span class="number">0</span></span>):</span><br><span class="line">    <span class="keyword">return</span> (np.dot(x, y) + coef0) ** degree</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_kernel_matrix</span>(<span class="params">X, degree, coef0=<span class="number">0</span></span>):</span><br><span class="line">    n = X.shape[<span class="number">0</span>]</span><br><span class="line">    K = np.zeros((n, n))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i, n):</span><br><span class="line">            K[i, j] = polynomial_kernel(X[i], X[j], degree, coef0)</span><br><span class="line">            K[j, i] = K[i, j]</span><br><span class="line">    <span class="keyword">return</span> K</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成示例数据集</span></span><br><span class="line">X = np.linspace(-<span class="number">5</span>, <span class="number">5</span>, <span class="number">100</span>).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">y = np.sin(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算不同阶数和常数项参数下的多项式核矩阵</span></span><br><span class="line">degrees = [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">coef0s = [-<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line"><span class="keyword">for</span> degree <span class="keyword">in</span> degrees:</span><br><span class="line">    <span class="keyword">for</span> coef0 <span class="keyword">in</span> coef0s:</span><br><span class="line">        K = compute_kernel_matrix(X, degree, coef0)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 绘制多项式核形状图像</span></span><br><span class="line">        plt.figure()</span><br><span class="line">        plt.imshow(K, cmap=<span class="string">&#x27;jet&#x27;</span>, interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">        plt.title(<span class="string">&#x27;Polynomial Kernel with degree=&#x27;</span> + <span class="built_in">str</span>(degree) + <span class="string">&#x27; and coef0=&#x27;</span> + <span class="built_in">str</span>(coef0))</span><br><span class="line">        plt.colorbar()</span><br><span class="line">        plt.show()</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402183116818.png"alt="image-20230402183116818" /><figcaption aria-hidden="true">image-20230402183116818</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402183128404.png"alt="image-20230402183128404" /><figcaption aria-hidden="true">image-20230402183128404</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402183137656.png"alt="image-20230402183137656" /><figcaption aria-hidden="true">image-20230402183137656</figcaption></figure><p><strong>Sigmoid核</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid_kernel</span>(<span class="params">x, y, alpha, c</span>):</span><br><span class="line">    <span class="keyword">return</span> np.tanh(alpha * np.dot(x, y) + c)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_kernel_matrix</span>(<span class="params">X, alpha, c</span>):</span><br><span class="line">    n = X.shape[<span class="number">0</span>]</span><br><span class="line">    K = np.zeros((n, n))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i, n):</span><br><span class="line">            K[i, j] = sigmoid_kernel(X[i], X[j], alpha, c)</span><br><span class="line">            K[j, i] = K[i, j]</span><br><span class="line">    <span class="keyword">return</span> K</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成示例数据集</span></span><br><span class="line">X = np.linspace(-<span class="number">5</span>, <span class="number">5</span>, <span class="number">100</span>).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">y = np.sin(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算不同超参数下的 Sigmoid 核矩阵</span></span><br><span class="line">alphas = [<span class="number">0.1</span>, <span class="number">0.5</span>, <span class="number">1</span>]</span><br><span class="line">cs = [-<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line"><span class="keyword">for</span> alpha <span class="keyword">in</span> alphas:</span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> cs:</span><br><span class="line">        K = compute_kernel_matrix(X, alpha, c)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 绘制 Sigmoid 核形状图像</span></span><br><span class="line">        plt.figure()</span><br><span class="line">        plt.imshow(K, cmap=<span class="string">&#x27;jet&#x27;</span>, interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">        plt.title(<span class="string">&#x27;Sigmoid Kernel with alpha=&#x27;</span> + <span class="built_in">str</span>(alpha) + <span class="string">&#x27; and c=&#x27;</span> + <span class="built_in">str</span>(c))</span><br><span class="line">        plt.colorbar()</span><br><span class="line">        plt.show()</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402183249517.png"alt="image-20230402183249517" /><figcaption aria-hidden="true">image-20230402183249517</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402183257364.png"alt="image-20230402183257364" /><figcaption aria-hidden="true">image-20230402183257364</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402183304889.png"alt="image-20230402183304889" /><figcaption aria-hidden="true">image-20230402183304889</figcaption></figure><h2 id="似然">似然</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">random.seed(<span class="number">615</span>)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_synth_data</span>(<span class="params">N, beta</span>):</span><br><span class="line">    X_N =np.random.uniform(-<span class="number">1</span>,<span class="number">1</span>, N)</span><br><span class="line">    X_N = np.column_stack((np.ones(N), X_N))</span><br><span class="line">    <span class="comment"># for this example the true function is f(x,a) = a_0 + a_1*x</span></span><br><span class="line">    <span class="comment"># where a_0 = -.3 and a_1 = .5 are the parameters that we</span></span><br><span class="line">    <span class="comment"># are going to estimate</span></span><br><span class="line">    a = np.array([-<span class="number">.3</span>, <span class="number">.5</span>])</span><br><span class="line">    t = np.dot(X_N, a)</span><br><span class="line">    <span class="keyword">return</span> X_N, t + np.random.normal(loc=<span class="number">0.0</span>, scale=np.sqrt(<span class="number">1.</span>/beta), size=N)</span><br><span class="line"></span><br><span class="line">beta_ = <span class="number">25.0</span></span><br><span class="line">alpha = <span class="number">2.0</span></span><br><span class="line">N = <span class="number">20</span></span><br><span class="line">X_N, t_N = get_synth_data(N, beta_)</span><br><span class="line">x = np.linspace(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">70</span>)</span><br><span class="line">y = np.linspace(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">70</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">w0, w1 = np.meshgrid(x, y)</span><br><span class="line">m_0 = [<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">S_0 = <span class="number">1</span>/alpha * np.eye(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">n = <span class="number">1</span></span><br><span class="line">X_n = X_N[<span class="built_in">range</span>(n), :]</span><br><span class="line">t_n = t_N[<span class="built_in">range</span>(n)]</span><br><span class="line">plt.xlim(-<span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line">plt.ylim(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">plt.scatter(X_n[:, <span class="number">1</span>], t_n)</span><br><span class="line">plt.title(<span class="string">&quot;First point in the data set&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>);</span><br><span class="line">plt.ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">likelihood</span>(<span class="params">t_, x, w, beta</span>):</span><br><span class="line">    <span class="keyword">from</span> math <span class="keyword">import</span> sqrt</span><br><span class="line">    <span class="keyword">return</span> stats.norm.pdf(t_,loc=np.dot(w,x), scale=sqrt(<span class="number">1.</span>/beta))</span><br><span class="line"></span><br><span class="line">Z = np.zeros((<span class="built_in">len</span>(y), <span class="built_in">len</span>(x)))</span><br><span class="line"><span class="keyword">for</span> i, w1 <span class="keyword">in</span> <span class="built_in">enumerate</span>(y):</span><br><span class="line">    <span class="keyword">for</span> j, w0 <span class="keyword">in</span> <span class="built_in">enumerate</span>(x):</span><br><span class="line">        Z[i, j] = likelihood(t_n[-<span class="number">1</span>], X_n[-<span class="number">1</span>,:], np.array([w0, w1]), beta_)</span><br><span class="line">extent = (-<span class="number">1</span>,<span class="number">1</span>,-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">plt.imshow(Z, extent=extent, origin=<span class="string">&#x27;lower&#x27;</span>)</span><br><span class="line">plt.plot(-<span class="number">0.3</span>, <span class="number">0.5</span>, <span class="string">&#x27;w+&#x27;</span>, markeredgewidth=<span class="number">2</span>, markersize=<span class="number">12</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Likelihood of the first point in the data set, white cross = true value&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;w0&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;w1&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402184647229.png"alt="image-20230402184647229" /><figcaption aria-hidden="true">image-20230402184647229</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402184827621.png"alt="image-20230402184827621" /><figcaption aria-hidden="true">image-20230402184827621</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230402184922104.png"alt="image-20230402184922104" /><figcaption aria-hidden="true">image-20230402184922104</figcaption></figure><h1 id="作业一-多项式拟合">作业一 多项式拟合</h1><h2 id="理论推导">理论推导</h2><p><span class="math display">\[\min ||f(\omega;x)-t||^2\\\sum_{i=0}^{n}{\omega_i*x_i^j}=t\]</span></p><p>写成矩阵形式： <span class="math display">\[XW=T\]</span> 使用平方和最小来衡量，设损失函数： <spanclass="math display">\[L(x)=\frac{1}{2}\sum^{N}_{i=1}{(\sum_{j=0}^{M}{\omega_jx_i^j-y_i)^2}}\]</span> 对损失函数求导，令导数等于0： <span class="math display">\[\begin{array}{l}\frac{\partial L(x;\omega)}{\partial \omega_i}=0 \\\\\frac{1}{2}\sum_{i=1}^{N}{2(\sum^{j=0}_{M}{\omega_jx_i^j-y_i)}\timesx_i^k}=0 \\\\\sum_{i=1}^{N}{\sum^{M}_{j=1}{\omega_ix_i^{j+k}}}=\sum_{j=1}^{M}{x_i^ky_i}(k=0,1,2,3,\cdots,M)\end{array}\]</span> 那么就有： <span class="math display">\[\begin{array}{l}X=\sum^M_{j=1}{x_i^{j+k}} \\W=\omega_i \\Y=\sum_{i=1}^{M}{x_i^ky_i}\\XW=Y\end{array}\]</span> 将以<spanclass="math inline">\(x\)</span>为参数的非线性模型转化为以<spanclass="math inline">\(w\)</span>的线性模型，从而转化为矩阵方程求解问题,需要将方程特征进行组合，实现上使用sklearn，进行多项式特征组合，然后使用线性回归进行预测：</p><p>算法语言描述：</p><ol type="1"><li><p>生成一个（特征数目+1，特征数目+1）的矩阵</p></li><li><p>分别计算0-特征阶数的幂</p></li><li><p>返回特征混合矩阵</p></li><li><p>线性回归</p></li></ol><h2 id="代码实现">代码实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Polyfeature</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,n_features</span>):</span><br><span class="line">        self.n_features=n_features</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 一元特征混合</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, x</span>):</span><br><span class="line">        xf = np.zeros((<span class="built_in">len</span>(x), self.n_features + <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.n_features + <span class="number">1</span>):</span><br><span class="line">            xf[:,i] = np.power(x, i).reshape(np.shape(xf[:,i]))</span><br><span class="line">        self.xf=xf</span><br><span class="line">        <span class="keyword">return</span> xf</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">transform</span>(<span class="params">self,x</span>):</span><br><span class="line">        xf = np.zeros((<span class="built_in">len</span>(x), self.n_features + <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.n_features + <span class="number">1</span>):</span><br><span class="line">            xf[:, i] = np.power(x, i).reshape(np.shape(xf[:, i]))</span><br><span class="line">        self.xf = xf</span><br><span class="line">        <span class="keyword">return</span> xf</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit_transform</span>(<span class="params">self, x</span>):</span><br><span class="line">        xf = np.zeros((<span class="built_in">len</span>(x), self.n_features + <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.n_features + <span class="number">1</span>):</span><br><span class="line">            xf[:, i] = np.power(x, i).reshape(np.shape(xf[:, i]))</span><br><span class="line">            self.xf = xf</span><br><span class="line">        <span class="keyword">return</span> xf</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">linearregression</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self,x,y,Lambda=<span class="number">0</span></span>):</span><br><span class="line">        c = np.dot(x.T, x)</span><br><span class="line">        I = np.eye(np.shape(c)[<span class="number">0</span>])</span><br><span class="line">        d = np.dot(Lambda, I)</span><br><span class="line">        e = (c + d)</span><br><span class="line">        e = np.linalg.inv(e)</span><br><span class="line">        w = np.dot(x.T, y)</span><br><span class="line">        w = np.dot(e, w)</span><br><span class="line">        self.w = w</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self,x</span>):</span><br><span class="line">        y=np.dot(x,self.w)</span><br><span class="line">        <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">polyregression</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,features</span>):</span><br><span class="line">        self.n_features=features</span><br><span class="line">    <span class="comment"># 生成数据</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">create_data</span>(<span class="params">self,n</span>):</span><br><span class="line">        self.n=n</span><br><span class="line">        X=np.random.rand(n,<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 考虑到需要保证高斯白噪声的0均值</span></span><br><span class="line">        noise=<span class="number">0.3</span>*np.random.uniform(low=-<span class="number">1</span>, high=<span class="number">1</span>, size=(n,<span class="number">1</span>))</span><br><span class="line">        t=np.sin(X*<span class="number">2</span>*math.pi)+noise</span><br><span class="line">        self.X=X</span><br><span class="line">        self.t=t</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 划分数据集</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">splitData</span>(<span class="params">self</span>):</span><br><span class="line">        X_train, X_test, T_train, T_test = train_test_split(self.X, self.t, test_size=<span class="number">0.3</span>, random_state=<span class="number">0</span>)</span><br><span class="line">        self.X_train=X_train</span><br><span class="line">        self.X_test=X_test</span><br><span class="line">        self.T_train=T_train</span><br><span class="line">        self.T_test=T_test</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 多项式拟合</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self</span>):</span><br><span class="line">        poly = PolynomialFeatures(self.n_features)</span><br><span class="line">        x_train_poly = poly.fit_transform(self.X_train)</span><br><span class="line"></span><br><span class="line">        lin=LinearRegression()</span><br><span class="line">        lin.fit(x_train_poly,self.T_train)</span><br><span class="line"></span><br><span class="line">        self.lin=lin</span><br><span class="line">        self.poly=poly</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">draw</span>(<span class="params">self</span>):</span><br><span class="line">        plt.style.use(<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line">        plt.figure()</span><br><span class="line">        plt.plot(np.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">50</span>),np.sin(np.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">50</span>)*<span class="number">2</span>*math.pi),color=<span class="string">&#x27;green&#x27;</span>)</span><br><span class="line">        plt.scatter(self.X,self.t,marker=<span class="string">&#x27;o&#x27;</span>,edgecolor=<span class="string">&#x27;blue&#x27;</span>,color=<span class="string">&#x27;white&#x27;</span>,linewidths=<span class="string">&#x27;1.1&#x27;</span>)</span><br><span class="line">        plt.plot(np.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">50</span>),self.lin.predict(self.poly.transform(np.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">50</span>).reshape(-<span class="number">1</span>,<span class="number">1</span>))),color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">        s=<span class="string">&#x27;n_features=&#x27;</span>+<span class="built_in">str</span>(self.n_features)</span><br><span class="line">        plt.text(<span class="number">0.7</span>,<span class="number">1</span>,s)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;X&#x27;</span>)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;Y&#x27;</span>)</span><br><span class="line">        plt.savefig(<span class="string">&#x27;features=&#x27;</span>+<span class="built_in">str</span>(self.n_features)+<span class="string">&#x27; samples=&#x27;</span>+<span class="built_in">str</span>(self.n)+<span class="string">&#x27;.png&#x27;</span>)</span><br><span class="line">        plt.show()</span><br><span class="line">    <span class="comment"># 衡量拟合的标准</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">RSME</span>(<span class="params">self</span>):</span><br><span class="line">        T_test_predict=self.lin.predict(self.poly.transform(self.X_test))</span><br><span class="line">        SSE=np.<span class="built_in">sum</span>(np.square(self.T_test-T_test_predict))</span><br><span class="line">        MSE=SSE/<span class="built_in">len</span>(T_test_predict)</span><br><span class="line">        rsme=np.sqrt(MSE)</span><br><span class="line">        <span class="keyword">return</span> rsme</span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 对不同特征选择的比较</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">features_test</span>():</span><br><span class="line">        RSME=[]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">            poly=polyregression(i)</span><br><span class="line">            poly.create_data(<span class="number">20</span>)</span><br><span class="line">            poly.splitData()</span><br><span class="line">            poly.fit()</span><br><span class="line">            poly.draw()</span><br><span class="line">            RSME.append(poly.RSME())</span><br><span class="line"></span><br><span class="line">        plt.figure()</span><br><span class="line">        plt.plot(np.linspace(<span class="number">0</span>,<span class="number">10</span>,<span class="number">10</span>),RSME,marker=<span class="string">&#x27;^&#x27;</span>,label=<span class="string">&quot;points&quot;</span>)</span><br><span class="line">        plt.show()</span><br><span class="line">    <span class="comment"># 对不同样本数量的比较</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">samples_test</span>():</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> [<span class="number">20</span>,<span class="number">200</span>,<span class="number">500</span>]:</span><br><span class="line">            RSME=[]</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">50</span>):</span><br><span class="line">                poly=polyregression(i)</span><br><span class="line">                poly.create_data(j)</span><br><span class="line">                poly.splitData()</span><br><span class="line">                poly.fit()</span><br><span class="line">                poly.draw()</span><br><span class="line">                RSME.append(poly.RSME())</span><br><span class="line">            plt.figure()</span><br><span class="line">            plt.plot(np.linspace(<span class="number">0</span>,<span class="number">50</span>,<span class="number">50</span>),RSME,marker=<span class="string">&#x27;^&#x27;</span>,label=<span class="string">&quot;points&quot;</span>)</span><br><span class="line">            plt.savefig(<span class="string">&#x27;sample=&#x27;</span>+<span class="built_in">str</span>(j)+<span class="string">&#x27;.png&#x27;</span>)</span><br><span class="line">            plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># features_test()</span></span><br><span class="line">    samples_test()</span><br></pre></td></tr></table></figure><h2 id="结果对比">结果对比</h2><p>不同的特征数量，首先全部针对样本数量为10的情况： <imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/features=0%20samples=10.png"alt="features=0 samples=10" /></p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/features=1%20samples=10.png"alt="features=1 samples=10" /><figcaption aria-hidden="true">features=1 samples=10</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/features=2%20samples=10.png"alt="features=2 samples=10" /><figcaption aria-hidden="true">features=2 samples=10</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/features=3%20samples=10.png"alt="features=3 samples=10" /><figcaption aria-hidden="true">features=3 samples=10</figcaption></figure><figure><imgsrc="G:\专业学习\第六学期\机器学习\实验一\selectF\features=4%20samples=10.png"alt="features=4 samples=10" /><figcaption aria-hidden="true">features=4 samples=10</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/features=5%20samples=10.png"alt="features=5 samples=10" /><figcaption aria-hidden="true">features=5 samples=10</figcaption></figure><p>从中可以大致看出，在选择特征过少时，会出现欠拟合现象，选择过多后则会过拟合，针对样本量为20的情况下，RSME曲线如图：<imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/sample=20.png"alt="sample=20.png" />图上显示的情况，并不是与我们预期中的情况完全吻合，其原因可能是因为测试集样本数量过少，导致无法很好的捕捉曲线拟合的问题，于是我们对其他样本数量进行对比、 <imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/sample=200.png"alt="sample=200.png" /> <imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/sample=500.png"alt="sample=500.png" /><br />可以看出样本数量增多后，特征的选择有明显的趋势。尝试复现使用样本为10的情况：<imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/sample=10.png"alt="sample=10" /> 且样本数量会明显的影响拟合的效果。</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/features=5%20samples=10.png"alt="features=5 samples=10" /><figcaption aria-hidden="true">features=5 samples=10</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/features=5%20samples=20.png"alt="features=5 samples=20" /><figcaption aria-hidden="true">features=5 samples=20</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/features=5%20samples=200.png"alt="features=5 samples=200" /><figcaption aria-hidden="true">features=5 samples=200</figcaption></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/features=5%20samples=500.png"alt="features=5 samples=500" /><figcaption aria-hidden="true">features=5 samples=500</figcaption></figure><p>针对样本为10，特征为5的情况下进行正则化：</p><p><span class="math inline">\(\lambda\)</span>=0.7740859059011267</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230311220541756.png"alt="image-20230311220541756" /><figcaption aria-hidden="true">image-20230311220541756</figcaption></figure><h1 id="作业二">作业二</h1><h2 id="频率学派与贝叶斯学派">频率学派与贝叶斯学派</h2><ul><li>频率观点认为频率能够趋近概率，模型的参数是一定的，只要采样数目足够多就能逼近参数值，我的理解是其符合大数定律的思想（此为辛钦大数定律）：<span class="math display">\[\lim_{n\to\infty}P\left(\left|\frac{1}{n}\sum_{i=1}^{n}{a_i-\mu}  \right|&lt;\varepsilon\right)=1\]</span></li><li>贝叶斯观点认为模型的参数是在变化的，样本是一定的。 <spanclass="math display">\[p(w|D)=\frac{p(D|w)p(w)}{p(D)}\]</span> 以一元高斯分布为例，解释样本分布问题：</li><li>频率：频率的思想是以样本代替总体，从而得到模型参数，假设有数据集<spanclass="math inline">\(D=\{x_1,x_2,\cdot\cdot\cdot,x_n\}\)</span>，则估计得到的一元高斯分布的参数为<span class="math display">\[\hat\mu=\frac{1}{n}\sum_{i=1}^{n}{x_i}\]</span> <span class="math display">\[\hat{\sigma^2}=\frac{1}{n}\sum_{i=1}^{n}{(x_i-\hat\mu)}^2\]</span>样本分布显然是和总体有差异的，对其求期望可以得到，均值为无偏估计，而方差存在偏差，而偏差随着样本数目n的增大而减小（<spanclass="math inline">\(E(\hat\sigma^2)=\frac{n-1}{n}\sigma^2\)</span>）。</li><li>贝叶斯：贝叶斯的思想认为所有参数都是一个分布，而样本是固定不变的量。所以通过先验尽可能使逼近高斯分布。<span class="math display">\[p(D|w)=\frac{p(w|D)p(D)}{p(w)}\]</span> 有似然函数，其中<spanclass="math inline">\(p(D)\)</span>为一个常数，可被忽略（归一化），根据课本给出的高斯分布求解结果，发现他的方差和均值均为无偏估计。## 公式推导 <imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230421154051248.png"alt="image-20230421154051248" /></li></ul><p>引入先验</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230421154116419.png"alt="image-20230421154116419" /><figcaption aria-hidden="true">image-20230421154116419</figcaption></figure><p>在这里将数据的概率分布进行了归一，认为样本概率为一常数</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230421154257436.png"alt="image-20230421154257436" /><figcaption aria-hidden="true">image-20230421154257436</figcaption></figure><p>然后对<span class="math inline">\(\lnp(\mathbf{w}|\alpha)\)</span>求解：</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230421154321678.png"alt="image-20230421154321678" /><figcaption aria-hidden="true">image-20230421154321678</figcaption></figure><p>取负数：<br /><span class="math display">\[-\ln p(\mathbf{t|x},w,\beta)p(\mathbf{w}|\alpha)=\frac{\beta}{2}\sum_{n=1}^{N}{(x-y_n(x_n,\mathbf{w}))^2 }+\frac{\alpha}{2}\mathbf{w^T}\mathbf{w}-\frac{n}{2}\ln \frac{\beta}{2\pi}-\frac{M+1}{2}\ln \alpha+\frac{M+1}{2}\ln 2\pi\]</span> 后三项均为常数，对最大化没有任何影响，因此损失函数为：</p><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230421154342936.png"alt="image-20230421154342936" /><figcaption aria-hidden="true">image-20230421154342936</figcaption></figure><h1 id="作业三">作业三</h1><h2 id="基函数图像复现">基函数图像复现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib.ticker <span class="keyword">import</span> MultipleLocator</span><br><span class="line"></span><br><span class="line">x_major_locator=MultipleLocator(<span class="number">1</span>)</span><br><span class="line">y_major_locator=MultipleLocator(<span class="number">0.25</span>)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>,<span class="number">5</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigma</span>(<span class="params">x,b</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>/(np.exp((-x+b)*<span class="number">10</span>)+<span class="number">1</span>)</span><br><span class="line">x=np.linspace(-<span class="number">1</span>,<span class="number">1</span>,<span class="number">100</span>)</span><br><span class="line">b=np.linspace(-<span class="number">1</span>,<span class="number">1</span>,<span class="number">11</span>).tolist()</span><br><span class="line"><span class="keyword">for</span> bi <span class="keyword">in</span> b:</span><br><span class="line">    plt.plot(x,sigma(x,bi))</span><br><span class="line">plt.xlim(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">plt.ylim(<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line">ax=plt.gca()</span><br><span class="line">ax.xaxis.set_major_locator(x_major_locator)</span><br><span class="line">ax.yaxis.set_major_locator(y_major_locator)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">def gaussian(mu,sigma,x,b):</span></span><br><span class="line"><span class="string">    return 1/(np.sqrt(2*np.pi)*sigma)*np.exp(-np.square((x+b)*5-mu)/2*np.square(sigma))</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">plt.subplot(1,3,2)</span></span><br><span class="line"><span class="string">for bi in b:</span></span><br><span class="line"><span class="string">    plt.plot(x,gaussian(0,1,x,bi))</span></span><br><span class="line"><span class="string">plt.xlim(-1,1)</span></span><br><span class="line"><span class="string">plt.ylim(0,0.4)</span></span><br><span class="line"><span class="string">plt.show()</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">poly</span>(<span class="params">x,n</span>):</span><br><span class="line">    <span class="keyword">return</span> np.power(x,n)</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>)</span><br><span class="line">n=np.linspace(<span class="number">1</span>,<span class="number">10</span>,<span class="number">10</span>).tolist()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> n:</span><br><span class="line">    plt.plot(x,poly(x,i))</span><br><span class="line">plt.xlim(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">plt.ylim(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">ax=plt.gca()</span><br><span class="line">y_major_locator1=MultipleLocator(<span class="number">0.5</span>)</span><br><span class="line">ax.xaxis.set_major_locator(x_major_locator)</span><br><span class="line">ax.yaxis.set_major_locator(y_major_locator1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gaussian1</span>(<span class="params">mu,sigma,x,b</span>):</span><br><span class="line">    <span class="keyword">return</span> np.exp(-np.square((x+b)*<span class="number">5</span>-mu)/<span class="number">2</span>*np.square(sigma))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"><span class="keyword">for</span> bi <span class="keyword">in</span> b:</span><br><span class="line">    plt.plot(x,gaussian1(<span class="number">0</span>,<span class="number">1</span>,x,bi))</span><br><span class="line"></span><br><span class="line">ax=plt.gca()</span><br><span class="line">ax.xaxis.set_major_locator(x_major_locator)</span><br><span class="line">ax.yaxis.set_major_locator(y_major_locator)</span><br><span class="line"></span><br><span class="line">plt.xlim(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">plt.ylim(<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><figure><imgsrc="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230317214519144.png"alt="image-20230317214519144" /><figcaption aria-hidden="true">image-20230317214519144</figcaption></figure><h1 id="作业四-多项式拟合加强版">作业四 多项式拟合（加强版）</h1><h2 id="实验项目结构">实验项目结构</h2><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230326184103754.png" alt="image-20230326184103754" style=" float:left" />/&gt;其中，data储存固化的数据</p><p>将数据生成函数与多项式拟合功能分离，建立createData.py</p><p>交叉验证函数</p><p>线性回归</p><p>多项式特征生成和多项式回归</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">createData.py</span><br><span class="line">__________________</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成数据集</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_data</span>(<span class="params">n,beta</span>):</span><br><span class="line">    n = n</span><br><span class="line">    X = np.linspace(<span class="number">0</span>, <span class="number">1</span>, n).reshape(n, <span class="number">1</span>)</span><br><span class="line">    noise = beta * np.random.uniform(low=-<span class="number">1</span>, high=<span class="number">1</span>, size=(n, <span class="number">1</span>))</span><br><span class="line">    t = np.sin(X * <span class="number">2</span> * np.pi) + noise</span><br><span class="line">    X = X</span><br><span class="line">    t = t</span><br><span class="line">    data=np.hstack((X,t))</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">splitData</span>(<span class="params">X,t</span>):</span><br><span class="line">    X_train, X_test, T_train, T_test = train_test_split(X, t, test_size=<span class="number">0.2</span>, random_state=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> X_train,X_test,T_train,T_test</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据固化</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">tocsv</span>(<span class="params">data</span>):</span><br><span class="line">    df=pd.DataFrame(data)</span><br><span class="line">    df.to_csv(<span class="string">&#x27;.\data\sample=&#x27;</span>+<span class="built_in">str</span>(data.shape[<span class="number">0</span>])+<span class="string">&#x27;.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    data=create_data(<span class="number">10</span>,<span class="number">0.1</span>)</span><br><span class="line">    tocsv(data)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">Cross_Validation.py</span><br><span class="line">_________________________________________</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Cross_Validation</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_folds</span>):</span><br><span class="line">        self.n_folds = n_folds</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">CV</span>(<span class="params">self,x,y</span>):</span><br><span class="line">        kf = KFold(n_splits=self.n_folds)</span><br><span class="line">        x_train=[]</span><br><span class="line">        x_test=[]</span><br><span class="line">        y_train=[]</span><br><span class="line">        y_test=[]</span><br><span class="line">        <span class="keyword">for</span> train_index,test_index <span class="keyword">in</span> kf.split(x):</span><br><span class="line">            xtr, xte = x[train_index], x[test_index]</span><br><span class="line">            ytr, yte = y[train_index], y[test_index]</span><br><span class="line">            x_train.append(xtr)</span><br><span class="line">            x_test.append(xte)</span><br><span class="line">            y_train.append(ytr)</span><br><span class="line">            y_test.append(yte)</span><br><span class="line">        <span class="keyword">return</span> x_train, x_test, y_train, y_test</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">linearregression.py</span><br><span class="line">_______________________</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">linearregression</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self,x,y,Lambda=<span class="number">0</span></span>):</span><br><span class="line">        c = np.dot(x.T, x)</span><br><span class="line">        I = np.eye(np.shape(c)[<span class="number">0</span>])</span><br><span class="line">        d = np.dot(Lambda, I)</span><br><span class="line">        e = (c + d)</span><br><span class="line">        e = np.linalg.inv(e)</span><br><span class="line">        w = np.dot(x.T, y)</span><br><span class="line">        w = np.dot(e, w)</span><br><span class="line">        self.w = w</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self,x</span>):</span><br><span class="line">        y=np.dot(x,self.w)</span><br><span class="line">        <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">Polyfeature.py</span><br><span class="line">____________________</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Polyfeature</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,n_features</span>):</span><br><span class="line">        self.n_features=n_features</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 一元特征混合</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># 单个数字</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(x,<span class="built_in">int</span>):</span><br><span class="line">            x=np.array([x])</span><br><span class="line">        <span class="comment"># 数组计算</span></span><br><span class="line">        xf = np.zeros((<span class="built_in">len</span>(x), self.n_features + <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.n_features + <span class="number">1</span>):</span><br><span class="line">            xf[:,i] = np.power(x, i).reshape(np.shape(xf[:,i]))</span><br><span class="line">        self.xf=xf</span><br><span class="line">        <span class="keyword">return</span> xf</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit_transform</span>(<span class="params">self,x</span>):</span><br><span class="line">        <span class="comment"># 单个数字</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(x, <span class="built_in">int</span>):</span><br><span class="line">            x = np.array([x])</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(x,<span class="built_in">float</span>):</span><br><span class="line">            x = np.array([x])</span><br><span class="line">        <span class="comment"># 数组计算</span></span><br><span class="line">        xf = np.zeros((<span class="built_in">len</span>(x), self.n_features + <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.n_features + <span class="number">1</span>):</span><br><span class="line">            xf[:, i] = np.power(x, i).reshape(np.shape(xf[:, i]))</span><br><span class="line">        <span class="keyword">return</span> xf</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br></pre></td><td class="code"><pre><span class="line">PolyRegress.py</span><br><span class="line">______________________________________</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.ticker <span class="keyword">as</span> mticker</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> Polyfeature <span class="keyword">import</span> Polyfeature</span><br><span class="line"><span class="keyword">from</span> linearregression <span class="keyword">import</span> linearregression</span><br><span class="line"><span class="keyword">from</span> Cross_Validation <span class="keyword">import</span> Cross_Validation</span><br><span class="line"><span class="keyword">from</span> createData <span class="keyword">import</span> create_data</span><br><span class="line"><span class="keyword">from</span> createData <span class="keyword">import</span> splitData</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">polyRegression</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, features, n_lambda</span>):</span><br><span class="line">        self.n_features = features</span><br><span class="line">        self.n_lambda = n_lambda</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 拟合</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self,x,y,l</span>):</span><br><span class="line">        <span class="comment"># 混合特征</span></span><br><span class="line">        pf=Polyfeature(self.n_features)</span><br><span class="line">        pf.fit(x)</span><br><span class="line">        <span class="comment"># 线性回归</span></span><br><span class="line">        lin = linearregression()</span><br><span class="line">        lin.fit(pf.xf,y,Lambda=l)</span><br><span class="line"></span><br><span class="line">        self.lin = lin</span><br><span class="line">        self.poly = pf</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self,x</span>):</span><br><span class="line">        x=self.poly.fit_transform(x)</span><br><span class="line">        prediction=self.lin.predict(x)</span><br><span class="line">        <span class="keyword">return</span> prediction</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">draw</span>(<span class="params">self,X,t</span>):</span><br><span class="line">        plt.style.use(<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line">        plt.figure()</span><br><span class="line">        plt.plot(np.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">50</span>),np.sin(np.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">50</span>)*<span class="number">2</span>*math.pi),c=<span class="string">&#x27;green&#x27;</span>)</span><br><span class="line">        plt.scatter(X,t,marker=<span class="string">&#x27;o&#x27;</span>,edgecolor=<span class="string">&#x27;blue&#x27;</span>,c=<span class="string">&#x27;white&#x27;</span>,linewidths=<span class="number">1.1</span>)</span><br><span class="line">        plt.plot(np.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">50</span>),</span><br><span class="line">                 self.lin.predict(self.poly.fit_transform(np.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">50</span>).reshape(-<span class="number">1</span>,<span class="number">1</span>))),</span><br><span class="line">                 c=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">        s=<span class="string">&#x27;n_features=&#x27;</span>+<span class="built_in">str</span>(self.n_features)</span><br><span class="line">        plt.text(<span class="number">0.7</span>,<span class="number">1</span>,s)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;X&#x27;</span>)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;Y&#x27;</span>)</span><br><span class="line">        s=<span class="string">&#x27;cv\\features=&#x27;</span>+<span class="built_in">str</span>(self.n_features)+<span class="string">&#x27; samples=&#x27;</span>+<span class="built_in">str</span>(<span class="number">1</span>)+<span class="string">&#x27;.png&#x27;</span></span><br><span class="line">        plt.savefig(<span class="string">&#x27;11.png&#x27;</span>)</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">cv_pridict</span>(<span class="params">self, X, y, n_fold</span>):</span><br><span class="line">        cv = Cross_Validation(n_fold)</span><br><span class="line">        X_train, X_test, y_train, y_test = cv.CV(X,y)</span><br><span class="line">        y_allPredict = np.ones((<span class="number">1</span>, self.n_lambda))</span><br><span class="line">        Lambda = np.logspace(-<span class="number">10</span>, -<span class="number">7</span>, self.n_lambda)</span><br><span class="line">        w=[]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_fold):</span><br><span class="line">            y_predict = np.zeros((y_test[i].shape[<span class="number">0</span>], self.n_lambda))</span><br><span class="line">            k=<span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> np.nditer(Lambda) :</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;第&#x27;</span>,k+<span class="number">1</span>+self.n_lambda*i,<span class="string">&#x27;次:&#x27;</span>,j)</span><br><span class="line">                poly = self.fit(X_train[i], y_train[i], j)</span><br><span class="line">                y_pre = self.predict(X_test[i])</span><br><span class="line">                w.append(self.lin.w)</span><br><span class="line">                y_predict[:, k] = y_pre.ravel()</span><br><span class="line">                k=k+<span class="number">1</span></span><br><span class="line">            y_allPredict = np.vstack((y_allPredict, y_predict))</span><br><span class="line">        y_allPredict = y_allPredict[<span class="number">1</span>:]</span><br><span class="line">        <span class="keyword">return</span> y_allPredict, cv, y_test, y_train, X_test, X_train,w</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">RMSE_CV</span>(<span class="params">self, y_allPredict, y_measure, n</span>):</span><br><span class="line">        press = np.square(np.subtract(y_allPredict, y_measure.reshape(-<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">        press_all = np.<span class="built_in">sum</span>(press, axis=<span class="number">0</span>)</span><br><span class="line">        RMSECV = np.sqrt(press_all / n)</span><br><span class="line">        lambda_best_index= np.argmin(RMSECV)</span><br><span class="line">        lambda_best=np.logspace(-<span class="number">10</span>,-<span class="number">7</span>, self.n_lambda)[lambda_best_index]</span><br><span class="line">        <span class="keyword">return</span> RMSECV, lambda_best</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">bias_cv</span>(<span class="params">self, y_allPredict, y_expect, n</span>):</span><br><span class="line">        press = np.square(np.subtract(y_allPredict, y_expect.reshape(-<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">        press_all = np.<span class="built_in">sum</span>(press, axis=<span class="number">0</span>)</span><br><span class="line">        bias_cv = press_all / n</span><br><span class="line">        <span class="keyword">return</span> bias_cv</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">variance_cv</span>(<span class="params">self,y_allPredict, y_expect</span>):</span><br><span class="line">        press = np.square(np.subtract(y_allPredict, y_expect.reshape(-<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">        variance=np.average(press,axis=<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> variance</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_error_cv</span>(<span class="params">self,y_allPredict,y,Lambda,w</span>):</span><br><span class="line">        press = np.square(np.subtract(y_allPredict, y.reshape(-<span class="number">1</span>, <span class="number">1</span>)))</span><br><span class="line">        error1 = np.<span class="built_in">sum</span>(press, axis=<span class="number">0</span>)/<span class="number">2</span></span><br><span class="line">        error2 = np.linalg.norm(w,axis=<span class="number">1</span>)</span><br><span class="line">        error_temp=[]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">            e=np.average(error2[i*<span class="number">5</span>:(i+<span class="number">1</span>)*<span class="number">5</span>])</span><br><span class="line">            error_temp.append(e)</span><br><span class="line">        error2=np.array(error_temp)*Lambda/<span class="number">2</span></span><br><span class="line">        error=error1+error2</span><br><span class="line">        <span class="keyword">return</span> error</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">show_Select_lambda</span>(<span class="params">self,RMSECV</span>):</span><br><span class="line">        x=np.logspace(-<span class="number">10</span>,-<span class="number">7</span>,self.n_lambda)</span><br><span class="line">        plt.plot(x,</span><br><span class="line">                 RMSECV,marker=<span class="string">&#x27;^&#x27;</span>,</span><br><span class="line">                 markersize=<span class="number">10</span>,</span><br><span class="line">                 markerfacecolor=<span class="string">&#x27;orange&#x27;</span>,</span><br><span class="line">                 color=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;lambda&#x27;</span>)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;RMSECV&#x27;</span>)</span><br><span class="line">        ax = plt.gca()</span><br><span class="line">        ax.set_xscale(<span class="string">&quot;log&quot;</span>)</span><br><span class="line">        ax.set_xlim(ax.get_xlim()[::-<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">RSME</span>(<span class="params">self,X,t</span>):</span><br><span class="line">        T_predict = self.lin.predict(self.poly.fit_transform(X))</span><br><span class="line">        SSE = np.<span class="built_in">sum</span>(np.square(t - T_predict))</span><br><span class="line">        MSE = SSE / <span class="built_in">len</span>(T_predict)</span><br><span class="line">        rsme = np.sqrt(MSE)</span><br><span class="line">        <span class="keyword">return</span> rsme</span><br></pre></td></tr></table></figure><h2 id="调整beta和lambda观察rmse变化">调整<spanclass="math inline">\(\beta\)</span>和<spanclass="math inline">\(\lambda\)</span>观察RMSE变化</h2><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__name__&#x27;</span>:</span><br><span class="line">   beta=np.linspace(<span class="number">0</span>,<span class="number">0.5</span>,<span class="number">1000</span>)</span><br><span class="line">   Lambda=np.logspace(-<span class="number">10</span>,<span class="number">0</span>,<span class="number">1000</span>)</span><br><span class="line">   RMSE_SUM=[]</span><br><span class="line">   <span class="comment"># beta和lambda对拟合效果影响</span></span><br><span class="line">   <span class="keyword">for</span> j <span class="keyword">in</span> beta:</span><br><span class="line">        poly = polyRegression(<span class="number">8</span>, <span class="number">1000</span>)</span><br><span class="line">        data=create_data(<span class="number">10</span>,j)</span><br><span class="line">        X=data[:,<span class="number">0</span>]</span><br><span class="line">        t=data[:,<span class="number">1</span>]</span><br><span class="line">        y_allPredict, cv, y_test, y_train, X_test, X_train = poly.cv_pridict(X, t, <span class="number">5</span>)</span><br><span class="line">        RMSECV, best_lambda = poly.RMSE_CV(y_allPredict, t, X.shape[<span class="number">0</span>])</span><br><span class="line">        RMSE_SUM.append(RMSECV)</span><br><span class="line">    RMSE=np.array(RMSE_SUM)</span><br><span class="line">    X, Y = np.meshgrid(Lambda, beta)</span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">15</span>,<span class="number">15</span>))</span><br><span class="line">    ax = plt.axes(projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line">    ax.set_xlabel(<span class="string">&#x27;beta&#x27;</span>)</span><br><span class="line">    ax.set_ylabel(<span class="string">&#x27;lambda&#x27;</span>)</span><br><span class="line">    ax.set_zlabel(<span class="string">&#x27;RSME&#x27;</span>)</span><br><span class="line">    ax.plot_surface(np.log(Y), np.log(X), RMSE, rstride=<span class="number">1</span>, cstride=<span class="number">1</span>, cmap=plt.get_cmap(<span class="string">&#x27;rainbow&#x27;</span>))</span><br><span class="line">    ax.set_title(<span class="string">&#x27;Surface plot&#x27;</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><center left><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230323215538367.png" alt="image-20230323215538367" style="zoom:50%;"  width="800"/><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230323220045143.png" alt="image-20230323220045143" style="zoom: 33%;" width="1250" /></center><p>右图<span class="math inline">\(-\ln \beta\)</span>值作为x轴，<spanclass="math inline">\(\ln \lambda\)</span>作为y轴，左图反之。</p><p>为了方便观察，对局部作图：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/img.png" alt="img" style="zoom: 67%;" /></p><p>首先，从<span class="math inline">\(\ln\lambda\)</span>方向观察，可以看出<spanclass="math inline">\(\lambda\)</span>对RMSE的影响呈波浪状，存在多个极小值，当<spanclass="math inline">\(\lambda\)</span>取很小的值时，在<spanclass="math inline">\(-ln\beta\)</span>较大的时候出现了比较严重的过拟合。</p><p>然后从<span class="math inline">\(-\ln\beta\)</span>方向观察，可以看出<spanclass="math inline">\(\beta\)</span>对RMSE的影响实际上并不大，呈小而密的波浪趋势。</p><h2 id="正则化前后回归系数">正则化前后回归系数</h2><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 选择参数lambda，给出拟合表达</span></span><br><span class="line">    df=pd.read_csv(<span class="string">&#x27;./data/sample=10.csv&#x27;</span>)</span><br><span class="line">    X=df.values[:,<span class="number">1</span>]</span><br><span class="line">    t=df.values[:,<span class="number">2</span>]</span><br><span class="line">    x_train, x_test, T_train, T_test=splitData(X,t)</span><br><span class="line">    <span class="comment"># 正则化</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        poly = polyRegression(i, <span class="number">50</span>)</span><br><span class="line">        y_allPredict, cv, y_test, y_train, X_test, X_train = poly.cv_pridict(X, t, <span class="number">5</span>)</span><br><span class="line">        RMSECV, best_lambda = poly.RMSE_CV(y_allPredict, t, X.shape[<span class="number">0</span>])</span><br><span class="line">        poly_best=polyRegression(i,<span class="number">5</span>)</span><br><span class="line">        poly_best.fit(x_train,T_train,best_lambda)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;次数为&#x27;</span>,i,<span class="string">&#x27;时的权重集合：&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(poly_best.lin.w)</span><br><span class="line">    <span class="comment"># 无正则化</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;无正则化\n&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        poly = polyRegression(i, <span class="number">50</span>)</span><br><span class="line">        poly.fit(x_train, T_train, <span class="number">0</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;次数为&#x27;</span>, i, <span class="string">&#x27;时的权重集合：&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(poly.lin.w)</span><br><span class="line">    rmse_train=[]</span><br><span class="line">    rmse_test=[]</span><br></pre></td></tr></table></figure><p>无正则化：</p><table><colgroup><col style="width: 6%" /><col style="width: 17%" /><col style="width: 17%" /><col style="width: 17%" /><col style="width: 18%" /><col style="width: 6%" /><col style="width: 17%" /></colgroup><thead><tr class="header"><th><span class="math inline">\(w\)</span></th><th>0</th><th>1</th><th>2</th><th>3</th><th>……</th><th>9</th></tr></thead><tbody><tr class="odd"><td></td><td>-0.08673405</td><td>0.43162238</td><td>0.5695881</td><td>-0.05816218</td><td></td><td>-0.07491257</td></tr><tr class="even"><td></td><td></td><td>-1.05343403</td><td>-2.17473669</td><td>11.14510403</td><td></td><td>10.41748047</td></tr><tr class="odd"><td></td><td></td><td></td><td>1.16724815</td><td>-33.31060868</td><td></td><td>-34.4765625</td></tr><tr class="even"><td></td><td></td><td></td><td></td><td>22.29544252</td><td></td><td>56.09375</td></tr><tr class="odd"><td></td><td></td><td></td><td></td><td></td><td></td><td>-60.</td></tr><tr class="even"><td></td><td></td><td></td><td></td><td></td><td></td><td>-14.375</td></tr><tr class="odd"><td></td><td></td><td></td><td></td><td></td><td></td><td>34.796875</td></tr><tr class="even"><td></td><td></td><td></td><td></td><td></td><td></td><td>44.5625</td></tr><tr class="odd"><td></td><td></td><td></td><td></td><td></td><td></td><td>-2.0625</td></tr><tr class="even"><td></td><td></td><td></td><td></td><td></td><td></td><td>-35.390625</td></tr></tbody></table><p>正则化后：</p><table><colgroup><col style="width: 6%" /><col style="width: 17%" /><col style="width: 17%" /><col style="width: 17%" /><col style="width: 17%" /><col style="width: 6%" /><col style="width: 17%" /></colgroup><thead><tr class="header"><th><span class="math inline">\(w\)</span></th><th>0</th><th>1</th><th>2</th><th>3</th><th>……</th><th>9</th></tr></thead><tbody><tr class="odd"><td></td><td>-0.07776724</td><td>0.15514244</td><td>0.17544013</td><td>0.33805469</td><td></td><td>0.21515437</td></tr><tr class="even"><td></td><td></td><td>-0.52292037</td><td>-0.38363097</td><td>-0.80726911</td><td></td><td>-0.44372143</td></tr><tr class="odd"><td></td><td></td><td></td><td>-0.25709792</td><td>-0.42717323</td><td></td><td>-0.42050595</td></tr><tr class="even"><td></td><td></td><td></td><td></td><td>0.41092392</td><td></td><td>-0.25649878</td></tr><tr class="odd"><td></td><td></td><td></td><td></td><td></td><td></td><td>-0.10138744</td></tr><tr class="even"><td></td><td></td><td></td><td></td><td></td><td></td><td>0.02127489</td></tr><tr class="odd"><td></td><td></td><td></td><td></td><td></td><td></td><td>0.1134249</td></tr><tr class="even"><td></td><td></td><td></td><td></td><td></td><td></td><td>0.1815334</td></tr><tr class="odd"><td></td><td></td><td></td><td></td><td></td><td></td><td>0.23170656</td></tr><tr class="even"><td></td><td></td><td></td><td></td><td></td><td></td><td>0.26874031</td></tr></tbody></table><h2 id="bias-variance结构">bias-variance结构</h2><p>程序如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 期望计算</span></span><br><span class="line">    predictAll=[]</span><br><span class="line">    T11=[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">        data1 = create_data(<span class="number">25</span>, np.random.uniform(<span class="number">0</span>,<span class="number">0.5</span>))</span><br><span class="line">        X1 = data1[:,<span class="number">0</span>]</span><br><span class="line">        t1 = data1[:,<span class="number">1</span>]</span><br><span class="line">        x1_train, x1_test, T1_train, T1_test = splitData(X1, t1)</span><br><span class="line">        poly_evey=polyRegression(<span class="number">25</span>,<span class="number">100</span>)</span><br><span class="line">        y_allPredict, cv, y_test, y_train, X_test, X_train,w = poly_evey.cv_pridict(X1, t1, <span class="number">5</span>)</span><br><span class="line">        predictAll.append(y_allPredict)</span><br><span class="line">        RMSECV, best_lambda = poly_evey.RMSE_CV(y_allPredict, t1, X1.shape[<span class="number">0</span>])</span><br><span class="line">        poly_evey.fit(x1_train,T1_train,best_lambda)</span><br><span class="line">        t_predict=poly_evey.predict(X1)</span><br><span class="line">        T11.append(t_predict)</span><br><span class="line"></span><br><span class="line">    T1=np.array(T11)</span><br><span class="line">    f_hat=np.average(T1,axis=<span class="number">0</span>)</span><br><span class="line">    poly11=polyRegression(<span class="number">25</span>,<span class="number">100</span>)</span><br><span class="line">    variances=[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> predictAll:</span><br><span class="line">        variance=poly11.variance_cv(i,f_hat)</span><br><span class="line">        variances.append(variance)</span><br><span class="line">    variance=np.average(variances,axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 生成一个新数据集</span></span><br><span class="line">    data2 = create_data(<span class="number">25</span>, np.random.uniform(<span class="number">0</span>, <span class="number">0.5</span>))</span><br><span class="line">    X2 = data2[:, <span class="number">0</span>]</span><br><span class="line">    t2 = data2[:, <span class="number">1</span>]</span><br><span class="line">    x2_train, x2_test, T2_train, T2_test = splitData(X2, t2)</span><br><span class="line">    poly2=polyRegression(<span class="number">25</span>,<span class="number">100</span>)</span><br><span class="line">    y_allPredict, cv, y_test, y_train, X_test, X_train, w = poly2.cv_pridict(X2, t2, <span class="number">5</span>)</span><br><span class="line">    RMSECV, best_lambda = poly2.RMSE_CV(y_allPredict, t2, X2.shape[<span class="number">0</span>])</span><br><span class="line">    poly2.show_Select_lambda(RMSECV)</span><br><span class="line">    bias_2=poly2.bias_cv(y_allPredict,f_hat,X2.shape[<span class="number">0</span>])</span><br><span class="line">    w=np.array(w)</span><br><span class="line">    error=poly2.test_error_cv(y_allPredict,t2,np.logspace(-<span class="number">10</span>,-<span class="number">7</span>,<span class="number">100</span>),w)</span><br><span class="line">    <span class="built_in">print</span>(bias_2)</span><br><span class="line"></span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.plot(np.logspace(-<span class="number">10</span>,-<span class="number">7</span>, <span class="number">100</span>),bias_2,label=<span class="string">&#x27;bias^2&#x27;</span>,color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">    plt.plot(np.logspace(-<span class="number">10</span>,-<span class="number">7</span>, <span class="number">100</span>),variance, label=<span class="string">&#x27;variance&#x27;</span>, color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">    plt.plot(np.logspace(-<span class="number">10</span>,-<span class="number">7</span>, <span class="number">100</span>),bias_2+variance, label=<span class="string">&#x27;bias^2+variance&#x27;</span>, color=<span class="string">&#x27;pink&#x27;</span>)</span><br><span class="line">    plt.plot(np.logspace(-<span class="number">10</span>,-<span class="number">7</span>, <span class="number">100</span>),error,label=<span class="string">&#x27;test error&#x27;</span>, color=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">    ax = plt.gca()</span><br><span class="line">    ax.set_xscale(<span class="string">&quot;log&quot;</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230326185731318.png" alt="image-20230326185731318" style="zoom:80%;" /></p><h2 id="degreelambda寻优过程"><spanclass="math inline">\(degree\)</span>、<spanclass="math inline">\(lambda\)</span>寻优过程</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">rmse_train=[]</span><br><span class="line">rmse_test=[]</span><br><span class="line"><span class="comment"># 寻找最优次数</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    poly = polyRegression(i, <span class="number">50</span>)</span><br><span class="line">    poly.fit(x_train,T_train,<span class="number">0</span>)</span><br><span class="line">    rmse_train.append(poly.RSME(x_train,T_train))</span><br><span class="line">    rmse_test.append(poly.RSME(x_test,T_test))</span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(np.linspace(<span class="number">0</span>,<span class="number">10</span>,<span class="number">10</span>),</span><br><span class="line">         rmse_test,</span><br><span class="line">         label=<span class="string">&#x27;test&#x27;</span>,</span><br><span class="line">         marker=<span class="string">&#x27;o&#x27;</span>,</span><br><span class="line">         markerfacecolor=<span class="string">&#x27;white&#x27;</span></span><br><span class="line">         , markeredgecolor=<span class="string">&#x27;b&#x27;</span>,</span><br><span class="line">         color=<span class="string">&#x27;b&#x27;</span>,</span><br><span class="line">         markeredgewidth=<span class="number">1.5</span>)</span><br><span class="line">plt.plot(np.linspace(<span class="number">0</span>,<span class="number">10</span>,<span class="number">10</span>),rmse_train,</span><br><span class="line">         label=<span class="string">&#x27;train&#x27;</span>,</span><br><span class="line">         marker=<span class="string">&#x27;o&#x27;</span>,</span><br><span class="line">         markerfacecolor=<span class="string">&#x27;white&#x27;</span>,</span><br><span class="line">         markeredgecolor=<span class="string">&#x27;r&#x27;</span>,</span><br><span class="line">         color=<span class="string">&#x27;r&#x27;</span>,</span><br><span class="line">         markeredgewidth=<span class="number">1.5</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;RMSE&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;degree&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line">best_degree=np.argmin(np.array(rmse_test))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;best degree is&#x27;</span>,best_degree)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;min RMSE in test sets:&#x27;</span>,np.<span class="built_in">min</span>(rmse_test))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对最优次数寻找合适的lambda</span></span><br><span class="line">poly = polyRegression(best_degree, <span class="number">50</span>)</span><br><span class="line">poly.fit(x_train, T_train, <span class="number">0</span>)</span><br><span class="line">poly.draw(X,t)</span><br><span class="line">y_allPredict, cv, y_test, y_train, X_test, X_train,w = poly.cv_pridict(X, t, <span class="number">5</span>)</span><br><span class="line">RMSECV, best_lambda = poly.RMSE_CV(y_allPredict, t, X.shape[<span class="number">0</span>])</span><br><span class="line">poly.show_Select_lambda(RMSECV)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;best lambda is&#x27;</span>,best_lambda)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;min RMSE with regularization:&#x27;</span>,np.<span class="built_in">min</span>(RMSECV))</span><br><span class="line">poly_best = polyRegression(best_degree, <span class="number">50</span>)</span><br><span class="line">poly_best.fit(x_train, T_train, best_lambda)</span><br><span class="line">poly_best.draw(X, t)</span><br></pre></td></tr></table></figure><p>degree寻优：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230326191813731.png" alt="image-20230326191813731" style="zoom:50%;" /></p><p><span class="math inline">\(lambda\)</span>寻优：</p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230326191840244.png" alt="image-20230326191840244" style="zoom: 67%;" /></p>正则化前后图像对比：<center><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230326191928367.png" alt="image-20230326191928367" style="zoom:50%;" /><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230326191912106.png" alt="image-20230326191912106" style="zoom:50%;" /></center><p>左图为未正则化，右图为正则化后。输出结果为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">best degree is 5</span><br><span class="line">min RMSE in test sets: 0.11753272730633338</span><br><span class="line">best lambda is 1.8420699693267162e-08</span><br><span class="line">min RMSE with regularization: 0.0998645060490816</span><br></pre></td></tr></table></figure><h2 id="样本数目影响">样本数目影响</h2><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">RMSEs=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>,<span class="number">50</span>):</span><br><span class="line">    data=create_data(i,<span class="number">0.25</span>)</span><br><span class="line">    X=data[:,<span class="number">0</span>]</span><br><span class="line">    t=data[:,<span class="number">1</span>]</span><br><span class="line">    X_train, X_test, T_train, T_test=splitData(X,t)</span><br><span class="line">    poly=polyRegression(<span class="number">8</span>,<span class="number">50</span>)</span><br><span class="line">    poly.fit(X_train,T_train,<span class="number">0</span>)</span><br><span class="line">    rmse=poly.RSME(X,t)</span><br><span class="line">    RMSEs.append(rmse)</span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">&#x27;seaborn&#x27;</span>)</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(np.linspace(<span class="number">10</span>,<span class="number">50</span>,<span class="number">40</span>),RMSEs)</span><br><span class="line">plt.ylabel(<span class="string">&quot;RMSE&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;samples&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230326193335597.png" alt="image-20230326193335597" style="zoom:50%;" /></p><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20230326193511771.png" alt="image-20230326193511771" style="zoom:50%;" /></p><p>上图是样本数量在（10,200）的RMSE图，下图是样本数量在（10,20）的RMSE图，可以明显看出随着样布数目增长RMSE逐渐趋于稳定，仅有很小的波动。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python基础语法总结</title>
      <link href="/2022/09/14/pythonSummry/"/>
      <url>/2022/09/14/pythonSummry/</url>
      
        <content type="html"><![CDATA[<h1 id="Python基础语法学习总结"><a href="#Python基础语法学习总结" class="headerlink" title="Python基础语法学习总结"></a>Python基础语法学习总结</h1><h2 id="实验目的"><a href="#实验目的" class="headerlink" title="实验目的"></a>实验目的</h2><p>学习Python基本语法</p><h2 id="实验场地与设备"><a href="#实验场地与设备" class="headerlink" title="实验场地与设备"></a>实验场地与设备</h2><p>线上</p><h2 id="实验方式"><a href="#实验方式" class="headerlink" title="实验方式"></a>实验方式</h2><p>阅读教程与程序设计</p><h2 id="实验设计"><a href="#实验设计" class="headerlink" title="实验设计"></a>实验设计</h2><p> <img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/Python%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80.png" alt="Python语言基础"></p><p>图1.1 Python基础语法学习实验设计</p><h2 id="实验内容"><a href="#实验内容" class="headerlink" title="实验内容"></a>实验内容</h2><h3 id="Python语法总结"><a href="#Python语法总结" class="headerlink" title="Python语法总结"></a>Python语法总结</h3><h4 id="Python基本语法"><a href="#Python基本语法" class="headerlink" title="Python基本语法"></a>Python基本语法</h4><h4 id="基本语句"><a href="#基本语句" class="headerlink" title="基本语句"></a>基本语句</h4><p>①  首先是输入输出语句，输入语句比较简单为<code>name=input()</code>，基本输出语句为<code>print()</code>,拼接输出使用逗号。</p><p>②  注释采用<code>#</code> 进行书写</p><p>③   代码风格：Python采用的是缩进式代码风格，所以对于复制粘贴比较不友好</p><p>④   条件判断语句：<code>if 条件1 :...elif 条件2 : ... else : ...</code></p><p>⑤循环语句：</p><p>第一种是<code>for</code>循环：<code>for x in []:</code> <code>for x in ...:</code> 循环就是把每个元素代入变量x，然后执行缩进块的语句</p><p>第二种是<code>while</code>循环：<code>while 条件判断语句 :</code>    <code>break</code>、<code>continue</code>和java中用法相同</p><h4 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h4><p><strong>①整数：</strong>对于很大的数，很难数清楚0的个数。Python允许在数字中间以_分隔。</p><p><strong>②浮点数：</strong>允许使用科学计数法定义</p><p><strong>③字符串：</strong>在Python没有严格要求<code>&#39;&#39; </code>和<code>&quot;&quot;</code>的区别在，也就是说没有区分字符和字符串使用二者没有任何区别。</p><ul><li>转义符和Java中保持一致</li><li>Python允许用<code>r&#39;&#39;</code>表示<code>&#39;&#39;</code>内部的字符串默认不转义</li></ul><p><strong>④    布尔值：</strong></p><p>在Python中要注意：<code>True</code>、<code>False</code>要注意开头首字母大写。<br>可以进行与、或、非的运算，运算符分别为：<code>and</code>，<code>or</code>，<code>not</code>  </p><p><strong>⑤空值：</strong>空值用<code>None</code>表示，意义与Java中的<code>null</code>相同。</p><p><strong>⑥list：</strong></p><p>list是Python内置的一种数据类型，list是一种有序的集合，可以随时添加和删除其中的元素。此数据类型在Java的实用类中有封装。list和数组很像，声明方式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">classname = [<span class="string">&#x27;老六&#x27;</span>,<span class="string">&#x27;老八&#x27;</span>,<span class="string">&#x27;老九&#x27;</span>]</span><br></pre></td></tr></table></figure><p>想要调取其中的某个元素也和数组一致，赋值修改等也相同<br>下面列举一下list的ADT</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">list:</span><br><span class="line">append(&#x27;Elem&#x27;)  # 在末尾添加新的元素</span><br><span class="line">insert(i,&#x27;Elem&#x27;) # 将元素插入指定位置</span><br><span class="line">pop() # 删除末尾元素</span><br><span class="line">pop(i) # 删除i处的元素</span><br><span class="line">len(list) # list列表的长度</span><br></pre></td></tr></table></figure><p>list允许混合类型，也允许list嵌套，从而出现多维数组。</p><p><strong>⑦ tuple</strong></p><p>tuple被称为元组，其最大的特点就是不可修改，声明方式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">classname = (<span class="string">&#x27;老六&#x27;</span>,<span class="string">&#x27;老八&#x27;</span>,<span class="string">&#x27;老九&#x27;</span>)</span><br></pre></td></tr></table></figure><p>tuple在定义时要确定元素个数，这里有一个问题，在定义只有一个元素的tuple时，Python语法会认为这是一个小括号，因此在定义一个元组的tuple时，要加一个<code>,</code>避免歧义。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t=(<span class="number">1</span>,)</span><br></pre></td></tr></table></figure><p><strong>⑧字典（dict）</strong></p><p>字典全称为dictionary，在Java实用类中叫hash map。其由键值对（key-value）组成，查找速度快。 下面是一种初始化方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d = &#123;<span class="string">&#x27;Michael&#x27;</span>: <span class="number">95</span>, <span class="string">&#x27;Bob&#x27;</span>: <span class="number">75</span>, <span class="string">&#x27;Tracy&#x27;</span>: <span class="number">85</span>&#125;</span><br></pre></td></tr></table></figure><p>也可以放入指定的key中：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d[<span class="string">&#x27;Adam&#x27;</span>] = <span class="number">67</span></span><br></pre></td></tr></table></figure><p>查找value:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d[<span class="string">&#x27;Adam&#x27;</span>]</span><br></pre></td></tr></table></figure><p>key与value是多对一的关系，key需要是一个不可变对象保证key做hash运算后的唯一性。如果多次对某个key赋值，后边的value会覆盖前面的value 提供了几个函数：</p><ol><li>通过<code>in</code>来判断key是否在dict中，返回值为布尔值，格式为：<code>key in dict</code></li><li>get()方法，<code>dict.get(&#39;key&#39;,空返回值)</code>key不存在时返回空返回值，空返回值可自定义，如果没有定义的话返回None</li><li>pop()方法，删除key，如果有value也一并删除，格式为<code>pop(&#39;key&#39;)</code></li></ol><p><strong>⑨集合（set）</strong></p><p>set是一组key的集合,集合特点；无序性、确定性、互异性<br>要创建一个set，需要提供一个list作为输入集合：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="built_in">set</span>([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure><ul><li>方法：<br><code>add(key)</code>添加一个新的元素<br><code>remove(key)</code>删除一个元素</li><li>两个set可以做交运算和并运算：<br>交运算：<code>s1&amp;s2</code><br>并运算：<code>s1|s2</code></li></ul><h4 id="理解变量"><a href="#理解变量" class="headerlink" title="理解变量"></a>理解变量</h4><p>在Python中变量仅仅是一个一个字母，变量与所对应的值之间的关系靠指针联系起来的。所以很重要的一点就是：<strong>当我们使用变量时，更多的要关注变量指向的东西，他可能是值，也可能是一个函数，也可能是一个变量</strong></p><h4 id="模块"><a href="#模块" class="headerlink" title="模块"></a>模块</h4><h4 id="模块导入"><a href="#模块导入" class="headerlink" title="模块导入"></a>模块导入</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><h4 id="模块下载"><a href="#模块下载" class="headerlink" title="模块下载"></a>模块下载</h4><p>模块下载有比较复杂的方法，也有比较傻瓜式的。先说复杂的，使用Python中自带的pip包管理工具，用命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install numpy</span><br></pre></td></tr></table></figure><p>但是使用pip需要事先了解要导的包的名字，而且不能批量导入，而且在Python编程里也有编程一分钟，导包一小时的说法。pip下载第三方库的源可能会很慢或者失效，需要会自己添加国内的高速镜像。</p><p>傻瓜式的导包，例如在pycharm中可以直接在代码中写出自己需要的包，然后交给pycharm自己去下载，或者用Anaconda提前构建好的Python的库环境。</p><h4 id="函数式编程"><a href="#函数式编程" class="headerlink" title="函数式编程"></a>函数式编程</h4><h4 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h4><p><strong>①函数定义</strong></p><p>在Python中定义函数为，<code>def 函数名(参数):</code>然后，在缩进块中编写函数体，函数的返回值用<code>return</code>语句返回。<br>如果没有return语句，函数执行完毕后也会返回结果，只是结果为None。return None可以简写为return。</p><p>1）空函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">nop</span>():</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>在这里<code>pass</code>作为占位符，表示跳过，也可以用在<code>if</code>的缩进块。</p><p>2）参数限制：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(x, (<span class="built_in">int</span>, <span class="built_in">float</span>)):</span><br><span class="line">      <span class="keyword">raise</span> TypeError(<span class="string">&#x27;bad operand type&#x27;</span>)</span><br></pre></td></tr></table></figure><p>实际上参数限制就是定义一个报错，<code>isinstance()</code>判断数据类型，如果不是就提出一个错误。  <strong>作为一个弱类型语言，定义这一步是很有必要的，有助于读懂代码。</strong></p><p>3）返回值：</p><p>Python允许返回多个值，其返回的实际上是一个tuple元组，但是也可以用两个变量接收。</p><p><strong>②参数定义</strong>  </p><p>在Python中函数参数的定义也比较灵活，提供位置参数、默认参数、可变参数、关键字（key）参数等</p><p>1）位置参数：位置参数指的是参数在传入时，实参和形参有着严格的位置对应关系，为常用参数形式。</p><p>2）默认参数：默认参数是指在位置参数的基础上为其添加默认值，有默认值的参数为默认参数，没有默认值的参数为必选参数<br>基本定义形式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">my_def</span>(<span class="params">a,b=<span class="number">1</span></span>):</span><br><span class="line">    a=b+<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> </span><br></pre></td></tr></table></figure><p>需要注意的是：</p><ul><li>默认参数必须在必选参数后边，否则会无法辨认是否输入必选参数，从而报错。</li><li>默认参数的默认值一定是<strong>不变对象</strong>，由于Python中的变量定义为指针指向，会导致可变对象值发生变化</li></ul><p>3）不可变对象有：数值类型、字符串、tuple元组、None等</p><p>4）可变参数：可变参数指的是参数的数目不固定，定义形式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">my_function</span>(<span class="params">*v</span>):</span><br><span class="line">    <span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> vi <span class="keyword">in</span> v:</span><br><span class="line">        <span class="built_in">sum</span>+=vi</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span></span><br></pre></td></tr></table></figure><p>在可变参数中传入的所有参数将作为一个tuple被接收，该tuple的变量名为函数在定义时的形参名，定义时的需要在参数名前加一个<code>*</code>。</p><p>5）关键字（key）参数</p><p>此处的关键字和c语言中的关键字并不是一个意义，而是在dict中的key的意义。即在传递参数时，同时传递键（key）和值(value),Python会自动封装为一个dict。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">my_function</span>(<span class="params">**v</span>):</span><br><span class="line">    <span class="built_in">print</span>(v)</span><br><span class="line">    <span class="keyword">return</span> </span><br></pre></td></tr></table></figure><p>6）命名关键字参数</p><p>在关键字参数上，进一步限制传入的key的命名，就有了命名关键词参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">person</span>(<span class="params">name, age, *, city, job</span>):</span><br><span class="line">    <span class="built_in">print</span>(name, age, city, job)</span><br></pre></td></tr></table></figure><p>这里需要一个<code>*</code>区分位置参数与命名关键字参数，如果在这之前有可变参数，那么就不需要加<code>*</code>。<br>命名关键字参数必须传入参数名，这和位置参数不同。如果没有传入参数名，调用将报错：</p><p>7）参数组合</p><p>在一个函数中使用多个参数要保证其中的顺序，依次为：必选参数、默认参数、可变参数、命名关键字参数和关键字参数。  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">onefunction</span>(<span class="params">a,b,c=<span class="number">0</span>,*args,job,city,**kw</span>):</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>tips：  </p><ul><li>使用<code>*args</code>和<code>**kw</code>是Python的习惯写法。</li><li>可变参数和关键字参数有一点层级的感觉，中间包裹的是命名关键字参数这个比较尴尬的参数。</li></ul><p><strong>③递归函数</strong></p><p>写法与Java相同。</p><h4 id="实用方法"><a href="#实用方法" class="headerlink" title="实用方法"></a>实用方法</h4><p><strong>①切片</strong></p><p>切片是一个针对tuple和list方便地取元素的方法，语法规则：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">L[起始坐标:终止坐标:步长]</span><br></pre></td></tr></table></figure><p>当起始坐标为0时可以省略；步长为1时可以省略。</p><p><strong>②迭代</strong></p><p>迭代是循环的增强，但是想要弄清迭代，需要知道两件事：一个是能不能迭代，一个是迭代出的数据是什么</p><p>想要知道一个数据能否迭代可以通过一个函数来完成：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections.abc <span class="keyword">import</span> Iterable</span><br><span class="line">L=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line"><span class="built_in">isinstance</span>(L,Iterable)</span><br></pre></td></tr></table></figure><p>迭代出的是什么，和要迭代的对象的储存方式，要特殊记忆一下dic。</p><p><strong>③ 列表生成器</strong></p><p>一种快捷生成list的方式，一个例子如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[x * x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>)]</span><br></pre></td></tr></table></figure><p>如果想要筛选生成的值，可以在<code>for</code>后加上<code>if</code>作为<strong>筛选条件</strong>，注意这里是筛选条件， 因此这里和平时的<code>if else</code>并不是一个东西。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[x * x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>) <span class="keyword">if</span> x % <span class="number">2</span> == <span class="number">0</span>]</span><br></pre></td></tr></table></figure><p><strong>④ 生成器</strong></p><p>生成器是一种惰性的计算方式。包含<code>yield</code>关键字，当一个函数包含<code>yield</code>关键字时，他就成了一个generator函数。<code>yield</code>在generator函数中起到了一个return的作用，即到<code>yield</code>便返回。 在调用时，使用一个变量接受一个generator对象。使用<code>next()</code>函数依次获得下一个返回值。</p><p><strong>⑤迭代器</strong></p><p>区分<code>Iterable</code>和<code>Iterator</code></p><p><code>Iterable</code>是可迭代的，是直接可用于<code>for</code>循环的。包括dict、list、tuple、set、str、grenerator。<br><code>Iterator</code>是迭代器，是直接可用于<code>next()</code>函数的，生成器都是<code>Iterator</code>对象，集合数据类型可以通过<code>iter()</code>获取<code>Interator</code>对象。</p><h4 id="函数式编程-1"><a href="#函数式编程-1" class="headerlink" title="函数式编程"></a>函数式编程</h4><p>函数式编程是一种面向过程的编程思想，实际上是将复杂问题转化为一个个函数。</p><p>在Java的函数定义中，除去<code>void</code>类型不返回值，其余的都需要返回值。因此也就经常存在，使用一个变量接受函数值：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">function</span><span class="params">(x,y)</span>&#123;</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> a=function(x,y);</span><br></pre></td></tr></table></figure><p>那么是不是存在一种可能，我们可以将函数嵌套，让函数调用函数，让函数返回函数，彻底抛弃变量？</p><p>抛弃变量、只有函数就是彻底的函数式编程</p><p><strong>①理解高阶函数</strong></p><p>之前有过变量名和值的理解，在Python中变量名和值是一个指针指向的关系。同理，函数名和函数也是这样的，函数名也是一个变量。也就是说，我们可以通过函数名，拿到函数体。也就是说函数名是什么并不重要，我们看中的是函数体。</p><p>![绘图1](<a href="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/">https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/</a> typora&#x2F;%E7%BB%98%E5%9B%BE1.png)</p><p>那么设想一种情况，现在我们定义了函数f2，那么我可以随便写一个函数，然后返回一个变量f2，那么实际上我就拿到了函数体。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">f2</span>(<span class="params">a,b</span>):</span><br><span class="line">    <span class="keyword">return</span> a+b</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">f3</span>():</span><br><span class="line">    <span class="keyword">return</span> f2</span><br><span class="line"><span class="built_in">print</span>(f3()(<span class="number">1</span>,<span class="number">2</span>))</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20220909173741530.png" alt="image-20220909173741530"></p><p>然后我们在设想另一种情况，现在我们定义了另一种情况，我们在一个函数中写了一个f1作为局部变量，那么我就可以传入变量f2，然后就相当于传入了函数体。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">f2</span>(<span class="params">a,b</span>):</span><br><span class="line">    <span class="keyword">return</span> a+b</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">f1</span>(<span class="params">a,b,f</span>):</span><br><span class="line">    <span class="keyword">return</span> f(a,b)</span><br><span class="line"><span class="built_in">print</span>(f1(<span class="number">1</span>,<span class="number">2</span>,f2))</span><br></pre></td></tr></table></figure><p>现在就可以进行一个区分：</p><ul><li><code>f</code>代表函数名，是变量</li><li><code>f()</code>代表数值，是函数的返回值，返回值是一个量</li></ul><p>高阶函数，就是让函数的参数能够接收别的函数。</p><p>实用的几个函数，有必要查表即可</p><p><strong>②返回函数</strong></p><p>同上文理解，只不过是将一个函数嵌套入了另一个函数</p><p><strong>③ lambda表达式</strong></p><p>与Java中语法相同，目的是为了简化返回函数嵌套</p><h4 id="面向对象编程"><a href="#面向对象编程" class="headerlink" title="面向对象编程"></a>面向对象编程</h4><h4 id="类和对象"><a href="#类和对象" class="headerlink" title="类和对象"></a>类和对象</h4><p>创建类：语法如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">类名</span>(<span class="title class_ inherited__">继承的类</span>):</span><br></pre></td></tr></table></figure><p>python的类非常随意，几乎可以不定义就能用。在类中自带有一个构造函数<code>__init__()</code>,此函数可以重新定义</p><p>生成对象：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a=A()</span><br></pre></td></tr></table></figure><h4 id="访问权限"><a href="#访问权限" class="headerlink" title="访问权限"></a>访问权限</h4><p>如果要让内部属性不被外部访问，可以把属性的名称前加上两个下划线<code>__</code>，在Python中，实例的变量名如果以<code>__</code>开头，就变成了一个私有变量（private），只有内部可以访问，外部不能访问。</p><p>此外，<code>__ __</code>这种变量都是特殊变量，在不清楚的时候不要随便乱改</p><h4 id="继承和多态"><a href="#继承和多态" class="headerlink" title="继承和多态"></a>继承和多态</h4><p>和Java中的思想完全相同</p><h4 id="常用变量和方法"><a href="#常用变量和方法" class="headerlink" title="常用变量和方法"></a>常用变量和方法</h4><p>①<code>__slots__</code></p><p>用这个变量可以起到参数列表的功能，可以在一定程度上限制参数的变量名，用turple进行限定</p><p>②<code>@property</code></p><p>注解编程，可以起到一个简化定义setter和getter函数的作用。@property注解在getter方法上，然后会自动生成 @函数名.setter 的注解，但是要注意的一点是，在getter中就不能使用函数名作为自身的调用值，否则会出现无限的调用，产生爆栈。</p><p>③多继承</p><p>与Java相同</p><p>⑤<code>__str__</code>:和Java中的toString方法相同</p><h4 id="错误调试"><a href="#错误调试" class="headerlink" title="错误调试"></a>错误调试</h4><h4 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a>错误处理</h4><p>参照Java中，对比来学习即可：</p><p>两种方法，一是尝试，二是抛出，尝试采用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line"><span class="keyword">pass</span></span><br><span class="line"><span class="keyword">except</span> baseexception  :</span><br><span class="line"><span class="keyword">pass</span></span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line"><span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>抛出采用<code>raise</code>关键字</p><h4 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h4><p>①断言：<code>assert</code>的意思是，表达式<code>n != 0</code>应该是<code>True</code>，否则，根据程序运行的逻辑，后面的代码肯定会出错。</p><p>如果断言失败，<code>assert</code>语句本身就会抛出<code>AssertionError</code></p><p>②断点：在强大IDE的辅助下，使用断点调试应该是最简单的。</p><h3 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h3><h4 id="石头剪子布"><a href="#石头剪子布" class="headerlink" title="石头剪子布"></a>石头剪子布</h4><p>使用random包中的random函数和条件控制语句，模拟两个电脑互相猜拳：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">win</span>(<span class="params">pc,cc</span>):</span><br><span class="line">    <span class="keyword">if</span> (cc==<span class="number">1</span> <span class="keyword">and</span> pc==<span class="number">2</span>) <span class="keyword">or</span> (cc==<span class="number">2</span> <span class="keyword">and</span> pc==<span class="number">3</span>)<span class="keyword">or</span>(cc==<span class="number">3</span> <span class="keyword">and</span> pc==<span class="number">1</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;电脑一输&quot;</span>)</span><br><span class="line">    <span class="keyword">elif</span> pc==cc:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;平&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;电脑二输&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">computer_choice</span>():</span><br><span class="line">    cc=random.randint(<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">return</span> cc</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show</span>(<span class="params">pc,cc</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;电脑一的出招为&quot;</span>,pc)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;电脑二的出招为&quot;</span>,cc)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">        pc=computer_choice()</span><br><span class="line">        cc=computer_choice()</span><br><span class="line">        show(pc,cc)</span><br><span class="line">        win(pc,cc)</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20220914212607801.png" alt="image-20220914212607801"></p><p>改进提升一下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">win</span>(<span class="params">pc,cc</span>):</span><br><span class="line">    <span class="keyword">if</span> (cc==<span class="number">1</span> <span class="keyword">and</span> pc==<span class="number">2</span>) <span class="keyword">or</span> (cc==<span class="number">2</span> <span class="keyword">and</span> pc==<span class="number">3</span>)<span class="keyword">or</span>(cc==<span class="number">3</span> <span class="keyword">and</span> pc==<span class="number">1</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;玩家输&quot;</span>)</span><br><span class="line">    <span class="keyword">elif</span> pc==cc:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;平&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;玩家赢&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">computer_choice</span>():</span><br><span class="line">    cc=random.randint(<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">return</span> cc</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">str</span>(<span class="params">cc</span>):</span><br><span class="line">    <span class="keyword">if</span> cc==<span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;石头&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> cc==<span class="number">2</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;剪刀&#x27;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;布&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show</span>(<span class="params">f,pc,cc</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;电脑一的出招为&quot;</span>,f(pc))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;电脑二的出招为&quot;</span>,f(cc))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">        cc=computer_choice()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;请输入：1.石头 2.剪刀 3.布&quot;</span>)</span><br><span class="line">        pc=<span class="built_in">input</span>()</span><br><span class="line">        show(<span class="built_in">str</span>,pc,cc)</span><br><span class="line">        win(pc,cc)</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20220914213324805.png" alt="image-20220914213324805"></p><h4 id="ATM模拟"><a href="#ATM模拟" class="headerlink" title="ATM模拟"></a>ATM模拟</h4><p>通过类和对象简单的设计了一个ATM取钱模拟器</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> Account</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ATM</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,money,accounts</span>):</span><br><span class="line">        self.money=money</span><br><span class="line">        self.accounts=accounts</span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">money</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self._money;</span><br><span class="line"><span class="meta">    @money.setter</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">money</span>(<span class="params">self,value</span>):</span><br><span class="line">        self._money=value</span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">accounts</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self._accounts</span><br><span class="line"><span class="meta">    @accounts.setter</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">accounts</span>(<span class="params">self,value</span>):</span><br><span class="line">        self._accounts=value</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">searchId</span>(<span class="params">self,<span class="built_in">id</span></span>):</span><br><span class="line">        <span class="keyword">for</span> account <span class="keyword">in</span> self.accounts:</span><br><span class="line">            <span class="keyword">if</span> account.<span class="built_in">id</span>==<span class="built_in">id</span>:</span><br><span class="line">                <span class="keyword">return</span> account</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">lode</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;请输入账号id&#x27;</span>)</span><br><span class="line">        <span class="built_in">id</span> = <span class="built_in">input</span>()</span><br><span class="line">        account1 = self.searchId(<span class="built_in">id</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;请输入密码&#x27;</span>)</span><br><span class="line">        password = <span class="built_in">input</span>()</span><br><span class="line">        <span class="keyword">if</span> password == account1.password:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;欢迎&quot;</span>, account1.name)</span><br><span class="line">        <span class="keyword">return</span> account1</span><br><span class="line">    <span class="comment"># 存钱</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">save_money</span>(<span class="params">self</span>):</span><br><span class="line">        account=self.lode();</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;请输入要存入的数目&quot;</span>)</span><br><span class="line">        saveMneyValue=<span class="built_in">input</span>()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;存款成功&#x27;</span>)</span><br><span class="line">        account.remain=<span class="built_in">int</span>(account.remain)+<span class="built_in">int</span>(saveMneyValue)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;您的账户余额为&#x27;</span>,account.remain)</span><br><span class="line">        self.money=self.money+<span class="built_in">int</span>(saveMneyValue)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 取钱</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">withdraw_money</span>(<span class="params">self</span>):</span><br><span class="line">        account=self.lode()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;请输入要取出的数目&#x27;</span>)</span><br><span class="line">        withdrawMoneyValue=<span class="built_in">input</span>()</span><br><span class="line">        <span class="keyword">if</span> account.remain &gt; withdrawMoneyValue:</span><br><span class="line">            account.remain=<span class="built_in">int</span>(account.remain)-<span class="built_in">int</span>(withdrawMoneyValue)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;取款成功，您的账户余额为&#x27;</span>,account.remain)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;您的账户余额不足&#x27;</span>)</span><br><span class="line">        self.money=<span class="built_in">int</span>(self.money)-<span class="built_in">int</span>(withdrawMoneyValue)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__str__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;当前ATM中有金额&quot;</span>,self.money,<span class="string">&quot;元&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># atm1=ATM(1000)</span></span><br><span class="line">    <span class="comment"># atm1.__str__()</span></span><br><span class="line">    <span class="comment"># atm1.ave_money(200)</span></span><br><span class="line">    <span class="comment"># atm1.__str__()</span></span><br><span class="line">    <span class="comment"># atm1.withdraw_money(200)</span></span><br><span class="line">    <span class="comment"># atm1.__str__()</span></span><br><span class="line">    accounts=[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        name=<span class="built_in">input</span>()</span><br><span class="line">        <span class="built_in">id</span> = <span class="built_in">input</span>()</span><br><span class="line">        password=<span class="built_in">input</span>()</span><br><span class="line">        remain=<span class="built_in">input</span>()</span><br><span class="line">        accounts.append(Account.account(name, <span class="built_in">id</span>, password, remain))</span><br><span class="line">    atm2=ATM(<span class="number">10000</span>,accounts)</span><br><span class="line">    atm2.save_money()</span><br><span class="line">    atm2.withdraw_money()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">account</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,name,<span class="built_in">id</span>,password,remain</span>):</span><br><span class="line">        self.name=name</span><br><span class="line">        self.remain=remain</span><br><span class="line">        self.password=password</span><br><span class="line">        self.<span class="built_in">id</span>=<span class="built_in">id</span></span><br><span class="line"></span><br><span class="line">    __slots__ = (<span class="string">&#x27;name&#x27;</span>,<span class="string">&#x27;remain&#x27;</span>,<span class="string">&#x27;password&#x27;</span>,<span class="string">&#x27;id&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20220914214759256.png" alt="image-20220914214759256"></p><h4 id="圣诞树画图"><a href="#圣诞树画图" class="headerlink" title="圣诞树画图"></a>圣诞树画图</h4><p>使用Python自带的turtle包，进行圣诞树绘制：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> turtle</span><br><span class="line"></span><br><span class="line">screen = turtle.Screen()</span><br><span class="line">screen.setup(<span class="number">375</span>, <span class="number">700</span>)</span><br><span class="line"></span><br><span class="line">circle = turtle.Turtle()</span><br><span class="line">circle.shape(<span class="string">&#x27;circle&#x27;</span>)</span><br><span class="line">circle.color(<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">circle.speed(<span class="string">&#x27;fastest&#x27;</span>)</span><br><span class="line">circle.up()</span><br><span class="line"></span><br><span class="line">square = turtle.Turtle()</span><br><span class="line">square.shape(<span class="string">&#x27;square&#x27;</span>)</span><br><span class="line">square.color(<span class="string">&#x27;green&#x27;</span>)</span><br><span class="line">square.speed(<span class="string">&#x27;fastest&#x27;</span>)</span><br><span class="line">square.up()</span><br><span class="line"></span><br><span class="line">circle.goto(<span class="number">0</span>, <span class="number">280</span>)</span><br><span class="line">circle.stamp()</span><br><span class="line"></span><br><span class="line">k = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">13</span>):</span><br><span class="line">    y = <span class="number">30</span> * i</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i - k):</span><br><span class="line">        x = <span class="number">30</span> * j</span><br><span class="line">        square.goto(x, -y + <span class="number">280</span>)</span><br><span class="line">        square.stamp()</span><br><span class="line">        square.goto(-x, -y + <span class="number">280</span>)</span><br><span class="line">        square.stamp()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">4</span> == <span class="number">0</span>:</span><br><span class="line">        x = <span class="number">30</span> * (j + <span class="number">1</span>)</span><br><span class="line">        circle.color(<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">        circle.goto(-x, -y + <span class="number">280</span>)</span><br><span class="line">        circle.stamp()</span><br><span class="line">        circle.goto(x, -y + <span class="number">280</span>)</span><br><span class="line">        circle.stamp()</span><br><span class="line">        k += <span class="number">3</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">4</span> == <span class="number">3</span>:</span><br><span class="line">        x = <span class="number">30</span> * (j + <span class="number">1</span>)</span><br><span class="line">        circle.color(<span class="string">&#x27;yellow&#x27;</span>)</span><br><span class="line">        circle.goto(-x, -y + <span class="number">280</span>)</span><br><span class="line">        circle.stamp()</span><br><span class="line">        circle.goto(x, -y + <span class="number">280</span>)</span><br><span class="line">        circle.stamp()</span><br><span class="line"></span><br><span class="line">square.color(<span class="string">&#x27;brown&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">13</span>, <span class="number">17</span>):</span><br><span class="line">    y = <span class="number">30</span> * i</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">        x = <span class="number">30</span> * j</span><br><span class="line">        square.goto(x, -y + <span class="number">280</span>)</span><br><span class="line">        square.stamp()</span><br><span class="line">        square.goto(-x, -y + <span class="number">280</span>)</span><br><span class="line">        square.stamp()</span><br><span class="line">turtle.mainloop()</span><br></pre></td></tr></table></figure><p><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/image-20220914215352995.png" alt="image-20220914215352995"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Python作为一个弱类型语言，是有他的弊端的，在一些需要数据类型转换和严格控制数据类型的情况下，会非常难受。而Python最大的优势在于有大量的库，这些库在特定的编程领域会非常便利。Python本身的语言具有极强的灵活性，而灵活性的言外之意就是规范性很难确定。因此，Python的重点是将第三方包为我所用，在数值计算中发挥他最大的作用。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>暑期Python学习（四）</title>
      <link href="/2022/07/18/day-4/"/>
      <url>/2022/07/18/day-4/</url>
      
        <content type="html"><![CDATA[<h1 id="函数高级特性"><a href="#函数高级特性" class="headerlink" title="函数高级特性"></a>函数高级特性</h1><h2 id="切片（Slice）"><a href="#切片（Slice）" class="headerlink" title="切片（Slice）"></a>切片（Slice）</h2><p>切片是一个针对tuple和list方便地取元素的方法，下面举例说明：</p><ol><li>取出list L中的0到3个元素</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">L[<span class="number">0</span>:<span class="number">3</span>]</span><br></pre></td></tr></table></figure><p>当取出元素从第0个开始时，第一个数字可以缺省</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">L[:<span class="number">3</span>]</span><br></pre></td></tr></table></figure><ol><li>取出倒数后三个元素<br>在Python中允许使用<code>L[-1]</code>来取出倒数第一个数，因此可以这样倒着取：</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">L[-<span class="number">3</span>:]</span><br></pre></td></tr></table></figure><ol><li>每两个数取一个数<br>切片的最后一个数字表示步长，步长为多少就隔几个数字。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">L[:<span class="number">10</span>:<span class="number">2</span>]</span><br></pre></td></tr></table></figure><p>字符串和tuple同样可以这样使用，只不过返回值为对应类型。</p><h2 id="迭代（Iteration）"><a href="#迭代（Iteration）" class="headerlink" title="迭代（Iteration）"></a>迭代（Iteration）</h2><p>Python的迭代相比c或者Java来说，功能更强大，除了可以迭代list，还可以迭代dict这种无下标的数据类型。<br>想要知道一个数据能否迭代可以通过一个函数来完成：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections.abc <span class="keyword">import</span> Iterable</span><br><span class="line">L=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line"><span class="built_in">isinstance</span>(L,Iterable)</span><br></pre></td></tr></table></figure><p>下面说明dict如何迭代：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">d=&#123;<span class="string">&#x27;a&#x27;</span>:<span class="number">1</span>,<span class="string">&#x27;b&#x27;</span>:<span class="number">2</span>,<span class="string">&#x27;c&#x27;</span>:<span class="number">3</span>&#125;</span><br><span class="line"><span class="comment"># 迭代key</span></span><br><span class="line"><span class="keyword">for</span> key <span class="keyword">in</span> d:</span><br><span class="line">    <span class="built_in">print</span>(key)</span><br><span class="line"><span class="comment"># 迭代value</span></span><br><span class="line"><span class="keyword">for</span> value <span class="keyword">in</span> d.values():</span><br><span class="line">    <span class="built_in">print</span>(value)</span><br><span class="line"><span class="comment"># 迭代key和value</span></span><br><span class="line"><span class="keyword">for</span> k,v <span class="keyword">in</span> d.items:</span><br><span class="line">    <span class="built_in">print</span>(k)</span><br><span class="line">    <span class="built_in">print</span>(v)</span><br></pre></td></tr></table></figure><p>需要理解的是，这里的key，value，k，v都是for循环中的形参，没有实际意义。也就是说当<code>in d</code>的时候默认就是取<code>key</code> 。当要迭代其他的时候只需要更改<code>in</code>的后面。我猜测这可能与dict的存储方式有关。</p><p>多个元素同时迭代在其他list中也是可以实现的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">l=&#123;(<span class="number">1</span>,<span class="number">2</span>),(<span class="number">3</span>,<span class="number">4</span>),(<span class="number">5</span>,<span class="number">6</span>)&#125;</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> l:</span><br><span class="line">    <span class="built_in">print</span>(x)</span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> l:</span><br><span class="line">    <span class="built_in">print</span>(x,y)</span><br></pre></td></tr></table></figure><h2 id="列表生成式"><a href="#列表生成式" class="headerlink" title="列表生成式"></a>列表生成式</h2><p>一种快捷生成list的方式，一个例子如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[x * x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>)]</span><br></pre></td></tr></table></figure><p>如果想要筛选生成的值，可以在<code>for</code>后加上<code>if</code>作为<strong>筛选条件</strong>，注意这里是筛选条件， 因此这里和平时的<code>if else</code>并不是一个东西。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[x * x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>) <span class="keyword">if</span> x % <span class="number">2</span> == <span class="number">0</span>]</span><br></pre></td></tr></table></figure><h2 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h2><p>如果列表元素可以按照某种算法推算出来，那我们是否可以在循环的过程中不断推算出后续的元素呢？这样就不必创建完整的list，从而节省大量的空间。在Python中，这种一边循环一边计算的机制，称为生成器：generator。</p><h3 id="创建generator"><a href="#创建generator" class="headerlink" title="创建generator"></a>创建generator</h3><ol><li>把一个列表生成式的<code>[]</code>改成<code>(）</code></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">g = (x * x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>))</span><br></pre></td></tr></table></figure><ol><li>包含<code>yield</code>关键字<br>当一个函数包含<code>yield</code>关键字时，他就成了一个generator函数。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">fib</span>(<span class="params"><span class="built_in">max</span></span>):</span><br><span class="line">    n, a, b = <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> n &lt; <span class="built_in">max</span>:</span><br><span class="line">        <span class="keyword">yield</span> b</span><br><span class="line">        a, b = b, a + b</span><br><span class="line">        n = n + <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;done&#x27;</span></span><br></pre></td></tr></table></figure><p><code>yield</code>在generator函数中起到了一个return的作用，即到<code>yield</code>便返回。 在调用时，使用一个变量接受一个generator对象。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">f = fib(<span class="number">6</span>)</span><br></pre></td></tr></table></figure><h3 id="调用generator获得值"><a href="#调用generator获得值" class="headerlink" title="调用generator获得值"></a>调用generator获得值</h3><ol><li>使用<code>next()</code>函数依次获得下一个返回值</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">next</span>(f)</span><br></pre></td></tr></table></figure><ol><li>使用<code>for</code>循环</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">g = (x * x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>))</span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> g:</span><br><span class="line">    <span class="built_in">print</span>(n)</span><br></pre></td></tr></table></figure><h2 id="迭代器"><a href="#迭代器" class="headerlink" title="迭代器"></a>迭代器</h2><h3 id="区分Iterable和Iterator"><a href="#区分Iterable和Iterator" class="headerlink" title="区分Iterable和Iterator"></a>区分<code>Iterable</code>和<code>Iterator</code></h3><p><code>Iterable</code>是可迭代的，是直接可用于<code>for</code>循环的。包括dict、list、tuple、set、str、grenerator。<br><code>Iterator</code>是迭代器，是直接可用于<code>next()</code>函数的，生成器都是<code>Iterator</code>对象，集合数据类型可以通过<code>iter()</code>获取<code>Interator</code>对象。</p><h3 id="for循环的本质"><a href="#for循环的本质" class="headerlink" title="for循环的本质"></a><code>for</code>循环的本质</h3><p>在Python中<code>for</code>循环本质上就是一个不断调用<code>next()</code>的过程。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">it=<span class="built_in">iter</span>([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        x=<span class="built_in">next</span>(it)</span><br><span class="line">    <span class="keyword">except</span> StopIteration:</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Python学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>暑期Python学习（三）</title>
      <link href="/2022/07/16/day3/"/>
      <url>/2022/07/16/day3/</url>
      
        <content type="html"><![CDATA[<h1 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h1><h2 id="函数定义"><a href="#函数定义" class="headerlink" title="函数定义"></a>函数定义</h2><p>在Python中定义函数为，<code>def 函数名(参数):</code>然后，在缩进块中编写函数体，函数的返回值用<code>return</code>语句返回。<br>如果没有return语句，函数执行完毕后也会返回结果，只是结果为None。return None可以简写为return。</p><h3 id="空函数"><a href="#空函数" class="headerlink" title="空函数"></a>空函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">nop</span>():</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>在这里<code>pass</code>作为占位符，表示跳过，也可以用在<code>if</code>的缩进块。</p><h3 id="参数限制"><a href="#参数限制" class="headerlink" title="参数限制"></a>参数限制</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(x, (<span class="built_in">int</span>, <span class="built_in">float</span>)):</span><br><span class="line">      <span class="keyword">raise</span> TypeError(<span class="string">&#x27;bad operand type&#x27;</span>)</span><br></pre></td></tr></table></figure><p>实际上参数限制就是定义一个报错，<code>isinstance()</code>判断数据类型，如果不是就提出一个错误。<br><strong><strong>作为一个弱类型语言，定义这一步是很有必要的，有助于读懂代码。</strong></strong></p><h3 id="返回值"><a href="#返回值" class="headerlink" title="返回值"></a>返回值</h3><p>Python允许返回多个值，其返回的实际上是一个tuple元组，但是也可以用两个变量接收。</p><h3 id="参数定义"><a href="#参数定义" class="headerlink" title="参数定义"></a>参数定义</h3><p>在Python中函数参数的定义也比较灵活，提供位置参数、默认参数、可变参数、关键字（key）参数等</p><h4 id="位置参数"><a href="#位置参数" class="headerlink" title="位置参数"></a>位置参数</h4><p>位置参数指的是参数在传入时，实参和形参有着严格的位置对应关系，为常用参数形式。</p><h4 id="默认参数"><a href="#默认参数" class="headerlink" title="默认参数"></a>默认参数</h4><p>默认参数是指在位置参数的基础上为其添加默认值，有默认值的参数为默认参数，没有默认值的参数为必选参数<br>基本定义形式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">my_def</span>(<span class="params">a,b=<span class="number">1</span></span>):</span><br><span class="line">    a=b+<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> </span><br></pre></td></tr></table></figure><p>需要注意的是：</p><ul><li>默认参数必须在必选参数后边，否则会无法辨认是否输入必选参数，从而报错。</li><li>默认参数的默认值一定是<strong>不变对象</strong>，由于Python中的变量定义为指针指向，会导致可变对象值发生变化</li></ul><p>不可变对象有：数值类型、字符串、tuple元组、None等</p><h4 id="可变参数"><a href="#可变参数" class="headerlink" title="可变参数"></a>可变参数</h4><p>可变参数指的是参数的数目不固定，定义形式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">my_function</span>(<span class="params">*v</span>):</span><br><span class="line">    <span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> vi <span class="keyword">in</span> v:</span><br><span class="line">        <span class="built_in">sum</span>+=vi</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span></span><br></pre></td></tr></table></figure><p>在可变参数中传入的所有参数将作为一个tuple被接收，该tuple的变量名为函数在定义时的形参名，<br>定义时的需要在参数名前加一个<code>*</code>。</p><h4 id="关键字（key）参数"><a href="#关键字（key）参数" class="headerlink" title="关键字（key）参数"></a>关键字（key）参数</h4><p>此处的关键字和c语言中的关键字并不是一个意义，而是在dict中的key的意义。即在传递参数时<br>，同时传递键（key）和值(value),Python会自动封装为一个dict。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">my_function</span>(<span class="params">**v</span>):</span><br><span class="line">    <span class="built_in">print</span>(v)</span><br><span class="line">    <span class="keyword">return</span> </span><br></pre></td></tr></table></figure><h4 id="命名关键字参数"><a href="#命名关键字参数" class="headerlink" title="命名关键字参数"></a>命名关键字参数</h4><p>在关键字参数上，进一步限制传入的key的命名，就有了命名关键词参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">person</span>(<span class="params">name, age, *, city, job</span>):</span><br><span class="line">    <span class="built_in">print</span>(name, age, city, job)</span><br></pre></td></tr></table></figure><p>这里需要一个<code>*</code>区分位置参数与命名关键字参数，如果在这之前有可变参数，那么就不需要加<code>*</code>。<br>命名关键字参数必须传入参数名，这和位置参数不同。如果没有传入参数名，调用将报错：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>person(<span class="string">&#x27;Jack&#x27;</span>, <span class="number">24</span>, <span class="string">&#x27;Beijing&#x27;</span>, <span class="string">&#x27;Engineer&#x27;</span>)</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">TypeError: person() missing <span class="number">2</span> required keyword-only arguments: <span class="string">&#x27;city&#x27;</span> <span class="keyword">and</span> <span class="string">&#x27;job&#x27;</span></span><br></pre></td></tr></table></figure><h4 id="参数组合"><a href="#参数组合" class="headerlink" title="参数组合"></a>参数组合</h4><p>在一个函数中使用多个参数要保证其中的顺序，依次为：必选参数、默认参数、可变参数、命名关键字参数和关键字参数。  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">onefunction</span>(<span class="params">a,b,c=<span class="number">0</span>,*args,job,city,**kw</span>):</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>tips：  </p><ul><li>使用<code>*args</code>和<code>**kw</code>是Python的习惯写法。</li><li>可变参数和关键字参数有一点层级的感觉，中间包裹的是命名关键字参数这个比较尴尬的参数。</li></ul><h2 id="递归函数"><a href="#递归函数" class="headerlink" title="递归函数"></a>递归函数</h2><p>写法与Java相同。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Python学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>暑期Python学习（二）</title>
      <link href="/2022/07/10/day2/"/>
      <url>/2022/07/10/day2/</url>
      
        <content type="html"><![CDATA[<h1 id="Python基本语法"><a href="#Python基本语法" class="headerlink" title="Python基本语法"></a>Python基本语法</h1><h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><p>首先必须说明一点，Python和JavaScript一样是一个弱类型语言，和Java、C++有所不同<br>，Python在定义变量时，无需进行类型声明。</p><h3 id="整数"><a href="#整数" class="headerlink" title="整数"></a>整数</h3><p>对于很大的数，很难数清楚0的个数。Python允许在数字中间以_分隔。</p><h3 id="浮点数"><a href="#浮点数" class="headerlink" title="浮点数"></a>浮点数</h3><p>允许使用科学计数法定义</p><h3 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h3><p>在Python没有严格要求<code>&#39;&#39; </code>和<code>&quot;&quot;</code>的区别在，也就是说没有区分字符和字符串<br>使用二者没有任何区别。</p><ul><li>转义符和Java中保持一致</li><li>Python允许用<code>r&#39;&#39;</code>表示<code>&#39;&#39;</code>内部的字符串默认不转义</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">r&#x27;\t\\&#x27;</span>)</span><br></pre></td></tr></table></figure><p>输出结果为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\t\\</span><br></pre></td></tr></table></figure><ul><li>Python允许用<code>&#39;&#39;&#39;...&#39;&#39;&#39;</code>的格式表示多行内容，输出结果按行。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#x27;&#x27;这是一个</span></span><br><span class="line"><span class="string">很长很长</span></span><br><span class="line"><span class="string">的句子&#x27;&#x27;&#x27;</span>)</span><br></pre></td></tr></table></figure><h3 id="布尔值"><a href="#布尔值" class="headerlink" title="布尔值"></a>布尔值</h3><p>在Python中要注意：<code>True</code>、<code>False</code>要注意开头首字母大写。<br>可以进行与、或、非的运算，运算符分别为：<code>and</code>，<code>or</code>，<code>not</code>  </p><h3 id="空值"><a href="#空值" class="headerlink" title="空值"></a>空值</h3><p>空值用<code>None</code>表示，意义与Java中的<code>null</code>相同。</p><h2 id="变量与常量"><a href="#变量与常量" class="headerlink" title="变量与常量"></a>变量与常量</h2><h3 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h3><p>变量名必须是大小写英文、数字和<code>_</code>的组合，且不能用数字开头</p><ul><li>在变量创立时，Python是这样的：<br>① 找一块内存，存储一个数值<br>② 找一块内存，建立一个变量，将这个变量指向数值</li><li>这里注意Python的变量建立和指针相关。</li></ul><h3 id="常量"><a href="#常量" class="headerlink" title="常量"></a>常量</h3><p>在Python中，通常用全部大写的变量名表示常量，但是并不能保证常量不变</p><h2 id="list和tuple"><a href="#list和tuple" class="headerlink" title="list和tuple"></a>list和tuple</h2><h3 id="list"><a href="#list" class="headerlink" title="list"></a>list</h3><p>list是Python内置的一种数据类型，list是一种有序的集合，可以随时添加和删除其中的元素。<br>此数据类型在Java的实用类中有封装。<br>list和数组很像，声明方式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">classname = [<span class="string">&#x27;老六&#x27;</span>,<span class="string">&#x27;老八&#x27;</span>,<span class="string">&#x27;老壁灯&#x27;</span>]</span><br></pre></td></tr></table></figure><p>想要调取其中的某个元素也和数组一致，赋值修改等也相同<br>下面列举一下list的ADT</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">list:</span><br><span class="line">append(&#x27;Elem&#x27;)  # 在末尾添加新的元素</span><br><span class="line">insert(i,&#x27;Elem&#x27;) # 将元素插入指定位置</span><br><span class="line">pop() # 删除末尾元素</span><br><span class="line">pop(i) # 删除i处的元素</span><br><span class="line">len(list) # list列表的长度</span><br></pre></td></tr></table></figure><p>list允许混合类型，也允许list嵌套，从而出现多维数组。</p><h3 id="tuple"><a href="#tuple" class="headerlink" title="tuple"></a>tuple</h3><p>tuple被称为元组，其最大的特点就是不可修改，声明方式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">classname = (<span class="string">&#x27;老六&#x27;</span>,<span class="string">&#x27;老八&#x27;</span>,<span class="string">&#x27;老壁灯&#x27;</span>)</span><br></pre></td></tr></table></figure><p>tuple在定义时要确定元素个数，这里有一个问题，在定义只有一个元素的tuple时，Python<br>语法会认为这是一个小括号，因此在定义一个元组的tuple时，要加一个<code>,</code>避免歧义。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t=(<span class="number">1</span>,)</span><br></pre></td></tr></table></figure><h2 id="流程控制语句"><a href="#流程控制语句" class="headerlink" title="流程控制语句"></a>流程控制语句</h2><h3 id="条件判断"><a href="#条件判断" class="headerlink" title="条件判断"></a>条件判断</h3><p>if语句，需要注意的是Python中的流程控制语句结尾都是冒号</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a=<span class="built_in">input</span>()</span><br><span class="line">a=<span class="built_in">int</span>(a)</span><br><span class="line"><span class="keyword">if</span> a&lt;<span class="number">1</span>:</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line"><span class="keyword">elif</span> a&gt;<span class="number">2</span>:</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>()</span><br></pre></td></tr></table></figure><p>因为是弱类型语言，在比较、计算时要给数据指定一个类型。</p><h3 id="循环"><a href="#循环" class="headerlink" title="循环"></a>循环</h3><ul><li><code>for x in []:</code><br><code>for x in ...:</code>循环就是把每个元素代入变量x，然后执行缩进块的语句<br>tips：</li></ul><ol><li>in后边可以是list或者tuple，也可以跟range(x)</li><li>Python提供了range(x)函数，生成[0,x-1]的整数</li></ol><ul><li><p><code>while</code><br><code>while 条件判断语句 :</code></p></li><li><p><code>break</code>、<code>continue</code>和java中用法相同</p></li></ul><h2 id="字典（dict）与集合（set）"><a href="#字典（dict）与集合（set）" class="headerlink" title="字典（dict）与集合（set）"></a>字典（dict）与集合（set）</h2><h3 id="字典（dict）"><a href="#字典（dict）" class="headerlink" title="字典（dict）"></a>字典（dict）</h3><p>字典全称为dictionary，在Java实用类中叫hash map。其由键值对（key-value）组成，查找速度快。 下面是一种初始化方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d = &#123;<span class="string">&#x27;Michael&#x27;</span>: <span class="number">95</span>, <span class="string">&#x27;Bob&#x27;</span>: <span class="number">75</span>, <span class="string">&#x27;Tracy&#x27;</span>: <span class="number">85</span>&#125;</span><br></pre></td></tr></table></figure><p>也可以放入指定的key中：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d[<span class="string">&#x27;Adam&#x27;</span>] = <span class="number">67</span></span><br></pre></td></tr></table></figure><p>查找value:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d[<span class="string">&#x27;Adam&#x27;</span>]</span><br></pre></td></tr></table></figure><p>key与value是多对一的关系，key需要是一个不可变对象保证key做hash运算后的唯一性。如果多次对某个key赋值，后边的value会覆盖前面的value 提供了几个函数：</p><ol><li>通过<code>in</code>来判断key是否在dict中，返回值为布尔值，格式为：<code>key in dict</code></li><li>get()方法，<code>dict.get(&#39;key&#39;,空返回值)</code>key不存在时返回空返回值，空返回值可自定义，如果没有定义的话返回None</li><li>pop()方法，删除key，如果有value也一并删除，格式为<code>pop(&#39;key&#39;)</code></li></ol><h3 id="集合（set）"><a href="#集合（set）" class="headerlink" title="集合（set）"></a>集合（set）</h3><p>set是一组key的集合,集合特点；无序性、确定性、互异性<br>要创建一个set，需要提供一个list作为输入集合：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="built_in">set</span>([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure><ul><li>方法：<br><code>add(key)</code>添加一个新的元素<br><code>remove(key)</code>删除一个元素</li><li>两个set可以做交运算和并运算：<br>交运算：<code>s1&amp;s2</code><br>并运算：<code>s1|s2</code></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Python学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>暑期Python学习（一）</title>
      <link href="/2022/07/10/day_1/"/>
      <url>/2022/07/10/day_1/</url>
      
        <content type="html"><![CDATA[<h1 id="Python入门"><a href="#Python入门" class="headerlink" title="Python入门"></a>Python入门</h1><p> 个人笔记，在有C++和Java基础下的学习。</p><h2 id="命令控制行和python交互页面的区别："><a href="#命令控制行和python交互页面的区别：" class="headerlink" title="命令控制行和python交互页面的区别："></a>命令控制行和python交互页面的区别：</h2><ul><li>命令控制行：输入命令Python进入交互界面，然后可以写Python命令，<br>可以通过<code>python 文件名.py</code>运行整个Python文件。使用<code>exit（） </code>命令退出。<br><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/day_1_2.png" alt="day_1_2"></li><li>Python交互界面：直接输入Python语句，不能运行整个Python文件。<br><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/day_1_1.png" alt="day_1_1"><br>Python交互模式主要是为了调试Python代码用的，也便于初学者学习，它不是正式运行Python代码的环境！<br>tip：SyntaxError指的是代码语法有错误。</li></ul><h2 id="第一个程序"><a href="#第一个程序" class="headerlink" title="第一个程序"></a>第一个程序</h2><p>写一个hello world，用记事本或者IDE都可以。通过命令控制行运行</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;hello world&quot;</span>)</span><br></pre></td></tr></table></figure><ul><li>在py文件所在目录下，打开命令控制行，使用命令运行：<br><img src="https://blogpicture-1310464487.cos.ap-nanjing.myqcloud.com/%20typora/day_1_3.png" alt="day_1_3"></li></ul><h2 id="输入输出"><a href="#输入输出" class="headerlink" title="输入输出"></a>输入输出</h2><p>输入：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">name = <span class="built_in">input</span>(<span class="string">&#x27;这里可以加一个提示，不必用print&#x27;</span>)     <span class="comment"># name是接收变量</span></span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#x27;</span>,<span class="string">&#x27;&#x27;</span>)  <span class="comment"># 用于连续输出，中间有空格</span></span><br></pre></td></tr></table></figure><h2 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用#表示注释</span></span><br></pre></td></tr></table></figure><h2 id="代码风格"><a href="#代码风格" class="headerlink" title="代码风格"></a>代码风格</h2><p>Python中代码采用缩进，可以不写分号。<code>:</code>结尾时，后续视为代码块自动缩进（采用IDE时），缩进距离无限制<br>一般为四个空格。显然Python对cv工程师很不友好，要检查缩进是否正确。<br>Python是大小写敏感型。 </p>]]></content>
      
      
      
        <tags>
            
            <tag> Python学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2022/07/01/hello-world/"/>
      <url>/2022/07/01/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p><p><a href="https://zh.usa1lib.org/booklist/155353/c2a989">书集 (usa1lib.org)</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
